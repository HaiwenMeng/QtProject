#include "halxlailib.h"

using namespace HalxAI;
// Procedures
// External procedures
// Chapter: Image / Channel
void HalxAI:: add_colormap_to_image (HObject ho_GrayValueImage, HObject ho_Image, HObject *ho_ColoredImage,
                                     HTuple hv_HeatmapColorScheme)
{

    // Local iconic variables
    HObject  ho_RGBValueImage, ho_Channels, ho_ChannelsScaled;
    HObject  ho_Channel, ho_ChannelScaled, ho_ChannelScaledByte;
    HObject  ho_ImageByte, ho_ImageByteR, ho_ImageByteG, ho_ImageByteB;

    // Local control variables
    HTuple  hv_Type, hv_NumChannels, hv_ChannelIndex;
    HTuple  hv_ChannelMin, hv_ChannelMax, hv__;

    //
    //This procedure adds a gray-value image to a RGB image with a chosen color map.
    //
    GetImageType(ho_GrayValueImage, &hv_Type);
    //The image LUT needs a byte image. Rescale real images.
    if (0 != (int(hv_Type==HTuple("real"))))
    {
        scale_image_range(ho_GrayValueImage, &ho_GrayValueImage, 0, 1);
        ConvertImageType(ho_GrayValueImage, &ho_GrayValueImage, "byte");
    }
    else if (0 != (int(hv_Type!=HTuple("byte"))))
    {
        throw HException(HTuple("For this transformation, a byte or real image is needed!"));
    }
    //
    //Apply the chosen color scheme on the gray value.
    apply_colorscheme_on_gray_value_image(ho_GrayValueImage, &ho_RGBValueImage, hv_HeatmapColorScheme);
    //
    //Convert input image to byte image for visualization.
    ImageToChannels(ho_Image, &ho_Channels);
    CountChannels(ho_Image, &hv_NumChannels);
    GenEmptyObj(&ho_ChannelsScaled);
    {
        HTuple end_val19 = hv_NumChannels;
        HTuple step_val19 = 1;
        for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val19, step_val19); hv_ChannelIndex += step_val19)
        {
            SelectObj(ho_Channels, &ho_Channel, hv_ChannelIndex);
            MinMaxGray(ho_Channel, ho_Channel, 0, &hv_ChannelMin, &hv_ChannelMax, &hv__);
            scale_image_range(ho_Channel, &ho_ChannelScaled, hv_ChannelMin, hv_ChannelMax);
            ConvertImageType(ho_ChannelScaled, &ho_ChannelScaledByte, "byte");
            ConcatObj(ho_ChannelsScaled, ho_ChannelScaledByte, &ho_ChannelsScaled);
        }
    }
    ChannelsToImage(ho_ChannelsScaled, &ho_ImageByte);
    //
    //Note that ImageByte needs to have the same number of channels as
    //RGBValueImage to display color map image correctly.
    CountChannels(ho_ImageByte, &hv_NumChannels);
    if (0 != (int(hv_NumChannels!=3)))
    {
        //Just take the first channel and use this to generate
        //an image with 3 channels for visualization.
        AccessChannel(ho_ImageByte, &ho_ImageByteR, 1);
        CopyImage(ho_ImageByteR, &ho_ImageByteG);
        CopyImage(ho_ImageByteR, &ho_ImageByteB);
        Compose3(ho_ImageByteR, ho_ImageByteG, ho_ImageByteB, &ho_ImageByte);
    }
    //
    AddImage(ho_ImageByte, ho_RGBValueImage, &ho_RGBValueImage, 0.5, 0);
    (*ho_ColoredImage) = ho_RGBValueImage;
    //
    return;
}

// Chapter: Image / Channel
// Short Description: Create a lookup table and convert a gray scale image.
void HalxAI:: apply_colorscheme_on_gray_value_image (HObject ho_InputImage, HObject *ho_ResultImage,
                                                     HTuple hv_Schema)
{

    // Local iconic variables
    HObject  ho_ImageR, ho_ImageG, ho_ImageB;

    // Local control variables
    HTuple  hv_X, hv_Low, hv_High, hv_OffR, hv_OffG;
    HTuple  hv_OffB, hv_A1, hv_A0, hv_R, hv_G, hv_B, hv_A0R;
    HTuple  hv_A0G, hv_A0B;

    //
    //This procedure generates an RGB ResultImage for a gray-value InputImage.
    //In order to do so, create a color distribution as look up table
    //according to the Schema.
    //
    hv_X = HTuple::TupleGenSequence(0,255,1);
    TupleGenConst(256, 0, &hv_Low);
    TupleGenConst(256, 255, &hv_High);
    //
    if (0 != (int(hv_Schema==HTuple("jet"))))
    {
        //Scheme Jet: from blue to red
        hv_OffR = 3.0*64.0;
        hv_OffG = 2.0*64.0;
        hv_OffB = 64.0;
        hv_A1 = -4.0;
        hv_A0 = 255.0+128.0;
        hv_R = (((((hv_X-hv_OffR).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_G = (((((hv_X-hv_OffG).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_B = (((((hv_X-hv_OffB).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
        //
    }
    else if (0 != (int(hv_Schema==HTuple("inverse_jet"))))
    {
        //Scheme InvJet: from red to blue.
        hv_OffR = 64;
        hv_OffG = 2*64;
        hv_OffB = 3*64;
        hv_A1 = -4.0;
        hv_A0 = 255.0+128.0;
        hv_R = (((((hv_X-hv_OffR).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_G = (((((hv_X-hv_OffG).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_B = (((((hv_X-hv_OffB).TupleAbs())*hv_A1)+hv_A0).TupleMax2(hv_Low)).TupleMin2(hv_High);
        //
    }
    else if (0 != (int(hv_Schema==HTuple("hot"))))
    {
        //Scheme Hot.
        hv_A1 = 3.0;
        hv_A0R = 0.0;
        hv_A0G = ((1.0/3.0)*hv_A1)*255.0;
        hv_A0B = ((2.0/3.0)*hv_A1)*255.0;
        hv_R = (((hv_X*hv_A1)-hv_A0R).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_G = (((hv_X*hv_A1)-hv_A0G).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_B = (((hv_X*hv_A1)-hv_A0B).TupleMax2(hv_Low)).TupleMin2(hv_High);
        //
    }
    else if (0 != (int(hv_Schema==HTuple("inverse_hot"))))
    {
        //Scheme Inverse Hot.
        hv_A1 = -3.0;
        hv_A0R = hv_A1*255.0;
        hv_A0G = ((2.0/3.0)*hv_A1)*255.0;
        hv_A0B = ((1.0/3.0)*hv_A1)*255.0;
        hv_R = (((hv_X*hv_A1)-hv_A0R).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_G = (((hv_X*hv_A1)-hv_A0G).TupleMax2(hv_Low)).TupleMin2(hv_High);
        hv_B = (((hv_X*hv_A1)-hv_A0B).TupleMax2(hv_Low)).TupleMin2(hv_High);
        //
    }
    else
    {
        //
        throw HException(("Unknown color schema: "+hv_Schema)+".");
        //
    }
    //
    LutTrans(ho_InputImage, &ho_ImageR, hv_R);
    LutTrans(ho_InputImage, &ho_ImageG, hv_G);
    LutTrans(ho_InputImage, &ho_ImageB, hv_B);
    Compose3(ho_ImageR, ho_ImageG, ho_ImageB, &(*ho_ResultImage));
    //
    return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
void HalxAI:: area_iou (HTuple hv_Sample, HTuple hv_Result, HTuple hv_InstanceType, HTuple hv_ResultSortIndices,
                        HTuple *hv_SampleArea, HTuple *hv_ResultArea, HTuple *hv_IoU)
{

    // Local iconic variables
    HObject  ho_GtMask, ho_ResMask, ho_CurrentGtMask;
    HObject  ho_ValidResMask, ho_RegionIntersection;

    // Local control variables
    HTuple  hv_GtRow1, hv_GtCol1, hv_GtRow2, hv_GtCol2;
    HTuple  hv_ResRow1, hv_ResCol1, hv_ResRow2, hv_ResCol2;
    HTuple  hv_GtIdx, hv_Height, hv_Width, hv_ValidIdxs, hv_Intersection;
    HTuple  hv_Union, hv_GtRow, hv_GtCol, hv_GtLength1, hv_GtLength2;
    HTuple  hv_GtPhi, hv_ResRow, hv_ResCol, hv_ResLength1, hv_ResLength2;
    HTuple  hv_ResPhi, hv__, hv_NumGt, hv_NumRes;

    //
    //Compute the intersection over union (IoU) between
    //the ground truth and the inferred bounding box or instance
    //segmentation mask of the object instances.
    //The instance type is determined over the InstanceType.
    //
    if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
    {
        //Get bounding box coordinates.
        GetDictTuple(hv_Sample, "bbox_row1", &hv_GtRow1);
        GetDictTuple(hv_Sample, "bbox_col1", &hv_GtCol1);
        GetDictTuple(hv_Sample, "bbox_row2", &hv_GtRow2);
        GetDictTuple(hv_Sample, "bbox_col2", &hv_GtCol2);
        GetDictTuple(hv_Result, "bbox_row1", &hv_ResRow1);
        GetDictTuple(hv_Result, "bbox_col1", &hv_ResCol1);
        GetDictTuple(hv_Result, "bbox_row2", &hv_ResRow2);
        GetDictTuple(hv_Result, "bbox_col2", &hv_ResCol2);
        //
        //Sort the results.
        hv_ResRow1 = HTuple(hv_ResRow1[hv_ResultSortIndices]);
        hv_ResCol1 = HTuple(hv_ResCol1[hv_ResultSortIndices]);
        hv_ResRow2 = HTuple(hv_ResRow2[hv_ResultSortIndices]);
        hv_ResCol2 = HTuple(hv_ResCol2[hv_ResultSortIndices]);
        //
        //Compute areas.
        (*hv_SampleArea) = (hv_GtRow2-hv_GtRow1)*(hv_GtCol2-hv_GtCol1);
        (*hv_ResultArea) = (hv_ResRow2-hv_ResRow1)*(hv_ResCol2-hv_ResCol1);
        //
        //Compute IoUs.
        (*hv_IoU) = HTuple((hv_GtRow1.TupleLength())*(hv_ResRow1.TupleLength()),0);
        if (0 != (int(((*hv_IoU).TupleLength())>0)))
        {
            {
                HTuple end_val30 = (hv_GtRow1.TupleLength())-1;
                HTuple step_val30 = 1;
                for (hv_GtIdx=0; hv_GtIdx.Continue(end_val30, step_val30); hv_GtIdx += step_val30)
                {
                    hv_Height = (HTuple(hv_GtRow2[hv_GtIdx]).TupleMin2(hv_ResRow2))-(HTuple(hv_GtRow1[hv_GtIdx]).TupleMax2(hv_ResRow1));
                    hv_Width = (HTuple(hv_GtCol2[hv_GtIdx]).TupleMin2(hv_ResCol2))-(HTuple(hv_GtCol1[hv_GtIdx]).TupleMax2(hv_ResCol1));
                    hv_ValidIdxs = HTuple((hv_Height.TupleGreaterElem(0)).TupleAnd(hv_Width.TupleGreaterElem(0))).TupleFind(1);
                    if (0 != (int(hv_ValidIdxs>-1)))
                    {
                        hv_Intersection = HTuple(hv_Height[hv_ValidIdxs])*HTuple(hv_Width[hv_ValidIdxs]);
                        hv_Union = (HTuple((*hv_SampleArea)[hv_GtIdx])+HTuple((*hv_ResultArea)[hv_ValidIdxs]))-hv_Intersection;
                        (*hv_IoU)[(hv_GtIdx*(hv_ResRow1.TupleLength()))+hv_ValidIdxs] = (hv_Intersection.TupleReal())/hv_Union;
                    }
                }
            }
        }
    }
    else if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
    {
        //Get bounding box coordinates.
        GetDictTuple(hv_Sample, "bbox_row", &hv_GtRow);
        GetDictTuple(hv_Sample, "bbox_col", &hv_GtCol);
        GetDictTuple(hv_Sample, "bbox_length1", &hv_GtLength1);
        GetDictTuple(hv_Sample, "bbox_length2", &hv_GtLength2);
        GetDictTuple(hv_Sample, "bbox_phi", &hv_GtPhi);
        GetDictTuple(hv_Result, "bbox_row", &hv_ResRow);
        GetDictTuple(hv_Result, "bbox_col", &hv_ResCol);
        GetDictTuple(hv_Result, "bbox_length1", &hv_ResLength1);
        GetDictTuple(hv_Result, "bbox_length2", &hv_ResLength2);
        GetDictTuple(hv_Result, "bbox_phi", &hv_ResPhi);
        //
        //Sort results.
        hv_ResRow = HTuple(hv_ResRow[hv_ResultSortIndices]);
        hv_ResCol = HTuple(hv_ResCol[hv_ResultSortIndices]);
        hv_ResLength1 = HTuple(hv_ResLength1[hv_ResultSortIndices]);
        hv_ResLength2 = HTuple(hv_ResLength2[hv_ResultSortIndices]);
        hv_ResPhi = HTuple(hv_ResPhi[hv_ResultSortIndices]);
        //
        //Compute Areas.
        (*hv_SampleArea) = (4.0*hv_GtLength1)*hv_GtLength2;
        (*hv_ResultArea) = (4.0*hv_ResLength1)*hv_ResLength2;
        //
        //Compute IoUs.
        (*hv_IoU) = HTuple((hv_GtRow.TupleLength())*(hv_ResRow.TupleLength()),0);
        if (0 != (int(((*hv_IoU).TupleLength())>0)))
        {
            {
                HTuple end_val68 = (hv_GtRow.TupleLength())-1;
                HTuple step_val68 = 1;
                for (hv_GtIdx=0; hv_GtIdx.Continue(end_val68, step_val68); hv_GtIdx += step_val68)
                {
                    hv_ValidIdxs = HTuple((HTuple((*hv_SampleArea)[hv_GtIdx]).TupleGreaterElem(0)).TupleAnd((*hv_ResultArea).TupleGreaterElem(0))).TupleFind(1);
                    if (0 != (int(hv_ValidIdxs>-1)))
                    {
                        AreaIntersectionRectangle2(HTuple(hv_GtRow[hv_GtIdx]), HTuple(hv_GtCol[hv_GtIdx]),
                                                   HTuple(hv_GtPhi[hv_GtIdx]), HTuple(hv_GtLength1[hv_GtIdx]), HTuple(hv_GtLength2[hv_GtIdx]),
                                                   HTuple(hv_ResRow[hv_ValidIdxs]), HTuple(hv_ResCol[hv_ValidIdxs]), HTuple(hv_ResPhi[hv_ValidIdxs]),
                                                   HTuple(hv_ResLength1[hv_ValidIdxs]), HTuple(hv_ResLength2[hv_ValidIdxs]),
                                                   &hv_Intersection);
                        hv_Union = (HTuple((*hv_SampleArea)[hv_GtIdx])+HTuple((*hv_ResultArea)[hv_ValidIdxs]))-hv_Intersection;
                        (*hv_IoU)[(hv_GtIdx*(hv_ResRow.TupleLength()))+hv_ValidIdxs] = (hv_Intersection.TupleReal())/hv_Union;
                    }
                }
            }
        }
    }
    else if (0 != (int(hv_InstanceType==HTuple("mask"))))
    {
        //Get the ground truth mask.
        GetDictObject(&ho_GtMask, hv_Sample, "mask");
        //
        //Get the result mask.
        GetDictObject(&ho_ResMask, hv_Result, "mask");
        //
        //Sort the results.
        SelectObj(ho_ResMask, &ho_ResMask, hv_ResultSortIndices+1);
        //
        //Compute Areas.
        AreaCenter(ho_GtMask, &(*hv_SampleArea), &hv__, &hv__);
        AreaCenter(ho_ResMask, &(*hv_ResultArea), &hv__, &hv__);
        //
        //Compute IoUs.
        CountObj(ho_GtMask, &hv_NumGt);
        CountObj(ho_ResMask, &hv_NumRes);
        (*hv_IoU) = HTuple(hv_NumGt*hv_NumRes,0);
        if (0 != (int(((*hv_IoU).TupleLength())>0)))
        {
            {
                HTuple end_val96 = hv_NumGt-1;
                HTuple step_val96 = 1;
                for (hv_GtIdx=0; hv_GtIdx.Continue(end_val96, step_val96); hv_GtIdx += step_val96)
                {
                    hv_ValidIdxs = HTuple((HTuple((*hv_SampleArea)[hv_GtIdx]).TupleGreaterElem(0)).TupleAnd((*hv_ResultArea).TupleGreaterElem(0))).TupleFind(1);
                    if (0 != (int(hv_ValidIdxs>-1)))
                    {
                        SelectObj(ho_GtMask, &ho_CurrentGtMask, hv_GtIdx+1);
                        SelectObj(ho_ResMask, &ho_ValidResMask, hv_ValidIdxs+1);
                        Intersection(ho_ValidResMask, ho_CurrentGtMask, &ho_RegionIntersection);
                        AreaCenter(ho_RegionIntersection, &hv_Intersection, &hv__, &hv__);
                        hv_Union = (HTuple((*hv_SampleArea)[hv_GtIdx])+HTuple((*hv_ResultArea)[hv_ValidIdxs]))-hv_Intersection;
                        (*hv_IoU)[(hv_GtIdx*hv_NumRes)+hv_ValidIdxs] = (hv_Intersection.TupleReal())/hv_Union;
                    }
                }
            }
        }
    }
    else
    {
        throw HException(("Instance type '"+hv_InstanceType)+"' is not supported");
    }
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_brightness_variation (HTuple hv_DLSample, HTuple hv_BrightnessVariation)
{

    // Local iconic variables
    HObject  ho_Image, ho_ImageScaled;

    // Local control variables
    HTuple  hv_OCRType, hv_BrightnessShift;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //For OCR Recognition samples, only a certain range is allowed for BrightnessVariation.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    if (0 != (HTuple(int(hv_OCRType==HTuple("ocr_recognition"))).TupleAnd(int(hv_BrightnessVariation>1))))
    {
        throw HException("Value of augmentation method 'brightness_variation' cannot be greater than 1 for ocr_recognition models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    //
    //Add random brightness variation.
    hv_BrightnessShift = ((HTuple::TupleRand(1)*2)-1)*hv_BrightnessVariation;
    ScaleImage(ho_Image, &ho_ImageScaled, 1.0, hv_BrightnessShift);
    //
    //Set the augmented image to DLSample.
    SetDictObject(ho_ImageScaled, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_brightness_variation_spot (HTuple hv_DLSample, HTuple hv_BrightnessVariation)
{

    // Local iconic variables
    HObject  ho_Image, ho_Filter, ho_GaussImage, ho_GaussFilter;
    HObject  ho_Gauss, ho_GaussTargetType, ho_AddImage, ho_ImageSpot;

    // Local control variables
    HTuple  hv_OCRType, hv_ImageWidth, hv_ImageHeight;
    HTuple  hv_BrightnessShift, hv_SpotSize, hv_SpotRow, hv_SpotColumn;
    HTuple  hv_Direction, hv_ShiftRow, hv_ShiftCol, hv_Type;
    HTuple  hv_NChannels, hv__;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation method should not be applied to OCR Recognition samples.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    if (0 != (int(hv_OCRType==HTuple("ocr_recognition"))))
    {
        throw HException("The augmentation method 'brightness_variation_spot' is not supported by ocr_recognition models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    //Determine random brightness variation.
    hv_BrightnessShift = ((HTuple::TupleRand(1)*2)-1)*hv_BrightnessVariation;
    //Determine random spot size between [0.5*ImageHeight, ImageWidth]
    hv_SpotSize = hv_ImageWidth*((HTuple::TupleRand(1)/2)+0.5);
    //Determine random spot position.
    hv_SpotRow = HTuple::TupleRand(1)*hv_ImageHeight;
    hv_SpotColumn = HTuple::TupleRand(1)*hv_ImageWidth;
    //
    if (0 != (int(hv_BrightnessShift<0)))
    {
        hv_Direction = 0;
        hv_BrightnessShift = -hv_BrightnessShift;
    }
    else
    {
        hv_Direction = 1;
    }
    //Generate Gauss filter that simulates an illumination spot of size 'SpotSize'.
    GenGaussFilter(&ho_Filter, 1, 1, 0, "none", "dc_center", hv_SpotSize, hv_SpotSize);
    //Shift the filter image to the given position.
    hv_ShiftRow = -((hv_SpotSize/2)-hv_SpotRow);
    hv_ShiftCol = -((hv_SpotSize/2)-hv_SpotColumn);
    TileImagesOffset(ho_Filter, &ho_GaussImage, hv_ShiftRow, hv_ShiftCol, -1, -1, -1,
                     -1, hv_ImageWidth, hv_ImageHeight);
    FullDomain(ho_GaussImage, &ho_GaussFilter);
    //Convert Gauss filter to target image type and apply brightness variation.
    GetImageType(ho_Image, &hv_Type);
    ScaleImage(ho_GaussFilter, &ho_Gauss, hv_BrightnessShift, 0);
    ConvertImageType(ho_Gauss, &ho_GaussTargetType, hv_Type);
    //Add channels to fit input image.
    CountChannels(ho_Image, &hv_NChannels);
    CopyObj(ho_GaussTargetType, &ho_AddImage, 1, 1);
    {
        HTuple end_val43 = hv_NChannels-1;
        HTuple step_val43 = 1;
        for (hv__=1; hv__.Continue(end_val43, step_val43); hv__ += step_val43)
        {
            AppendChannel(ho_AddImage, ho_GaussTargetType, &ho_AddImage);
        }
    }
    //Apply on image.
    if (0 != hv_Direction)
    {
        AddImage(ho_Image, ho_AddImage, &ho_ImageSpot, 1, 0);
    }
    else
    {
        SubImage(ho_Image, ho_AddImage, &ho_ImageSpot, 1, 0);
    }
    //
    //Set the augmented image to DLSample.
    SetDictObject(ho_ImageSpot, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_contrast_variation (HTuple hv_DLSample, HTuple hv_ContrastVariation)
{

    // Local iconic variables
    HObject  ho_Image, ho_GrayImage, ho_MeanImage;
    HObject  ho_MeanImageScaled, ho_ImageScaled, ho_ImageOut;

    // Local control variables
    HTuple  hv_OCRType, hv_Borders, hv_Factor, hv_NumChannels;
    HTuple  hv_MeanGray, hv__;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation method should not be applied to OCR Recognition samples.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    if (0 != (int(hv_OCRType==HTuple("ocr_recognition"))))
    {
        throw HException(("The augmentation method 'contrast_variation' is not supported by "+hv_OCRType)+" models.");
    }
    //
    //*** Augmentation ***
    //
    //Adjust contrast of the input image by blending it with its mean image.
    //
    //Minimum and maximum blend factors.
    hv_Borders.Clear();
    hv_Borders.Append(HTuple(0.0).TupleMax2(1-hv_ContrastVariation));
    hv_Borders.Append(1+hv_ContrastVariation);
    //Random blend factor.
    hv_Factor = HTuple(hv_Borders[0])+((HTuple(hv_Borders[1])-HTuple(hv_Borders[0]))*HTuple::TupleRand(1));
    //
    if (0 != (int(hv_Factor==1.0)))
    {
        return;
    }
    //
    //Convert Image to a gray value image.
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    CountChannels(ho_Image, &hv_NumChannels);
    if (0 != (int(hv_NumChannels==1)))
    {
        ho_GrayImage = ho_Image;
    }
    else if (0 != (int(hv_NumChannels==3)))
    {
        Rgb1ToGray(ho_Image, &ho_GrayImage);
    }
    else
    {
        throw HException("The augmentation method 'contrast_variation' can only be applied to gray scale and RGB images.");
    }
    //
    //Compute the mean of the gray value image.
    Intensity(ho_GrayImage, ho_GrayImage, &hv_MeanGray, &hv__);
    //Create a constant image with the gray value mean.
    GenImageProto(ho_GrayImage, &ho_MeanImage, hv_MeanGray);
    if (0 != (int(hv_NumChannels==3)))
    {
        Compose3(ho_MeanImage, ho_MeanImage, ho_MeanImage, &ho_MeanImage);
    }
    //
    //Blend Image and MeanImage.
    //The resulting ImageOut will have the same domain as Image.
    ScaleImage(ho_MeanImage, &ho_MeanImageScaled, 1.0-hv_Factor, 0.0);
    ScaleImage(ho_Image, &ho_ImageScaled, hv_Factor, 0.0);
    AddImage(ho_MeanImageScaled, ho_ImageScaled, &ho_ImageOut, 1.0, 0.0);
    //
    //Set the augmented image to DLSample.
    SetDictObject(ho_ImageOut, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_crop_percentage (HTuple hv_DLSample, HTuple hv_CropPercentage)
{

    // Local iconic variables
    HObject  ho_Image, ho_ImagePart;

    // Local control variables
    HTuple  hv_ClassificationLabelExists, hv_XKeyExists;
    HTuple  hv_SegmenationImageKeyExists, hv_GrippingPointKeysExists;
    HTuple  hv_ImageWidth, hv_ImageHeight, hv_CropRate, hv_Row1;
    HTuple  hv_Row2, hv_Column1, hv_Column2, hv_Keys, hv_Index;
    HTuple  hv_Key;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation can only be applied to samples from a classification or
    //3D Gripping Point Detection datasets.
    GetDictParam(hv_DLSample, "key_exists", "image_label_id", &hv_ClassificationLabelExists);
    GetDictParam(hv_DLSample, "key_exists", "x", &hv_XKeyExists);
    GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmenationImageKeyExists);
    hv_GrippingPointKeysExists = hv_XKeyExists.TupleAnd(hv_SegmenationImageKeyExists);
    if (0 != (HTuple(hv_ClassificationLabelExists.TupleOr(hv_GrippingPointKeysExists)).TupleNot()))
    {
        throw HException("The augmentation method 'crop_percentage' is only supported by classification or 3D gripping point detection models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    //
    //Define cropping rectangle.
    hv_CropRate = hv_CropPercentage*0.01;
    hv_Row1 = (((1-hv_CropRate)*hv_ImageHeight)*HTuple::TupleRand(1)).TupleFloor();
    hv_Row2 = hv_Row1+(hv_CropRate*hv_ImageHeight);
    hv_Column1 = (((1-hv_CropRate)*hv_ImageWidth)*HTuple::TupleRand(1)).TupleFloor();
    hv_Column2 = hv_Column1+(hv_CropRate*hv_ImageWidth);
    //
    //Crop the image.
    CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
    //
    //Scale image to the input size and set the augmented image to DLSample.
    ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "constant");
    SetDictObject(ho_ImagePart, hv_DLSample, "image");
    //
    //3D sensor data should not be interpolated to avoid HalxAI:: introducing unwanted
    //interpolation effects. Therfore we use 'nearest_neighbor' interpolation.
    if (0 != hv_GrippingPointKeysExists)
    {
        hv_Keys.Clear();
        hv_Keys[0] = "x";
        hv_Keys[1] = "y";
        hv_Keys[2] = "z";
        hv_Keys[3] = "normals";
        hv_Keys[4] = "segmentation_image";
        hv_Keys[5] = "weight_image";
        {
            HTuple end_val38 = (hv_Keys.TupleLength())-1;
            HTuple step_val38 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val38, step_val38); hv_Index += step_val38)
            {
                hv_Key = HTuple(hv_Keys[hv_Index]);
                ho_Image = hv_DLSample.TupleGetDictObject(hv_Key);
                //
                //Crop the image.
                CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
                //
                //Scale image to the input size and set the augmented image to DLSample.
                ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "nearest_neighbor");
                SetDictObject(ho_ImagePart, hv_DLSample, hv_Key);
            }
        }
    }
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_crop_pixel (HTuple hv_DLSample, HTuple hv_CropPixel)
{

    // Local iconic variables
    HObject  ho_Image, ho_ImagePart;

    // Local control variables
    HTuple  hv_ClassificationLabelExists, hv_ImageWidth;
    HTuple  hv_ImageHeight, hv_Length, hv_Row1, hv_Row2, hv_Column1;
    HTuple  hv_Column2;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation can only be applied to samples from a classification dataset.
    GetDictParam(hv_DLSample, "key_exists", "image_label_id", &hv_ClassificationLabelExists);
    if (0 != (hv_ClassificationLabelExists.TupleNot()))
    {
        throw HException("The augmentation method 'crop_pixel' is only supported by classification models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    //
    //Define cropping rectangle.
    hv_Length = hv_CropPixel;
    hv_Row1 = HTuple::TupleRand(1)*(hv_ImageHeight-hv_Length);
    hv_Row2 = (hv_Row1+hv_Length)-1;
    hv_Column1 = HTuple::TupleRand(1)*(hv_ImageWidth-hv_Length);
    hv_Column2 = (hv_Column1+hv_Length)-1;
    //
    //Crop the image.
    CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
    //
    //Scale the image to the input size and set the augmented image to DLSample.
    ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "constant");
    SetDictObject(ho_ImagePart, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_mirror (HTuple hv_DLSample, HTuple hv_MirrorMethods, HTuple hv_ClassIDsNoOrientation,
                                        HTuple hv_IgnoreDirection)
{

    // Local iconic variables
    HObject  ho_Image, ho_Mask, ho_SegmentationImage;
    HObject  ho_WeightImage;

    // Local control variables
    HTuple  hv_OCRType, hv_Rectangle1ParamExist, hv_Rectangle2ParamExist;
    HTuple  hv_InstanceMaskExists, hv_SegmentationImageExists;
    HTuple  hv_WeightImageExists, hv_BBoxRow1, hv_BBoxCol1;
    HTuple  hv_BBoxRow2, hv_BBoxCol2, hv_BBoxRow, hv_BBoxCol;
    HTuple  hv_BBoxPhi, hv_BBoxLabelID, hv_NumMirrorMethods;
    HTuple  hv_ProbabilityMethods, hv_StrMirror, hv_StrIdx;
    HTuple  hv_SelectedChar, hv_ImageWidth, hv_ImageHeight;
    HTuple  hv_BBoxCol1Mirror, hv_BBoxCol2Mirror, hv_ObjIdx;
    HTuple  hv_BBoxRow1Mirror, hv_BBoxRow2Mirror;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation method should not be applied to OCR Detection/Recognition samples.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    if (0 != (HTuple(int(hv_OCRType==HTuple("ocr_detection"))).TupleOr(int(hv_OCRType==HTuple("ocr_recognition")))))
    {
        throw HException(("The augmentation method 'mirror' is not supported by "+hv_OCRType)+" models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    //Get the annotations from the sample that need to be
    //augmented together with the image.
    GetDictParam(hv_DLSample, "key_exists", "bbox_row1", &hv_Rectangle1ParamExist);
    GetDictParam(hv_DLSample, "key_exists", "bbox_phi", &hv_Rectangle2ParamExist);
    GetDictParam(hv_DLSample, "key_exists", "mask", &hv_InstanceMaskExists);
    GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmentationImageExists);
    GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
    if (0 != hv_Rectangle1ParamExist)
    {
        GetDictTuple(hv_DLSample, "bbox_row1", &hv_BBoxRow1);
        GetDictTuple(hv_DLSample, "bbox_col1", &hv_BBoxCol1);
        GetDictTuple(hv_DLSample, "bbox_row2", &hv_BBoxRow2);
        GetDictTuple(hv_DLSample, "bbox_col2", &hv_BBoxCol2);
    }
    else if (0 != hv_Rectangle2ParamExist)
    {
        GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
        GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
        GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
        if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
        {
            GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabelID);
        }
    }
    if (0 != hv_InstanceMaskExists)
    {
        GetDictObject(&ho_Mask, hv_DLSample, "mask");
    }
    if (0 != hv_SegmentationImageExists)
    {
        GetDictObject(&ho_SegmentationImage, hv_DLSample, "segmentation_image");
    }
    if (0 != hv_WeightImageExists)
    {
        GetDictObject(&ho_WeightImage, hv_DLSample, "weight_image");
    }
    //
    //Mirroring
    //
    //If more than one axis is allowed,
    //choose mirror axis/axes to be applied.
    hv_NumMirrorMethods = hv_MirrorMethods.TupleStrlen();
    hv_ProbabilityMethods = 1.0/hv_NumMirrorMethods;
    hv_StrMirror = "";
    while (0 != (int(hv_StrMirror==HTuple(""))))
    {
        {
            HTuple end_val52 = hv_NumMirrorMethods-1;
            HTuple step_val52 = 1;
            for (hv_StrIdx=0; hv_StrIdx.Continue(end_val52, step_val52); hv_StrIdx += step_val52)
            {
                hv_SelectedChar = hv_MirrorMethods.TupleStrBitSelect(hv_StrIdx);
                if (0 != (int(HTuple::TupleRand(1)<hv_ProbabilityMethods)))
                {
                    hv_StrMirror += hv_SelectedChar;
                }
            }
        }
    }
    //Apply the chosen mirror axis/axes to the given sample data.
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    if (0 != (hv_StrMirror.TupleRegexpTest("c")))
    {
        MirrorImage(ho_Image, &ho_Image, "column");
        if (0 != hv_Rectangle1ParamExist)
        {
            hv_BBoxCol1Mirror = (hv_ImageWidth-hv_BBoxCol2)-1;
            hv_BBoxCol2Mirror = (hv_ImageWidth-hv_BBoxCol1)-1;
            hv_BBoxCol1 = hv_BBoxCol1Mirror;
            hv_BBoxCol2 = hv_BBoxCol2Mirror;
        }
        else if (0 != hv_Rectangle2ParamExist)
        {
            hv_BBoxCol = (hv_ImageWidth-hv_BBoxCol)-1;
            //Check that BBoxPhi is only mirrored for classes with orientation.
            if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
            {
                {
                    HTuple end_val72 = (hv_BBoxLabelID.TupleLength())-1;
                    HTuple step_val72 = 1;
                    for (hv_ObjIdx=0; hv_ObjIdx.Continue(end_val72, step_val72); hv_ObjIdx += step_val72)
                    {
                        if (0 != (int((hv_ClassIDsNoOrientation.TupleFind(HTuple(hv_BBoxLabelID[hv_ObjIdx])))==-1)))
                        {
                            if (0 != hv_IgnoreDirection)
                            {
                                hv_BBoxPhi[hv_ObjIdx] = -HTuple(hv_BBoxPhi[hv_ObjIdx]);
                            }
                            else
                            {
                                hv_BBoxPhi[hv_ObjIdx] = (((-(HTuple(hv_BBoxPhi[hv_ObjIdx]).TupleLessElem(0.0)))+(HTuple(hv_BBoxPhi[hv_ObjIdx]).TupleGreaterEqualElem(0.0)))*(HTuple(180).TupleRad()))-HTuple(hv_BBoxPhi[hv_ObjIdx]);
                            }
                        }
                    }
                }
            }
            else
            {
                if (0 != hv_IgnoreDirection)
                {
                    hv_BBoxPhi = -hv_BBoxPhi;
                }
                else
                {
                    hv_BBoxPhi = (((-(hv_BBoxPhi.TupleLessElem(0.0)))+(hv_BBoxPhi.TupleGreaterEqualElem(0.0)))*(HTuple(180).TupleRad()))-hv_BBoxPhi;
                }
            }
        }
        if (0 != hv_InstanceMaskExists)
        {
            MirrorRegion(ho_Mask, &ho_Mask, "column", hv_ImageWidth);
        }
        if (0 != hv_SegmentationImageExists)
        {
            MirrorImage(ho_SegmentationImage, &ho_SegmentationImage, "column");
        }
        if (0 != hv_WeightImageExists)
        {
            MirrorImage(ho_WeightImage, &ho_WeightImage, "column");
        }
    }
    //
    if (0 != (hv_StrMirror.TupleRegexpTest("r")))
    {
        MirrorImage(ho_Image, &ho_Image, "row");
        if (0 != hv_Rectangle1ParamExist)
        {
            hv_BBoxRow1Mirror = (hv_ImageHeight-hv_BBoxRow2)-1;
            hv_BBoxRow2Mirror = (hv_ImageHeight-hv_BBoxRow1)-1;
            hv_BBoxRow1 = hv_BBoxRow1Mirror;
            hv_BBoxRow2 = hv_BBoxRow2Mirror;
        }
        else if (0 != hv_Rectangle2ParamExist)
        {
            hv_BBoxRow = (hv_ImageHeight-hv_BBoxRow)-1;
            if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
            {
                {
                    HTuple end_val110 = (hv_BBoxLabelID.TupleLength())-1;
                    HTuple step_val110 = 1;
                    for (hv_ObjIdx=0; hv_ObjIdx.Continue(end_val110, step_val110); hv_ObjIdx += step_val110)
                    {
                        if (0 != (int((hv_ClassIDsNoOrientation.TupleFind(HTuple(hv_BBoxLabelID[hv_ObjIdx])))==-1)))
                        {
                            hv_BBoxPhi[hv_ObjIdx] = -HTuple(hv_BBoxPhi[hv_ObjIdx]);
                        }
                    }
                }
            }
            else
            {
                hv_BBoxPhi = -hv_BBoxPhi;
            }
        }
        if (0 != hv_InstanceMaskExists)
        {
            MirrorRegion(ho_Mask, &ho_Mask, "row", hv_ImageHeight);
        }
        if (0 != hv_SegmentationImageExists)
        {
            MirrorImage(ho_SegmentationImage, &ho_SegmentationImage, "row");
        }
        if (0 != hv_WeightImageExists)
        {
            MirrorImage(ho_WeightImage, &ho_WeightImage, "row");
        }
    }
    //
    //Set the mirrored data to DLSample.
    SetDictObject(ho_Image, hv_DLSample, "image");
    if (0 != hv_Rectangle1ParamExist)
    {
        SetDictTuple(hv_DLSample, "bbox_col1", hv_BBoxCol1);
        SetDictTuple(hv_DLSample, "bbox_row1", hv_BBoxRow1);
        SetDictTuple(hv_DLSample, "bbox_col2", hv_BBoxCol2);
        SetDictTuple(hv_DLSample, "bbox_row2", hv_BBoxRow2);
    }
    else if (0 != hv_Rectangle2ParamExist)
    {
        SetDictTuple(hv_DLSample, "bbox_row", hv_BBoxRow);
        SetDictTuple(hv_DLSample, "bbox_col", hv_BBoxCol);
        SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhi);
    }
    if (0 != hv_InstanceMaskExists)
    {
        SetDictObject(ho_Mask, hv_DLSample, "mask");
    }
    if (0 != hv_SegmentationImageExists)
    {
        SetDictObject(ho_SegmentationImage, hv_DLSample, "segmentation_image");
    }
    if (0 != hv_WeightImageExists)
    {
        SetDictObject(ho_WeightImage, hv_DLSample, "weight_image");
    }
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_remove_pixel (HTuple hv_DLSample, HTuple hv_NumPixelsToRemoveX,
                                              HTuple hv_NumPixelsToRemoveY)
{

    // Local iconic variables
    HObject  ho_Image, ho_ImageHighRes, ho_Domain;
    HObject  ho_DomainHighRes, ho_ImagePart;

    // Local control variables
    HTuple  hv_OCRType, hv_IsOCRRecognition, hv_AugmentationDataExists;
    HTuple  hv_AugmentationData, hv_ImageHighResExists, hv_ImageWidth;
    HTuple  hv_ImageHeight, hv_Row1, hv_Column1, hv_Row2, hv_Column2;
    HTuple  hv_Width, hv_Height, hv_ImageHighResWidth, hv_ImageHighResHeight;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation method applies only to OCR Recognition samples.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    hv_IsOCRRecognition = int(hv_OCRType==HTuple("ocr_recognition"));
    if (0 != (hv_IsOCRRecognition.TupleNot()))
    {
        throw HException("The augmentation method 'remove_pixel' is only supported by ocr_recognition models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    //
    //Select the augmentation image with high resolution if available for ocr_recognition models.
    //Note the difference between Image and ImageHighRes.
    GetDictParam(hv_DLSample, "key_exists", "augmentation_data", &hv_AugmentationDataExists);
    if (0 != (hv_IsOCRRecognition.TupleAnd(hv_AugmentationDataExists)))
    {
        hv_AugmentationData = hv_DLSample.TupleGetDictTuple("augmentation_data");
        GetDictParam(hv_AugmentationData, "key_exists", "image_high_res", &hv_ImageHighResExists);
        if (0 != hv_ImageHighResExists)
        {
            ho_ImageHighRes = hv_AugmentationData.TupleGetDictObject("image_high_res");
        }
    }
    //
    //Get dimensions of the domain of the preprocessed image,
    //The domain is assumed to be a rectangle1 domain.
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    GetDomain(ho_Image, &ho_Domain);
    SmallestRectangle1(ho_Domain, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
    hv_Width = (hv_Column2-hv_Column1)+1;
    hv_Height = (hv_Row2-hv_Row1)+1;
    //Do nothing if no pixel would remain available.
    if (0 != (HTuple(int(hv_Width<=(2*hv_NumPixelsToRemoveX))).TupleOr(int(hv_Height<=(2*hv_NumPixelsToRemoveY)))))
    {
        return;
    }
    //In case of ocr_recognition use the high-resolution image if available.
    if (0 != (hv_IsOCRRecognition.TupleAnd(hv_AugmentationDataExists)))
    {
        GetImageSize(ho_ImageHighRes, &hv_ImageHighResWidth, &hv_ImageHighResHeight);
        hv_NumPixelsToRemoveX = ((hv_NumPixelsToRemoveX*hv_ImageHighResWidth)/(hv_Width.TupleReal())).TupleInt();
        hv_NumPixelsToRemoveY = ((hv_NumPixelsToRemoveY*hv_ImageHighResHeight)/(hv_Height.TupleReal())).TupleInt();
        ho_Image = ho_ImageHighRes;
        //The high-resolution image is expected to have full domain.
        GetDomain(ho_ImageHighRes, &ho_DomainHighRes);
        SmallestRectangle1(ho_DomainHighRes, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
    }
    //Define cropping rectangle.
    if (0 != (int(hv_NumPixelsToRemoveY>0)))
    {
        hv_Row1 += ((HTuple::TupleRand(1)*hv_NumPixelsToRemoveY).TupleInt())+1;
        hv_Row2 = hv_Row2-(((HTuple::TupleRand(1)*hv_NumPixelsToRemoveY).TupleInt())+1);
    }
    if (0 != (int(hv_NumPixelsToRemoveX>0)))
    {
        hv_Column1 += ((HTuple::TupleRand(1)*hv_NumPixelsToRemoveX).TupleInt())+1;
        hv_Column2 = hv_Column2-(((HTuple::TupleRand(1)*hv_NumPixelsToRemoveX).TupleInt())+1);
    }
    //Crop the image.
    CropRectangle1(ho_Image, &ho_ImagePart, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
    //Scale the image to the input size and set the augmented image to DLSample.
    if (0 != (hv_IsOCRRecognition.TupleAnd(hv_AugmentationDataExists)))
    {
        preprocess_dl_model_images_ocr_recognition(ho_ImagePart, &ho_ImagePart, hv_AugmentationData.TupleGetDictTuple("preprocess_params"));
    }
    else
    {
        ZoomImageSize(ho_ImagePart, &ho_ImagePart, hv_ImageWidth, hv_ImageHeight, "constant");
    }
    //Set the augmented image to DLSample.
    SetDictObject(ho_ImagePart, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_rotate (HTuple hv_DLSample, HTuple hv_RotationStep, HTuple hv_ClassIDsNoOrientation,
                                        HTuple hv_IgnoreDirection)
{

    // Local iconic variables
    HObject  ho_Image, ho_Mask, ho_SegmentationImage;
    HObject  ho_WeightImage, ho_ImageRotate;

    // Local control variables
    HTuple  hv_OCRType, hv_Rectangle1ParamExist, hv_Rectangle2ParamExist;
    HTuple  hv_InstanceMaskExists, hv_SegmentationImageExists;
    HTuple  hv_WeightImageExists, hv_BBoxRow1, hv_BBoxCol1;
    HTuple  hv_BBoxRow2, hv_BBoxCol2, hv_BBoxRow, hv_BBoxCol;
    HTuple  hv_BBoxLength1, hv_BBoxLength2, hv_BBoxPhi, hv_BBoxLabelID;
    HTuple  hv_NumPossibleRotations, hv_CurrentRotation, hv_ImageWidth;
    HTuple  hv_ImageHeight, hv_HomMat2DIdentity, hv_HomMat2DTmp;
    HTuple  hv_HomMat2DAdapted, hv_Offset, hv_HomMat2DRotate;
    HTuple  hv_RowTrans1, hv_ColTrans1, hv_RowTrans2, hv_ColTrans2;
    HTuple  hv_RowTrans, hv_ColTrans, hv_MaxAngle, hv_DiffAngle;
    HTuple  hv_IndicesLarge, hv_ObjIdx, hv_BBoxLengthTmp;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation method should not be applied to OCR Detection/Recognition samples.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    if (0 != (HTuple(int(hv_OCRType==HTuple("ocr_detection"))).TupleOr(int(hv_OCRType==HTuple("ocr_recognition")))))
    {
        throw HException(("The augmentation method 'rotate' is not supported by "+hv_OCRType)+" models.");
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    //Get the annotations from the sample that need to be
    //augmented together with the image.
    GetDictParam(hv_DLSample, "key_exists", "bbox_row1", &hv_Rectangle1ParamExist);
    GetDictParam(hv_DLSample, "key_exists", "bbox_phi", &hv_Rectangle2ParamExist);
    GetDictParam(hv_DLSample, "key_exists", "mask", &hv_InstanceMaskExists);
    GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmentationImageExists);
    GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
    if (0 != hv_Rectangle1ParamExist)
    {
        GetDictTuple(hv_DLSample, "bbox_row1", &hv_BBoxRow1);
        GetDictTuple(hv_DLSample, "bbox_col1", &hv_BBoxCol1);
        GetDictTuple(hv_DLSample, "bbox_row2", &hv_BBoxRow2);
        GetDictTuple(hv_DLSample, "bbox_col2", &hv_BBoxCol2);
    }
    else if (0 != hv_Rectangle2ParamExist)
    {
        GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
        GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
        GetDictTuple(hv_DLSample, "bbox_length1", &hv_BBoxLength1);
        GetDictTuple(hv_DLSample, "bbox_length2", &hv_BBoxLength2);
        GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
        if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
        {
            GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabelID);
        }
    }
    if (0 != hv_InstanceMaskExists)
    {
        GetDictObject(&ho_Mask, hv_DLSample, "mask");
    }
    if (0 != hv_SegmentationImageExists)
    {
        GetDictObject(&ho_SegmentationImage, hv_DLSample, "segmentation_image");
    }
    if (0 != hv_WeightImageExists)
    {
        GetDictObject(&ho_WeightImage, hv_DLSample, "weight_image");
    }
    //
    //Rotation
    //
    //Determine rotation angle for distortion type 'rotate' (angle in range (0:RotationStep:360)).
    hv_NumPossibleRotations = (360.0/hv_RotationStep)-1;
    hv_CurrentRotation = hv_RotationStep*(((hv_NumPossibleRotations*HTuple::TupleRand(1)).TupleInt())+1);
    //
    if (0 != (int(hv_CurrentRotation!=0)))
    {
        GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
        if (0 != (HTuple(int(hv_ImageWidth!=hv_ImageHeight)).TupleAnd(int(hv_CurrentRotation!=180.0))))
        {
            //If an image is not quadratic, a rotation by 90 or 270 degrees is ignored.
            return;
        }
        //
        RotateImage(ho_Image, &ho_ImageRotate, hv_CurrentRotation, "constant");
        SetDictObject(ho_ImageRotate, hv_DLSample, "image");
        //
        if (0 != (hv_Rectangle1ParamExist.TupleOr(hv_Rectangle2ParamExist)))
        {
            //Create a transformation matrix for the rotation of the bounding boxes.
            GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
            HomMat2dIdentity(&hv_HomMat2DIdentity);
            HomMat2dTranslate(hv_HomMat2DIdentity, 0.5, 0.5, &hv_HomMat2DTmp);
            HomMat2dTranslateLocal(hv_HomMat2DTmp, -0.5, -0.5, &hv_HomMat2DAdapted);
            hv_Offset = ((hv_ImageHeight-hv_ImageWidth)*0.5)*((hv_CurrentRotation.TupleRad()).TupleSin());
            HomMat2dTranslate(hv_HomMat2DAdapted, hv_Offset, hv_Offset, &hv_HomMat2DAdapted);
            HomMat2dRotate(hv_HomMat2DAdapted, hv_CurrentRotation.TupleRad(), hv_ImageHeight*0.5,
                           hv_ImageWidth*0.5, &hv_HomMat2DRotate);
        }
        if (0 != hv_Rectangle1ParamExist)
        {
            AffineTransPixel(hv_HomMat2DRotate, hv_BBoxRow1, hv_BBoxCol1, &hv_RowTrans1,
                             &hv_ColTrans1);
            AffineTransPixel(hv_HomMat2DRotate, hv_BBoxRow2, hv_BBoxCol2, &hv_RowTrans2,
                             &hv_ColTrans2);
            if (0 != (int(hv_CurrentRotation==90)))
            {
                hv_BBoxRow1 = hv_RowTrans2;
                hv_BBoxCol1 = hv_ColTrans1;
                hv_BBoxRow2 = hv_RowTrans1;
                hv_BBoxCol2 = hv_ColTrans2;
            }
            else if (0 != (int(hv_CurrentRotation==180)))
            {
                hv_BBoxRow1 = hv_RowTrans2;
                hv_BBoxCol1 = hv_ColTrans2;
                hv_BBoxRow2 = hv_RowTrans1;
                hv_BBoxCol2 = hv_ColTrans1;
            }
            else if (0 != (int(hv_CurrentRotation==270)))
            {
                hv_BBoxRow1 = hv_RowTrans1;
                hv_BBoxCol1 = hv_ColTrans2;
                hv_BBoxRow2 = hv_RowTrans2;
                hv_BBoxCol2 = hv_ColTrans1;
            }
            //
            SetDictTuple(hv_DLSample, "bbox_row1", hv_BBoxRow1);
            SetDictTuple(hv_DLSample, "bbox_col1", hv_BBoxCol1);
            SetDictTuple(hv_DLSample, "bbox_row2", hv_BBoxRow2);
            SetDictTuple(hv_DLSample, "bbox_col2", hv_BBoxCol2);
        }
        else if (0 != hv_Rectangle2ParamExist)
        {
            AffineTransPixel(hv_HomMat2DRotate, hv_BBoxRow, hv_BBoxCol, &hv_RowTrans, &hv_ColTrans);
            //Write the bounding box angles phi in the expected interval:
            //-180бу < phi <= 180бу or if IgnoreDirection set to true -90бу < phi <= 90бу.
            if (0 != (hv_IgnoreDirection.TupleNot()))
            {
                hv_BBoxPhi += hv_CurrentRotation.TupleRad();
                hv_MaxAngle = 180;
                hv_DiffAngle = 360;
            }
            else
            {
                if (0 != (HTuple(int(hv_CurrentRotation==90)).TupleOr(int(hv_CurrentRotation==270))))
                {
                    hv_BBoxPhi += HTuple(90).TupleRad();
                }
                hv_MaxAngle = 90;
                hv_DiffAngle = 180;
            }
            hv_IndicesLarge = (hv_BBoxPhi.TupleGreaterElem(hv_MaxAngle.TupleRad())).TupleFind(1);
            if (0 != (int(hv_IndicesLarge!=-1)))
            {
                hv_BBoxPhi[hv_IndicesLarge] = HTuple(hv_BBoxPhi[hv_IndicesLarge])-(hv_DiffAngle.TupleRad());
            }
            //Check that the angle BBoxPhi for objects without orientation is always set to 0.0.
            if (0 != (int(hv_ClassIDsNoOrientation!=HTuple())))
            {
                {
                    HTuple end_val117 = (hv_BBoxLabelID.TupleLength())-1;
                    HTuple step_val117 = 1;
                    for (hv_ObjIdx=0; hv_ObjIdx.Continue(end_val117, step_val117); hv_ObjIdx += step_val117)
                    {
                        if (0 != (int((hv_ClassIDsNoOrientation.TupleFind(HTuple(hv_BBoxLabelID[hv_ObjIdx])))!=-1)))
                        {
                            hv_BBoxPhi[hv_ObjIdx] = 0.0;
                            //These classes require Length1 <= Length2: exchange them for 90бу or 270бу rotations.
                            if (0 != (HTuple(int(hv_CurrentRotation==90)).TupleOr(int(hv_CurrentRotation==270))))
                            {
                                hv_BBoxLengthTmp = HTuple(hv_BBoxLength1[hv_ObjIdx]);
                                hv_BBoxLength1[hv_ObjIdx] = HTuple(hv_BBoxLength2[hv_ObjIdx]);
                                hv_BBoxLength2[hv_ObjIdx] = hv_BBoxLengthTmp;
                            }
                        }
                    }
                }
            }
            SetDictTuple(hv_DLSample, "bbox_row", hv_RowTrans);
            SetDictTuple(hv_DLSample, "bbox_col", hv_ColTrans);
            SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhi);
            SetDictTuple(hv_DLSample, "bbox_length1", hv_BBoxLength1);
            SetDictTuple(hv_DLSample, "bbox_length2", hv_BBoxLength2);
        }
        if (0 != hv_InstanceMaskExists)
        {
            AffineTransRegion(ho_Mask, &ho_Mask, hv_HomMat2DRotate, "nearest_neighbor");
            SetDictObject(ho_Mask, hv_DLSample, "mask");
        }
        if (0 != hv_SegmentationImageExists)
        {
            RotateImage(ho_SegmentationImage, &ho_SegmentationImage, hv_CurrentRotation.TupleInt(),
                        "constant");
            SetDictObject(ho_SegmentationImage, hv_DLSample, "segmentation_image");
        }
        if (0 != hv_WeightImageExists)
        {
            RotateImage(ho_WeightImage, &ho_WeightImage, hv_CurrentRotation.TupleInt(),
                        "constant");
            SetDictObject(ho_WeightImage, hv_DLSample, "weight_image");
        }
    }
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_rotate_range (HTuple hv_DLSample, HTuple hv_RotateRange)
{

    // Local iconic variables
    HObject  ho_Image, ho_DomainRotated;

    // Local control variables
    HTuple  hv_OCRType, hv_IsOCRDetection, hv_IsOCRRecognition;
    HTuple  hv_IsOCR, hv_RotateRangeMax, hv_Rectangle1ParamExist;
    HTuple  hv_Rectangle2ParamExist, hv_InstanceMaskExists;
    HTuple  hv_SegmentationImageExists, hv_WeightImageExists;
    HTuple  hv_ImageHighResExists, hv_AugmentationDataExists;
    HTuple  hv_AugmentationData, hv_SampleHighResExists, hv_SampleHighRes;
    HTuple  hv_PreprocessParams, hv_ImageWidth, hv_ImageHeight;
    HTuple  hv_RotationAngle, hv_HomMat2DIdentity, hv_HomMat2DRotate;
    HTuple  hv_Row1, hv_Column1, hv_Row2, hv_Column2, hv_PreprocessWidth;
    HTuple  hv_PreprocessHeight, hv_FactorWidth, hv_FactorHeight;
    HTuple  hv_TempWidth, hv_TempHeight, hv_HomMat2DTranslate;
    HTuple  hv_HomMat2DTransform, hv_BBoxRow1, hv_BBoxCol1;
    HTuple  hv_BBoxRow2, hv_BBoxCol2, hv_BBoxRow3, hv_BBoxCol3;
    HTuple  hv_BBoxRow4, hv_BBoxCol4, hv_Row1Trans, hv_Col1Trans;
    HTuple  hv_Row2Trans, hv_Col2Trans, hv_Row3Trans, hv_Col3Trans;
    HTuple  hv_Row4Trans, hv_Col4Trans, hv___Tmp_Ctrl_0, hv___Tmp_Ctrl_1;
    HTuple  hv___Tmp_Ctrl_2, hv___Tmp_Ctrl_3, hv___Tmp_Ctrl_4;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    hv_IsOCRDetection = int(hv_OCRType==HTuple("ocr_detection"));
    hv_IsOCRRecognition = int(hv_OCRType==HTuple("ocr_recognition"));
    hv_IsOCR = hv_IsOCRDetection.TupleOr(hv_IsOCRRecognition);
    if (0 != hv_IsOCR)
    {
        //For OCR Recognition samples only a certain RotateRange is allowed.
        if (0 != hv_IsOCRRecognition)
        {
            hv_RotateRangeMax = 5;
            if (0 != (int(hv_RotateRange>hv_RotateRangeMax)))
            {
                throw HException(((("Value of augmentation method 'rotate_range' cannot be greater than "+hv_RotateRangeMax)+" for ")+hv_OCRType)+" models.");
            }
        }
    }
    else
    {
        //This augmentation method cannot be applied to samples with
        //object detection annotations or semantic segmentation annotations.
        GetDictParam(hv_DLSample, "key_exists", "bbox_row1", &hv_Rectangle1ParamExist);
        GetDictParam(hv_DLSample, "key_exists", "bbox_phi", &hv_Rectangle2ParamExist);
        GetDictParam(hv_DLSample, "key_exists", "mask", &hv_InstanceMaskExists);
        GetDictParam(hv_DLSample, "key_exists", "segmentation_image", &hv_SegmentationImageExists);
        GetDictParam(hv_DLSample, "key_exists", "weight_image", &hv_WeightImageExists);
        if (0 != (HTuple(HTuple(HTuple(hv_Rectangle1ParamExist.TupleOr(hv_Rectangle2ParamExist)).TupleOr(hv_InstanceMaskExists)).TupleOr(hv_SegmentationImageExists)).TupleOr(hv_WeightImageExists)))
        {
            throw HException(HTuple("The augmentation method 'rotate_range' is not supported for object detection, instance segmentation or semantic segmentation samples."));
        }
    }
    //
    //*** Augmentation ***
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    //
    //Select the augmentation image with high resolution if available for OCR Detection/Recognition models.
    hv_ImageHighResExists = 0;
    GetDictParam(hv_DLSample, "key_exists", "augmentation_data", &hv_AugmentationDataExists);
    if (0 != (hv_IsOCR.TupleAnd(hv_AugmentationDataExists)))
    {
        hv_AugmentationData = hv_DLSample.TupleGetDictTuple("augmentation_data");
        if (0 != hv_IsOCRDetection)
        {
            GetDictParam(hv_AugmentationData, "key_exists", "sample_high_res", &hv_SampleHighResExists);
            if (0 != hv_SampleHighResExists)
            {
                hv_SampleHighRes = hv_AugmentationData.TupleGetDictTuple("sample_high_res");
                GetDictParam(hv_SampleHighRes, "key_exists", "image", &hv_ImageHighResExists);
                if (0 != hv_ImageHighResExists)
                {
                    ho_Image = hv_SampleHighRes.TupleGetDictObject("image");
                }
                hv_PreprocessParams = hv_AugmentationData.TupleGetDictTuple("preprocess_params");
            }
        }
        else
        {
            GetDictParam(hv_AugmentationData, "key_exists", "image_high_res", &hv_ImageHighResExists);
            if (0 != hv_ImageHighResExists)
            {
                ho_Image = hv_AugmentationData.TupleGetDictObject("image_high_res");
            }
        }
    }
    if (0 != (hv_IsOCRDetection.TupleAnd(hv_ImageHighResExists.TupleNot())))
    {
        throw HException("The augmentation method 'rotate_range' requires sample images with high resolution for ocr_detection models.");
    }
    //
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    //Determine rotation angle for method 'rotate_range': angle in range [1:RotateRange].
    hv_RotationAngle = ((hv_RotateRange*HTuple::TupleRand(1)).TupleInt())+1;
    //Select direction of rotation randomly.
    if (0 != (int(HTuple::TupleRand(1)<0.5)))
    {
        hv_RotationAngle = 360-hv_RotationAngle;
    }
    //For ocr_detection the transformation matrix is always needed so
    //the else-case is also used for angles multiple of 90 degrees.
    if (0 != (HTuple(int((hv_RotationAngle%90)==0)).TupleAnd(hv_IsOCRDetection.TupleNot())))
    {
        //Rotations around 90 degrees are faster with rotate_image.
        RotateImage(ho_Image, &ho_Image, hv_RotationAngle, "constant");
    }
    else
    {
        HomMat2dIdentity(&hv_HomMat2DIdentity);
        if (0 != (hv_IsOCRDetection.TupleNot()))
        {
            //Create rotation matrix and apply the rotation.
            HomMat2dRotate(hv_HomMat2DIdentity, hv_RotationAngle.TupleRad(), hv_ImageHeight/2.0,
                           hv_ImageWidth/2.0, &hv_HomMat2DRotate);
            AffineTransImage(ho_Image, &ho_Image, hv_HomMat2DRotate, "constant", "false");
            //Remove potential undefined domain.
            GetDomain(ho_Image, &ho_DomainRotated);
            InnerRectangle1(ho_DomainRotated, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
            CropRectangle1(ho_Image, &ho_Image, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
        }
        else
        {
            //Calculate temporary image dimensions with the same aspect ratio
            //as the preprocessed image to enlarge the input image, such that
            //the rotation output fits most part of it without zooming the content.
            hv_PreprocessWidth = hv_PreprocessParams.TupleGetDictTuple("image_width");
            hv_PreprocessHeight = hv_PreprocessParams.TupleGetDictTuple("image_height");
            calculate_dl_image_zoom_factors(hv_ImageWidth, hv_ImageHeight, hv_PreprocessWidth,
                                            hv_PreprocessHeight, hv_PreprocessParams, &hv_FactorWidth, &hv_FactorHeight);
            hv_TempWidth = hv_PreprocessWidth/(hv_FactorWidth.TupleReal());
            hv_TempHeight = hv_PreprocessHeight/(hv_FactorHeight.TupleReal());
            //Rotate image.
            HomMat2dTranslate(hv_HomMat2DIdentity, (-hv_ImageHeight)/2.0, (-hv_ImageWidth)/2.0,
                              &hv_HomMat2DTranslate);
            HomMat2dRotate(hv_HomMat2DTranslate, hv_RotationAngle.TupleRad(), 0, 0, &hv_HomMat2DRotate);
            HomMat2dTranslate(hv_HomMat2DRotate, hv_ImageHeight/2.0, hv_ImageWidth/2.0,
                              &hv_HomMat2DTransform);
            AffineTransImageSize(ho_Image, &ho_Image, hv_HomMat2DTransform, "constant",
                                 hv_TempWidth, hv_TempHeight);
            //Rotate bounding boxes.
            convert_rect2_5to8param(hv_SampleHighRes.TupleGetDictTuple("bbox_row"), hv_SampleHighRes.TupleGetDictTuple("bbox_col"),
                                    hv_SampleHighRes.TupleGetDictTuple("bbox_length1"), hv_SampleHighRes.TupleGetDictTuple("bbox_length2"),
                                    hv_SampleHighRes.TupleGetDictTuple("bbox_phi"), &hv_BBoxRow1, &hv_BBoxCol1,
                                    &hv_BBoxRow2, &hv_BBoxCol2, &hv_BBoxRow3, &hv_BBoxCol3, &hv_BBoxRow4, &hv_BBoxCol4);
            AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow1, hv_BBoxCol1, &hv_Row1Trans,
                             &hv_Col1Trans);
            AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow2, hv_BBoxCol2, &hv_Row2Trans,
                             &hv_Col2Trans);
            AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow3, hv_BBoxCol3, &hv_Row3Trans,
                             &hv_Col3Trans);
            AffineTransPixel(hv_HomMat2DTransform, hv_BBoxRow4, hv_BBoxCol4, &hv_Row4Trans,
                             &hv_Col4Trans);
            convert_rect2_8to5param(hv_Row1Trans, hv_Col1Trans, hv_Row2Trans, hv_Col2Trans,
                                    hv_Row3Trans, hv_Col3Trans, hv_Row4Trans, hv_Col4Trans, 0, &hv___Tmp_Ctrl_0,
                                    &hv___Tmp_Ctrl_1, &hv___Tmp_Ctrl_2, &hv___Tmp_Ctrl_3, &hv___Tmp_Ctrl_4);
            SetDictTuple(hv_DLSample, "bbox_phi", hv___Tmp_Ctrl_4);
            SetDictTuple(hv_DLSample, "bbox_length2", hv___Tmp_Ctrl_3);
            SetDictTuple(hv_DLSample, "bbox_length1", hv___Tmp_Ctrl_2);
            SetDictTuple(hv_DLSample, "bbox_col", hv___Tmp_Ctrl_1);
            SetDictTuple(hv_DLSample, "bbox_row", hv___Tmp_Ctrl_0);
        }
    }
    //Do model specific operations before scaling.
    if (0 != hv_IsOCRDetection)
    {
    }
    //Scale image to the input size.
    if (0 != (hv_IsOCR.TupleAnd(hv_ImageHighResExists)))
    {
        if (0 != hv_IsOCRDetection)
        {
            //Scale bounding boxes to the input size.
            preprocess_dl_model_bbox_rect2(ho_Image, hv_DLSample, hv_PreprocessParams);
            //Scale rotated image to the input size.
            preprocess_dl_model_images_ocr_detection(ho_Image, &ho_Image, hv_PreprocessParams);
            //Generate targets from the scaled rotated image.
            SetDictObject(ho_Image, hv_DLSample, "image");
            gen_dl_ocr_detection_targets(hv_DLSample, hv_PreprocessParams);
        }
        else
        {
            preprocess_dl_model_images_ocr_recognition(ho_Image, &ho_Image, hv_PreprocessParams);
        }
    }
    else
    {
        ZoomImageSize(ho_Image, &ho_Image, hv_ImageWidth, hv_ImageHeight, "constant");
    }
    //
    //Set the augmented image to DLSample.
    SetDictObject(ho_Image, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: augment_dl_sample_saturation_variation (HTuple hv_DLSample, HTuple hv_SaturationVariation)
{

    // Local iconic variables
    HObject  ho_Image, ho_GrayImage, ho_GrayRGBChannelImage;
    HObject  ho_GrayRGBChannelImageScaled, ho_ImageScaled, ho_ImageOut;

    // Local control variables
    HTuple  hv_OCRType, hv_NumChannels, hv_Borders;
    HTuple  hv_Factor;

    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //*** Input validation ***
    //
    //This augmentation method should not be applied to OCR Recognition samples.
    get_dl_sample_ocr_type(hv_DLSample, &hv_OCRType);
    if (0 != (int(hv_OCRType==HTuple("ocr_recognition"))))
    {
        throw HException("The augmentation method 'saturation_variation' is not supported by ocr_recognition models.");
    }
    //
    ho_Image = hv_DLSample.TupleGetDictObject("image");
    //
    //If the image has only one channel, this augmentation has no effect.
    CountChannels(ho_Image, &hv_NumChannels);
    if (0 != (int(hv_NumChannels==1)))
    {
        return;
    }
    else if (0 != (int(hv_NumChannels!=3)))
    {
        //Otherwise, only RGB images are allowed.
        throw HException("The augmentation method 'saturation_variation' can only be applied to gray scale and RGB images.");
    }
    //
    //*** Augmentation ***
    //
    //Adjust the saturation of the input image by blending it with its gray value version.
    //
    //Minimum and maximum blend factors.
    hv_Borders.Clear();
    hv_Borders.Append(HTuple(0.0).TupleMax2(1-hv_SaturationVariation));
    hv_Borders.Append(1+hv_SaturationVariation);
    hv_Factor = HTuple(hv_Borders[0])+((HTuple(hv_Borders[1])-HTuple(hv_Borders[0]))*HTuple::TupleRand(1));
    //
    if (0 != (int(hv_Factor==1.0)))
    {
        return;
    }
    //
    //Get the gray value image as an RGB image.
    Rgb1ToGray(ho_Image, &ho_GrayImage);
    Compose3(ho_GrayImage, ho_GrayImage, ho_GrayImage, &ho_GrayRGBChannelImage);
    //
    //Blend Image and GrayRGBChannelImage.
    ScaleImage(ho_GrayRGBChannelImage, &ho_GrayRGBChannelImageScaled, 1.0-hv_Factor,
               0.0);
    ScaleImage(ho_Image, &ho_ImageScaled, hv_Factor, 0.0);
    AddImage(ho_GrayRGBChannelImageScaled, ho_ImageScaled, &ho_ImageOut, 1.0, 0.0);
    //
    //Set the augmented image to DLSample.
    SetDictObject(ho_ImageOut, hv_DLSample, "image");
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Perform data augmentation on the given samples.
void HalxAI:: augment_dl_samples (HTuple hv_DLSampleBatch, HTuple hv_GenParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_NumSamples, hv_AugParams, hv_GenKeys;
    HTuple  hv_KeyIndex, hv_GenKey, hv_AugMethodsToApply, hv_SampleIndex;
    HTuple  hv_DLSample, hv_ChosenIndex, hv_AugMethod, hv_AugMethodValue;
    HTuple  hv___Tmp_Ctrl_Dict_Init_1, hv___Tmp_Ctrl_Type;

    //
    //This procedure augments samples in the DLSampleBatch randomly.
    //The augmentation methods have to be specified using the dictionary GenParam.
    //
    //
    //*** Input validation ***
    //
    //If no augmentation parameter is given we return directly and the samples stay unchanged.
    if (0 != (int((hv_GenParam.TupleLength())==0)))
    {
        return;
    }
    //
    //Check number of samples to be augmented.
    hv_NumSamples = hv_DLSampleBatch.TupleLength();
    if (0 != (int(hv_NumSamples==0)))
    {
        throw HException("There are no DLSamples to be processed.");
    }
    //
    //Validate and sanitize the input.
    //Note that this is just a shallow check of the given GenParam dict.
    //The compatibility of the resulting augmentation parameters dict with the
    //DLSampleBatch at hand needs to be checked below.
    check_augment_dl_samples_gen_param(hv_GenParam);
    //
    //
    //*** Default augmentation values ***
    //
    CreateDict(&hv_AugParams);
    //
    //Augmentation methods:
    //
    //The absolute brightness change can vary in the range [-value, +value].
    SetDictTuple(hv_AugParams, "brightness_variation", 0);
    //The absolute brightness peak of a randomly positioned spot can vary in the range [-value, +value].
    SetDictTuple(hv_AugParams, "brightness_variation_spot", 0);
    //Contrast variation can be enabled by setting a value larger than zero, for example 0.2.
    SetDictTuple(hv_AugParams, "contrast_variation", 0);
    //Fraction of image length and width that remains after cropping (in %).
    SetDictTuple(hv_AugParams, "crop_percentage", "off");
    //Image length and width that remains after cropping (in pixel).
    SetDictTuple(hv_AugParams, "crop_pixel", "off");
    //Allowed mirroring types are coded by 'r' (row), 'c' (column).
    SetDictTuple(hv_AugParams, "mirror", "off");
    //In case of a ocr_recognition model:
    //Maximum amount of pixels that can be removed from the image borders: [x,y] => x:left,right and y:top,bottom.
    SetDictTuple(hv_AugParams, "remove_pixel", (HTuple(0).Append(0)));
    //Step size for possible rotations.
    //This parameter and augmentation method is independent from the 'rotate_range' parameter.
    SetDictTuple(hv_AugParams, "rotate", 0);
    //Step range for rotations with step size 1.
    //This parameter and augmentation method is independent from the 'rotate' parameter.
    SetDictTuple(hv_AugParams, "rotate_range", 0);
    //Saturation variation can be enabled by setting a value larger than zero, for example 0.2.
    SetDictTuple(hv_AugParams, "saturation_variation", 0);
    //
    //Other settings:
    //
    //The percentage of the images that are to be augmented.
    SetDictTuple(hv_AugParams, "augmentation_percentage", 50);
    //In case of a detection model of instance_type 'rectangle2': Use directions of instances within bounding boxes.
    SetDictTuple(hv_AugParams, "ignore_direction", 0);
    //In case of a detection model of instance_type 'rectangle2': Class IDs without orientation.
    //These are the IDs of the classes, for whose instances the orientation is not to be considered.
    SetDictTuple(hv_AugParams, "class_ids_no_orientation", HTuple());
    //
    //
    //*** Get the augmentation that should be applied ***
    //
    //Set user-defined parameters:
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenKeys);
    {
        HTuple end_val70 = (hv_GenKeys.TupleLength())-1;
        HTuple step_val70 = 1;
        for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val70, step_val70); hv_KeyIndex += step_val70)
        {
            hv_GenKey = HTuple(hv_GenKeys[hv_KeyIndex]);
            GetDictParam(hv_GenParam, "key_data_type", hv_GenKey, &hv___Tmp_Ctrl_Type);
            if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
            {
                SetDictObject(hv_GenParam.TupleGetDictObject(hv_GenKey), hv_AugParams, hv_GenKey);
            }
            else
            {
                SetDictTuple(hv_AugParams, hv_GenKey, hv_GenParam.TupleGetDictTuple(hv_GenKey));
            }
        }
    }
    //
    //Get all methods that would actually have an effect when applied with the
    //augmentation value stored in AugParams.
    hv_AugMethodsToApply = HTuple();
    //Brightness variation.
    if (0 != (int((hv_AugParams.TupleGetDictTuple("brightness_variation"))>0)))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("brightness_variation");
    }
    //Brightness variation spot.
    if (0 != (int((hv_AugParams.TupleGetDictTuple("brightness_variation_spot"))>0)))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("brightness_variation_spot");
    }
    //Contrast variation.
    if (0 != (int((hv_AugParams.TupleGetDictTuple("contrast_variation"))>0)))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("contrast_variation");
    }
    //Cropping percentage.
    if (0 != ((hv_AugParams.TupleGetDictTuple("crop_percentage")).TupleIsNumber()))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("crop_percentage");
    }
    //Cropping pixels.
    if (0 != ((hv_AugParams.TupleGetDictTuple("crop_pixel")).TupleIsNumber()))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("crop_pixel");
    }
    //Mirroring is allowed in row and column direction.
    if (0 != (HTuple((hv_AugParams.TupleGetDictTuple("mirror")).TupleRegexpTest("r")).TupleOr((hv_AugParams.TupleGetDictTuple("mirror")).TupleRegexpTest("c"))))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("mirror");
    }
    //Removing pixels.
    if (0 != (HTuple(int(HTuple((hv_AugParams.TupleGetDictTuple("remove_pixel"))[0])>0)).TupleOr(int(HTuple((hv_AugParams.TupleGetDictTuple("remove_pixel"))[1])>0))))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("remove_pixel");
    }
    //Rotation with a given angular step size.
    if (0 != (int((hv_AugParams.TupleGetDictTuple("rotate"))>0)))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("rotate");
    }
    //Rotation within a given range (step size 1).
    if (0 != (int((hv_AugParams.TupleGetDictTuple("rotate_range"))>0)))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("rotate_range");
    }
    //Saturation variation.
    if (0 != (int((hv_AugParams.TupleGetDictTuple("saturation_variation"))>0)))
    {
        hv_AugMethodsToApply = hv_AugMethodsToApply.TupleConcat("saturation_variation");
    }
    //
    //Exit early if there is nothing to be applied
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
    SetDictTuple(hv___Tmp_Ctrl_Dict_Init_1, "comp", 0);
    if (0 != (HTuple(int((hv_AugMethodsToApply.TupleLength())==0)).TupleOr((hv_AugParams.TupleConcat(hv___Tmp_Ctrl_Dict_Init_1)).TupleTestEqualDictItem("augmentation_percentage","comp"))))
    {
        return;
    }
    hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
    //
    //
    //*** Augment the samples ***
    //
    {
        HTuple end_val135 = (hv_DLSampleBatch.TupleLength())-1;
        HTuple step_val135 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val135, step_val135); hv_SampleIndex += step_val135)
        {
            hv_DLSample = HTuple(hv_DLSampleBatch[hv_SampleIndex]);
            //Only augment the given percentage of samples.
            if (0 != (int((HTuple::TupleRand(1)*100)>(hv_AugParams.TupleGetDictTuple("augmentation_percentage")))))
            {
                continue;
            }
            //Select the augmentation method.
            hv_ChosenIndex = HTuple(HTuple::TupleRand(1)*(hv_AugMethodsToApply.TupleLength())).TupleInt();
            hv_AugMethod = HTuple(hv_AugMethodsToApply[hv_ChosenIndex]);
            hv_AugMethodValue = hv_AugParams.TupleGetDictTuple(hv_AugMethod);
            //
            if (0 != (int(hv_AugMethod==HTuple("brightness_variation"))))
            {
                augment_dl_sample_brightness_variation(hv_DLSample, hv_AugMethodValue);
            }
            else if (0 != (int(hv_AugMethod==HTuple("brightness_variation_spot"))))
            {
                augment_dl_sample_brightness_variation_spot(hv_DLSample, hv_AugMethodValue);
            }
            else if (0 != (int(hv_AugMethod==HTuple("contrast_variation"))))
            {
                augment_dl_sample_contrast_variation(hv_DLSample, hv_AugMethodValue);
            }
            else if (0 != (int(hv_AugMethod==HTuple("crop_percentage"))))
            {
                augment_dl_sample_crop_percentage(hv_DLSample, hv_AugMethodValue);
            }
            else if (0 != (int(hv_AugMethod==HTuple("crop_pixel"))))
            {
                augment_dl_sample_crop_pixel(hv_DLSample, hv_AugMethodValue);
            }
            else if (0 != (int(hv_AugMethod==HTuple("mirror"))))
            {
                augment_dl_sample_mirror(hv_DLSample, hv_AugMethodValue, hv_AugParams.TupleGetDictTuple("class_ids_no_orientation"),
                                         hv_AugParams.TupleGetDictTuple("ignore_direction"));
            }
            else if (0 != (int(hv_AugMethod==HTuple("remove_pixel"))))
            {
                augment_dl_sample_remove_pixel(hv_DLSample, HTuple(hv_AugMethodValue[0]), HTuple(hv_AugMethodValue[1]));
            }
            else if (0 != (int(hv_AugMethod==HTuple("rotate"))))
            {
                augment_dl_sample_rotate(hv_DLSample, hv_AugMethodValue, hv_AugParams.TupleGetDictTuple("class_ids_no_orientation"),
                                         hv_AugParams.TupleGetDictTuple("ignore_direction"));
            }
            else if (0 != (int(hv_AugMethod==HTuple("rotate_range"))))
            {
                augment_dl_sample_rotate_range(hv_DLSample, hv_AugMethodValue);
            }
            else if (0 != (int(hv_AugMethod==HTuple("saturation_variation"))))
            {
                augment_dl_sample_saturation_variation(hv_DLSample, hv_AugMethodValue);
            }
        }
    }
    return;
}

// Chapter: Deep Learning / OCR
// Short Description: Compute zoom factors to fit an image to a target size.
void HalxAI:: calculate_dl_image_zoom_factors (HTuple hv_ImageWidth, HTuple hv_ImageHeight,
                                               HTuple hv_TargetWidth, HTuple hv_TargetHeight, HTuple hv_DLPreprocessParam, HTuple *hv_ZoomFactorWidth,
                                               HTuple *hv_ZoomFactorHeight)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ScaleWidthUnit, hv_ScaleHeightUnit;
    HTuple  hv_PreserveAspectRatio, hv_Scale, hv___Tmp_Ctrl_Dict_Init_0;

    //Calculate the unit zoom factors, which zoom the input image to 1px.
    hv_ScaleWidthUnit = 1.0/(hv_ImageWidth.TupleReal());
    hv_ScaleHeightUnit = 1.0/(hv_ImageHeight.TupleReal());
    //
    //Calculate the required zoom factors for the available target size.
    (*hv_ZoomFactorWidth) = hv_TargetWidth*hv_ScaleWidthUnit;
    (*hv_ZoomFactorHeight) = hv_TargetHeight*hv_ScaleHeightUnit;
    //
    //Aspect-ratio preserving zoom is supported for model type 'ocr_detection' only.
    CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
    SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "ocr_detection");
    hv_PreserveAspectRatio = (hv_DLPreprocessParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("model_type","comp");
    hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
    //
    if (0 != hv_PreserveAspectRatio)
    {
        //
        //Use smaller scaling factor, which results in unfilled domain
        //on the respective other axis.
        hv_Scale = (*hv_ZoomFactorWidth).TupleMin2((*hv_ZoomFactorHeight));
        //Ensure that the zoom factors result in lengths of at least 1px.
        (*hv_ZoomFactorWidth) = hv_Scale.TupleMax2(hv_ScaleWidthUnit);
        (*hv_ZoomFactorHeight) = hv_Scale.TupleMax2(hv_ScaleHeightUnit);
    }
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate the channel-wise mean and standard deviation of a DL model layer.
void HalxAI:: calculate_dl_model_layer_mean_stddev (HTuple hv_DLModelHandle, HTuple hv_LayerName,
                                                    HTuple hv_DLSamples, HTuple *hv_Mean, HTuple *hv_StdDev)
{

    // Local iconic variables
    HObject  ho_LayerOutput, ho_SquaredLayerOutput;
    HObject  ho_MeanOfFeatureMaps, ho_MeanOfSquaredFeatureMaps;
    HObject  ho_UpdateScaled, ho_MeanOfFeatureMap, ho_MeanOfSquaredFeatureMap;

    // Local control variables
    HTuple  hv_Shape, hv_N, hv_C, hv_NumIterations;
    HTuple  hv_Index, hv_FirstSampleIdx, hv_LastSampleIdx, hv_DLSamplesBatch;
    HTuple  hv_DLResultBatch, hv_IndexSamples, hv_Iteration;
    HTuple  hv_SampleDict, hv_Var, hv_IndexC, hv_FeatureMapMean;
    HTuple  hv__, hv_FeatureMapSquaredMean;

    //Calculate the running mean and standard deviation of a
    //DL model layer. The layer output has the shape
    //N x C x H x W, where
    //- N is the batch size,
    //- C is number of channels, and
    //- H and W are the height and width, respectively.
    //
    GetDlModelLayerParam(hv_DLModelHandle, hv_LayerName, "shape", &hv_Shape);
    hv_N = ((const HTuple&)hv_Shape)[3];
    hv_C = ((const HTuple&)hv_Shape)[2];
    //Compute the average of the layer output and its square
    //over all samples.
    hv_NumIterations = ((hv_DLSamples.TupleLength())/(hv_N.TupleReal())).TupleCeil();
    {
        HTuple end_val13 = hv_NumIterations-1;
        HTuple step_val13 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val13, step_val13); hv_Index += step_val13)
        {
            hv_FirstSampleIdx = hv_Index*hv_N;
            hv_LastSampleIdx = (((hv_Index+1)*hv_N)-1).TupleMin2((hv_DLSamples.TupleLength())-1);
            hv_DLSamplesBatch = hv_DLSamples.TupleSelectRange(hv_FirstSampleIdx,hv_LastSampleIdx);
            ApplyDlModel(hv_DLModelHandle, hv_DLSamplesBatch, hv_LayerName, &hv_DLResultBatch);
            //
            {
                HTuple end_val19 = (hv_DLResultBatch.TupleLength())-1;
                HTuple step_val19 = 1;
                for (hv_IndexSamples=0; hv_IndexSamples.Continue(end_val19, step_val19); hv_IndexSamples += step_val19)
                {
                    hv_Iteration = (hv_Index*hv_N)+hv_IndexSamples;
                    //
                    hv_SampleDict = HTuple(hv_DLResultBatch[hv_IndexSamples]);
                    ho_LayerOutput = hv_SampleDict.TupleGetDictObject(hv_LayerName);
                    MultImage(ho_LayerOutput, ho_LayerOutput, &ho_SquaredLayerOutput, 1, 0);
                    //
                    if (0 != (int(hv_Iteration==0)))
                    {
                        ScaleImage(ho_LayerOutput, &ho_MeanOfFeatureMaps, 1.0/(hv_DLSamples.TupleLength()),
                                   0);
                        ScaleImage(ho_SquaredLayerOutput, &ho_MeanOfSquaredFeatureMaps, 1.0/(hv_DLSamples.TupleLength()),
                                   0);
                    }
                    else
                    {
                        ScaleImage(ho_LayerOutput, &ho_UpdateScaled, 1.0/(hv_DLSamples.TupleLength()),
                                   0);
                        AddImage(ho_MeanOfFeatureMaps, ho_UpdateScaled, &ho_MeanOfFeatureMaps, 1,
                                 0);
                        //
                        ScaleImage(ho_SquaredLayerOutput, &ho_UpdateScaled, 1.0/(hv_DLSamples.TupleLength()),
                                   0);
                        AddImage(ho_MeanOfSquaredFeatureMaps, ho_UpdateScaled, &ho_MeanOfSquaredFeatureMaps,
                                 1, 0);
                    }
                }
            }
        }
    }
    //
    (*hv_Mean) = HTuple(hv_C,0.0);
    hv_Var = HTuple(hv_C,0.0);
    //
    {
        HTuple end_val42 = hv_C-1;
        HTuple step_val42 = 1;
        for (hv_IndexC=0; hv_IndexC.Continue(end_val42, step_val42); hv_IndexC += step_val42)
        {
            //Compute Var[X] as E[X^2] - (E[X])^2.
            AccessChannel(ho_MeanOfFeatureMaps, &ho_MeanOfFeatureMap, hv_IndexC+1);
            Intensity(ho_MeanOfFeatureMap, ho_MeanOfFeatureMap, &hv_FeatureMapMean, &hv__);
            AccessChannel(ho_MeanOfSquaredFeatureMaps, &ho_MeanOfSquaredFeatureMap, hv_IndexC+1);
            Intensity(ho_MeanOfSquaredFeatureMap, ho_MeanOfSquaredFeatureMap, &hv_FeatureMapSquaredMean,
                      &hv__);
            (*hv_Mean)[hv_IndexC] = hv_FeatureMapMean;
            hv_Var[hv_IndexC] = hv_FeatureMapSquaredMean-(hv_FeatureMapMean*hv_FeatureMapMean);
        }
    }
    (*hv_StdDev) = hv_Var.TupleSqrt();
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Calculate evaluation measures based on the values of RunningMeasures and the settings in EvalParams.
void HalxAI:: calculate_evaluation_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                             HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_EvaluationType, hv_EvaluationResultTmp;
    HTuple  hv_PixelMeasures, hv_PixelMeasureValues, hv_ResultKeys;
    HTuple  hv_KeyIndex, hv___Tmp_Ctrl_Type;

    //
    //This procedure calculates the final measures depending on the evaluation type.
    //
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
    {
        calculate_image_anomaly_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
    }
    else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
    {
        calculate_image_classification_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("detection"))).TupleOr(int(hv_EvaluationType==HTuple("ocr_detection")))))
    {
        calculate_instance_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
        if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
        {
            calculate_ocr_detection_measures((*hv_EvaluationResult), &(*hv_EvaluationResult));
        }
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("segmentation"))).TupleOr(int(hv_EvaluationType==HTuple("3d_gripping_point_detection")))))
    {
        calculate_pixel_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
        if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
        {
            calculate_region_measures(hv_RunningMeasures, hv_EvalParams, &hv_EvaluationResultTmp);
            //Only report requested pixel and region measures.
            get_requested_pixel_measures(hv_EvalParams.TupleGetDictTuple("measures"), hv_EvaluationType,
                                         &hv_PixelMeasures);
            GetDictTuple((*hv_EvaluationResult), hv_PixelMeasures, &hv_PixelMeasureValues);
            SetDictTuple(hv_EvaluationResultTmp, hv_PixelMeasures, hv_PixelMeasureValues);
            (*hv_EvaluationResult) = hv_EvaluationResultTmp;
            calculate_running_gripping_point_measures(hv_RunningMeasures, hv_EvalParams,
                                                      &hv_EvaluationResultTmp);
            GetDictParam(hv_EvaluationResultTmp, "keys", HTuple(), &hv_ResultKeys);
            {
                HTuple end_val24 = (hv_ResultKeys.TupleLength())-1;
                HTuple step_val24 = 1;
                for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val24, step_val24); hv_KeyIndex += step_val24)
                {
                    GetDictParam(hv_EvaluationResultTmp, "key_data_type", HTuple(hv_ResultKeys[hv_KeyIndex]),
                                 &hv___Tmp_Ctrl_Type);
                    if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
                    {
                        SetDictObject(hv_EvaluationResultTmp.TupleGetDictObject(HTuple(hv_ResultKeys[hv_KeyIndex])),
                                      (*hv_EvaluationResult), HTuple(hv_ResultKeys[hv_KeyIndex]));
                    }
                    else
                    {
                        SetDictTuple((*hv_EvaluationResult), HTuple(hv_ResultKeys[hv_KeyIndex]),
                                     hv_EvaluationResultTmp.TupleGetDictTuple(HTuple(hv_ResultKeys[hv_KeyIndex])));
                    }
                }
            }
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
    {
        calculate_ocr_recognition_measures(hv_RunningMeasures, hv_EvalParams, &(*hv_EvaluationResult));
    }
    //
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Calculate anomaly measures based on RunningMeasures.
void HalxAI:: calculate_image_anomaly_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                                HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_CalcAnomalyHistogram, hv_CalcPrecision;
    HTuple  hv_CalcRecall, hv_CalcAbsoluteConfusionMatrix, hv_CalcRelativeConfusionMatrix;
    HTuple  hv_MeasuresExists, hv_Measures, hv_M, hv_AnomalyClassificationThresholdExists;
    HTuple  hv_AnomalyClassificationThreshold, hv_ImageIDs;
    HTuple  hv_AnomalyLabelIDs, hv_AnomalyScores, hv_OKIndices;
    HTuple  hv_NOKIndices, hv_HistoOKXValues, hv_HistoOKYValues;
    HTuple  hv_NumOKEvalData, hv_ImageLevelScoresOK, hv_HistoNOKXValues;
    HTuple  hv_HistoNOKYValues, hv_NumNOKEvalData, hv_ImageLevelScoresNOK;
    HTuple  hv_ScoreHistogram, hv_NumClasses, hv_ClassIDs, hv_AllPredictions;
    HTuple  hv_IndThreshold, hv_CurrentThresholdValue, hv_CurrentThresholdKey;
    HTuple  hv_Predictions, hv_AbsoluteConfustionMatrices, hv_AbsoluteConfusionMatrix;
    HTuple  hv_Rows, hv_Columns, hv_Value, hv_AbsoluteConfusionMatrixDictionary;
    HTuple  hv_RelativeConfustionMatrices, hv_RelativeConfusionMatrix;
    HTuple  hv_RelativeConfusionMatrixDictionary, hv_GlobalEvaluation;
    HTuple  hv_AllClassPrecisions, hv_AllMeanPrecisions, hv_AbsoluteConfusionMatrices;
    HTuple  hv_ClassPrecisions, hv_MatrixRowSumID, hv_MatrixColumnSumID;
    HTuple  hv_Index, hv_TruePositive, hv_SumPredictedClass;
    HTuple  hv_SumLabel, hv_ClassPrecision, hv_ValidClassPrecisions;
    HTuple  hv_MeanPrecision, hv_AllClassRecalls, hv_AllMeanRecalls;
    HTuple  hv_ClassRecalls, hv_ClassRecall, hv_ValidClassRecalls;
    HTuple  hv_MeanRecall;

    //
    //This procedure calculates the final summarizing image anomaly measures based on the running measures.
    //
    hv_CalcAnomalyHistogram = 1;
    hv_CalcPrecision = 0;
    hv_CalcRecall = 0;
    hv_CalcAbsoluteConfusionMatrix = 0;
    hv_CalcRelativeConfusionMatrix = 0;
    GetDictParam(hv_EvalParams, "key_exists", "measures", &hv_MeasuresExists);
    if (0 != hv_MeasuresExists)
    {
        GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
        {
            HTuple end_val11 = (hv_Measures.TupleLength())-1;
            HTuple step_val11 = 1;
            for (hv_M=0; hv_M.Continue(end_val11, step_val11); hv_M += step_val11)
            {
                if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("anomaly_score_histogram"))))
                {
                    //The default, just here for consistency.
                    hv_CalcAnomalyHistogram = 1;
                }
                else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("precision"))))
                {
                    hv_CalcPrecision = 1;
                    hv_CalcAbsoluteConfusionMatrix = 1;
                }
                else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("recall"))))
                {
                    hv_CalcRecall = 1;
                    hv_CalcAbsoluteConfusionMatrix = 1;
                }
                else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("absolute_confusion_matrix"))))
                {
                    hv_CalcAbsoluteConfusionMatrix = 1;
                }
                else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("relative_confusion_matrix"))))
                {
                    hv_CalcRelativeConfusionMatrix = 1;
                }
                else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
                {
                    hv_CalcPrecision = 1;
                    hv_CalcRecall = 1;
                    hv_CalcAbsoluteConfusionMatrix = 1;
                    hv_CalcRelativeConfusionMatrix = 1;
                }
                else
                {
                    throw HException(("Unknown Measure: "+HTuple(hv_Measures[hv_M]))+".");
                }
            }
        }
    }
    //
    GetDictParam(hv_EvalParams, "key_exists", "anomaly_classification_thresholds",
                 &hv_AnomalyClassificationThresholdExists);
    if (0 != hv_AnomalyClassificationThresholdExists)
    {
        GetDictTuple(hv_EvalParams, "anomaly_classification_thresholds", &hv_AnomalyClassificationThreshold);
    }
    else if (0 != (hv_CalcRelativeConfusionMatrix.TupleOr(hv_CalcAbsoluteConfusionMatrix)))
    {
        throw HException("A threshold value is needed to calculate a confusion matrix.");
    }
    //
    //Get and check values in RunningMeasures.
    //
    //Get image ids.
    GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
    //Get anomaly ids.
    GetDictTuple(hv_RunningMeasures, "anomaly_label_ids", &hv_AnomalyLabelIDs);
    //Get image scores.
    GetDictTuple(hv_RunningMeasures, "anomaly_scores", &hv_AnomalyScores);
    //
    //Calculate histograms.
    //
    //Find scores of 'ok' and 'nok' images.
    hv_OKIndices = hv_AnomalyLabelIDs.TupleFind(0);
    hv_NOKIndices = hv_AnomalyLabelIDs.TupleFind(1);
    if (0 != (HTuple(int(hv_OKIndices==-1)).TupleAnd(int(hv_NOKIndices==-1))))
    {
        throw HException("No data available for evaluation");
    }
    //
    //Calculate histogram for 'ok' images.
    hv_HistoOKXValues = HTuple();
    hv_HistoOKYValues = HTuple();
    hv_NumOKEvalData = 0;
    if (0 != (int(hv_OKIndices!=-1)))
    {
        hv_NumOKEvalData = hv_OKIndices.TupleLength();
        hv_ImageLevelScoresOK = HTuple(hv_AnomalyScores[hv_OKIndices]);
        hv_HistoOKXValues = hv_ImageLevelScoresOK.TupleSort();
        hv_HistoOKYValues = (HTuple::TupleGenSequence(hv_ImageLevelScoresOK.TupleLength(),1,-1).TupleReal())/(hv_ImageLevelScoresOK.TupleLength());
    }
    //
    //Calculate histogram for 'nok' images.
    hv_HistoNOKXValues = HTuple();
    hv_HistoNOKYValues = HTuple();
    hv_NumNOKEvalData = 0;
    if (0 != (int(hv_NOKIndices!=-1)))
    {
        hv_NumNOKEvalData = hv_NOKIndices.TupleLength();
        hv_ImageLevelScoresNOK = HTuple(hv_AnomalyScores[hv_NOKIndices]);
        hv_HistoNOKXValues = hv_ImageLevelScoresNOK.TupleSort();
        hv_HistoNOKYValues = (HTuple::TupleGenSequence(1,hv_ImageLevelScoresNOK.TupleLength(),1).TupleReal())/(hv_ImageLevelScoresNOK.TupleLength());
    }
    //
    //Create dictionary for the score histogram.
    CreateDict(&hv_ScoreHistogram);
    SetDictTuple(hv_ScoreHistogram, "ok_x", hv_HistoOKXValues);
    SetDictTuple(hv_ScoreHistogram, "ok_y", hv_HistoOKYValues);
    SetDictTuple(hv_ScoreHistogram, "nok_x", hv_HistoNOKXValues);
    SetDictTuple(hv_ScoreHistogram, "nok_y", hv_HistoNOKYValues);
    //
    //Set the score histogram in the results dictionary.
    CreateDict(&(*hv_EvaluationResult));
    SetDictTuple((*hv_EvaluationResult), "anomaly_score_histogram", hv_ScoreHistogram);
    //
    //Get Predictions according to given Threshold value(s).
    //Remember, precision and recall base on the absolute confusion matrix.
    if (0 != (hv_CalcAbsoluteConfusionMatrix.TupleOr(hv_CalcRelativeConfusionMatrix)))
    {
        GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
        GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
        CreateDict(&hv_AllPredictions);
        {
            HTuple end_val100 = (hv_AnomalyClassificationThreshold.TupleLength())-1;
            HTuple step_val100 = 1;
            for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val100, step_val100); hv_IndThreshold += step_val100)
            {
                hv_CurrentThresholdValue = HTuple(hv_AnomalyClassificationThreshold[hv_IndThreshold]);
                hv_CurrentThresholdKey = hv_IndThreshold.TupleString(".3d");
                hv_Predictions = hv_AnomalyScores.TupleGreaterEqualElem(hv_CurrentThresholdValue);
                SetDictTuple(hv_AllPredictions, hv_CurrentThresholdKey, hv_Predictions);
            }
        }
    }
    //
    //Calculate absolute confusion matrix.
    if (0 != hv_CalcAbsoluteConfusionMatrix)
    {
        hv_AbsoluteConfustionMatrices = HTuple();
        {
            HTuple end_val111 = (hv_AnomalyClassificationThreshold.TupleLength())-1;
            HTuple step_val111 = 1;
            for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val111, step_val111); hv_IndThreshold += step_val111)
            {
                hv_CurrentThresholdValue = HTuple(hv_AnomalyClassificationThreshold[hv_IndThreshold]);
                hv_CurrentThresholdKey = hv_IndThreshold.TupleString(".3d");
                GetDictTuple(hv_AllPredictions, hv_CurrentThresholdKey, &hv_Predictions);
                gen_confusion_matrix(hv_AnomalyLabelIDs, hv_Predictions, (HTuple("display_matrix").Append("return_matrix")),
                                     (HTuple("none").Append("absolute")), HTuple(), &hv_AbsoluteConfusionMatrix);
                GetSizeMatrix(hv_AbsoluteConfusionMatrix, &hv_Rows, &hv_Columns);
                if (0 != (HTuple(HTuple(int(hv_NumOKEvalData<=0)).TupleOr(int(hv_NumNOKEvalData<=0))).TupleAnd(HTuple(int(hv_Rows<2)).TupleOr(int(hv_Columns<2)))))
                {
                    //Patch matrix to 2x2 in case only 'ok' or only 'nok'
                    //data is used for evaluation.
                    GetValueMatrix(hv_AbsoluteConfusionMatrix, 0, 0, &hv_Value);
                    CreateMatrix(2, 2, 0, &hv_AbsoluteConfusionMatrix);
                    if (0 != (int(hv_NumOKEvalData<=0)))
                    {
                        SetValueMatrix(hv_AbsoluteConfusionMatrix, 0, 1, (hv_Predictions.TupleLength())-hv_Value);
                        SetValueMatrix(hv_AbsoluteConfusionMatrix, 1, 1, hv_Value);
                    }
                    if (0 != (int(hv_NumNOKEvalData<=0)))
                    {
                        SetValueMatrix(hv_AbsoluteConfusionMatrix, 0, 0, hv_Value);
                        SetValueMatrix(hv_AbsoluteConfusionMatrix, 1, 0, (hv_Predictions.TupleLength())-hv_Value);
                    }
                }
                CreateDict(&hv_AbsoluteConfusionMatrixDictionary);
                SetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "confusion_matrix", hv_AbsoluteConfusionMatrix);
                SetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "threshold", hv_CurrentThresholdValue);
                hv_AbsoluteConfustionMatrices[hv_IndThreshold] = hv_AbsoluteConfusionMatrixDictionary;
            }
        }
        SetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", hv_AbsoluteConfustionMatrices);
    }
    //
    //Calculate relative confusion matrix.
    if (0 != hv_CalcRelativeConfusionMatrix)
    {
        hv_RelativeConfustionMatrices = HTuple();
        {
            HTuple end_val142 = (hv_AnomalyClassificationThreshold.TupleLength())-1;
            HTuple step_val142 = 1;
            for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val142, step_val142); hv_IndThreshold += step_val142)
            {
                hv_CurrentThresholdValue = HTuple(hv_AnomalyClassificationThreshold[hv_IndThreshold]);
                hv_CurrentThresholdKey = hv_IndThreshold.TupleString(".3d");
                GetDictTuple(hv_AllPredictions, hv_CurrentThresholdKey, &hv_Predictions);
                gen_confusion_matrix(hv_AnomalyLabelIDs, hv_Predictions, (HTuple("display_matrix").Append("return_matrix")),
                                     (HTuple("none").Append("relative")), HTuple(), &hv_RelativeConfusionMatrix);
                GetSizeMatrix(hv_RelativeConfusionMatrix, &hv_Rows, &hv_Columns);
                if (0 != (HTuple(HTuple(int(hv_NumOKEvalData<=0)).TupleOr(int(hv_NumNOKEvalData<=0))).TupleAnd(HTuple(int(hv_Rows<2)).TupleOr(int(hv_Columns<2)))))
                {
                    //Patch matrix to 2x2 in case only 'ok' or only 'nok'
                    //data is used for evaluation.
                    GetValueMatrix(hv_RelativeConfusionMatrix, 0, 0, &hv_Value);
                    CreateMatrix(2, 2, 0, &hv_RelativeConfusionMatrix);
                    if (0 != (int(hv_NumOKEvalData<=0)))
                    {
                        SetValueMatrix(hv_RelativeConfusionMatrix, 0, 1, 1.0-hv_Value);
                        SetValueMatrix(hv_RelativeConfusionMatrix, 1, 1, hv_Value);
                    }
                    if (0 != (int(hv_NumNOKEvalData<=0)))
                    {
                        SetValueMatrix(hv_RelativeConfusionMatrix, 0, 0, hv_Value);
                        SetValueMatrix(hv_RelativeConfusionMatrix, 1, 0, 1.0-hv_Value);
                    }
                }
                CreateDict(&hv_RelativeConfusionMatrixDictionary);
                SetDictTuple(hv_RelativeConfusionMatrixDictionary, "confusion_matrix", hv_RelativeConfusionMatrix);
                SetDictTuple(hv_RelativeConfusionMatrixDictionary, "threshold", hv_CurrentThresholdValue);
                hv_RelativeConfustionMatrices[hv_IndThreshold] = hv_RelativeConfusionMatrixDictionary;
            }
        }
        SetDictTuple((*hv_EvaluationResult), "relative_confusion_matrix", hv_RelativeConfustionMatrices);
    }
    //
    if (0 != (hv_CalcPrecision.TupleOr(hv_CalcRecall)))
    {
        CreateDict(&hv_GlobalEvaluation);
    }
    //Calculate precision.
    if (0 != hv_CalcPrecision)
    {
        hv_AllClassPrecisions = HTuple();
        hv_AllMeanPrecisions = HTuple();
        GetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", &hv_AbsoluteConfusionMatrices);
        {
            HTuple end_val178 = (hv_AbsoluteConfusionMatrices.TupleLength())-1;
            HTuple step_val178 = 1;
            for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val178, step_val178); hv_IndThreshold += step_val178)
            {
                hv_AbsoluteConfusionMatrixDictionary = HTuple(hv_AbsoluteConfusionMatrices[hv_IndThreshold]);
                GetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "confusion_matrix", &hv_AbsoluteConfusionMatrix);
                hv_ClassPrecisions = HTuple();
                SumMatrix(hv_AbsoluteConfusionMatrix, "rows", &hv_MatrixRowSumID);
                SumMatrix(hv_AbsoluteConfusionMatrix, "columns", &hv_MatrixColumnSumID);
                {
                    HTuple end_val184 = hv_NumClasses-1;
                    HTuple step_val184 = 1;
                    for (hv_Index=0; hv_Index.Continue(end_val184, step_val184); hv_Index += step_val184)
                    {
                        //Compute the precision for every selected class.
                        GetValueMatrix(hv_AbsoluteConfusionMatrix, HTuple(hv_ClassIDs[hv_Index]),
                                       HTuple(hv_ClassIDs[hv_Index]), &hv_TruePositive);
                        GetValueMatrix(hv_MatrixRowSumID, HTuple(hv_ClassIDs[hv_Index]), 0, &hv_SumPredictedClass);
                        GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_ClassIDs[hv_Index]), &hv_SumLabel);
                        if (0 != (int(hv_SumLabel<=0)))
                        {
                            //Invalid per-class precision.
                            hv_ClassPrecision = -1.0;
                        }
                        else if (0 != (int(hv_SumPredictedClass==0)))
                        {
                            hv_ClassPrecision = 0.0;
                        }
                        else
                        {
                            hv_ClassPrecision = hv_TruePositive/hv_SumPredictedClass;
                        }
                        hv_ClassPrecisions = hv_ClassPrecisions.TupleConcat(hv_ClassPrecision);
                    }
                }
                TupleSelectMask(hv_ClassPrecisions, hv_ClassPrecisions.TupleGreaterEqualElem(0.0),
                                &hv_ValidClassPrecisions);
                hv_MeanPrecision = hv_ValidClassPrecisions.TupleMean();
                hv_AllClassPrecisions = hv_AllClassPrecisions.TupleConcat(hv_ClassPrecisions);
                hv_AllMeanPrecisions = hv_AllMeanPrecisions.TupleConcat(hv_MeanPrecision);
                ClearMatrix(hv_MatrixRowSumID);
            }
        }
        SetDictTuple(hv_GlobalEvaluation, "precision_per_class", hv_AllClassPrecisions);
        SetDictTuple(hv_GlobalEvaluation, "mean_precision", hv_AllMeanPrecisions);
    }
    //
    //Calculate recall.
    if (0 != hv_CalcRecall)
    {
        hv_AllClassRecalls = HTuple();
        hv_AllMeanRecalls = HTuple();
        GetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", &hv_AbsoluteConfustionMatrices);
        {
            HTuple end_val214 = (hv_AbsoluteConfustionMatrices.TupleLength())-1;
            HTuple step_val214 = 1;
            for (hv_IndThreshold=0; hv_IndThreshold.Continue(end_val214, step_val214); hv_IndThreshold += step_val214)
            {
                hv_AbsoluteConfusionMatrixDictionary = HTuple(hv_AbsoluteConfustionMatrices[hv_IndThreshold]);
                GetDictTuple(hv_AbsoluteConfusionMatrixDictionary, "confusion_matrix", &hv_AbsoluteConfusionMatrix);
                hv_ClassRecalls = HTuple();
                SumMatrix(hv_AbsoluteConfusionMatrix, "columns", &hv_MatrixColumnSumID);
                {
                    HTuple end_val219 = hv_NumClasses-1;
                    HTuple step_val219 = 1;
                    for (hv_Index=0; hv_Index.Continue(end_val219, step_val219); hv_Index += step_val219)
                    {
                        //Compute the recall for every selected class.
                        GetValueMatrix(hv_AbsoluteConfusionMatrix, HTuple(hv_ClassIDs[hv_Index]),
                                       HTuple(hv_ClassIDs[hv_Index]), &hv_TruePositive);
                        GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_ClassIDs[hv_Index]), &hv_SumLabel);
                        if (0 != (int(hv_SumLabel==0)))
                        {
                            //Invalid per-class recall.
                            hv_ClassRecall = -1.0;
                        }
                        else
                        {
                            hv_ClassRecall = hv_TruePositive/hv_SumLabel;
                        }
                        hv_ClassRecalls = hv_ClassRecalls.TupleConcat(hv_ClassRecall);
                    }
                }
                TupleSelectMask(hv_ClassRecalls, hv_ClassRecalls.TupleGreaterEqualElem(0.0),
                                &hv_ValidClassRecalls);
                hv_MeanRecall = hv_ValidClassRecalls.TupleMean();
                hv_AllClassRecalls = hv_AllClassRecalls.TupleConcat(hv_ClassRecalls);
                hv_AllMeanRecalls = hv_AllMeanRecalls.TupleConcat(hv_MeanRecall);
                ClearMatrix(hv_MatrixColumnSumID);
                //
            }
        }
        SetDictTuple(hv_GlobalEvaluation, "recall_per_class", hv_AllClassRecalls);
        SetDictTuple(hv_GlobalEvaluation, "mean_recall", hv_AllMeanRecalls);
    }
    //
    if (0 != (hv_CalcPrecision.TupleOr(hv_CalcRecall)))
    {
        SetDictTuple((*hv_EvaluationResult), "global_evaluation", hv_GlobalEvaluation);
    }
    //
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Calculate image classification measures based on RunningMeasures.
void HalxAI:: calculate_image_classification_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                                       HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_TopKErrorKs, hv_CalcPrecision, hv_CalcRecall;
    HTuple  hv_CalcFScore, hv_CalcAbsoluteConfusionMatrix, hv_CalcRelativeConfusionMatrix;
    HTuple  hv_Measures, hv_RegExpTopKError, hv_M, hv_ComputeTopKError;
    HTuple  hv_K, hv_ClassIDs, hv_KeyExists, hv_ClassesToEvaluate;
    HTuple  hv_ClassIDsToEvaluate, hv_ClassNames, hv_Index;
    HTuple  hv_Position, hv_ImageIDs, hv_ImageLabelIDs, hv_Predictions;
    HTuple  hv_TopKPredictions, hv_EvalIndex, hv_CurrentEvalClass;
    HTuple  hv_IndexClass, hv_EvaluatedSamples, hv_ConfusionMatrix;
    HTuple  hv_RelativeConfusionMatrix, hv_EvalClassID, hv_KIndex;
    HTuple  hv_Indices, hv_TopKError, hv_NumClasses, hv_ClassPrecisions;
    HTuple  hv_MatrixRowSumID, hv_TruePositive, hv_SumPredictedClass;
    HTuple  hv_ClassPrecision, hv_Precision, hv_ClassRecalls;
    HTuple  hv_MatrixColumnSumID, hv_SumLabel, hv_ClassRecall;
    HTuple  hv_Recall, hv_ClassFScores, hv_SumPrecisionRecall;
    HTuple  hv_PositiveIndices, hv_FScore, hv_KeyName;

    //
    //This procedure calculates the final summarizing image classification measures based on the running measures.
    //
    //Set default values.
    hv_TopKErrorKs = HTuple();
    hv_CalcPrecision = 0;
    hv_CalcRecall = 0;
    hv_CalcFScore = 0;
    hv_CalcAbsoluteConfusionMatrix = 0;
    hv_CalcRelativeConfusionMatrix = 0;
    //
    //Check which measures are to be calculated.
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    hv_RegExpTopKError = "top([0-9]+)_error";
    {
        HTuple end_val14 = (hv_Measures.TupleLength())-1;
        HTuple step_val14 = 1;
        for (hv_M=0; hv_M.Continue(end_val14, step_val14); hv_M += step_val14)
        {
            hv_ComputeTopKError = HTuple(hv_Measures[hv_M]).TupleRegexpTest("top([0-9]+)_error");
            if (0 != hv_ComputeTopKError)
            {
                hv_K = (HTuple(hv_Measures[hv_M]).TupleRegexpMatch(hv_RegExpTopKError)).TupleNumber();
                hv_TopKErrorKs = (hv_TopKErrorKs.TupleConcat(hv_K)).TupleSort();
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("precision"))))
            {
                hv_CalcPrecision = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("recall"))))
            {
                hv_CalcRecall = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("f_score"))))
            {
                hv_CalcFScore = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("absolute_confusion_matrix"))))
            {
                hv_CalcAbsoluteConfusionMatrix = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("relative_confusion_matrix"))))
            {
                hv_CalcRelativeConfusionMatrix = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
            {
                hv_TopKErrorKs = (hv_TopKErrorKs.TupleConcat(1)).TupleSort();
                hv_CalcPrecision = 1;
                hv_CalcRecall = 1;
                hv_CalcFScore = 1;
                hv_CalcAbsoluteConfusionMatrix = 1;
                hv_CalcRelativeConfusionMatrix = 1;
            }
            else
            {
                throw HException("Unknown image classification measure: "+HTuple(hv_Measures[hv_M]));
            }
        }
    }
    //
    //Initialize output dictionary and get necessary evaluation parameters.
    CreateDict(&(*hv_EvaluationResult));
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    GetDictParam(hv_EvalParams, "key_exists", "class_names_to_evaluate", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
        GetDictTuple(hv_EvalParams, "class_names_to_evaluate", &hv_ClassesToEvaluate);
        hv_ClassIDsToEvaluate = HTuple();
        GetDictTuple(hv_EvalParams, "class_names", &hv_ClassNames);
        {
            HTuple end_val49 = (hv_ClassesToEvaluate.TupleLength())-1;
            HTuple step_val49 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val49, step_val49); hv_Index += step_val49)
            {
                hv_Position = ((HTuple("global").TupleConcat(hv_ClassNames)).TupleEqualElem(HTuple(hv_ClassesToEvaluate[hv_Index]))).TupleFind(1);
                if (0 != (HTuple(int(hv_Position==-1)).TupleOr(int(hv_Position==HTuple()))))
                {
                    throw HException("Invalid entry in  'class_names_to_evaluate': "+HTuple((HTuple("global").TupleConcat(hv_ClassesToEvaluate))[hv_Index]));
                }
                hv_ClassIDsToEvaluate = hv_ClassIDsToEvaluate.TupleConcat(HTuple((HTuple("global").TupleConcat(hv_ClassIDs))[hv_Position]));
            }
        }
        SetDictTuple(hv_EvalParams, "class_ids_to_evaluate", hv_ClassIDsToEvaluate);
    }
    GetDictTuple(hv_EvalParams, "class_ids_to_evaluate", &hv_ClassIDsToEvaluate);
    //
    //Get and check values in RunningMeasures.
    GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
    GetDictTuple(hv_RunningMeasures, "image_label_ids", &hv_ImageLabelIDs);
    GetDictTuple(hv_RunningMeasures, "top1_predictions", &hv_Predictions);
    GetDictTuple(hv_RunningMeasures, "topk_predictions", &hv_TopKPredictions);
    //
    //Check if needed classes appear in image label IDs.
    //For the confusion matrices, all classes need to be represented.
    hv_CalcAbsoluteConfusionMatrix = HTuple(HTuple(hv_CalcPrecision.TupleOr(hv_CalcRecall)).TupleOr(hv_CalcFScore)).TupleOr(hv_CalcAbsoluteConfusionMatrix);
    hv_CalcRelativeConfusionMatrix = HTuple(HTuple(hv_CalcPrecision.TupleOr(hv_CalcRecall)).TupleOr(hv_CalcFScore)).TupleOr(hv_CalcRelativeConfusionMatrix);
    if (0 != (hv_CalcAbsoluteConfusionMatrix.TupleOr(hv_CalcRelativeConfusionMatrix)))
    {
        if (0 != (int(((hv_ImageLabelIDs.TupleSort()).TupleUniq())!=(hv_ClassIDs.TupleSort()))))
        {
            throw HException("Not all classes are represented in the ground truth labels. \nPlease check your data split.");
        }
    }
    //For top-K errors, the evaluated classes need to be represented.
    if (0 != (int(hv_TopKErrorKs!=HTuple())))
    {
        {
            HTuple end_val77 = (hv_ClassIDsToEvaluate.TupleLength())-1;
            HTuple step_val77 = 1;
            for (hv_EvalIndex=0; hv_EvalIndex.Continue(end_val77, step_val77); hv_EvalIndex += step_val77)
            {
                hv_CurrentEvalClass = HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex]);
                if (0 != (int(hv_CurrentEvalClass!=HTuple("global"))))
                {
                    hv_IndexClass = hv_ImageLabelIDs.TupleFind(hv_CurrentEvalClass);
                    if (0 != (HTuple(int(hv_IndexClass==-1)).TupleOr(int(hv_IndexClass==HTuple()))))
                    {
                        throw HException(("The evaluated class ID "+hv_CurrentEvalClass)+" is not represented in the ground truth labels.");
                    }
                }
            }
        }
    }
    //
    //Set image IDs, image label IDs, and top1-predictions to of evaluated samples EvaluationResult.
    CreateDict(&hv_EvaluatedSamples);
    SetDictTuple(hv_EvaluatedSamples, "image_ids", hv_ImageIDs);
    SetDictTuple(hv_EvaluatedSamples, "image_label_ids", hv_ImageLabelIDs);
    SetDictTuple(hv_EvaluatedSamples, "top1_predictions", hv_Predictions);
    SetDictTuple((*hv_EvaluationResult), "evaluated_samples", hv_EvaluatedSamples);
    //
    //Calculate absolute confusion matrix if needed and set it to EvaluationResult.
    if (0 != hv_CalcAbsoluteConfusionMatrix)
    {
        gen_confusion_matrix(hv_ImageLabelIDs, hv_Predictions, "display_matrix", "none",
                             HTuple(), &hv_ConfusionMatrix);
        SetDictTuple((*hv_EvaluationResult), "absolute_confusion_matrix", hv_ConfusionMatrix);
    }
    //
    //Calculate relative confusion matrix.
    if (0 != hv_CalcRelativeConfusionMatrix)
    {
        gen_confusion_matrix(hv_ImageLabelIDs, hv_Predictions, (HTuple("display_matrix").Append("return_matrix")),
                             (HTuple("none").Append("relative")), HTuple(), &hv_RelativeConfusionMatrix);
        SetDictTuple((*hv_EvaluationResult), "relative_confusion_matrix", hv_RelativeConfusionMatrix);
    }
    //
    // Calculate measures for every class to be evaluated.
    {
        HTuple end_val108 = (hv_ClassIDsToEvaluate.TupleLength())-1;
        HTuple step_val108 = 1;
        for (hv_EvalIndex=0; hv_EvalIndex.Continue(end_val108, step_val108); hv_EvalIndex += step_val108)
        {
            hv_CurrentEvalClass = HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex]);
            CreateDict(&hv_EvalClassID);
            //
            //Calculate top-K errors.
            {
                HTuple end_val113 = (hv_TopKErrorKs.TupleLength())-1;
                HTuple step_val113 = 1;
                for (hv_KIndex=0; hv_KIndex.Continue(end_val113, step_val113); hv_KIndex += step_val113)
                {
                    hv_K = HTuple(hv_TopKErrorKs[hv_KIndex]);
                    if (0 != (int(hv_CurrentEvalClass==HTuple("global"))))
                    {
                        hv_Indices = HTuple::TupleGenSequence(0,(hv_ImageLabelIDs.TupleLength())-1,1);
                    }
                    else
                    {
                        hv_Indices = hv_ImageLabelIDs.TupleFind(hv_CurrentEvalClass);
                    }
                    compute_top_k_error(HTuple(hv_ImageLabelIDs[hv_Indices]), HTuple(hv_TopKPredictions[hv_Indices]),
                                        hv_K, &hv_TopKError);
                    SetDictTuple(hv_EvalClassID, ("top"+hv_K)+"_error", hv_TopKError);
                }
            }
            //
            if (0 != (int(hv_CurrentEvalClass==HTuple("global"))))
            {
                //Compute the mean of the measures for all classes.
                hv_NumClasses = hv_ClassIDs.TupleLength();
                hv_IndexClass = hv_ClassIDs;
            }
            else
            {
                //Compute the measures for a certain class.
                hv_NumClasses = 1;
                hv_IndexClass = hv_ClassIDs.TupleFind(hv_CurrentEvalClass);
            }
            //
            //Calculate prediction.
            if (0 != (hv_CalcPrecision.TupleOr(hv_CalcFScore)))
            {
                hv_ClassPrecisions = HTuple();
                SumMatrix(hv_ConfusionMatrix, "rows", &hv_MatrixRowSumID);
                {
                    HTuple end_val138 = hv_NumClasses-1;
                    HTuple step_val138 = 1;
                    for (hv_Index=0; hv_Index.Continue(end_val138, step_val138); hv_Index += step_val138)
                    {
                        //Compute the precision for every selected class.
                        GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]),
                                       &hv_TruePositive);
                        GetValueMatrix(hv_MatrixRowSumID, HTuple(hv_IndexClass[hv_Index]), 0, &hv_SumPredictedClass);
                        if (0 != (int(hv_SumPredictedClass==0)))
                        {
                            hv_ClassPrecision = 0;
                        }
                        else
                        {
                            hv_ClassPrecision = hv_TruePositive/hv_SumPredictedClass;
                        }
                        hv_ClassPrecisions = hv_ClassPrecisions.TupleConcat(hv_ClassPrecision);
                    }
                }
                hv_Precision = hv_ClassPrecisions.TupleMean();
                ClearMatrix(hv_MatrixRowSumID);
                if (0 != (int(hv_NumClasses==1)))
                {
                    SetDictTuple(hv_EvalClassID, "precision", hv_Precision);
                }
                else
                {
                    SetDictTuple(hv_EvalClassID, "mean_precision", hv_Precision);
                    SetDictTuple(hv_EvalClassID, "precision_per_class", hv_ClassPrecisions);
                }
            }
            //
            //Calculate recall.
            if (0 != (hv_CalcRecall.TupleOr(hv_CalcFScore)))
            {
                hv_ClassRecalls = HTuple();
                SumMatrix(hv_ConfusionMatrix, "columns", &hv_MatrixColumnSumID);
                {
                    HTuple end_val163 = hv_NumClasses-1;
                    HTuple step_val163 = 1;
                    for (hv_Index=0; hv_Index.Continue(end_val163, step_val163); hv_Index += step_val163)
                    {
                        //Compute the recall for every class.
                        GetValueMatrix(hv_ConfusionMatrix, HTuple(hv_IndexClass[hv_Index]), HTuple(hv_IndexClass[hv_Index]),
                                       &hv_TruePositive);
                        GetValueMatrix(hv_MatrixColumnSumID, 0, HTuple(hv_IndexClass[hv_Index]),
                                       &hv_SumLabel);
                        hv_ClassRecall = hv_TruePositive/hv_SumLabel;
                        hv_ClassRecalls = hv_ClassRecalls.TupleConcat(hv_ClassRecall);
                    }
                }
                hv_Recall = hv_ClassRecalls.TupleMean();
                ClearMatrix(hv_MatrixColumnSumID);
                if (0 != (int(hv_NumClasses==1)))
                {
                    SetDictTuple(hv_EvalClassID, "recall", hv_Recall);
                }
                else
                {
                    SetDictTuple(hv_EvalClassID, "mean_recall", hv_Recall);
                    SetDictTuple(hv_EvalClassID, "recall_per_class", hv_ClassRecalls);
                }
            }
            //
            //Calculate F-score.
            if (0 != hv_CalcFScore)
            {
                TupleGenConst(hv_ClassPrecisions.TupleLength(), 0.0, &hv_ClassFScores);
                hv_SumPrecisionRecall = hv_ClassPrecisions+hv_ClassRecalls;
                hv_PositiveIndices = (hv_SumPrecisionRecall.TupleNotEqualElem(0.0)).TupleFind(1);
                if (0 != (HTuple(int(hv_PositiveIndices!=-1)).TupleAnd(int(hv_PositiveIndices!=HTuple()))))
                {
                    hv_ClassFScores[hv_PositiveIndices] = ((2*HTuple(hv_ClassPrecisions[hv_PositiveIndices]))*HTuple(hv_ClassRecalls[hv_PositiveIndices]))/HTuple(hv_SumPrecisionRecall[hv_PositiveIndices]);
                }
                hv_FScore = hv_ClassFScores.TupleMean();
                if (0 != (int(hv_NumClasses==1)))
                {
                    SetDictTuple(hv_EvalClassID, "f_score", hv_FScore);
                }
                else
                {
                    SetDictTuple(hv_EvalClassID, "mean_f_score", hv_FScore);
                    SetDictTuple(hv_EvalClassID, "f_score_per_class", hv_ClassFScores);
                }
            }
            //
            //Set evaluation results for current class ID.
            hv_KeyName = HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex]);
            if (0 != (int(HTuple(hv_ClassIDsToEvaluate[hv_EvalIndex])!=HTuple("global"))))
            {
                hv_KeyName = "class_id_"+hv_KeyName;
            }
            SetDictTuple((*hv_EvaluationResult), hv_KeyName, hv_EvalClassID);
        }
    }
    //
    return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Calculate instance measures based on RunningMeasures.
void HalxAI:: calculate_instance_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                           HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_CalcClassAP, hv_CalcMeanAP, hv_CalcSoAP;
    HTuple  hv_EvalType, hv_InstanceType, hv_Measures, hv_M;
    HTuple  hv_ClassIDs, hv_NumClasses, hv_MaxNumDetections;
    HTuple  hv_AreaRanges, hv_IoUThresholds, hv_DetailedEvaluation;
    HTuple  hv_InterpolatePRCurves, hv_KeyExists, hv_AreaNames;
    HTuple  hv_MinAreas, hv_MaxAreas, hv_RecThreshs, hv_MDIdx;
    HTuple  hv_MaxNum, hv_MaxNumStr, hv_CurrentRunningMeasures;
    HTuple  hv_PerMaxNumEvaluationResult, hv_AreaIdx, hv_MinArea;
    HTuple  hv_MaxArea, hv_AreaName, hv_AreaRunningMeasures;
    HTuple  hv_PerClassNumGt, hv_PerClassNumPred, hv_PerClassConfidence;
    HTuple  hv_PerClassNumGtIgnore, hv_CurrentEvaluationResult;
    HTuple  hv_ITIdx, hv_PerIoUAP, hv_PerIoUSoAP, hv_PerIoUDetailedEvaluation;
    HTuple  hv_ClsIdx, hv_PerClassDetailedEvaluation, hv_DetectionConfusionMatrix;
    HTuple  hv_PerIoUMeasure, hv_NumImgIDsWithFN, hv_NumImgIDsWithFP;
    HTuple  hv_ImgIDsWithFN, hv_ImgIDsWithFP, hv_ClassMAPDict;
    HTuple  hv_ClassMSoAPDict, hv_ClassesWithGt, hv_PerClassMAP;
    HTuple  hv_PerIoUMAP, hv_PerClassMSoAP, hv_PerIoUMSoAP;
    HTuple  hv_PerIoUNumClassesWithTP, hv_PerIoUTP, hv_PerIoUFN;
    HTuple  hv_PerIoUFP, hv_PerIoUFPClass, hv_PerIoUFPBackground;
    HTuple  hv_PerIoUFPLocalization, hv_PerIoUFPDuplicate, hv_PerIoUFPMultiple;
    HTuple  hv_PerIoUSoAPClass, hv_PerIoUSoAPLocalization, hv_PerIoUSoAPDuplicate;
    HTuple  hv_PerIoUSoAPMultiple, hv_PerIoUNumClassesWithFPClass;
    HTuple  hv_PerIoUNumClassesWithFPLocalization, hv_PerIoUNumClassesWithFPDuplicate;
    HTuple  hv_PerIoUNumClassesWithFPMultiple, hv_ClassAPPerIoU;
    HTuple  hv_ClassSoAPPerIoU, hv_NumGt, hv_NumGtIgnore, hv_NumPred;
    HTuple  hv_Confidences, hv_SortIdxs, hv_CurrentClassMeasures;
    HTuple  hv_IsTP, hv_Ignore, hv_NoIgnoreIdxs, hv_IsFP, hv_AccumulatedIsTP;
    HTuple  hv_AccumulatedIsFP, hv_Recall, hv_Precision, hv_InterpolatedPrecision;
    HTuple  hv_PIdx, hv_PrecisionAtRecThreshs, hv_RTIdx, hv_RecQuantile;
    HTuple  hv_AOD, hv_IdxsTP, hv_IsFPClass, hv_IsFPBackground;
    HTuple  hv_IsFPLocalization, hv_IsFPDuplicate, hv_IsFPMultiple;
    HTuple  hv_NumTP, hv_NumFP, hv_NumFN, hv_NumFPClass, hv_NumFPBackground;
    HTuple  hv_NumFPLocalization, hv_NumFPDuplicate, hv_NumFPMultiple;
    HTuple  hv_IndicesWithClassConfusion, hv_IsFPClassIdxs;
    HTuple  hv_ClassIdxsConfused, hv_Idx, hv_NumConfusedThisIdx;
    HTuple  hv_AODClass, hv_IdxsClass, hv_ResSoAPClass, hv_AODLocalization;
    HTuple  hv_IdxsLocalization, hv_ResSoAPLocalization, hv_AODDuplicate;
    HTuple  hv_IdxsDuplicate, hv_ResSoAPDuplicate, hv_AODMultiple;
    HTuple  hv_IdxsMultiple, hv_ResSoAPMultiple, hv_SoAPIoUIdxsPositive;
    HTuple  hv_MeanClassAP, hv_MeanClassSoAP, hv_MAP, hv_MSoAP;
    HTuple  hv_IoUsWithTP, hv_MSoAPAll, hv_NumSoAPAll, hv_IoUsWithFPClass;
    HTuple  hv_IoUsWithFPLocalization, hv_IoUsWithFPDuplicate;
    HTuple  hv_IoUsWithFPMultiple;

    //
    //This procedure calculates the final summarizing instance measures based on the running measures.
    //
    //Set default values.
    hv_CalcClassAP = 0;
    hv_CalcMeanAP = 0;
    hv_CalcSoAP = 0;
    //Check which measures are to be calculated.
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvalType);
    GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    {
        HTuple end_val11 = (hv_Measures.TupleLength())-1;
        HTuple step_val11 = 1;
        for (hv_M=0; hv_M.Continue(end_val11, step_val11); hv_M += step_val11)
        {
            if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("mean_ap"))))
            {
                hv_CalcMeanAP = 1;
                //As we need to calculate the class APs anyway, we also write them out.
                hv_CalcClassAP = 1;
            }
            else if (0 != (HTuple(int(HTuple(hv_Measures[hv_M])==HTuple("soap"))).TupleAnd(int(hv_InstanceType==HTuple("rectangle2")))))
            {
                hv_CalcSoAP = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
            {
                hv_CalcClassAP = 1;
                hv_CalcMeanAP = 1;
                if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
                {
                    hv_CalcSoAP = 1;
                }
            }
            else
            {
                if (0 != (HTuple(int(hv_EvalType==HTuple("ocr_detection"))).TupleAnd(HTuple(HTuple(int(HTuple(hv_Measures[hv_M])==HTuple("recall"))).TupleOr(int(HTuple(hv_Measures[hv_M])==HTuple("precision")))).TupleOr(int(HTuple(hv_Measures[hv_M])==HTuple("f_score"))))))
                {
                    hv_CalcMeanAP = 1;
                    hv_CalcClassAP = 1;
                    continue;
                }
                else
                {
                    throw HException("Unknown Instance Measure: "+HTuple(hv_Measures[hv_M]));
                }
            }
        }
    }
    //*
    //Dependencies of measures:
    //
    //Recall (per-class)       *                   --> AP per class --> mAP
    //Precision (per-class)  /
    //
    //*
    //Initialize output dictionary and get necessary evaluation parameters.
    CreateDict(&(*hv_EvaluationResult));
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
    GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
    GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
    GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IoUThresholds);
    //Check if a detailed evaluation should be done and if PR-curves should be interpolated.
    hv_DetailedEvaluation = 0;
    hv_InterpolatePRCurves = 0;
    GetDictParam(hv_EvalParams, "key_exists", (HTuple("detailed_evaluation").Append("interpolate_pr_curves")),
                 &hv_KeyExists);
    if (0 != (HTuple(hv_KeyExists[0])))
    {
        GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
    }
    if (0 != (HTuple(hv_KeyExists[1])))
    {
        GetDictTuple(hv_EvalParams, "interpolate_pr_curves", &hv_InterpolatePRCurves);
    }
    //
    //Get information about area ranges.
    GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
    GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
    GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
    //
    //Equidistant thresholds used to approximate the area under the Precision-Recall curve.
    hv_RecThreshs = HTuple::TupleGenSequence(0.0,1.0,0.01);
    //Start with calculation.
    if (0 != (HTuple(hv_CalcClassAP.TupleOr(hv_CalcMeanAP)).TupleOr(hv_CalcSoAP)))
    {
        //Loop over maximal number of detections.
        {
            HTuple end_val69 = (hv_MaxNumDetections.TupleLength())-1;
            HTuple step_val69 = 1;
            for (hv_MDIdx=0; hv_MDIdx.Continue(end_val69, step_val69); hv_MDIdx += step_val69)
            {
                //
                //Get corresponding running measures.
                hv_MaxNum = HTuple(hv_MaxNumDetections[hv_MDIdx]);
                hv_MaxNumStr = ""+hv_MaxNum;
                if (0 != (int(hv_MaxNum==-1)))
                {
                    hv_MaxNumStr = "all";
                }
                GetDictTuple(hv_RunningMeasures, "max_num_detections_"+hv_MaxNumStr, &hv_CurrentRunningMeasures);
                //
                //Initialize output dictionary.
                CreateDict(&hv_PerMaxNumEvaluationResult);
                //
                //Loop over area ranges.
                {
                    HTuple end_val83 = (hv_AreaNames.TupleLength())-1;
                    HTuple step_val83 = 1;
                    for (hv_AreaIdx=0; hv_AreaIdx.Continue(end_val83, step_val83); hv_AreaIdx += step_val83)
                    {
                        //Get area thresholds.
                        hv_MinArea = HTuple(hv_MinAreas[hv_AreaIdx]);
                        hv_MaxArea = HTuple(hv_MaxAreas[hv_AreaIdx]);
                        hv_AreaName = HTuple(hv_AreaNames[hv_AreaIdx]);
                        //
                        GetDictTuple(hv_CurrentRunningMeasures, "area_"+hv_AreaName, &hv_AreaRunningMeasures);
                        //
                        GetDictTuple(hv_AreaRunningMeasures, "num_gt", &hv_PerClassNumGt);
                        GetDictTuple(hv_AreaRunningMeasures, "num_pred", &hv_PerClassNumPred);
                        GetDictTuple(hv_AreaRunningMeasures, "confidence", &hv_PerClassConfidence);
                        GetDictTuple(hv_AreaRunningMeasures, "num_gt_ignore", &hv_PerClassNumGtIgnore);
                        //
                        //Initialize output dictionary.
                        CreateDict(&hv_CurrentEvaluationResult);
                        {
                            HTuple end_val98 = (hv_IoUThresholds.TupleLength())-1;
                            HTuple step_val98 = 1;
                            for (hv_ITIdx=0; hv_ITIdx.Continue(end_val98, step_val98); hv_ITIdx += step_val98)
                            {
                                CreateDict(&hv_PerIoUAP);
                                SetDictTuple(hv_CurrentEvaluationResult, "ap_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                             hv_PerIoUAP);
                                if (0 != hv_CalcSoAP)
                                {
                                    CreateDict(&hv_PerIoUSoAP);
                                    SetDictTuple(hv_CurrentEvaluationResult, "soap_tp_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                 hv_PerIoUSoAP);
                                }
                                if (0 != hv_DetailedEvaluation)
                                {
                                    //Initialize detailed measures.
                                    CreateDict(&hv_PerIoUDetailedEvaluation);
                                    {
                                        HTuple end_val108 = hv_NumClasses-1;
                                        HTuple step_val108 = 1;
                                        for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val108, step_val108); hv_ClsIdx += step_val108)
                                        {
                                            CreateDict(&hv_PerClassDetailedEvaluation);
                                            //Initialize with zeros in case there is no ground truth for this class.
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_tp", 0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fn", 0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp", 0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_class", 0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_background", 0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_duplicate", 0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_localization",
                                                         0);
                                            SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_multiple", 0);
                                            if (0 != hv_CalcSoAP)
                                            {
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_class", -1);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_duplicate",
                                                             -1);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_localization",
                                                             -1);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_multiple", -1);
                                            }
                                            SetDictTuple(hv_PerIoUDetailedEvaluation, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                         hv_PerClassDetailedEvaluation);
                                        }
                                    }
                                    CreateMatrix(hv_NumClasses+1, hv_NumClasses+4, 0, &hv_DetectionConfusionMatrix);
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "detection_confusion_matrix",
                                                 hv_DetectionConfusionMatrix);
                                    //
                                    //Get and set image IDs with false negatives and false positives.
                                    GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                 &hv_PerIoUMeasure);
                                    //Get image IDs with false negatives and false positives, respectively.
                                    GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_negatives",
                                                 &hv_NumImgIDsWithFN);
                                    GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_positives",
                                                 &hv_NumImgIDsWithFP);
                                    GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_negatives", &hv_ImgIDsWithFN);
                                    GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_positives", &hv_ImgIDsWithFP);
                                    //Set in current output.
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "image_ids_with_false_negatives",
                                                 hv_ImgIDsWithFN.TupleSelectRange(0,hv_NumImgIDsWithFN-1));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "image_ids_with_false_positives",
                                                 hv_ImgIDsWithFP.TupleSelectRange(0,hv_NumImgIDsWithFP-1));
                                    //
                                    //Set output for this IoU.
                                    SetDictTuple(hv_CurrentEvaluationResult, "detailed_evaluation_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                 hv_PerIoUDetailedEvaluation);
                                }
                            }
                        }
                        CreateDict(&hv_ClassMAPDict);
                        SetDictTuple(hv_CurrentEvaluationResult, "mean_iou_ap", hv_ClassMAPDict);
                        if (0 != hv_CalcSoAP)
                        {
                            CreateDict(&hv_ClassMSoAPDict);
                            SetDictTuple(hv_CurrentEvaluationResult, "mean_iou_soap_tp", hv_ClassMSoAPDict);
                        }
                        //
                        //Check which classes have ground truth annotations.
                        hv_ClassesWithGt = ((hv_PerClassNumGt-hv_PerClassNumGtIgnore).TupleGreaterElem(0)).TupleFind(1);
                        if (0 != (int(hv_ClassesWithGt==-1)))
                        {
                            hv_ClassesWithGt = HTuple();
                        }
                        //
                        //Initialize PerClassMAP, i.e. mean average precision over IoU-thresholds per class.
                        hv_PerClassMAP = HTuple(hv_NumClasses,-1.0);
                        //
                        //Initialize PerIoUMAP, i.e. mean average precision over classes per IoU-threshold.
                        hv_PerIoUMAP = HTuple(hv_IoUThresholds.TupleLength(),0.0);
                        //
                        if (0 != hv_CalcSoAP)
                        {
                            //Initialize PerClassMSoAP, i.e. mean SoAP over IoU-thresholds per class.
                            hv_PerClassMSoAP = HTuple(hv_NumClasses,-1.0);
                            //Initialize PerIoUMSoAP, i.e. mean SoAP over classes per IoU-threshold.
                            hv_PerIoUMSoAP = HTuple(hv_IoUThresholds.TupleLength(),0.0);
                            //Initialize PerIoUNumClassesWithTP to store the class-indices where true positives occurred.
                            hv_PerIoUNumClassesWithTP = HTuple(hv_IoUThresholds.TupleLength(),0);
                        }
                        //
                        if (0 != hv_DetailedEvaluation)
                        {
                            //Initialize overall num_fn, num_tp, ...
                            hv_PerIoUTP = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFN = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFP = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFPClass = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFPBackground = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFPLocalization = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFPDuplicate = HTuple(hv_IoUThresholds.TupleLength(),0);
                            hv_PerIoUFPMultiple = HTuple(hv_IoUThresholds.TupleLength(),0);
                            if (0 != hv_CalcSoAP)
                            {
                                hv_PerIoUSoAPClass = HTuple(hv_IoUThresholds.TupleLength(),-1);
                                hv_PerIoUSoAPLocalization = HTuple(hv_IoUThresholds.TupleLength(),-1);
                                hv_PerIoUSoAPDuplicate = HTuple(hv_IoUThresholds.TupleLength(),-1);
                                hv_PerIoUSoAPMultiple = HTuple(hv_IoUThresholds.TupleLength(),-1);
                                hv_PerIoUNumClassesWithFPClass = HTuple(hv_IoUThresholds.TupleLength(),0);
                                hv_PerIoUNumClassesWithFPLocalization = HTuple(hv_IoUThresholds.TupleLength(),0);
                                hv_PerIoUNumClassesWithFPDuplicate = HTuple(hv_IoUThresholds.TupleLength(),0);
                                hv_PerIoUNumClassesWithFPMultiple = HTuple(hv_IoUThresholds.TupleLength(),0);
                            }
                        }
                        //Loop over all classes.
                        {
                            HTuple end_val195 = hv_NumClasses-1;
                            HTuple step_val195 = 1;
                            for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val195, step_val195); hv_ClsIdx += step_val195)
                            {
                                //
                                //Initialize per-class AP per IoU-threshold (only for one class).
                                hv_ClassAPPerIoU = HTuple(hv_IoUThresholds.TupleLength(),-1.0);
                                //
                                if (0 != hv_CalcSoAP)
                                {
                                    hv_ClassSoAPPerIoU = HTuple(hv_IoUThresholds.TupleLength(),-1.0);
                                }
                                //Get results for this class.
                                hv_NumGt = HTuple(hv_PerClassNumGt[hv_ClsIdx]);
                                hv_NumGtIgnore = HTuple(hv_PerClassNumGtIgnore[hv_ClsIdx]);
                                if (0 != (int((hv_NumGt-hv_NumGtIgnore)>0)))
                                {
                                    hv_NumPred = HTuple(hv_PerClassNumPred[hv_ClsIdx]);
                                    GetDictTuple(hv_PerClassConfidence, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                 &hv_Confidences);
                                    //
                                    //Sort the confidences in descending order and
                                    //only take the first NumPred ones due to block allocation.
                                    hv_SortIdxs = (-(hv_Confidences.TupleSelectRange(0,hv_NumPred-1))).TupleSortIndex();
                                    hv_Confidences = HTuple(hv_Confidences[hv_SortIdxs]);
                                }
                                //
                                //Loop over IoU thresholds.
                                {
                                    HTuple end_val217 = (hv_IoUThresholds.TupleLength())-1;
                                    HTuple step_val217 = 1;
                                    for (hv_ITIdx=0; hv_ITIdx.Continue(end_val217, step_val217); hv_ITIdx += step_val217)
                                    {
                                        //
                                        //Check if there are ground truth labels for this class.
                                        if (0 != (int((hv_NumGt-hv_NumGtIgnore)>0)))
                                        {
                                            //
                                            //Get results for this class and IoU-threshold.
                                            GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                         &hv_PerIoUMeasure);
                                            GetDictTuple(hv_PerIoUMeasure, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                         &hv_CurrentClassMeasures);
                                            GetDictTuple(hv_CurrentClassMeasures, "is_tp", &hv_IsTP);
                                            GetDictTuple(hv_CurrentClassMeasures, "ignore", &hv_Ignore);
                                            //
                                            //Sort the arrays IsTP and Ignore according to the confidence values.
                                            hv_IsTP = HTuple(hv_IsTP[hv_SortIdxs]);
                                            hv_Ignore = HTuple(hv_Ignore[hv_SortIdxs]);
                                            //
                                            //Sort out the ignored results.
                                            if (0 != (int((hv_IsTP.TupleLength())>0)))
                                            {
                                                hv_NoIgnoreIdxs = hv_Ignore.TupleFind(0);
                                                if (0 != (int(hv_NoIgnoreIdxs!=-1)))
                                                {
                                                    hv_IsTP = HTuple(hv_IsTP[hv_NoIgnoreIdxs]);
                                                    hv_IsFP = hv_IsTP.TupleNot();
                                                }
                                                else
                                                {
                                                    hv_IsTP = HTuple();
                                                    hv_IsFP = HTuple();
                                                }
                                            }
                                            else
                                            {
                                                hv_IsFP = HTuple();
                                            }
                                            //
                                            //Accumulate IsTP and IsFP.
                                            hv_AccumulatedIsTP = hv_IsTP.TupleCumul();
                                            hv_AccumulatedIsFP = hv_IsFP.TupleCumul();
                                            //
                                            //Compute recall.
                                            //The recall is computed with respect to all ground truth instances,
                                            //independent of MaxNum.
                                            hv_Recall = (hv_AccumulatedIsTP.TupleReal())/(hv_NumGt-hv_NumGtIgnore);
                                            //
                                            //Compute precision.
                                            hv_Precision = (hv_AccumulatedIsTP.TupleReal())/(hv_AccumulatedIsTP+hv_AccumulatedIsFP);
                                            //
                                            //(Optionally) smooth precision-recall curve.
                                            hv_InterpolatedPrecision = hv_Precision;
                                            if (0 != hv_InterpolatePRCurves)
                                            {
                                                for (hv_PIdx=hv_NumPred-2; hv_PIdx>=0; hv_PIdx+=-1)
                                                {
                                                    hv_InterpolatedPrecision[hv_PIdx] = HTuple(hv_InterpolatedPrecision[hv_PIdx]).TupleMax2(HTuple(hv_InterpolatedPrecision[hv_PIdx+1]));
                                                }
                                            }
                                            //Compute approximated area under the Precision-Recall curve using Recall-Thresholds.
                                            hv_PrecisionAtRecThreshs = HTuple(hv_RecThreshs.TupleLength(),0.);
                                            {
                                                HTuple end_val267 = (hv_RecThreshs.TupleLength())-1;
                                                HTuple step_val267 = 1;
                                                for (hv_RTIdx=0; hv_RTIdx.Continue(end_val267, step_val267); hv_RTIdx += step_val267)
                                                {
                                                    hv_RecQuantile = (hv_Recall.TupleGreaterEqualElem(HTuple(hv_RecThreshs[hv_RTIdx]))).TupleFindFirst(1);
                                                    if (0 != (int(hv_RecQuantile>-1)))
                                                    {
                                                        hv_PrecisionAtRecThreshs[hv_RTIdx] = HTuple(hv_InterpolatedPrecision[hv_RecQuantile]);
                                                    }
                                                }
                                            }
                                            //
                                            //Calculate AP as mean of precision at equidistant recall values.
                                            hv_ClassAPPerIoU[hv_ITIdx] = hv_PrecisionAtRecThreshs.TupleMean();
                                            //
                                            //Accumulate AP over classes.
                                            hv_PerIoUMAP[hv_ITIdx] = HTuple(hv_PerIoUMAP[hv_ITIdx])+HTuple(hv_ClassAPPerIoU[hv_ITIdx]);
                                            //
                                            if (0 != hv_CalcSoAP)
                                            {
                                                //Calculate SoAP out of the mean over absolute orientation differences.
                                                GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff", &hv_AOD);
                                                hv_IdxsTP = hv_IsTP.TupleFind(1);
                                                if (0 != (HTuple(int((hv_IdxsTP.TupleLength())>0)).TupleAnd(int(hv_IdxsTP!=-1))))
                                                {
                                                    hv_ClassSoAPPerIoU[hv_ITIdx] = 1.0-((HTuple(hv_AOD[HTuple(hv_SortIdxs[HTuple(hv_NoIgnoreIdxs[hv_IdxsTP])])]).TupleMean())/(HTuple(180).TupleRad()));
                                                    //Accumulate SoAP over classes.
                                                    hv_PerIoUMSoAP[hv_ITIdx] = HTuple(hv_PerIoUMSoAP[hv_ITIdx])+HTuple(hv_ClassSoAPPerIoU[hv_ITIdx]);
                                                }
                                                //Update PerIoUNumClassesWithTP.
                                                if (0 != (int((hv_AccumulatedIsTP.TupleLength())>0)))
                                                {
                                                    hv_PerIoUNumClassesWithTP[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithTP[hv_ITIdx])+(HTuple(hv_AccumulatedIsTP[(hv_AccumulatedIsTP.TupleLength())-1]).TupleGreaterElem(0));
                                                }
                                            }
                                            //
                                            if (0 != hv_DetailedEvaluation)
                                            {
                                                //Summarize detailed evaluation running measures, set matrix-values and update overall detailed measures.
                                                //
                                                //Get the necessary running measures.
                                                GetDictTuple(hv_CurrentClassMeasures, "is_fp_class", &hv_IsFPClass);
                                                GetDictTuple(hv_CurrentClassMeasures, "is_fp_background", &hv_IsFPBackground);
                                                GetDictTuple(hv_CurrentClassMeasures, "is_fp_localization", &hv_IsFPLocalization);
                                                GetDictTuple(hv_CurrentClassMeasures, "is_fp_duplicate", &hv_IsFPDuplicate);
                                                GetDictTuple(hv_CurrentClassMeasures, "is_fp_multiple", &hv_IsFPMultiple);
                                                //
                                                //We use the values with maximal recall,
                                                //in case a higher precision is desired, increase 'min_confidence'.
                                                if (0 != (int((hv_AccumulatedIsTP.TupleLength())>0)))
                                                {
                                                    hv_NumTP = ((const HTuple&)hv_AccumulatedIsTP)[(hv_AccumulatedIsTP.TupleLength())-1];
                                                }
                                                else
                                                {
                                                    hv_NumTP = 0;
                                                }
                                                if (0 != (int((hv_AccumulatedIsFP.TupleLength())>0)))
                                                {
                                                    hv_NumFP = ((const HTuple&)hv_AccumulatedIsFP)[(hv_AccumulatedIsFP.TupleLength())-1];
                                                }
                                                else
                                                {
                                                    hv_NumFP = 0;
                                                }
                                                hv_NumFN = (hv_NumGt-hv_NumGtIgnore)-hv_NumTP;
                                                hv_NumFPClass = (HTuple(hv_IsFPClass[hv_SortIdxs]).TupleGreaterElem(-1)).TupleSum();
                                                hv_NumFPBackground = (HTuple(hv_IsFPBackground[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                                                hv_NumFPLocalization = (HTuple(hv_IsFPLocalization[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                                                hv_NumFPDuplicate = (HTuple(hv_IsFPDuplicate[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                                                hv_NumFPMultiple = (HTuple(hv_IsFPMultiple[hv_SortIdxs]).TupleGreaterElem(0)).TupleSum();
                                                if (0 != (int((hv_SortIdxs.TupleLength())==0)))
                                                {
                                                    hv_NumFPClass = 0;
                                                    hv_NumFPBackground = 0;
                                                    hv_NumFPLocalization = 0;
                                                    hv_NumFPDuplicate = 0;
                                                    hv_NumFPMultiple = 0;
                                                }
                                                //Consistency checks.
                                                if (0 != (int(((((((((hv_NumTP.TupleConcat(hv_NumFN)).TupleConcat(hv_NumFP)).TupleConcat(hv_NumFPClass)).TupleConcat(hv_NumFPBackground)).TupleConcat(hv_NumFPLocalization)).TupleConcat(hv_NumFPDuplicate)).TupleConcat(hv_NumFPMultiple)).TupleMin())<0)))
                                                {
                                                    throw HException("Fatal error while calculating instance measures.");
                                                }
                                                if (0 != (int(hv_NumFP!=((((hv_NumFPClass+hv_NumFPBackground)+hv_NumFPLocalization)+hv_NumFPDuplicate)+hv_NumFPMultiple))))
                                                {
                                                    throw HException("Fatal error while calculating instance measures.");
                                                }
                                                //
                                                //Set per-class measures.
                                                GetDictTuple(hv_CurrentEvaluationResult, "detailed_evaluation_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                             &hv_PerIoUDetailedEvaluation);
                                                GetDictTuple(hv_PerIoUDetailedEvaluation, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                             &hv_PerClassDetailedEvaluation);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_tp", hv_NumTP);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fn", hv_NumFN);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp", hv_NumFP);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_class", hv_NumFPClass);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_background",
                                                             hv_NumFPBackground);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_duplicate", hv_NumFPDuplicate);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_localization",
                                                             hv_NumFPLocalization);
                                                SetDictTuple(hv_PerClassDetailedEvaluation, "num_fp_multiple", hv_NumFPMultiple);
                                                //
                                                //Set detection confusion matrix values.
                                                GetDictTuple(hv_PerIoUDetailedEvaluation, "detection_confusion_matrix",
                                                             &hv_DetectionConfusionMatrix);
                                                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_ClsIdx,
                                                               hv_NumTP);
                                                SetValueMatrix(hv_DetectionConfusionMatrix, hv_NumClasses, hv_ClsIdx,
                                                               hv_NumFN);
                                                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses,
                                                               hv_NumFPBackground);
                                                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses+1,
                                                               hv_NumFPLocalization);
                                                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses+2,
                                                               hv_NumFPDuplicate);
                                                SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, hv_NumClasses+3,
                                                               hv_NumFPMultiple);
                                                //
                                                //Go over IsFPClass and set confusions in matrix.
                                                hv_IndicesWithClassConfusion = (HTuple(hv_IsFPClass[hv_SortIdxs]).TupleGreaterElem(-1)).TupleFind(1);
                                                hv_IsFPClassIdxs = HTuple();
                                                if (0 != (int(hv_IndicesWithClassConfusion>-1)))
                                                {
                                                    hv_IsFPClassIdxs = HTuple(hv_IsFPClass[HTuple(hv_SortIdxs[hv_IndicesWithClassConfusion])]);
                                                }
                                                hv_ClassIdxsConfused = (hv_IsFPClassIdxs.TupleSort()).TupleUniq();
                                                {
                                                    HTuple end_val366 = (hv_ClassIdxsConfused.TupleLength())-1;
                                                    HTuple step_val366 = 1;
                                                    for (hv_Idx=0; hv_Idx.Continue(end_val366, step_val366); hv_Idx += step_val366)
                                                    {
                                                        hv_NumConfusedThisIdx = ((hv_IsFPClassIdxs.TupleFind(HTuple(hv_ClassIdxsConfused[hv_Idx]))).TupleGreaterElem(-1)).TupleSum();
                                                        SetValueMatrix(hv_DetectionConfusionMatrix, hv_ClsIdx, HTuple(hv_ClassIdxsConfused[hv_Idx]),
                                                                       hv_NumConfusedThisIdx);
                                                    }
                                                }
                                                //
                                                //Update overall measures.
                                                hv_PerIoUFN[hv_ITIdx] = HTuple(hv_PerIoUFN[hv_ITIdx])+hv_NumFN;
                                                hv_PerIoUTP[hv_ITIdx] = HTuple(hv_PerIoUTP[hv_ITIdx])+hv_NumTP;
                                                hv_PerIoUFP[hv_ITIdx] = HTuple(hv_PerIoUFP[hv_ITIdx])+hv_NumFP;
                                                hv_PerIoUFPClass[hv_ITIdx] = HTuple(hv_PerIoUFPClass[hv_ITIdx])+hv_NumFPClass;
                                                hv_PerIoUFPBackground[hv_ITIdx] = HTuple(hv_PerIoUFPBackground[hv_ITIdx])+hv_NumFPBackground;
                                                hv_PerIoUFPLocalization[hv_ITIdx] = HTuple(hv_PerIoUFPLocalization[hv_ITIdx])+hv_NumFPLocalization;
                                                hv_PerIoUFPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUFPDuplicate[hv_ITIdx])+hv_NumFPDuplicate;
                                                hv_PerIoUFPMultiple[hv_ITIdx] = HTuple(hv_PerIoUFPMultiple[hv_ITIdx])+hv_NumFPMultiple;
                                                if (0 != hv_CalcSoAP)
                                                {
                                                    //Calculate and update absolute difference of orientation for class false positives.
                                                    GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_class",
                                                                 &hv_AODClass);
                                                    hv_IdxsClass = (hv_AODClass.TupleGreaterElem(-1)).TupleFind(1);
                                                    if (0 != (int(hv_IdxsClass!=-1)))
                                                    {
                                                        hv_ResSoAPClass = 1.0-((HTuple(hv_AODClass[hv_IdxsClass]).TupleMean())/(HTuple(180).TupleRad()));
                                                        SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_class",
                                                                     hv_ResSoAPClass);
                                                        //Update mean over classes.
                                                        hv_PerIoUNumClassesWithFPClass[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPClass[hv_ITIdx])+1;
                                                        if (0 != (int(HTuple(hv_PerIoUSoAPClass[hv_ITIdx])==-1)))
                                                        {
                                                            hv_PerIoUSoAPClass[hv_ITIdx] = hv_ResSoAPClass;
                                                        }
                                                        else
                                                        {
                                                            hv_PerIoUSoAPClass[hv_ITIdx] = HTuple(hv_PerIoUSoAPClass[hv_ITIdx])+hv_ResSoAPClass;
                                                        }
                                                    }
                                                    //Calculate and update absolute difference of orientation for localization false positives.
                                                    GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_localization",
                                                                 &hv_AODLocalization);
                                                    hv_IdxsLocalization = (hv_AODLocalization.TupleGreaterElem(-1)).TupleFind(1);
                                                    if (0 != (int(hv_IdxsLocalization!=-1)))
                                                    {
                                                        hv_ResSoAPLocalization = 1.0-((HTuple(hv_AODLocalization[hv_IdxsLocalization]).TupleMean())/(HTuple(180).TupleRad()));
                                                        SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_localization",
                                                                     hv_ResSoAPLocalization);
                                                        //Update mean over classes.
                                                        hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx])+1;
                                                        if (0 != (int(HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx])==-1)))
                                                        {
                                                            hv_PerIoUSoAPLocalization[hv_ITIdx] = hv_ResSoAPLocalization;
                                                        }
                                                        else
                                                        {
                                                            hv_PerIoUSoAPLocalization[hv_ITIdx] = HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx])+hv_ResSoAPLocalization;
                                                        }
                                                    }
                                                    //Calculate and update absolute difference of orientation for class false positives.
                                                    GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_duplicate",
                                                                 &hv_AODDuplicate);
                                                    hv_IdxsDuplicate = (hv_AODDuplicate.TupleGreaterElem(-1)).TupleFind(1);
                                                    if (0 != (int(hv_IdxsDuplicate!=-1)))
                                                    {
                                                        hv_ResSoAPDuplicate = 1.0-((HTuple(hv_AODDuplicate[hv_IdxsDuplicate]).TupleMean())/(HTuple(180).TupleRad()));
                                                        SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_duplicate",
                                                                     hv_ResSoAPDuplicate);
                                                        //Update mean over classes.
                                                        hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx])+1;
                                                        if (0 != (int(HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx])==-1)))
                                                        {
                                                            hv_PerIoUSoAPDuplicate[hv_ITIdx] = hv_ResSoAPDuplicate;
                                                        }
                                                        else
                                                        {
                                                            hv_PerIoUSoAPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx])+hv_ResSoAPDuplicate;
                                                        }
                                                    }
                                                    //Calculate and update absolute difference of orientation for multiple false positives.
                                                    GetDictTuple(hv_CurrentClassMeasures, "abs_orientation_diff_multiple",
                                                                 &hv_AODMultiple);
                                                    hv_IdxsMultiple = (hv_AODMultiple.TupleGreaterElem(-1)).TupleFind(1);
                                                    if (0 != (int(hv_IdxsMultiple!=-1)))
                                                    {
                                                        hv_ResSoAPMultiple = 1.0-((HTuple(hv_AODMultiple[hv_IdxsMultiple]).TupleMean())/(HTuple(180).TupleRad()));
                                                        SetDictTuple(hv_PerClassDetailedEvaluation, "soap_fp_multiple",
                                                                     hv_ResSoAPMultiple);
                                                        //Update mean over classes.
                                                        hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx] = HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx])+1;
                                                        if (0 != (int(HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx])==-1)))
                                                        {
                                                            hv_PerIoUSoAPMultiple[hv_ITIdx] = hv_ResSoAPMultiple;
                                                        }
                                                        else
                                                        {
                                                            hv_PerIoUSoAPMultiple[hv_ITIdx] = HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx])+hv_ResSoAPMultiple;
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                        //
                                        //Write to output.
                                        GetDictTuple(hv_CurrentEvaluationResult, "ap_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                     &hv_PerIoUAP);
                                        SetDictTuple(hv_PerIoUAP, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), HTuple(hv_ClassAPPerIoU[hv_ITIdx]));
                                        if (0 != hv_CalcSoAP)
                                        {
                                            GetDictTuple(hv_CurrentEvaluationResult, "soap_tp_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                         &hv_PerIoUSoAP);
                                            SetDictTuple(hv_PerIoUSoAP, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                         HTuple(hv_ClassSoAPPerIoU[hv_ITIdx]));
                                        }
                                    }
                                }
                                //
                                //Class mAP is the mean over IoU-thresholds.
                                hv_PerClassMAP[hv_ClsIdx] = hv_ClassAPPerIoU.TupleMean();
                                GetDictTuple(hv_CurrentEvaluationResult, "mean_iou_ap", &hv_ClassMAPDict);
                                SetDictTuple(hv_ClassMAPDict, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                             HTuple(hv_PerClassMAP[hv_ClsIdx]));
                                if (0 != hv_CalcSoAP)
                                {
                                    //ClassMSoAP is the mean over IoU-thresholds.
                                    hv_SoAPIoUIdxsPositive = (hv_ClassSoAPPerIoU.TupleGreaterEqualElem(0.0)).TupleFind(1);
                                    if (0 != (int(hv_SoAPIoUIdxsPositive!=-1)))
                                    {
                                        hv_PerClassMSoAP[hv_ClsIdx] = HTuple(hv_ClassSoAPPerIoU[hv_SoAPIoUIdxsPositive]).TupleMean();
                                    }
                                    else
                                    {
                                        hv_PerClassMSoAP[hv_ClsIdx] = -1.0;
                                    }
                                    GetDictTuple(hv_CurrentEvaluationResult, "mean_iou_soap_tp", &hv_ClassMSoAPDict);
                                    SetDictTuple(hv_ClassMSoAPDict, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                 HTuple(hv_PerClassMSoAP[hv_ClsIdx]));
                                }
                            }
                        }
                        //
                        //Calculate the mean AP and optionally mean SoAP (over classes) per IoU-threshold.
                        {
                            HTuple end_val468 = (hv_IoUThresholds.TupleLength())-1;
                            HTuple step_val468 = 1;
                            for (hv_ITIdx=0; hv_ITIdx.Continue(end_val468, step_val468); hv_ITIdx += step_val468)
                            {
                                GetDictTuple(hv_CurrentEvaluationResult, "ap_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                             &hv_PerIoUAP);
                                //
                                //Consider only present classes.
                                hv_MeanClassAP = -1.0;
                                if (0 != (int((hv_ClassesWithGt.TupleLength())>0)))
                                {
                                    hv_MeanClassAP = HTuple(hv_PerIoUMAP[hv_ITIdx])/(hv_ClassesWithGt.TupleLength());
                                }
                                SetDictTuple(hv_PerIoUAP, "mean_class_ap", hv_MeanClassAP);
                                if (0 != hv_CalcSoAP)
                                {
                                    GetDictTuple(hv_CurrentEvaluationResult, "soap_tp_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                 &hv_PerIoUSoAP);
                                    //
                                    //Consider only present classes.
                                    hv_MeanClassSoAP = -1.0;
                                    if (0 != (int(HTuple(hv_PerIoUNumClassesWithTP[hv_ITIdx])>0)))
                                    {
                                        hv_MeanClassSoAP = HTuple(hv_PerIoUMSoAP[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithTP[hv_ITIdx]);
                                    }
                                    SetDictTuple(hv_PerIoUSoAP, "mean_class_soap_tp", hv_MeanClassSoAP);
                                }
                                //
                                if (0 != hv_DetailedEvaluation)
                                {
                                    //Add overall measures for TP, FN, FP, ...
                                    GetDictTuple(hv_CurrentEvaluationResult, "detailed_evaluation_iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                 &hv_PerIoUDetailedEvaluation);
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_tp", HTuple(hv_PerIoUTP[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fn", HTuple(hv_PerIoUFN[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp", HTuple(hv_PerIoUFP[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_class", HTuple(hv_PerIoUFPClass[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_background", HTuple(hv_PerIoUFPBackground[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_duplicate", HTuple(hv_PerIoUFPDuplicate[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_localization", HTuple(hv_PerIoUFPLocalization[hv_ITIdx]));
                                    SetDictTuple(hv_PerIoUDetailedEvaluation, "num_fp_multiple", HTuple(hv_PerIoUFPMultiple[hv_ITIdx]));
                                    if (0 != hv_CalcSoAP)
                                    {
                                        if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPClass[hv_ITIdx])>0)))
                                        {
                                            hv_PerIoUSoAPClass[hv_ITIdx] = HTuple(hv_PerIoUSoAPClass[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPClass[hv_ITIdx]);
                                        }
                                        if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx])>0)))
                                        {
                                            hv_PerIoUSoAPLocalization[hv_ITIdx] = HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_ITIdx]);
                                        }
                                        if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx])>0)))
                                        {
                                            hv_PerIoUSoAPDuplicate[hv_ITIdx] = HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_ITIdx]);
                                        }
                                        if (0 != (int(HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx])>0)))
                                        {
                                            hv_PerIoUSoAPMultiple[hv_ITIdx] = HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx])/HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_ITIdx]);
                                        }
                                        SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_class", HTuple(hv_PerIoUSoAPClass[hv_ITIdx]));
                                        SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_localization", HTuple(hv_PerIoUSoAPLocalization[hv_ITIdx]));
                                        SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_duplicate", HTuple(hv_PerIoUSoAPDuplicate[hv_ITIdx]));
                                        SetDictTuple(hv_PerIoUDetailedEvaluation, "soap_fp_multiple", HTuple(hv_PerIoUSoAPMultiple[hv_ITIdx]));
                                    }
                                }
                            }
                        }
                        //
                        //Calculate overall mean AP (over classes and IoU-thresholds).
                        //Also here only classes with ground truth annotations are taken into account.
                        hv_MAP = -1.0;
                        if (0 != (int((hv_ClassesWithGt.TupleLength())>0)))
                        {
                            hv_MAP = (HTuple(hv_PerClassMAP[hv_ClassesWithGt]).TupleSum())/(hv_ClassesWithGt.TupleLength());
                        }
                        SetDictTuple(hv_CurrentEvaluationResult, "mean_ap", hv_MAP);
                        if (0 != hv_CalcSoAP)
                        {
                            hv_MSoAP = -1.0;
                            if (0 != (int((hv_PerIoUNumClassesWithTP.TupleSum())>0)))
                            {
                                hv_IoUsWithTP = (hv_PerIoUNumClassesWithTP.TupleGreaterElem(0)).TupleFind(1);
                                hv_MSoAP = ((HTuple(hv_PerIoUMSoAP[hv_IoUsWithTP])/HTuple(hv_PerIoUNumClassesWithTP[hv_IoUsWithTP])).TupleSum())/(hv_IoUsWithTP.TupleLength());
                            }
                            SetDictTuple(hv_CurrentEvaluationResult, "mean_soap_tp", hv_MSoAP);
                            if (0 != hv_DetailedEvaluation)
                            {
                                hv_MSoAPAll = 0.0;
                                hv_NumSoAPAll = 0;
                                if (0 != (int((hv_PerIoUNumClassesWithTP.TupleSum())>0)))
                                {
                                    hv_IoUsWithTP = (hv_PerIoUNumClassesWithTP.TupleGreaterElem(0)).TupleFind(1);
                                    hv_MSoAPAll = hv_MSoAP*(HTuple(hv_PerIoUNumClassesWithTP[hv_IoUsWithTP]).TupleSum());
                                    hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithTP[hv_IoUsWithTP]).TupleSum();
                                }
                                if (0 != (int((hv_PerIoUNumClassesWithFPClass.TupleSum())>0)))
                                {
                                    hv_IoUsWithFPClass = (hv_PerIoUNumClassesWithFPClass.TupleGreaterElem(0)).TupleFind(1);
                                    hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPClass[hv_IoUsWithFPClass]).TupleSum())/(hv_IoUsWithFPClass.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPClass[hv_IoUsWithFPClass]).TupleSum());
                                    hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPClass[hv_IoUsWithFPClass]).TupleSum();
                                }
                                if (0 != (int((hv_PerIoUNumClassesWithFPLocalization.TupleSum())>0)))
                                {
                                    hv_IoUsWithFPLocalization = (hv_PerIoUNumClassesWithFPLocalization.TupleGreaterElem(0)).TupleFind(1);
                                    hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPLocalization[hv_IoUsWithFPLocalization]).TupleSum())/(hv_IoUsWithFPLocalization.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_IoUsWithFPLocalization]).TupleSum());
                                    hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPLocalization[hv_IoUsWithFPLocalization]).TupleSum();
                                }
                                if (0 != (int((hv_PerIoUNumClassesWithFPDuplicate.TupleSum())>0)))
                                {
                                    hv_IoUsWithFPDuplicate = (hv_PerIoUNumClassesWithFPDuplicate.TupleGreaterElem(0)).TupleFind(1);
                                    hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPDuplicate[hv_IoUsWithFPDuplicate]).TupleSum())/(hv_IoUsWithFPDuplicate.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_IoUsWithFPDuplicate]).TupleSum());
                                    hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPDuplicate[hv_IoUsWithFPDuplicate]).TupleSum();
                                }
                                if (0 != (int((hv_PerIoUNumClassesWithFPMultiple.TupleSum())>0)))
                                {
                                    hv_IoUsWithFPMultiple = (hv_PerIoUNumClassesWithFPMultiple.TupleGreaterElem(0)).TupleFind(1);
                                    hv_MSoAPAll += ((HTuple(hv_PerIoUSoAPMultiple[hv_IoUsWithFPMultiple]).TupleSum())/(hv_IoUsWithFPMultiple.TupleLength()))*(HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_IoUsWithFPMultiple]).TupleSum());
                                    hv_NumSoAPAll += HTuple(hv_PerIoUNumClassesWithFPMultiple[hv_IoUsWithFPMultiple]).TupleSum();
                                }
                                if (0 != (int(hv_NumSoAPAll>0)))
                                {
                                    SetDictTuple(hv_CurrentEvaluationResult, "mean_soap_all", (hv_MSoAPAll.TupleReal())/hv_NumSoAPAll);
                                }
                                else
                                {
                                    SetDictTuple(hv_CurrentEvaluationResult, "mean_soap_all", -1);
                                }
                                //
                            }
                        }
                        //
                        //Add CurrentEvaluationResult to output.
                        SetDictTuple(hv_PerMaxNumEvaluationResult, "area_"+hv_AreaName, hv_CurrentEvaluationResult);
                    }
                }
                //Add PerMaxNumEvaluationResult to output.
                SetDictTuple((*hv_EvaluationResult), "max_num_detections_"+hv_MaxNumStr, hv_PerMaxNumEvaluationResult);
            }
        }
    }
    //
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Computes the ocr_detection relevant evaluation measures.
void HalxAI:: calculate_ocr_detection_measures (HTuple hv_DetectionEvaluationResult, HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Keys, hv_Matches, hv_Key, hv_WordEval;
    HTuple  hv_NumAll, hv_NumTPFP, hv_Divisor, hv___Tmp_Ctrl_Type;

    GetDictParam((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all"),
                 "keys", HTuple(), &hv_Keys);
    //Use the first matching key in order to compute the measures.
    TupleRegexpSelect(hv_Keys, "detailed_evaluation_iou_.*", &hv_Matches);
    hv_Key = ((const HTuple&)hv_Matches)[0];
    hv_WordEval = (((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key)).TupleGetDictTuple("class_0");
    CreateDict(&(*hv_EvaluationResult));
    //Recall
    hv_NumAll = (hv_WordEval.TupleGetDictTuple("num_tp"))+(hv_WordEval.TupleGetDictTuple("num_fn"));
    if (0 != (int(hv_NumAll>0)))
    {
        SetDictTuple((*hv_EvaluationResult), "recall", (hv_WordEval.TupleGetDictTuple("num_tp"))/(hv_NumAll.TupleReal()));
    }
    else
    {
        SetDictTuple((*hv_EvaluationResult), "recall", 0.0);
    }
    //Precision
    hv_NumTPFP = (hv_WordEval.TupleGetDictTuple("num_tp"))+(hv_WordEval.TupleGetDictTuple("num_fp"));
    if (0 != (int(hv_NumTPFP>0)))
    {
        SetDictTuple((*hv_EvaluationResult), "precision", (hv_WordEval.TupleGetDictTuple("num_tp"))/(hv_NumTPFP.TupleReal()));
    }
    else
    {
        SetDictTuple((*hv_EvaluationResult), "precision", 0.0);
    }
    //F-Score
    hv_Divisor = ((*hv_EvaluationResult).TupleGetDictTuple("precision"))+((*hv_EvaluationResult).TupleGetDictTuple("recall"));
    if (0 != (int(hv_Divisor!=0)))
    {
        SetDictTuple((*hv_EvaluationResult), "f_score", ((2*((*hv_EvaluationResult).TupleGetDictTuple("precision")))*((*hv_EvaluationResult).TupleGetDictTuple("recall")))/hv_Divisor);
    }
    else
    {
        SetDictTuple((*hv_EvaluationResult), "f_score", 0.0);
    }
    //SoAP
    TupleRegexpSelect(hv_Keys, "soap_tp_iou_.*", &hv_Matches);
    if (0 != (int((hv_Matches.TupleLength())>0)))
    {
        hv_Key = ((const HTuple&)hv_Matches)[0];
        GetDictParam(((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key),
                     "key_data_type", "class_0", &hv___Tmp_Ctrl_Type);
        if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
        {
            SetDictObject((((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key)).TupleGetDictObject("class_0"),
                          (*hv_EvaluationResult), "soap");
        }
        else
        {
            SetDictTuple((*hv_EvaluationResult), "soap", (((hv_DetectionEvaluationResult.TupleGetDictTuple("max_num_detections_all")).TupleGetDictTuple("area_all")).TupleGetDictTuple(hv_Key)).TupleGetDictTuple("class_0"));
        }
    }
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Calculate OCR recognition measures based on RunningMeasures.
void HalxAI:: calculate_ocr_recognition_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                                  HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Equal;

    //
    //This procedure calculates the final summarizing OCR recognition measures based on the running measures.
    //
    //
    //Initialize output dictionary and get necessary evaluation parameters.
    CreateDict(&(*hv_EvaluationResult));
    //
    //Compute Accuracy
    hv_Equal = (hv_RunningMeasures.TupleGetDictTuple("words_ground_truth")).TupleEqualElem(hv_RunningMeasures.TupleGetDictTuple("words_prediction"));
    if (0 != (int((hv_Equal.TupleLength())>0)))
    {
        SetDictTuple((*hv_EvaluationResult), "accuracy", ((hv_Equal.TupleSum())/(HTuple(hv_Equal.TupleLength()).TupleReal()))*100);
    }
    else
    {
        SetDictTuple((*hv_EvaluationResult), "accuracy", 0);
    }
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Calculate pixel measures based on RunningMeasures.
void HalxAI:: calculate_pixel_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams, HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_CalcClassPixelAccuracy, hv_CalcPixelAccuracy;
    HTuple  hv_CalcPixelConfusionMatrix, hv_CalcMeanAccuracy;
    HTuple  hv_CalcMeanPrecision, hv_CalcMeanIou, hv_CalcClassIou;
    HTuple  hv_CalcFWIou, hv_Measures, hv_EvaluationType, hv_PixelMeasures;
    HTuple  hv_M, hv_ConfMatrix, hv_TPMat, hv_TP, hv_SumRowMat;
    HTuple  hv_RowSum, hv_FP, hv_SumColMat, hv_ColSum, hv_FN;
    HTuple  hv_IgnoreClassIDs, hv_Rows, hv_Columns, hv_FPIgnore;
    HTuple  hv_GT, hv_ClsIdxValid, hv_ClassPixelAccuracy, hv_MeanAccuracy;
    HTuple  hv_PixelAccuracy, hv_PD, hv_PDIdxValid, hv_ClassPixelPrecision;
    HTuple  hv_MeanPrecision, hv_ClassIoU, hv_MeanIoU, hv_FWIoU;
    HTuple  hv_FwWeights;

    //
    //This procedure calculates the pixel-wise measures based on the values in running measures.
    //
    //Set default values.
    hv_CalcClassPixelAccuracy = 0;
    hv_CalcPixelAccuracy = 0;
    hv_CalcPixelConfusionMatrix = 0;
    hv_CalcMeanAccuracy = 0;
    hv_CalcMeanPrecision = 0;
    hv_CalcMeanIou = 0;
    hv_CalcClassIou = 0;
    hv_CalcFWIou = 0;
    CreateDict(&(*hv_EvaluationResult));
    //
    //Check which measures are to be calculated.
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    get_requested_pixel_measures(hv_Measures, hv_EvaluationType, &hv_PixelMeasures);
    if (0 != (int((hv_PixelMeasures.TupleLength())==0)))
    {
        return;
    }
    //
    {
        HTuple end_val22 = (hv_PixelMeasures.TupleLength())-1;
        HTuple step_val22 = 1;
        for (hv_M=0; hv_M.Continue(end_val22, step_val22); hv_M += step_val22)
        {
            if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("pixel_accuracy"))))
            {
                hv_CalcPixelAccuracy = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("class_pixel_accuracy"))))
            {
                hv_CalcClassPixelAccuracy = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("pixel_confusion_matrix"))))
            {
                hv_CalcPixelConfusionMatrix = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("mean_accuracy"))))
            {
                hv_CalcMeanAccuracy = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("mean_precision"))))
            {
                hv_CalcMeanPrecision = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("mean_iou"))))
            {
                hv_CalcMeanIou = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("class_iou"))))
            {
                hv_CalcClassIou = 1;
            }
            else if (0 != (int(HTuple(hv_PixelMeasures[hv_M])==HTuple("frequency_weighted_iou"))))
            {
                hv_CalcFWIou = 1;
            }
            else
            {
                throw HException("Unknown pixel measure: "+HTuple(hv_PixelMeasures[hv_M]));
            }
        }
    }
    //
    //Depending on the running measure values (ConfusionMatrix or TP/FP/FN),
    //we first calculate TP/FP/FN from the ConfusionMatrix.
    if (0 != hv_CalcPixelConfusionMatrix)
    {
        //Get the running measures.
        GetDictTuple(hv_RunningMeasures, "pixel_confusion_matrix", &hv_ConfMatrix);
        //Get the per-class true positives as the diagonal of the matrix.
        GetDiagonalMatrix(hv_ConfMatrix, 0, &hv_TPMat);
        GetFullMatrix(hv_TPMat, &hv_TP);
        //For the confusion matrix, the row determines the predicted class-IDs,
        //the column determines the ground truth class-IDs.
        //Get the per-class false positives (FP) as the sum over the rows minus the diagonal (TP).
        SumMatrix(hv_ConfMatrix, "rows", &hv_SumRowMat);
        GetFullMatrix(hv_SumRowMat, &hv_RowSum);
        hv_FP = hv_RowSum-hv_TP;
        //Get the per-class false negatives (FN) as the sum over the columns minus the diagonal (TP).
        SumMatrix(hv_ConfMatrix, "columns", &hv_SumColMat);
        GetFullMatrix(hv_SumColMat, &hv_ColSum);
        hv_FN = hv_ColSum-hv_TP;
        //We do not want to count the false positives (FP) in the ignore region.
        //The false negatives (FN) are not affected, since the model does not predict the ignore class.
        GetDictTuple(hv_EvalParams, "ignore_class_ids", &hv_IgnoreClassIDs);
        if (0 != (int((hv_IgnoreClassIDs.TupleLength())>0)))
        {
            //The ignore class corresponds to the last row/column in the confusion matrix.
            GetSizeMatrix(hv_ConfMatrix, &hv_Rows, &hv_Columns);
            GetValueMatrix(hv_ConfMatrix, HTuple::TupleGenSequence(0,hv_Rows-1,1), HTuple(hv_Rows,hv_Columns-1),
                           &hv_FPIgnore);
            hv_FP = hv_FP-hv_FPIgnore;
            //Remove last entries of TP, FP, FN (those related to the ignore class).
            hv_TP = hv_TP.TupleSelectRange(0,(hv_TP.TupleLength())-2);
            hv_FP = hv_FP.TupleSelectRange(0,(hv_FP.TupleLength())-2);
            hv_FN = hv_FN.TupleSelectRange(0,(hv_FN.TupleLength())-2);
            //Remove last row/column from confusion matrix.
            GetSubMatrix(hv_ConfMatrix, 0, 0, hv_Rows-1, hv_Columns-1, &hv_ConfMatrix);
        }
        //Paste the confusion matrix to the output.
        SetDictTuple((*hv_EvaluationResult), "pixel_confusion_matrix", hv_ConfMatrix);
    }
    else
    {
        //Get the running measure values.
        GetDictTuple(hv_RunningMeasures, "tp", &hv_TP);
        GetDictTuple(hv_RunningMeasures, "fp", &hv_FP);
        GetDictTuple(hv_RunningMeasures, "fn", &hv_FN);
    }
    //
    //It might be the case, that some of the classes are not present in the set of validation images.
    //--> Exclude these classes (they are indirectly present as they reduce the number of TP for other classes).
    hv_GT = hv_TP+hv_FN;
    hv_ClsIdxValid = (hv_GT.TupleGreaterElem(0)).TupleFind(1);
    //
    //Mean Accuracy, Class Pixel Accuracy.
    //-> If one of 'mean_accuracy', 'class_pixel_accuracy' is specified, we give back both of them
    //   as they have to be calculated anyway (to the most part).
    if (0 != (hv_CalcClassPixelAccuracy.TupleOr(hv_CalcMeanAccuracy)))
    {
        //Compute pixel accuracy per class (although we might only use it for the overall pixel accuracy).
        hv_ClassPixelAccuracy = HTuple(hv_GT.TupleLength(),-1);
        hv_MeanAccuracy = -1;
        if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
        {
            hv_ClassPixelAccuracy[hv_ClsIdxValid] = (HTuple(hv_TP[hv_ClsIdxValid]).TupleReal())/HTuple(hv_GT[hv_ClsIdxValid]);
            hv_MeanAccuracy = HTuple(hv_ClassPixelAccuracy[hv_ClsIdxValid]).TupleMean();
        }
        SetDictTuple((*hv_EvaluationResult), "class_pixel_accuracy", hv_ClassPixelAccuracy);
        SetDictTuple((*hv_EvaluationResult), "mean_accuracy", hv_MeanAccuracy);
    }
    //Pixel Accuracy.
    if (0 != hv_CalcPixelAccuracy)
    {
        //Compute pixel accuracy as the total ratio of pixels that have been correctly predicted.
        hv_PixelAccuracy = -1;
        if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
        {
            hv_PixelAccuracy = ((HTuple(hv_TP[hv_ClsIdxValid]).TupleSum()).TupleReal())/(HTuple(hv_GT[hv_ClsIdxValid]).TupleSum());
        }
        SetDictTuple((*hv_EvaluationResult), "pixel_accuracy", hv_PixelAccuracy);
    }
    //Mean Precision.
    //-> Also includes precisions for each of the classes which are
    //   used to calculate the mean precision.
    if (0 != hv_CalcMeanPrecision)
    {
        //Compute pixel-level precision averaged over all classes.
        hv_PD = hv_TP+hv_FP;
        hv_PDIdxValid = (hv_PD.TupleGreaterElem(0.0)).TupleFind(1);
        hv_ClassPixelPrecision = HTuple(hv_PD.TupleLength(),-1);
        hv_MeanPrecision = -1;
        if (0 != (int(HTuple(hv_PDIdxValid[0])>-1)))
        {
            hv_ClassPixelPrecision[hv_PDIdxValid] = (HTuple(hv_TP[hv_PDIdxValid]).TupleReal())/HTuple(hv_PD[hv_PDIdxValid]);
            hv_MeanPrecision = HTuple(hv_ClassPixelPrecision[hv_PDIdxValid]).TupleMean();
        }
        SetDictTuple((*hv_EvaluationResult), "mean_precision", hv_MeanPrecision);
    }
    //Mean IoU, class IoU, frequency weighted IoU:
    //-> If the measures 'class_iou', 'mean_iou' or 'frequency_weighted_iou' is specified,
    //   we return all three of them as they have to be calculated anyway (to the most part).
    if (0 != (HTuple(hv_CalcMeanIou.TupleOr(hv_CalcClassIou)).TupleOr(hv_CalcFWIou)))
    {
        hv_ClassIoU = HTuple(hv_GT.TupleLength(),-1);
        hv_MeanIoU = -1;
        hv_FWIoU = -1;
        if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
        {
            hv_ClassIoU[hv_ClsIdxValid] = (HTuple(hv_TP[hv_ClsIdxValid]).TupleReal())/(HTuple(hv_GT[hv_ClsIdxValid])+HTuple(hv_FP[hv_ClsIdxValid]));
            hv_MeanIoU = HTuple(hv_ClassIoU[hv_ClsIdxValid]).TupleMean();
            hv_FwWeights = (hv_GT.TupleReal())/(hv_GT.TupleSum());
            hv_FWIoU = (HTuple(hv_FwWeights[hv_ClsIdxValid])*HTuple(hv_ClassIoU[hv_ClsIdxValid])).TupleSum();
        }
        SetDictTuple((*hv_EvaluationResult), "class_iou", hv_ClassIoU);
        SetDictTuple((*hv_EvaluationResult), "mean_iou", hv_MeanIoU);
        SetDictTuple((*hv_EvaluationResult), "frequency_weighted_iou", hv_FWIoU);
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Calculate region measures based on running measure values.
void HalxAI:: calculate_region_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                         HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_CalcMeanPRO, hv_Measures, hv_M, hv_ClsIdxValid;
    HTuple  hv_ClassPRO, hv_MeanPRO;

    //
    //This procedure calculates the region measures based on the
    //values in running measures.
    //
    //Set default values.
    hv_CalcMeanPRO = 0;
    CreateDict(&(*hv_EvaluationResult));
    //
    //Check which measures are to be calculated.
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    {
        HTuple end_val10 = (hv_Measures.TupleLength())-1;
        HTuple step_val10 = 1;
        for (hv_M=0; hv_M.Continue(end_val10, step_val10); hv_M += step_val10)
        {
            if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("mean_pro"))))
            {
                hv_CalcMeanPRO = 1;
            }
            else if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
            {
                hv_CalcMeanPRO = 1;
            }
        }
    }
    //
    if (0 != hv_CalcMeanPRO)
    {
        //It might be the case, that some of the classes are not present
        //in the set of evaluation images and are excluded.
        hv_ClsIdxValid = ((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions")).TupleGreaterElem(0)).TupleFind(1);
        //
        //Compute per-region-overlap averaged over the valid classes.
        hv_ClassPRO = HTuple((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions")).TupleLength(),-1);
        hv_MeanPRO = -1;
        if (0 != (int(HTuple(hv_ClsIdxValid[0])>-1)))
        {
            hv_ClassPRO[hv_ClsIdxValid] = HTuple((hv_RunningMeasures.TupleGetDictTuple("gt_overlap"))[hv_ClsIdxValid])/(HTuple((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions"))[hv_ClsIdxValid]).TupleReal());
            hv_MeanPRO = HTuple(hv_ClassPRO[hv_ClsIdxValid]).TupleMean();
        }
        SetDictTuple((*hv_EvaluationResult), "mean_pro", hv_MeanPRO);
    }
    //
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Calculate 3D gripping point measures based on RunningMeasures.
void HalxAI:: calculate_running_gripping_point_measures (HTuple hv_RunningMeasures, HTuple hv_EvalParams,
                                                         HTuple *hv_EvaluationResult)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Positives, hv_GT, hv_Precision, hv_Recall;
    HTuple  hv_SumPrecisionRecall, hv_FScore;

    CreateDict(&(*hv_EvaluationResult));
    if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_.*|all")).TupleLength())>0)))
    {
        hv_Positives = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))+(hv_RunningMeasures.TupleGetDictTuple("gp_fp"));
        hv_GT = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))+(hv_RunningMeasures.TupleGetDictTuple("gp_fn"));
        if (0 != (int(hv_Positives>0.0)))
        {
            hv_Precision = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))/hv_Positives;
        }
        else
        {
            hv_Precision = 0.0;
        }
        if (0 != (int(hv_GT>0.0)))
        {
            hv_Recall = (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))/hv_GT;
        }
        else
        {
            hv_Recall = 0.0;
        }
        hv_SumPrecisionRecall = hv_Precision+hv_Recall;
        if (0 != (int(hv_SumPrecisionRecall>0.0)))
        {
            hv_FScore = ((2*hv_Precision)*hv_Recall)/hv_SumPrecisionRecall;
        }
        else
        {
            hv_FScore = 0.0;
        }
        if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_precision|all")).TupleLength())>0)))
        {
            SetDictTuple((*hv_EvaluationResult), "gripping_point_precision", hv_Precision);
        }
        if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_recall|all")).TupleLength())>0)))
        {
            SetDictTuple((*hv_EvaluationResult), "gripping_point_recall", hv_Recall);
        }
        if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_f_score|all")).TupleLength())>0)))
        {
            SetDictTuple((*hv_EvaluationResult), "gripping_point_f_score", hv_FScore);
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Check and sanitize the parameters of augment_dl_samples.
void HalxAI:: check_augment_dl_samples_gen_param (HTuple hv_GenParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_GenKeys, hv_ValidAugMethods, hv_ValidOtherKeys;
    HTuple  hv_ValidKeys, hv_InvalidKeys, hv_Exception, hv_KeyIndex;
    HTuple  hv_GenKey, hv_GenValue, hv_NumValues, hv_V, hv_Value;
    HTuple  hv_SanitizedValue;

    //This procedure validates and sanitizes the GenParam parameter of the
    //augment_dl_samples procedure.
    //
    //This procedure should not be used outside of the augment_dl_samples procedure!
    //The name, parameters, and functionality of this procedure are subject to change.
    //
    //Check that there are no unknown parameters.
    GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenKeys);
    hv_ValidAugMethods.Clear();
    hv_ValidAugMethods[0] = "brightness_variation";
    hv_ValidAugMethods[1] = "brightness_variation_spot";
    hv_ValidAugMethods[2] = "contrast_variation";
    hv_ValidAugMethods[3] = "crop_percentage";
    hv_ValidAugMethods[4] = "crop_pixel";
    hv_ValidAugMethods[5] = "mirror";
    hv_ValidAugMethods[6] = "remove_pixel";
    hv_ValidAugMethods[7] = "rotate";
    hv_ValidAugMethods[8] = "rotate_range";
    hv_ValidAugMethods[9] = "saturation_variation";
    hv_ValidOtherKeys.Clear();
    hv_ValidOtherKeys[0] = "augmentation_percentage";
    hv_ValidOtherKeys[1] = "class_ids_no_orientation";
    hv_ValidOtherKeys[2] = "ignore_direction";
    hv_ValidKeys.Clear();
    hv_ValidKeys.Append(hv_ValidAugMethods);
    hv_ValidKeys.Append(hv_ValidOtherKeys);
    TupleDifference(hv_GenKeys, hv_ValidKeys, &hv_InvalidKeys);
    if (0 != (int((hv_InvalidKeys.TupleLength())>0)))
    {
        hv_Exception = "These keys in GenParam are not supported by augment_dl_samples: '"+(hv_InvalidKeys.TupleJoin(HTuple("', '")+"'"));
        throw HException(hv_Exception);
    }
    //
    //Check each parameter.
    {
        HTuple end_val18 = (hv_GenKeys.TupleLength())-1;
        HTuple step_val18 = 1;
        for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val18, step_val18); hv_KeyIndex += step_val18)
        {
            //Get the key and value, for example 'rotate_range' and 3.
            hv_GenKey = HTuple(hv_GenKeys[hv_KeyIndex]);
            hv_GenValue = hv_GenParam.TupleGetDictTuple(hv_GenKey);
            //Perform validation
            if (0 != (int(hv_GenKey==HTuple("augmentation_percentage"))))
            {
                //Check if input value is in range of 0-100 %.
                hv_Exception = "The given value for 'augmentation_percentage' has to be in the range 0-100.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>100))))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("brightness_variation"))))
            {
                //Check if the input value is in range of 0-255.
                hv_Exception = "The given value for 'brightness_variation' has to be in the range 0-255.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>255))))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("brightness_variation_spot"))))
            {
                //Check if the input value is in range of 0-255.
                hv_Exception = "The given value for 'brightness_variation_spot' has to be in the range 0-255.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>255))))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("contrast_variation"))))
            {
                //Check if the input value is not negative.
                hv_Exception = "The given value for 'contrast_variation' has to be greater than or equal to zero.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (int(hv_GenValue<0)))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("crop_percentage"))))
            {
                //Check if the input value is in range of 1-100%.
                hv_Exception = "The given value for 'crop_percentage' has to be in the range 1-100.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (HTuple(int(hv_GenValue<1)).TupleOr(int(hv_GenValue>100))))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("crop_pixel"))))
            {
                //Check if the input value is greater 0.
                hv_Exception = "The given value for 'crop_pixel' has to be greater or equal to 1.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (int(hv_GenValue<1)))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("ignore_direction"))))
            {
                hv_Exception = HTuple("The value given for 'ignore_direction' has to be either 'true','false', true or false.");
                if (0 != (int(((((HTuple("true").Append("false")).Append(1)).Append(0)).TupleFind(hv_GenValue))==-1)))
                {
                    throw HException(hv_Exception);
                }
                //Sanitize string values to Booleans.
                if (0 != (int(hv_GenValue==HTuple("false"))))
                {
                    hv_GenValue = 0;
                }
                else if (0 != (int(hv_GenValue==HTuple("true"))))
                {
                    hv_GenValue = 1;
                }
                //Overwrite the value in GenParam.
                SetDictTuple(hv_GenParam, hv_GenKey, hv_GenValue);
            }
            if (0 != (int(hv_GenKey==HTuple("mirror"))))
            {
                //Check if the input is a string and contains either 'off' or the mirroring code.
                if (0 != ((hv_GenValue.TupleIsNumber()).TupleOr(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_GenValue==HTuple("off"))).TupleOr(int(hv_GenValue==HTuple("c")))).TupleOr(int(hv_GenValue==HTuple("r")))).TupleOr(int(hv_GenValue==HTuple("cr")))).TupleOr(int(hv_GenValue==HTuple("rc")))).TupleNot())))
                {
                    throw HException("Unknown type for mirroring.");
                }
            }
            if (0 != (int(hv_GenKey==HTuple("remove_pixel"))))
            {
                //Set pixels to remove.
                //Check if the input values are valid. Valid are either 1d-tuples with
                //the pixels to remove for both dimensions, or 2d-tuples with the pixels
                //to remove for each dimension [x,y].
                hv_NumValues = hv_GenValue.TupleLength();
                if (0 != (HTuple(int(hv_NumValues!=1)).TupleAnd(int(hv_NumValues!=2))))
                {
                    throw HException("The number of values for 'remove_pixel' has to be 1 or 2.");
                }
                {
                    HTuple end_val118 = hv_NumValues-1;
                    HTuple step_val118 = 1;
                    for (hv_V=0; hv_V.Continue(end_val118, step_val118); hv_V += step_val118)
                    {
                        hv_Value = HTuple(hv_GenValue[hv_V]);
                        if (0 != ((hv_Value.TupleIsInt()).TupleNot()))
                        {
                            throw HException("The given value for 'remove_pixel' has to be an integer value.");
                        }
                        if (0 != (int(hv_Value<0)))
                        {
                            throw HException("The given value for 'remove_pixel' has to be equal or greater than 0.");
                        }
                    }
                }
                //Store the input values for each dimension [x,y].
                hv_SanitizedValue = ((const HTuple&)hv_GenValue)[0];
                if (0 != (int(hv_NumValues==1)))
                {
                    hv_SanitizedValue[1] = HTuple(hv_GenValue[0]);
                }
                else
                {
                    hv_SanitizedValue[1] = HTuple(hv_GenValue[1]);
                }
                //Overwrite the value in GenParam.
                SetDictTuple(hv_GenParam, hv_GenKey, hv_SanitizedValue);
            }
            if (0 != (int(hv_GenKey==HTuple("rotate"))))
            {
                //Check if the input value is either 0, 90, or 180.
                hv_Exception = HTuple("The value given for 'rotate' has to be either 0, 90, or 180.");
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (int((((HTuple(0).Append(90)).Append(180)).TupleFind(hv_GenValue))==-1)))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("rotate_range"))))
            {
                //Check if the input value is in range of 0-180.
                hv_Exception = "The given value for 'rotate_range' has to be in the range 0-180.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (HTuple(int(hv_GenValue<0)).TupleOr(int(hv_GenValue>180))))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
            if (0 != (int(hv_GenKey==HTuple("saturation_variation"))))
            {
                //Check if the input value is not negative.
                hv_Exception = "The given value for 'saturation_variation' has to be greater than or equal to zero.";
                if (0 != (hv_GenValue.TupleIsNumber()))
                {
                    if (0 != (int(hv_GenValue<0)))
                    {
                        throw HException(hv_Exception);
                    }
                }
                else
                {
                    throw HException(hv_Exception);
                }
            }
        }
    }
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Initialize and check parameter for the generation of 3D gripping points and poses.
void HalxAI:: check_dl_3d_gripping_points_and_poses_params (HTuple hv_DLGrippingPointParams)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_HasMinAreaSize, hv_HasSortingDir, hv_SortingDirectionRaw;
    HTuple  hv_LenSortingDirectionRaw;

    GetDictParam(hv_DLGrippingPointParams, "key_exists", "min_area_size", &hv_HasMinAreaSize);
    if (0 != hv_HasMinAreaSize)
    {
        if (0 != (int((hv_DLGrippingPointParams.TupleGetDictTuple("min_area_size"))<=0)))
        {
            throw HException("DLGrippingPointParams.min_area_size has to be at least 1.");
        }
    }
    else
    {
        SetDictTuple(hv_DLGrippingPointParams, "min_area_size", 1);
    }
    //
    GetDictParam(hv_DLGrippingPointParams, "key_exists", "sorting_direction", &hv_HasSortingDir);
    if (0 != hv_HasSortingDir)
    {
        if (0 != (int(((hv_DLGrippingPointParams.TupleGetDictTuple("sorting_direction")).TupleLength())!=3)))
        {
            throw HException("DLGrippingPointParams.sorting_direction has to be a 3D-vector.");
        }
        hv_SortingDirectionRaw = hv_DLGrippingPointParams.TupleGetDictTuple("sorting_direction");
        hv_LenSortingDirectionRaw = ((hv_SortingDirectionRaw*hv_SortingDirectionRaw).TupleSum()).TupleSqrt();
        if (0 != (int(hv_LenSortingDirectionRaw<1.0e-06)))
        {
            throw HException("DLGrippingPointParams.sorting_direction must not be the zero-vector.");
        }
        SetDictTuple(hv_DLGrippingPointParams, "sorting_direction", hv_SortingDirectionRaw/hv_LenSortingDirectionRaw);
    }
    else
    {
        SetDictTuple(hv_DLGrippingPointParams, "sorting_direction", ((HTuple(0.0).Append(0.0)).Append(0.1)));
    }
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Check if scores of a Global Context Anomaly Detection model have been normalized
void HalxAI:: check_dl_gc_anomaly_scores_normalization (HTuple hv_DLModelHandle, HTuple hv_GenParam)
{

    // Local iconic variables
    HObject  ho_Weights, ho_Bias;

    // Local control variables
    HTuple  hv_DLModelIsConverted, hv_Networks, hv_HasLocalNetwork;
    HTuple  hv_HasGlobalNetwork, hv_NormalizationLayers, hv_Index;
    HTuple  hv_LayerName, hv_Rows, hv_Columns, hv_WeightsValues;
    HTuple  hv_HasDefaultWeights, hv_BiasValues, hv_HasDefaultBias;

    //This procedure checks if all gc anomaly scores have been normalized.
    //
    //Make sure GenParam is an empty tuple.
    if (0 != (int(hv_GenParam!=HTuple())))
    {
        throw HException("The parameter GenParam must be an empty tuple.");
    }
    //
    //For models using an AI accelerator interface for inference, the
    //weights of internal layers are no longer available. They are
    //removed to reduce the memory footprint of the model. Therefore
    //we have no means to check if the gc anomaly scores have been
    //normalized, and thus we assume that this is already the case.
    GetDlModelParam(hv_DLModelHandle, "precision_is_converted", &hv_DLModelIsConverted);
    if (0 != (int(hv_DLModelIsConverted==HTuple("true"))))
    {
        return;
    }
    //
    //Find networks to be normalized.
    GetDlModelParam(hv_DLModelHandle, "gc_anomaly_networks", &hv_Networks);
    hv_HasLocalNetwork = int((hv_Networks.TupleFind("local"))!=-1);
    hv_HasGlobalNetwork = int((hv_Networks.TupleFind("global"))!=-1);
    hv_NormalizationLayers = HTuple();
    if (0 != hv_HasLocalNetwork)
    {
        hv_NormalizationLayers = hv_NormalizationLayers.TupleConcat("local_normalization");
    }
    if (0 != hv_HasGlobalNetwork)
    {
        hv_NormalizationLayers = hv_NormalizationLayers.TupleConcat("global_normalization");
    }
    //
    {
        HTuple end_val29 = (hv_NormalizationLayers.TupleLength())-1;
        HTuple step_val29 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val29, step_val29); hv_Index += step_val29)
        {
            hv_LayerName = HTuple(hv_NormalizationLayers[hv_Index]);
            GetDlModelLayerWeights(&ho_Weights, hv_DLModelHandle, hv_LayerName, "weights");
            GetRegionPoints(ho_Weights, &hv_Rows, &hv_Columns);
            GetGrayval(ho_Weights, hv_Rows, hv_Columns, &hv_WeightsValues);
            //Calculate if weights are equal since some floating point arithmetic
            //is involved in their creation.
            hv_HasDefaultWeights = int(((((hv_WeightsValues.TupleLength())*hv_WeightsValues)-HTuple(hv_WeightsValues.TupleLength(),1.0)).TupleAbs())<((hv_WeightsValues.TupleLength())*1e-6));
            //
            GetDlModelLayerWeights(&ho_Bias, hv_DLModelHandle, hv_LayerName, "bias");
            GetRegionPoints(ho_Bias, &hv_Rows, &hv_Columns);
            GetGrayval(ho_Bias, hv_Rows, hv_Columns, &hv_BiasValues);
            //The bias is set directly, hence an equality check is sufficient.
            hv_HasDefaultBias = int(hv_BiasValues==HTuple(hv_BiasValues.TupleLength(),0.0));
            //
            if (0 != (hv_HasDefaultWeights.TupleAnd(hv_HasDefaultBias)))
            {
                throw HException(HTuple("For a model of type gc_anomaly_detection, the anomaly scores must be normalized first."));
            }
        }
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Check the content of the parameter dictionary DLPreprocessParam.
void HalxAI:: check_dl_preprocess_param (HTuple hv_DLPreprocessParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_CheckParams, hv_KeyExists, hv_DLModelType;
    HTuple  hv_Exception, hv_SupportedModelTypes, hv_Index;
    HTuple  hv_ParamNamesGeneral, hv_ParamNamesSegmentation;
    HTuple  hv_ParamNamesDetectionOptional, hv_ParamNamesPreprocessingOptional;
    HTuple  hv_ParamNames3DGrippingPointsOptional, hv_ParamNamesAll;
    HTuple  hv_ParamNames, hv_KeysExists, hv_I, hv_Exists, hv_InputKeys;
    HTuple  hv_Key, hv_Value, hv_Indices, hv_ValidValues, hv_ValidTypes;
    HTuple  hv_V, hv_T, hv_IsInt, hv_ValidTypesListing, hv_ValidValueListing;
    HTuple  hv_EmptyStrings, hv_ImageRangeMinExists, hv_ImageRangeMaxExists;
    HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_IndexParam;
    HTuple  hv_SetBackgroundID, hv_ClassIDsBackground, hv_Intersection;
    HTuple  hv_IgnoreClassIDs, hv_KnownClasses, hv_IgnoreClassID;
    HTuple  hv_OptionalKeysExist, hv_InstanceType, hv_IsInstanceSegmentation;
    HTuple  hv_IgnoreDirection, hv_ClassIDsNoOrientation, hv_SemTypes;

    //
    //This procedure checks a dictionary with parameters for DL preprocessing.
    //
    hv_CheckParams = 1;
    //If check_params is set to false, do not check anything.
    GetDictParam(hv_DLPreprocessParam, "key_exists", "check_params", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
        GetDictTuple(hv_DLPreprocessParam, "check_params", &hv_CheckParams);
        if (0 != (hv_CheckParams.TupleNot()))
        {
            return;
        }
    }
    //
    try
    {
        GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_DLModelType);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        throw HException(HTuple(HTuple("DLPreprocessParam needs the parameter: '")+"model_type")+"'");
    }
    //
    //Check for correct model type.
    hv_SupportedModelTypes.Clear();
    hv_SupportedModelTypes[0] = "3d_gripping_point_detection";
    hv_SupportedModelTypes[1] = "anomaly_detection";
    hv_SupportedModelTypes[2] = "classification";
    hv_SupportedModelTypes[3] = "detection";
    hv_SupportedModelTypes[4] = "gc_anomaly_detection";
    hv_SupportedModelTypes[5] = "ocr_recognition";
    hv_SupportedModelTypes[6] = "ocr_detection";
    hv_SupportedModelTypes[7] = "segmentation";
    TupleFind(hv_SupportedModelTypes, hv_DLModelType, &hv_Index);
    if (0 != (HTuple(int(hv_Index==-1)).TupleOr(int(hv_Index==HTuple()))))
    {
        throw HException(HTuple("Only models of type '3d_gripping_point_detection', 'anomaly_detection', 'classification', 'detection', 'gc_anomaly_detection', 'ocr_recognition', 'ocr_detection' or 'segmentation' are supported"));
        return;
    }
    //
    //Parameter names that are required.
    //General parameters.
    hv_ParamNamesGeneral.Clear();
    hv_ParamNamesGeneral[0] = "model_type";
    hv_ParamNamesGeneral[1] = "image_width";
    hv_ParamNamesGeneral[2] = "image_height";
    hv_ParamNamesGeneral[3] = "image_num_channels";
    hv_ParamNamesGeneral[4] = "image_range_min";
    hv_ParamNamesGeneral[5] = "image_range_max";
    hv_ParamNamesGeneral[6] = "normalization_type";
    hv_ParamNamesGeneral[7] = "domain_handling";
    //Segmentation specific parameters.
    hv_ParamNamesSegmentation.Clear();
    hv_ParamNamesSegmentation[0] = "ignore_class_ids";
    hv_ParamNamesSegmentation[1] = "set_background_id";
    hv_ParamNamesSegmentation[2] = "class_ids_background";
    //Detection specific parameters.
    hv_ParamNamesDetectionOptional.Clear();
    hv_ParamNamesDetectionOptional[0] = "instance_type";
    hv_ParamNamesDetectionOptional[1] = "ignore_direction";
    hv_ParamNamesDetectionOptional[2] = "class_ids_no_orientation";
    hv_ParamNamesDetectionOptional[3] = "instance_segmentation";
    //Optional preprocessing parameters.
    hv_ParamNamesPreprocessingOptional.Clear();
    hv_ParamNamesPreprocessingOptional[0] = "mean_values_normalization";
    hv_ParamNamesPreprocessingOptional[1] = "deviation_values_normalization";
    hv_ParamNamesPreprocessingOptional[2] = "check_params";
    hv_ParamNamesPreprocessingOptional[3] = "augmentation";
    //3D Gripping Point Detection specific parameters.
    hv_ParamNames3DGrippingPointsOptional.Clear();
    hv_ParamNames3DGrippingPointsOptional[0] = "min_z";
    hv_ParamNames3DGrippingPointsOptional[1] = "max_z";
    hv_ParamNames3DGrippingPointsOptional[2] = "normal_image_width";
    hv_ParamNames3DGrippingPointsOptional[3] = "normal_image_height";
    //All parameters
    hv_ParamNamesAll.Clear();
    hv_ParamNamesAll.Append(hv_ParamNamesGeneral);
    hv_ParamNamesAll.Append(hv_ParamNamesSegmentation);
    hv_ParamNamesAll.Append(hv_ParamNamesDetectionOptional);
    hv_ParamNamesAll.Append(hv_ParamNames3DGrippingPointsOptional);
    hv_ParamNamesAll.Append(hv_ParamNamesPreprocessingOptional);
    hv_ParamNames = hv_ParamNamesGeneral;
    if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
    {
        //Extend ParamNames for models of type segmentation.
        hv_ParamNames = hv_ParamNames.TupleConcat(hv_ParamNamesSegmentation);
    }
    //
    //Check if legacy parameter exist.
    //Otherwise map it to the legal parameter.
    replace_legacy_preprocessing_parameters(hv_DLPreprocessParam);
    //
    //Check that all necessary parameters are included.
    //
    GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNames, &hv_KeysExists);
    if (0 != (int(((hv_KeysExists.TupleEqualElem(0)).TupleSum())>0)))
    {
        {
            HTuple end_val54 = hv_KeysExists.TupleLength();
            HTuple step_val54 = 1;
            for (hv_I=0; hv_I.Continue(end_val54, step_val54); hv_I += step_val54)
            {
                hv_Exists = HTuple(hv_KeysExists[hv_I]);
                if (0 != (hv_Exists.TupleNot()))
                {
                    throw HException(("DLPreprocessParam needs the parameter: '"+HTuple(hv_ParamNames[hv_I]))+"'");
                }
            }
        }
    }
    //
    //Check the keys provided.
    GetDictParam(hv_DLPreprocessParam, "keys", HTuple(), &hv_InputKeys);
    {
        HTuple end_val64 = (hv_InputKeys.TupleLength())-1;
        HTuple step_val64 = 1;
        for (hv_I=0; hv_I.Continue(end_val64, step_val64); hv_I += step_val64)
        {
            hv_Key = HTuple(hv_InputKeys[hv_I]);
            GetDictTuple(hv_DLPreprocessParam, hv_Key, &hv_Value);
            //Check that the key is known.
            TupleFind(hv_ParamNamesAll, hv_Key, &hv_Indices);
            if (0 != (int(hv_Indices==-1)))
            {
                throw HException(("Unknown key for DLPreprocessParam: '"+HTuple(hv_InputKeys[hv_I]))+"'");
                return;
            }
            //Set expected values and types.
            hv_ValidValues = HTuple();
            hv_ValidTypes = HTuple();
            if (0 != (int(hv_Key==HTuple("normalization_type"))))
            {
                hv_ValidValues.Clear();
                hv_ValidValues[0] = "all_channels";
                hv_ValidValues[1] = "first_channel";
                hv_ValidValues[2] = "constant_values";
                hv_ValidValues[3] = "none";
            }
            else if (0 != (int(hv_Key==HTuple("domain_handling"))))
            {
                if (0 != (int(hv_DLModelType==HTuple("anomaly_detection"))))
                {
                    hv_ValidValues.Clear();
                    hv_ValidValues[0] = "full_domain";
                    hv_ValidValues[1] = "crop_domain";
                    hv_ValidValues[2] = "keep_domain";
                }
                else if (0 != (int(hv_DLModelType==HTuple("3d_gripping_point_detection"))))
                {
                    hv_ValidValues.Clear();
                    hv_ValidValues[0] = "full_domain";
                    hv_ValidValues[1] = "crop_domain";
                    hv_ValidValues[2] = "keep_domain";
                }
                else
                {
                    hv_ValidValues.Clear();
                    hv_ValidValues[0] = "full_domain";
                    hv_ValidValues[1] = "crop_domain";
                }
            }
            else if (0 != (int(hv_Key==HTuple("model_type"))))
            {
                hv_ValidValues.Clear();
                hv_ValidValues[0] = "3d_gripping_point_detection";
                hv_ValidValues[1] = "anomaly_detection";
                hv_ValidValues[2] = "classification";
                hv_ValidValues[3] = "detection";
                hv_ValidValues[4] = "gc_anomaly_detection";
                hv_ValidValues[5] = "ocr_recognition";
                hv_ValidValues[6] = "ocr_detection";
                hv_ValidValues[7] = "segmentation";
            }
            else if (0 != (int(hv_Key==HTuple("augmentation"))))
            {
                hv_ValidValues.Clear();
                hv_ValidValues[0] = "true";
                hv_ValidValues[1] = "false";
            }
            else if (0 != (int(hv_Key==HTuple("set_background_id"))))
            {
                hv_ValidTypes = "int";
            }
            else if (0 != (int(hv_Key==HTuple("class_ids_background"))))
            {
                hv_ValidTypes = "int";
            }
            //Check that type is valid.
            if (0 != (int((hv_ValidTypes.TupleLength())>0)))
            {
                {
                    HTuple end_val97 = (hv_ValidTypes.TupleLength())-1;
                    HTuple step_val97 = 1;
                    for (hv_V=0; hv_V.Continue(end_val97, step_val97); hv_V += step_val97)
                    {
                        hv_T = HTuple(hv_ValidTypes[hv_V]);
                        if (0 != (int(hv_T==HTuple("int"))))
                        {
                            TupleIsInt(hv_Value, &hv_IsInt);
                            if (0 != (hv_IsInt.TupleNot()))
                            {
                                hv_ValidTypes = ("'"+hv_ValidTypes)+"'";
                                if (0 != (int((hv_ValidTypes.TupleLength())<2)))
                                {
                                    hv_ValidTypesListing = hv_ValidTypes;
                                }
                                else
                                {
                                    hv_ValidTypesListing = (((hv_ValidTypes.TupleSelectRange(0,HTuple(0).TupleMax2((hv_ValidTypes.TupleLength())-2)))+HTuple(", "))+HTuple(hv_ValidTypes[(hv_ValidTypes.TupleLength())-1])).TupleSum();
                                }
                                throw HException(((((("The value given in the key '"+hv_Key)+"' of DLPreprocessParam is invalid. Valid types are: ")+hv_ValidTypesListing)+". The given value was '")+hv_Value)+"'.");
                                return;
                            }
                        }
                        else
                        {
                            throw HException("Internal error. Unknown valid type.");
                        }
                    }
                }
            }
            //Check that value is valid.
            if (0 != (int((hv_ValidValues.TupleLength())>0)))
            {
                TupleFindFirst(hv_ValidValues, hv_Value, &hv_Index);
                if (0 != (int(hv_Index==-1)))
                {
                    hv_ValidValues = ("'"+hv_ValidValues)+"'";
                    if (0 != (int((hv_ValidValues.TupleLength())<2)))
                    {
                        hv_ValidValueListing = hv_ValidValues;
                    }
                    else
                    {
                        hv_EmptyStrings = HTuple((hv_ValidValues.TupleLength())-2,"");
                        hv_ValidValueListing = (((hv_ValidValues.TupleSelectRange(0,HTuple(0).TupleMax2((hv_ValidValues.TupleLength())-2)))+HTuple(", "))+(hv_EmptyStrings.TupleConcat(HTuple(hv_ValidValues[(hv_ValidValues.TupleLength())-1])))).TupleSum();
                    }
                    throw HException(((((("The value given in the key '"+hv_Key)+"' of DLPreprocessParam is invalid. Valid values are: ")+hv_ValidValueListing)+". The given value was '")+hv_Value)+"'.");
                }
            }
        }
    }
    //
    //Check the correct setting of ImageRangeMin and ImageRangeMax.
    if (0 != (HTuple(int(hv_DLModelType==HTuple("classification"))).TupleOr(int(hv_DLModelType==HTuple("detection")))))
    {
        //Check ImageRangeMin and ImageRangeMax.
        GetDictParam(hv_DLPreprocessParam, "key_exists", "image_range_min", &hv_ImageRangeMinExists);
        GetDictParam(hv_DLPreprocessParam, "key_exists", "image_range_max", &hv_ImageRangeMaxExists);
        //If they are present, check that they are set correctly.
        if (0 != hv_ImageRangeMinExists)
        {
            GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
            if (0 != (int(hv_ImageRangeMin!=-127)))
            {
                throw HException(("For model type "+hv_DLModelType)+" ImageRangeMin has to be -127.");
            }
        }
        if (0 != hv_ImageRangeMaxExists)
        {
            GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
            if (0 != (int(hv_ImageRangeMax!=128)))
            {
                throw HException(("For model type "+hv_DLModelType)+" ImageRangeMax has to be 128.");
            }
        }
    }
    //
    //Check segmentation specific parameters.
    if (0 != (HTuple(int(hv_DLModelType==HTuple("segmentation"))).TupleOr(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
    {
        //Check if detection specific parameters are set.
        GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional,
                     &hv_KeysExists);
        //If they are present, check that they are [].
        {
            HTuple end_val157 = (hv_ParamNamesDetectionOptional.TupleLength())-1;
            HTuple step_val157 = 1;
            for (hv_IndexParam=0; hv_IndexParam.Continue(end_val157, step_val157); hv_IndexParam += step_val157)
            {
                if (0 != (HTuple(hv_KeysExists[hv_IndexParam])))
                {
                    GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[hv_IndexParam]),
                                 &hv_Value);
                    if (0 != (int(hv_Value!=HTuple())))
                    {
                        throw HException(((("The preprocessing parameter '"+HTuple(hv_ParamNamesDetectionOptional[hv_IndexParam]))+"' was set to ")+hv_Value)+HTuple(" but for segmentation it should be set to [], as it is not used for this method."));
                    }
                }
            }
        }
        //Check 'set_background_id'.
        GetDictTuple(hv_DLPreprocessParam, "set_background_id", &hv_SetBackgroundID);
        if (0 != (HTuple(int(hv_SetBackgroundID!=HTuple())).TupleAnd(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
        {
            throw HException(HTuple(HTuple("The preprocessing parameter '")+"set_background_id")+HTuple("' should be set to [] for 3d_gripping_point_detection, as it is not used for this method."));
        }
        if (0 != (int((hv_SetBackgroundID.TupleLength())>1)))
        {
            throw HException("Only one class_id as 'set_background_id' allowed.");
        }
        //Check 'class_ids_background'.
        GetDictTuple(hv_DLPreprocessParam, "class_ids_background", &hv_ClassIDsBackground);
        if (0 != (HTuple(int(hv_ClassIDsBackground!=HTuple())).TupleAnd(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
        {
            throw HException(HTuple(HTuple("The preprocessing parameter '")+"class_ids_background")+HTuple("' should be set to [] for 3d_gripping_point_detection, as it is not used for this method."));
        }
        if (0 != (HTuple(HTuple(int((hv_SetBackgroundID.TupleLength())>0)).TupleAnd(HTuple(int((hv_ClassIDsBackground.TupleLength())>0)).TupleNot())).TupleOr(HTuple(int((hv_ClassIDsBackground.TupleLength())>0)).TupleAnd(HTuple(int((hv_SetBackgroundID.TupleLength())>0)).TupleNot()))))
        {
            throw HException("Both keys 'set_background_id' and 'class_ids_background' are required.");
        }
        //Check that 'class_ids_background' and 'set_background_id' are disjoint.
        if (0 != (int((hv_SetBackgroundID.TupleLength())>0)))
        {
            TupleIntersection(hv_SetBackgroundID, hv_ClassIDsBackground, &hv_Intersection);
            if (0 != (hv_Intersection.TupleLength()))
            {
                throw HException("Class IDs in 'set_background_id' and 'class_ids_background' need to be disjoint.");
            }
        }
        //Check 'ignore_class_ids'.
        GetDictTuple(hv_DLPreprocessParam, "ignore_class_ids", &hv_IgnoreClassIDs);
        if (0 != (HTuple(int(hv_IgnoreClassIDs!=HTuple())).TupleAnd(int(hv_DLModelType==HTuple("3d_gripping_point_detection")))))
        {
            throw HException(HTuple(HTuple("The preprocessing parameter '")+"ignore_class_ids")+HTuple("' should be set to [] for 3d_gripping_point_detection, as it is not used for this method."));
        }
        hv_KnownClasses.Clear();
        hv_KnownClasses.Append(hv_SetBackgroundID);
        hv_KnownClasses.Append(hv_ClassIDsBackground);
        {
            HTuple end_val194 = (hv_IgnoreClassIDs.TupleLength())-1;
            HTuple step_val194 = 1;
            for (hv_I=0; hv_I.Continue(end_val194, step_val194); hv_I += step_val194)
            {
                hv_IgnoreClassID = HTuple(hv_IgnoreClassIDs[hv_I]);
                TupleFindFirst(hv_KnownClasses, hv_IgnoreClassID, &hv_Index);
                if (0 != (HTuple(int((hv_Index.TupleLength())>0)).TupleAnd(int(hv_Index!=-1))))
                {
                    throw HException("The given 'ignore_class_ids' must not be included in the 'class_ids_background' or 'set_background_id'.");
                }
            }
        }
    }
    else if (0 != (int(hv_DLModelType==HTuple("detection"))))
    {
        //Check if segmentation specific parameters are set.
        GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesSegmentation, &hv_KeysExists);
        //If they are present, check that they are [].
        {
            HTuple end_val205 = (hv_ParamNamesSegmentation.TupleLength())-1;
            HTuple step_val205 = 1;
            for (hv_IndexParam=0; hv_IndexParam.Continue(end_val205, step_val205); hv_IndexParam += step_val205)
            {
                if (0 != (HTuple(hv_KeysExists[hv_IndexParam])))
                {
                    GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesSegmentation[hv_IndexParam]),
                                 &hv_Value);
                    if (0 != (int(hv_Value!=HTuple())))
                    {
                        throw HException(((("The preprocessing parameter '"+HTuple(hv_ParamNamesSegmentation[hv_IndexParam]))+"' was set to ")+hv_Value)+HTuple(" but for detection it should be set to [], as it is not used for this method."));
                    }
                }
            }
        }
        //Check optional parameters.
        GetDictParam(hv_DLPreprocessParam, "key_exists", hv_ParamNamesDetectionOptional,
                     &hv_OptionalKeysExist);
        if (0 != (HTuple(hv_OptionalKeysExist[0])))
        {
            //Check 'instance_type'.
            GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[0]),
                    &hv_InstanceType);
            if (0 != (int((((HTuple("rectangle1").Append("rectangle2")).Append("mask")).TupleFind(hv_InstanceType))==-1)))
            {
                throw HException(("Invalid generic parameter for 'instance_type': "+hv_InstanceType)+HTuple(", only 'rectangle1' and 'rectangle2' are allowed"));
            }
        }
        //If instance_segmentation is set we might overwrite the instance_type for the preprocessing.
        if (0 != (HTuple(hv_OptionalKeysExist[3])))
        {
            GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[3]),
                    &hv_IsInstanceSegmentation);
            if (0 != (int(((((HTuple(1).Append(0)).Append("true")).Append("false")).TupleFind(hv_IsInstanceSegmentation))==-1)))
            {
                throw HException(("Invalid generic parameter for 'instance_segmentation': "+hv_IsInstanceSegmentation)+HTuple(", only true, false, 'true' and 'false' are allowed"));
            }
        }
        if (0 != (HTuple(hv_OptionalKeysExist[1])))
        {
            //Check 'ignore_direction'.
            GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[1]),
                    &hv_IgnoreDirection);
            if (0 != (int(((HTuple(1).Append(0)).TupleFind(hv_IgnoreDirection))==-1)))
            {
                throw HException(("Invalid generic parameter for 'ignore_direction': "+hv_IgnoreDirection)+HTuple(", only true and false are allowed"));
            }
        }
        if (0 != (HTuple(hv_OptionalKeysExist[2])))
        {
            //Check 'class_ids_no_orientation'.
            GetDictTuple(hv_DLPreprocessParam, HTuple(hv_ParamNamesDetectionOptional[2]),
                    &hv_ClassIDsNoOrientation);
            TupleSemTypeElem(hv_ClassIDsNoOrientation, &hv_SemTypes);
            if (0 != (HTuple(int(hv_ClassIDsNoOrientation!=HTuple())).TupleAnd(int(((hv_SemTypes.TupleEqualElem("integer")).TupleSum())!=(hv_ClassIDsNoOrientation.TupleLength())))))
            {
                throw HException(("Invalid generic parameter for 'class_ids_no_orientation': "+hv_ClassIDsNoOrientation)+HTuple(", only integers are allowed"));
            }
            else
            {
                if (0 != (HTuple(int(hv_ClassIDsNoOrientation!=HTuple())).TupleAnd(int(((hv_ClassIDsNoOrientation.TupleGreaterEqualElem(0)).TupleSum())!=(hv_ClassIDsNoOrientation.TupleLength())))))
                {
                    throw HException(("Invalid generic parameter for 'class_ids_no_orientation': "+hv_ClassIDsNoOrientation)+HTuple(", only non-negative integers are allowed"));
                }
            }
        }
    }
    //
    return;
}

// Chapter: Deep Learning / Model
void HalxAI:: check_train_dl_model_params (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_NumTrainSamples,
                                           HTuple hv_StartEpoch, HTuple hv_TrainParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ModelType, hv_PreprocessedDataset;
    HTuple  hv_PreprocessParam, hv_Exception, hv_ImageRangeMin;
    HTuple  hv_ImageRangeMax, hv_DLPreprocessParams, hv_DLPreprocessImageRange;
    HTuple  hv_DLPreprocessNormalizationType, hv_TrainParamAnomaly;
    HTuple  hv_DomainRatio, hv_ErrorThreshold, hv_RegularizationNoise;
    HTuple  hv_NumEpochs, hv_BatchSizeDevice, hv_BatchSizeMultiplier;
    HTuple  hv_BatchSize, hv_ClassIdsExist, hv_ClassIDsModel;
    HTuple  hv_ClassIDsDataset, hv_Index, hv_IndexFind, hv_ClassIDsModelStr;
    HTuple  hv_ClassIDsDatasetStr, hv_DisplayParam, hv_DisplayKeys;
    HTuple  hv_KeyName, hv_KeyValue, hv_KeyExists, hv_EvaluationComparisonKeys;
    HTuple  hv_OptimizationMethod, hv_EvaluationComparisonKeysString;
    HTuple  hv_TrainParamCopy, hv__;

    //
    //This procedure checks the parameters used in the procedure train_dl_model for consistency.
    //
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    //
    //Check the NumEpochs parameter.
    if (0 != (hv_StartEpoch.TupleIsNumber()))
    {
        if (0 != (int(hv_StartEpoch<0.0)))
        {
            throw HException("Error: StartEpoch < 0 is not allowed.");
        }
    }
    //
    //Check if the dataset is already preprocessed.
    hv_PreprocessedDataset = 0;
    try
    {
        GetDictTuple(hv_DLDataset, "preprocess_param", &hv_PreprocessParam);
        hv_PreprocessedDataset = 1;
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    if (0 != (hv_PreprocessedDataset.TupleNot()))
    {
        throw HException("Error: The supplied dataset needs to be preprocessed already. Use the standard procedure preprocess_dl_dataset.");
    }
    //
    //Check if the dataset preprocessing parameters fit
    //to the parameters required by the model.
    GetDlModelParam(hv_DLModelHandle, "image_range_min", &hv_ImageRangeMin);
    GetDlModelParam(hv_DLModelHandle, "image_range_max", &hv_ImageRangeMax);
    hv_DLPreprocessParams = hv_DLDataset.TupleGetDictTuple("preprocess_param");
    hv_DLPreprocessImageRange.Clear();
    hv_DLPreprocessImageRange.Append((hv_DLDataset.TupleGetDictTuple("preprocess_param")).TupleGetDictTuple("image_range_min"));
    hv_DLPreprocessImageRange.Append((hv_DLDataset.TupleGetDictTuple("preprocess_param")).TupleGetDictTuple("image_range_max"));
    hv_DLPreprocessNormalizationType = (hv_DLDataset.TupleGetDictTuple("preprocess_param")).TupleGetDictTuple("normalization_type");
    if (0 != (HTuple(int(hv_ModelType==HTuple("gc_anomaly_detection"))).TupleAnd(HTuple(int(hv_DLPreprocessImageRange!=(hv_ImageRangeMin.TupleConcat(hv_ImageRangeMax)))).TupleOr(int(hv_DLPreprocessNormalizationType!=HTuple("none"))))))
    {
        throw HException(HTuple("Error: For models of type 'gc_anomaly_detection' the dataset must be preprocessed with 'normalization_type' set to 'none' and default image range [-127, 128]."));
    }
    //
    //Check parameters for anomaly detection
    if (0 != (int(hv_ModelType==HTuple("anomaly_detection"))))
    {
        GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
        GetDictTuple(hv_TrainParamAnomaly, "domain_ratio", &hv_DomainRatio);
        if (0 != (HTuple(int(hv_DomainRatio<=0)).TupleOr(int(hv_DomainRatio>1.0))))
        {
            throw HException("Error: The anomaly detection parameter 'domain_ratio' must be between 0 and 1.");
        }
        GetDictTuple(hv_TrainParamAnomaly, "error_threshold", &hv_ErrorThreshold);
        if (0 != (HTuple(int(hv_ErrorThreshold<0)).TupleOr(int(hv_ErrorThreshold>1))))
        {
            throw HException("Error: The anomaly detection parameter 'error_threshold' must be between 0 and 1.");
        }
        GetDictTuple(hv_TrainParamAnomaly, "regularization_noise", &hv_RegularizationNoise);
        if (0 != (int(hv_RegularizationNoise<0)))
        {
            throw HException("Error: The anomaly detection parameter 'regularization_noise' must be greater than or equal to 0.");
        }
        return;
    }
    //
    //Check parameters for other models.
    //
    //Check the NumEpochs parameter.
    if (0 != (hv_StartEpoch.TupleIsNumber()))
    {
        GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
        if (0 != (int(hv_StartEpoch>hv_NumEpochs)))
        {
            throw HException("Error: StartEpoch > NumEpochs is not allowed.");
        }
    }
    else
    {
        if (0 != (int(hv_StartEpoch!=HTuple("resume"))))
        {
            throw HException("Error: StartEpoch has to be a number or equal to 'resume'.");
        }
    }
    //
    //Check that the number of training samples is at least as big as the total batch size.
    GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
    GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
    hv_BatchSize = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
    if (0 != (int(hv_NumTrainSamples<hv_BatchSize)))
    {
        throw HException("Error: Number of training samples is smaller than the batch size.");
    }
    //
    //Check that all model class IDs are a part of the DLDataset class IDs.
    GetHandleParam(hv_PreprocessParam, "key_exists", "class_ids", &hv_ClassIdsExist);
    if (0 != hv_ClassIdsExist)
    {
        GetDlModelParam(hv_DLModelHandle, "class_ids", &hv_ClassIDsModel);
        GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDsDataset);
        {
            HTuple end_val79 = (hv_ClassIDsModel.TupleLength())-1;
            HTuple step_val79 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val79, step_val79); hv_Index += step_val79)
            {
                TupleFindFirst(hv_ClassIDsDataset, HTuple(hv_ClassIDsModel[hv_Index]), &hv_IndexFind);
                if (0 != (int(hv_IndexFind<0)))
                {
                    hv_ClassIDsModelStr = (" "+hv_ClassIDsModel).TupleSum();
                    hv_ClassIDsDatasetStr = (" "+hv_ClassIDsDataset).TupleSum();
                    throw HException((((("Error: A model class ID is not part of the DLDataset class IDs. DLModelHandle class ID: "+hv_ClassIDsModelStr)+". ")+"DLDataset class IDs: ")+hv_ClassIDsDatasetStr)+".");
                }
            }
        }
    }

    //Check display parameters:╓▒╜╙╫в╩═╡Ї,▓╗╨ш╥к╧╘╩╛
    GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
    GetDictParam(hv_DisplayParam, "keys", HTuple(), &hv_DisplayKeys);
    {
        HTuple end_val92 = (hv_DisplayKeys.TupleLength())-1;
        HTuple step_val92 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val92, step_val92); hv_Index += step_val92)
        {
            hv_KeyName = HTuple(hv_DisplayKeys[hv_Index]);
            if (0 != (int(hv_KeyName==HTuple("enabled"))))
            {
                GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
                if (0 != (HTuple(int(hv_KeyValue!=1)).TupleAnd(int(hv_KeyValue!=0))))
                {
                    throw HException("The value for 'enabled' is not supported.");
                }
            }
            else if (0 != (int(hv_KeyName==HTuple("change_plot_interval_seconds"))))
            {
                GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
                if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleOr(hv_KeyValue.TupleIsReal())).TupleNot()))
                {
                    throw HException("The value of 'change_plot_interval_seconds' has to be of type integer or real");
                }
            }
            else if (0 != (int(hv_KeyName==HTuple("num_images"))))
            {
                GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
                if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleNot()).TupleOr(int(hv_KeyValue<1))))
                {
                    throw HException("The value of 'num_images' has to be of type integer and larger or equal to one");
                }
            }
            else if (0 != (int(hv_KeyName==HTuple("selected_percentage_train_samples"))))
            {
                GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
                if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleOr(hv_KeyValue.TupleIsReal())).TupleNot()))
                {
                    throw HException("The value of 'selected_percentage_train_samples' has to be of type integer or real");
                }
                if (0 != (HTuple(int(hv_KeyValue<0)).TupleOr(int(hv_KeyValue>100))))
                {
                    throw HException(HTuple("The value of 'selected_percentage_train_samples' has to be in [0,100]"));
                }
            }
            else if (0 != (int(hv_KeyName==HTuple("update_images_interval_epochs"))))
            {
                GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
                if (0 != (HTuple((hv_KeyValue.TupleIsInt()).TupleOr(hv_KeyValue.TupleIsReal())).TupleNot()))
                {
                    throw HException("The value of 'update_images_interval_epochs' has to be of type integer or real");
                }
                if (0 != (int(hv_KeyValue<=0)))
                {
                    throw HException("The value of 'update_images_interval_epochs' has to be larger than zero");
                }
            }
            else if (0 != (int(hv_KeyName==HTuple("x_axis_label"))))
            {
                GetDictTuple(hv_DisplayParam, hv_KeyName, &hv_KeyValue);
                if (0 != (HTuple(int(hv_KeyValue!=HTuple("epochs"))).TupleAnd(int(hv_KeyValue!=HTuple("iterations")))))
                {
                    throw HException("The value for 'x_axis_label' is not supported.");
                }
            }
            else if (0 != (HTuple(HTuple(int(hv_KeyName==HTuple("status_model_params"))).TupleOr(int(hv_KeyName==HTuple("tiled_param")))).TupleOr(int(hv_KeyName==HTuple("randomize_images")))))
            {
                //No check for these advanced settings.
                //No check for randomize_images for backward compatibility.
                continue;
            }
            else
            {
                throw HException(("The provided key "+hv_KeyName)+" for 'display' is invalid.");
            }
        }
    }

    //
    //Check evaluation related train parameters.
    GetDictParam(hv_TrainParam, "key_exists", "evaluation_comparison_keys", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
        GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
        //Check optimization method based on provided evaluation comparison keys.
        get_dl_evaluation_optimization_method(hv_EvaluationComparisonKeys, &hv_OptimizationMethod);
        if (0 != (int(hv_OptimizationMethod==HTuple("mixed"))))
        {
            hv_EvaluationComparisonKeysString = (hv_EvaluationComparisonKeys+" ").TupleSum();
            throw HException(HTuple("Comparison keys invalid. No useful combination of values possible that are compared differently (\"<\", \">\"). EvaluationComparisonKeys: ")+hv_EvaluationComparisonKeysString);
        }
    }
    //
    //Initialize change and serialization strategies in order to test for valid values.
    CopyDict(hv_TrainParam, HTuple(), HTuple(), &hv_TrainParamCopy);
    init_train_dl_model_change_strategies(hv_TrainParamCopy, &hv__);
    init_train_dl_model_serialization_strategies(hv_TrainParamCopy, &hv__);
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Collect the information required for displaying the training progress update.
void HalxAI:: collect_train_dl_model_info (HTuple hv_DLModelHandle, HTuple hv_TrainResults,
                                           HTuple hv_EvaluationInfos, HTuple hv_EvaluationComparisonKeys, HTuple hv_EvaluationOptimizationMethod,
                                           HTuple hv_Iteration, HTuple hv_NumIterations, HTuple hv_NumIterationsPerEpoch,
                                           HTuple hv_NumSamplesMeanLoss, HTuple *hv_TrainInfo)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_EpochReal, hv_NumEpochs, hv_TrainResultsStored;
    HTuple  hv_Exception, hv_PossibleParamNames, hv_ModelParams;
    HTuple  hv_Index, hv_ParamName, hv_DeviceHandles, hv_DeviceLength;
    HTuple  hv_DeviceTypes, hv_DeviceNames, hv_DeviceIndex;
    HTuple  hv_DeviceType, hv_DeviceName, hv_GenParamValue;
    HTuple  hv_LossSamplesTrainResults, hv_Indices, hv_TrainResultsUsed;
    HTuple  hv_BatchSizeDevice, hv_BatchSizeMultiplier, hv_BatchSize;
    HTuple  hv_NumIterationsMean, hv_LossParam, hv_LossValues;
    HTuple  hv_TrainResult, hv_LossValue, hv_LossMean, hv_BestEvaluationInfo;
    HTuple  hv_BestEvaluationInfoTrain, hv_BestEvaluationValue;
    HTuple  hv_BestEvaluationValueTrain, hv_BestEvaluationKeys;
    HTuple  hv_BestEvaluationKeysTrain, hv_EvaluationInfo, hv_ValidationEvaluationResult;
    HTuple  hv_TrainEvaluationResult, hv_Value, hv_ValidEvaluationKeys;
    HTuple  hv_ValueTrain, hv_ValidEvaluationKeysTrain, hv_BestEvaluationData;

    //
    //This procedure computes training information for the given iteration.
    //
    CreateDict(&(*hv_TrainInfo));
    //
    //General iteration and epoch status.
    hv_EpochReal = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
    //Important note:
    //Inside of this procedure, we compute iterations like that:
    //*  IterationTmp := int(round(EpochReal * (NumIterationsPerEpoch))-1)
    //If a caller of this procedure supplies a value we should use:
    //*  IterationTmp := int(floor(EpochReal * NumIterationsPerEpoch))
    //
    hv_NumEpochs = hv_NumIterations/(hv_NumIterationsPerEpoch.TupleReal());
    //
    //Note, iterations depend on a specific batch size,
    //hence only epochs are expressive.
    SetDictTuple((*hv_TrainInfo), "epoch", hv_EpochReal);
    SetDictTuple((*hv_TrainInfo), "num_epochs", hv_NumEpochs);
    SetDictTuple((*hv_TrainInfo), "num_iterations_per_epoch", hv_NumIterationsPerEpoch);
    //
    try
    {
        hv_TrainResultsStored = HTuple(hv_TrainResults[(hv_TrainResults.TupleNotEqualElem(-1)).TupleFind(1)]);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_TrainResultsStored = HTuple();
    }
    //
    //Collect all model parameters.
    GetParamInfo("get_dl_model_param", "GenParamName", "value_list", &hv_PossibleParamNames);
    CreateDict(&hv_ModelParams);
    SetDictTuple((*hv_TrainInfo), "model_params", hv_ModelParams);
    {
        HTuple end_val31 = (hv_PossibleParamNames.TupleLength())-1;
        HTuple step_val31 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val31, step_val31); hv_Index += step_val31)
        {
            hv_ParamName = HTuple(hv_PossibleParamNames[hv_Index]);
            //Do not collect summary as it cannot change during training and consumes much space.
            if (0 != (int(hv_ParamName==HTuple("summary"))))
            {
                continue;
            }
            //
            try
            {
                if (0 != (int(hv_ParamName==HTuple("device"))))
                {
                    //The device handle cannot be serialized. Therefore we get the
                    //information via keys and serialize them.
                    GetDlModelParam(hv_DLModelHandle, hv_ParamName, &hv_DeviceHandles);
                    TupleLength(hv_DeviceHandles, &hv_DeviceLength);
                    hv_DeviceTypes = HTuple();
                    hv_DeviceNames = HTuple();
                    TupleGenConst(hv_DeviceLength, "", &hv_DeviceTypes);
                    TupleGenConst(hv_DeviceLength, "", &hv_DeviceNames);
                    {
                        HTuple end_val48 = (hv_DeviceLength.TupleLength())-1;
                        HTuple step_val48 = 1;
                        for (hv_DeviceIndex=0; hv_DeviceIndex.Continue(end_val48, step_val48); hv_DeviceIndex += step_val48)
                        {
                            GetHandleTuple(HTuple(hv_DeviceHandles[hv_DeviceIndex]), "type", &hv_DeviceType);
                            GetHandleTuple(HTuple(hv_DeviceHandles[hv_DeviceIndex]), "name", &hv_DeviceName);
                            hv_DeviceTypes[hv_DeviceIndex] = hv_DeviceType;
                            hv_DeviceNames[hv_DeviceIndex] = hv_DeviceName;
                        }
                    }
                }
                else
                {
                    GetDlModelParam(hv_DLModelHandle, hv_ParamName, &hv_GenParamValue);
                }
            }
            // catch (Exception)
            catch (HException &HDevExpDefaultException)
            {
                HDevExpDefaultException.ToHTuple(&hv_Exception);
                continue;
            }
            //
            if (0 != (int(hv_ParamName==HTuple("device"))))
            {
                SetDictTuple(hv_ModelParams, "device_type", hv_DeviceTypes);
                SetDictTuple(hv_ModelParams, "device_name", hv_DeviceNames);
            }
            else
            {
                SetDictTuple(hv_ModelParams, hv_ParamName, hv_GenParamValue);
            }
        }
    }
    //
    //Calculate a mean loss value.
    SetDictTuple((*hv_TrainInfo), "mean_loss", HTuple());
    SetDictTuple((*hv_TrainInfo), "mean_loss_samples", 0);
    //
    hv_LossSamplesTrainResults = HTuple();
    TupleFind(hv_TrainResults.TupleNotEqualElem(-1), 1, &hv_Indices);
    if (0 != (int(hv_Indices!=-1)))
    {
        hv_TrainResultsUsed = HTuple(hv_TrainResults[hv_Indices]);
    }
    else
    {
        hv_TrainResultsUsed = HTuple();
    }
    if (0 != (int((hv_TrainResultsUsed.TupleLength())>0)))
    {
        GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
        GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
        hv_BatchSize = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
        hv_NumIterationsMean = ((hv_NumSamplesMeanLoss/(hv_BatchSize.TupleReal())).TupleCeil()).TupleInt();
        //
        if (0 != (int(hv_NumIterationsMean==0)))
        {
            hv_TrainResultsUsed = ((const HTuple&)hv_TrainResultsUsed)[(hv_TrainResultsUsed.TupleLength())-1];
        }
        else
        {
            hv_TrainResultsUsed = hv_TrainResultsUsed.TupleSelectRange(((hv_TrainResultsUsed.TupleLength())-hv_NumIterationsMean).TupleMax2(0),(hv_TrainResultsUsed.TupleLength())-1);
        }
        //
        hv_LossParam = "total_loss";
        TupleGenConst(hv_TrainResultsUsed.TupleLength(), -1, &hv_LossValues);
        {
            HTuple end_val94 = (hv_TrainResultsUsed.TupleLength())-1;
            HTuple step_val94 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val94, step_val94); hv_Index += step_val94)
            {
                hv_TrainResult = HTuple(hv_TrainResultsUsed[hv_Index]);
                GetDictTuple(hv_TrainResult, hv_LossParam, &hv_LossValue);
                hv_LossValues[hv_Index] = hv_LossValue;
            }
        }
        hv_LossMean = hv_LossValues.TupleMean();
        SetDictTuple((*hv_TrainInfo), "mean_loss", hv_LossMean);
        SetDictTuple((*hv_TrainInfo), "mean_loss_samples", hv_LossValues.TupleLength());
    }
    //
    //Collect the best evaluation information.
    hv_BestEvaluationInfo = HTuple();
    hv_BestEvaluationInfoTrain = HTuple();
    hv_BestEvaluationValue = HTuple();
    hv_BestEvaluationValueTrain = HTuple();
    hv_BestEvaluationKeys = HTuple();
    hv_BestEvaluationKeysTrain = HTuple();
    {
        HTuple end_val111 = (hv_EvaluationInfos.TupleLength())-1;
        HTuple step_val111 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val111, step_val111); hv_Index += step_val111)
        {
            hv_EvaluationInfo = HTuple(hv_EvaluationInfos[hv_Index]);
            //Ignore missing information
            if (0 != (int(hv_EvaluationInfo==-1)))
            {
                continue;
            }
            //
            GetDictTuple(hv_EvaluationInfo, "result", &hv_ValidationEvaluationResult);
            GetDictTuple(hv_EvaluationInfo, "result_train", &hv_TrainEvaluationResult);
            //
            //Reduce the result to a single (mean) value.
            reduce_dl_evaluation_result(hv_ValidationEvaluationResult, hv_EvaluationComparisonKeys,
                                        &hv_Value, &hv_ValidEvaluationKeys);
            reduce_dl_evaluation_result(hv_TrainEvaluationResult, hv_EvaluationComparisonKeys,
                                        &hv_ValueTrain, &hv_ValidEvaluationKeysTrain);
            //
            //Compare current evaluation result with the best one.
            if (0 != (int(hv_EvaluationOptimizationMethod==HTuple("min"))))
            {
                //Validation.
                if (0 != (HTuple(int((hv_BestEvaluationInfo.TupleLength())==0)).TupleOr(int(hv_Value<=hv_BestEvaluationValue))))
                {
                    hv_BestEvaluationInfo = hv_EvaluationInfo;
                    hv_BestEvaluationValue = hv_Value;
                    hv_BestEvaluationKeys = hv_ValidEvaluationKeys;
                }
                //Training.
                if (0 != (HTuple(int((hv_BestEvaluationInfoTrain.TupleLength())==0)).TupleOr(int(hv_ValueTrain<=hv_BestEvaluationValueTrain))))
                {
                    hv_BestEvaluationInfoTrain = hv_EvaluationInfo;
                    hv_BestEvaluationValueTrain = hv_ValueTrain;
                    hv_BestEvaluationKeysTrain = hv_ValidEvaluationKeysTrain;
                }
            }
            else if (0 != (int(hv_EvaluationOptimizationMethod==HTuple("max"))))
            {
                //Validation.
                if (0 != (HTuple(int((hv_BestEvaluationInfo.TupleLength())==0)).TupleOr(int(hv_Value>=hv_BestEvaluationValue))))
                {
                    hv_BestEvaluationInfo = hv_EvaluationInfo;
                    hv_BestEvaluationValue = hv_Value;
                    hv_BestEvaluationKeys = hv_ValidEvaluationKeys;
                }
                //Training.
                if (0 != (HTuple(int((hv_BestEvaluationInfoTrain.TupleLength())==0)).TupleOr(int(hv_ValueTrain>=hv_BestEvaluationValueTrain))))
                {
                    hv_BestEvaluationInfoTrain = hv_EvaluationInfo;
                    hv_BestEvaluationValueTrain = hv_ValueTrain;
                    hv_BestEvaluationKeysTrain = hv_ValidEvaluationKeysTrain;
                }
            }
            else
            {
                throw HException(("Invalid optimization method "+hv_EvaluationOptimizationMethod)+". Choose either \"min\" or \"max\".");
            }
        }
    }
    //
    //Store best evaluation information.
    if (0 != (int((hv_BestEvaluationInfo.TupleLength())>0)))
    {
        CreateDict(&hv_BestEvaluationData);
        SetDictTuple(hv_BestEvaluationData, "comparison_keys", hv_BestEvaluationKeys);
        SetDictTuple(hv_BestEvaluationData, "best_info", hv_BestEvaluationInfo);
        SetDictTuple(hv_BestEvaluationData, "best_value", hv_BestEvaluationValue);
        SetDictTuple(hv_BestEvaluationData, "comparison_keys_train", hv_BestEvaluationKeysTrain);
        SetDictTuple(hv_BestEvaluationData, "best_info_train", hv_BestEvaluationInfoTrain);
        SetDictTuple(hv_BestEvaluationData, "best_value_train", hv_BestEvaluationValueTrain);
        SetDictTuple((*hv_TrainInfo), "best_evaluation", hv_BestEvaluationData);
    }
    else
    {
        SetDictTuple((*hv_TrainInfo), "best_evaluation", HTuple());
    }
    //
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Calculate top-K error.
void HalxAI:: compute_top_k_error (HTuple hv_ImageLabelIDs, HTuple hv_TopKPredictions, HTuple hv_K,
                                   HTuple *hv_TopKError)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_NumMatches, hv_Index, hv_Predictions;
    HTuple  hv_PredictedClasses;

    //
    //This procedure calculates the top-K error out of the given predictions and labels.
    //
    hv_NumMatches = 0;
    //
    //Loop through all selected ground truth labels.
    {
        HTuple end_val6 = (hv_ImageLabelIDs.TupleLength())-1;
        HTuple step_val6 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
        {
            //Get the K best results.
            GetDictTuple(HTuple(hv_TopKPredictions[hv_Index]), "predictions", &hv_Predictions);
            hv_PredictedClasses = hv_Predictions.TupleSelectRange(0,hv_K-1);
            //Count how often the ground truth label
            //and K predicted classes match.
            if (0 != (int((hv_PredictedClasses.TupleFind(HTuple(hv_ImageLabelIDs[hv_Index])))!=-1)))
            {
                hv_NumMatches += 1;
            }
        }
    }
    (*hv_TopKError) = 1.0-((hv_NumMatches.TupleReal())/(hv_ImageLabelIDs.TupleLength()));
    //
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Compute a pose from a 3D point and orientation.
void HalxAI:: convert_dl_3d_gripping_point_to_pose (HTuple hv_X, HTuple hv_Y, HTuple hv_Z,
                                                    HTuple hv_NX, HTuple hv_NY, HTuple hv_NZ, HTuple *hv_Pose)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Normal, hv_Abs, hv_Indices, hv_ToolInCamY;
    HTuple  hv_ToolInCamX, hv_ToolInCamHRot, hv_ToolInCamPoseRot;
    HTuple  hv_HomMat3D, hv_Qx, hv_Qy, hv_Qz;

    //Check for invalid points.
    if (0 != (HTuple(HTuple(HTuple(int(hv_X==0.0)).TupleAnd(int(hv_Y==0.0))).TupleAnd(int(hv_Z==0.0))).TupleOr(HTuple(HTuple(int(hv_NX==0.0)).TupleAnd(int(hv_NY==0.0))).TupleAnd(int(hv_NZ==0.0)))))
    {
        (*hv_Pose) = HTuple();
        return;
    }
    //
    //Get rotation.
    hv_Normal.Clear();
    hv_Normal.Append(hv_NX);
    hv_Normal.Append(hv_NY);
    hv_Normal.Append(hv_NZ);
    TupleFabs(hv_Normal, &hv_Abs);
    TupleSortIndex(hv_Abs, &hv_Indices);
    hv_ToolInCamY[HTuple(hv_Indices[0])] = 0.0;
    hv_ToolInCamY[HTuple(hv_Indices[1])] = -HTuple(hv_Normal[HTuple(hv_Indices[2])]);
    hv_ToolInCamY[HTuple(hv_Indices[2])] = HTuple(hv_Normal[HTuple(hv_Indices[1])]);
    hv_ToolInCamY = hv_ToolInCamY/(((hv_ToolInCamY*hv_ToolInCamY).TupleSum()).TupleSqrt());
    tuple_vector_cross_product(hv_ToolInCamY, hv_Normal, &hv_ToolInCamX);
    hv_ToolInCamHRot.Clear();
    hv_ToolInCamHRot.Append(HTuple(hv_ToolInCamX[0]));
    hv_ToolInCamHRot.Append(HTuple(hv_ToolInCamY[0]));
    hv_ToolInCamHRot.Append(HTuple(hv_Normal[0]));
    hv_ToolInCamHRot.Append(0.0);
    hv_ToolInCamHRot.Append(HTuple(hv_ToolInCamX[1]));
    hv_ToolInCamHRot.Append(HTuple(hv_ToolInCamY[1]));
    hv_ToolInCamHRot.Append(HTuple(hv_Normal[1]));
    hv_ToolInCamHRot.Append(0.0);
    hv_ToolInCamHRot.Append(HTuple(hv_ToolInCamX[2]));
    hv_ToolInCamHRot.Append(HTuple(hv_ToolInCamY[2]));
    hv_ToolInCamHRot.Append(HTuple(hv_Normal[2]));
    hv_ToolInCamHRot.Append(0.0);
    HomMat3dToPose(hv_ToolInCamHRot, &hv_ToolInCamPoseRot);
    hv_ToolInCamPoseRot[5] = 0.0;
    PoseToHomMat3d(hv_ToolInCamPoseRot, &hv_HomMat3D);
    //
    //Get translation.
    AffineTransPoint3d(hv_HomMat3D, 0, 0, 0, &hv_Qx, &hv_Qy, &hv_Qz);
    (*hv_Pose) = hv_ToolInCamPoseRot;
    (*hv_Pose)[0] = hv_X-hv_Qx;
    (*hv_Pose)[1] = hv_Y-hv_Qy;
    (*hv_Pose)[2] = hv_Z-hv_Qz;
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: This procedure converts Deep OCR Detection results to an Object Detection results.
void HalxAI:: convert_ocr_detection_result_to_object_detection (HTuple hv_OcrResults, HTuple *hv_DetectionResults)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Index, hv_OcrResult, hv_RequiredKeysExist;
    HTuple  hv_DetectionResult, hv___Tmp_Ctrl_Type;

    //
    //Convert Deep OCR Detection results
    //to Object Detection results.
    //
    //Create DetectionResults Dict
    TupleGenConst(hv_OcrResults.TupleLength(), HTuple::TupleConstant("HNULL"), &(*hv_DetectionResults));
    {
        HTuple end_val6 = (hv_OcrResults.TupleLength())-1;
        HTuple step_val6 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val6, step_val6); hv_Index += step_val6)
        {
            hv_OcrResult = HTuple(hv_OcrResults[hv_Index]);
            //Check if input is valid
            GetDictParam(hv_OcrResult, "key_exists", "words", &hv_RequiredKeysExist);
            if (0 != (int((hv_RequiredKeysExist.TupleSum())!=(hv_RequiredKeysExist.TupleLength()))))
            {
                throw HException(("The item at Index "+hv_Index)+" is not a valid Deep OCR Detection Result");
            }
            GetDictParam(hv_OcrResult.TupleGetDictTuple("words"), "key_exists", ((((HTuple("row").Append("col")).Append("phi")).Append("length1")).Append("length2")),
                         &hv_RequiredKeysExist);
            if (0 != (int((hv_RequiredKeysExist.TupleSum())!=(hv_RequiredKeysExist.TupleLength()))))
            {
                throw HException(("The item at Index "+hv_Index)+" is not a valid Deep OCR Detection Result");
            }
            //Convert ocr detection result to object detection
            CreateDict(&hv_DetectionResult);
            GetDictParam(hv_OcrResult.TupleGetDictTuple("words"), "key_data_type", "row",
                         &hv___Tmp_Ctrl_Type);
            if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
            {
                SetDictObject((hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictObject("row"),
                              hv_DetectionResult, "bbox_row");
            }
            else
            {
                SetDictTuple(hv_DetectionResult, "bbox_row", (hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictTuple("row"));
            }
            GetDictParam(hv_OcrResult.TupleGetDictTuple("words"), "key_data_type", "col",
                         &hv___Tmp_Ctrl_Type);
            if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
            {
                SetDictObject((hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictObject("col"),
                              hv_DetectionResult, "bbox_col");
            }
            else
            {
                SetDictTuple(hv_DetectionResult, "bbox_col", (hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictTuple("col"));
            }
            GetDictParam(hv_OcrResult.TupleGetDictTuple("words"), "key_data_type", "phi",
                         &hv___Tmp_Ctrl_Type);
            if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
            {
                SetDictObject((hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictObject("phi"),
                              hv_DetectionResult, "bbox_phi");
            }
            else
            {
                SetDictTuple(hv_DetectionResult, "bbox_phi", (hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictTuple("phi"));
            }
            GetDictParam(hv_OcrResult.TupleGetDictTuple("words"), "key_data_type", "length1",
                         &hv___Tmp_Ctrl_Type);
            if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
            {
                SetDictObject((hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictObject("length1"),
                              hv_DetectionResult, "bbox_length1");
            }
            else
            {
                SetDictTuple(hv_DetectionResult, "bbox_length1", (hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictTuple("length1"));
            }
            GetDictParam(hv_OcrResult.TupleGetDictTuple("words"), "key_data_type", "length2",
                         &hv___Tmp_Ctrl_Type);
            if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
            {
                SetDictObject((hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictObject("length2"),
                              hv_DetectionResult, "bbox_length2");
            }
            else
            {
                SetDictTuple(hv_DetectionResult, "bbox_length2", (hv_OcrResult.TupleGetDictTuple("words")).TupleGetDictTuple("length2"));
            }
            SetDictTuple(hv_DetectionResult, "bbox_confidence", HTuple((hv_DetectionResult.TupleGetDictTuple("bbox_row")).TupleLength(),1.0));
            SetDictTuple(hv_DetectionResult, "bbox_class_id", HTuple((hv_DetectionResult.TupleGetDictTuple("bbox_row")).TupleLength(),0));
            (*hv_DetectionResults)[hv_Index] = hv_DetectionResult;
        }
    }


    return;
}

// Chapter: Tools / Geometry
// Short Description: Convert the parameters of rectangles with format rectangle2 to the coordinates of its 4 corner-points.
void HalxAI:: convert_rect2_5to8param (HTuple hv_Row, HTuple hv_Col, HTuple hv_Length1, HTuple hv_Length2,
                                       HTuple hv_Phi, HTuple *hv_Row1, HTuple *hv_Col1, HTuple *hv_Row2, HTuple *hv_Col2,
                                       HTuple *hv_Row3, HTuple *hv_Col3, HTuple *hv_Row4, HTuple *hv_Col4)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Co1, hv_Co2, hv_Si1, hv_Si2;

    //This procedure takes the parameters for a rectangle of type 'rectangle2'
    //and returns the coordinates of the four corners.
    //
    hv_Co1 = (hv_Phi.TupleCos())*hv_Length1;
    hv_Co2 = (hv_Phi.TupleCos())*hv_Length2;
    hv_Si1 = (hv_Phi.TupleSin())*hv_Length1;
    hv_Si2 = (hv_Phi.TupleSin())*hv_Length2;

    (*hv_Col1) = (hv_Co1-hv_Si2)+hv_Col;
    (*hv_Row1) = ((-hv_Si1)-hv_Co2)+hv_Row;
    (*hv_Col2) = ((-hv_Co1)-hv_Si2)+hv_Col;
    (*hv_Row2) = (hv_Si1-hv_Co2)+hv_Row;
    (*hv_Col3) = ((-hv_Co1)+hv_Si2)+hv_Col;
    (*hv_Row3) = (hv_Si1+hv_Co2)+hv_Row;
    (*hv_Col4) = (hv_Co1+hv_Si2)+hv_Col;
    (*hv_Row4) = ((-hv_Si1)+hv_Co2)+hv_Row;

    return;
}

// Chapter: Tools / Geometry
// Short Description: Convert for four-sided figures the coordinates of the 4 corner-points to the parameters of format rectangle2.
void HalxAI:: convert_rect2_8to5param (HTuple hv_Row1, HTuple hv_Col1, HTuple hv_Row2, HTuple hv_Col2,
                                       HTuple hv_Row3, HTuple hv_Col3, HTuple hv_Row4, HTuple hv_Col4, HTuple hv_ForceL1LargerL2,
                                       HTuple *hv_Row, HTuple *hv_Col, HTuple *hv_Length1, HTuple *hv_Length2, HTuple *hv_Phi)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Hor, hv_Vert, hv_IdxSwap, hv_Tmp;

    //This procedure takes the corners of four-sided figures
    //and returns the parameters of type 'rectangle2'.
    //
    //Calculate center row and column.
    (*hv_Row) = (((hv_Row1+hv_Row2)+hv_Row3)+hv_Row4)/4.0;
    (*hv_Col) = (((hv_Col1+hv_Col2)+hv_Col3)+hv_Col4)/4.0;
    //Length1 and Length2.
    (*hv_Length1) = ((((hv_Row1-hv_Row2)*(hv_Row1-hv_Row2))+((hv_Col1-hv_Col2)*(hv_Col1-hv_Col2))).TupleSqrt())/2.0;
    (*hv_Length2) = ((((hv_Row2-hv_Row3)*(hv_Row2-hv_Row3))+((hv_Col2-hv_Col3)*(hv_Col2-hv_Col3))).TupleSqrt())/2.0;
    //Calculate the angle phi.
    hv_Hor = hv_Col1-hv_Col2;
    hv_Vert = hv_Row2-hv_Row1;
    if (0 != hv_ForceL1LargerL2)
    {
        //Swap length1 and length2 if necessary.
        hv_IdxSwap = (((*hv_Length2)-(*hv_Length1)).TupleGreaterElem(1e-9)).TupleFind(1);
        if (0 != (int(hv_IdxSwap!=-1)))
        {
            hv_Tmp = HTuple((*hv_Length1)[hv_IdxSwap]);
            (*hv_Length1)[hv_IdxSwap] = HTuple((*hv_Length2)[hv_IdxSwap]);
            (*hv_Length2)[hv_IdxSwap] = hv_Tmp;
            hv_Hor[hv_IdxSwap] = HTuple(hv_Col2[hv_IdxSwap])-HTuple(hv_Col3[hv_IdxSwap]);
            hv_Vert[hv_IdxSwap] = HTuple(hv_Row3[hv_IdxSwap])-HTuple(hv_Row2[hv_IdxSwap]);
        }
    }
    (*hv_Phi) = hv_Vert.TupleAtan2(hv_Hor);
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Create a training parameter dictionary which is used in train_dl_model.
void HalxAI:: create_dl_train_param (HTuple hv_DLModelHandle, HTuple hv_NumEpochs, HTuple hv_EvaluationIntervalEpochs,
                                     HTuple hv_EnableDisplay, HTuple hv_RandomSeed, HTuple hv_GenParamName, HTuple hv_GenParamValue,
                                     HTuple *hv_TrainParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ModelType, hv_AvailableGenParam, hv_IndexGenParam;
    HTuple  hv_IndexFind, hv_IsString, hv_TrainParamAnomaly;
    HTuple  hv_DomainRatioKeyExists, hv_ErrorThresholdKeyExists;
    HTuple  hv_RegularizationNoiseKeyExists, hv_DisplayParam;
    HTuple  hv_EvaluateBeforeTrain, hv_EvaluationParam, hv_AugmentationParam;
    HTuple  hv_ClassIDsNoOrientation, hv_Exception, hv_ChangeStrategies;
    HTuple  hv_Indices, hv_SerializationStrategy, hv_SerializationStrategies;
    HTuple  hv_Seconds, hv_SetDisplayParam, hv_EvaluationComparisonKeys;
    HTuple  hv_ConvertToMean, hv_Index, hv_FoundIndices;

    //
    //This procedure creates a dictionary with all needed training parameters,
    //as required by train_dl_model as input.
    //
    //Check length of input GenParam tuple.
    if (0 != (int((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength()))))
    {
        throw HException("GenParamName and GenParamValue have to have the same length.");
    }
    //
    //Some default parameters depend on model type.
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
    {
        throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
    }
    //
    //Check if the given GenParamName strings are available.
    if (0 != (int(hv_ModelType!=HTuple("anomaly_detection"))))
    {
        hv_AvailableGenParam.Clear();
        hv_AvailableGenParam[0] = "evaluate";
        hv_AvailableGenParam[1] = "augment";
        hv_AvailableGenParam[2] = "change";
        hv_AvailableGenParam[3] = "serialize";
        hv_AvailableGenParam[4] = "display";
        hv_AvailableGenParam[5] = "evaluate_before_train";
        if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            hv_AvailableGenParam.Clear();
            hv_AvailableGenParam[0] = "augment";
            hv_AvailableGenParam[1] = "change";
            hv_AvailableGenParam[2] = "serialize";
            hv_AvailableGenParam[3] = "display";
        }
    }
    else
    {
        hv_AvailableGenParam = "anomaly";
    }
    {
        HTuple end_val24 = (hv_GenParamName.TupleLength())-1;
        HTuple step_val24 = 1;
        for (hv_IndexGenParam=0; hv_IndexGenParam.Continue(end_val24, step_val24); hv_IndexGenParam += step_val24)
        {
            hv_IndexFind = hv_AvailableGenParam.TupleFind(HTuple(hv_GenParamName[hv_IndexGenParam]));
            if (0 != (int(hv_IndexFind==-1)))
            {
                throw HException(("The provided GenParamName "+HTuple(hv_GenParamName[hv_IndexGenParam]))+" is invalid.");
            }
        }
    }
    //
    //Check if display is enabled.
    TupleIsString(hv_EnableDisplay, &hv_IsString);
    if (0 != hv_IsString)
    {
        hv_EnableDisplay = int(hv_EnableDisplay==HTuple("true"));
    }
    else
    {
        hv_EnableDisplay = int(hv_EnableDisplay==1);
    }
    //
    //Initialize the dictionary holding the training parameters.
    CreateDict(&(*hv_TrainParam));
    //
    //** User supplied parameters: ***
    //
    //Set training parameters for anomaly detection models.
    if (0 != (int(hv_ModelType==HTuple("anomaly_detection"))))
    {
        get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "anomaly", &hv_TrainParamAnomaly);
        //Set default values in case no values are provided.
        if (0 != (int(hv_TrainParamAnomaly==HTuple())))
        {
            CreateDict(&hv_TrainParamAnomaly);
        }
        GetDictParam(hv_TrainParamAnomaly, "key_exists", "domain_ratio", &hv_DomainRatioKeyExists);
        if (0 != (hv_DomainRatioKeyExists.TupleNot()))
        {
            SetDictTuple(hv_TrainParamAnomaly, "domain_ratio", 0.1);
        }
        GetDictParam(hv_TrainParamAnomaly, "key_exists", "error_threshold", &hv_ErrorThresholdKeyExists);
        if (0 != (hv_ErrorThresholdKeyExists.TupleNot()))
        {
            SetDictTuple(hv_TrainParamAnomaly, "error_threshold", 0.001);
        }
        GetDictParam(hv_TrainParamAnomaly, "key_exists", "regularization_noise", &hv_RegularizationNoiseKeyExists);
        if (0 != (hv_RegularizationNoiseKeyExists.TupleNot()))
        {
            SetDictTuple(hv_TrainParamAnomaly, "regularization_noise", 0.0001);
        }
        //
        SetDictTuple(hv_TrainParamAnomaly, "max_num_epochs", hv_NumEpochs);
        SetDictTuple((*hv_TrainParam), "anomaly_param", hv_TrainParamAnomaly);
        CreateDict(&hv_DisplayParam);
        SetDictTuple(hv_DisplayParam, "enabled", hv_EnableDisplay);
        SetDictTuple((*hv_TrainParam), "display_param", hv_DisplayParam);
        return;
    }
    //
    //Set training parameters for all model types except 'anomaly_detection'.
    //
    //Number of epochs to train the model on the train split of the dataset.
    SetDictTuple((*hv_TrainParam), "num_epochs", hv_NumEpochs);
    //
    //Interval (in epochs) to evaluate the model on the validation split of the dataset.
    if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
        //For models of type 'gc_anomaly_detection' no evaluation can be done.
        SetDictTuple((*hv_TrainParam), "evaluation_interval_epochs", 0);
    }
    else
    {
        SetDictTuple((*hv_TrainParam), "evaluation_interval_epochs", hv_EvaluationIntervalEpochs);
    }
    //
    //Transfer the parameter defining if an evaluation before training is to be done.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "evaluate_before_train",
                              &hv_EvaluateBeforeTrain);
    SetDictTuple((*hv_TrainParam), "evaluate_before_train", hv_EvaluateBeforeTrain);
    //
    //Transfer evaluation parameters used in further steps.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "evaluate", &hv_EvaluationParam);
    SetDictTuple((*hv_TrainParam), "evaluation_param", hv_EvaluationParam);
    //
    //Transfer augmentation parameters used in further steps.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "augment", &hv_AugmentationParam);
    if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        //In addition, add class IDs without orientation, since these classes require
        //special treatment during the augmentation.
        try
        {
            GetDlModelParam(hv_DLModelHandle, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
        }
        // catch (Exception)
        catch (HException &HDevExpDefaultException)
        {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            hv_ClassIDsNoOrientation = HTuple();
        }
        if (0 != (int((hv_ClassIDsNoOrientation.TupleLength())>0)))
        {
            if (0 != (int(hv_AugmentationParam==HTuple())))
            {
                CreateDict(&hv_AugmentationParam);
            }
            SetDictTuple(hv_AugmentationParam, "class_ids_no_orientation", hv_ClassIDsNoOrientation);
        }
    }
    SetDictTuple((*hv_TrainParam), "augmentation_param", hv_AugmentationParam);
    //
    //Change strategies for any parameters that need to be changed during training.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "change", &hv_ChangeStrategies);
    SetDictTuple((*hv_TrainParam), "change_strategies", hv_ChangeStrategies);
    //
    //Serialization strategies used during training.
    hv_Indices = hv_GenParamName.TupleFind("serialize");
    if (0 != (HTuple(int((hv_Indices.TupleLength())==0)).TupleOr(int(hv_Indices==-1))))
    {
        //Set a default in case no value is provided.
        CreateDict(&hv_SerializationStrategy);
        SetDictTuple(hv_SerializationStrategy, "type", "best");
        SetDictTuple(hv_SerializationStrategy, "basename", "model_best");
        hv_SerializationStrategies = hv_SerializationStrategy;
    }
    else
    {
        //Set user provided values.
        hv_SerializationStrategies = HTuple(hv_GenParamValue[hv_Indices]);
    }
    SetDictTuple((*hv_TrainParam), "serialization_strategies", hv_SerializationStrategies);
    //
    //Get random seed or set a useful default value.
    if (0 != (int((hv_RandomSeed.TupleLength())>0)))
    {
        SetDictTuple((*hv_TrainParam), "seed_rand", hv_RandomSeed);
    }
    else
    {
        //If no random seed is given we will use system time as a default.
        CountSeconds(&hv_Seconds);
        hv_RandomSeed = hv_Seconds.TupleInt();
        SetDictTuple((*hv_TrainParam), "seed_rand", hv_RandomSeed);
    }
    //
    //** Display parameters: ***
    //
    //Create display parameter dictionary.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "display", &hv_SetDisplayParam);
    if (0 != (int(hv_SetDisplayParam!=HTuple())))
    {
        hv_DisplayParam = hv_SetDisplayParam;
    }
    else
    {
        CreateDict(&hv_DisplayParam);
    }
    //
    SetDictTuple(hv_DisplayParam, "enabled", hv_EnableDisplay);
    SetDictTuple((*hv_TrainParam), "display_param", hv_DisplayParam);
    //
    //** Generic internal defaults: ***
    //
    //Default update interval (in seconds) of TrainInfo calculation and text/plot updates
    //in case display is enabled.
    SetDictTuple((*hv_TrainParam), "update_interval_seconds", 2);
    //
    //Evaluation comparison keys. Note, that internally only those keys apply which
    //are really available. No error is thrown as long as a valid key is given.
    //Hence, we use the major defaults here for classification ('top1_error'),
    //for detection ('mean_ap'), and for segmentation ('mean_iou') if no valid key
    //is given.
    hv_EvaluationComparisonKeys = HTuple();
    //
    try
    {
        GetDictTuple(hv_EvaluationParam, "measures", &hv_EvaluationComparisonKeys);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    if (0 != (int(hv_EvaluationComparisonKeys==HTuple())))
    {
        if (0 != (int(hv_ModelType==HTuple("classification"))))
        {
            hv_EvaluationComparisonKeys = "top1_error";
        }
        else if (0 != (int(hv_ModelType==HTuple("detection"))))
        {
            hv_EvaluationComparisonKeys = "mean_ap";
        }
        else if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            hv_EvaluationComparisonKeys = "none";
        }
        else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
        {
            hv_EvaluationComparisonKeys = "f_score";
        }
        else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
        {
            hv_EvaluationComparisonKeys = "accuracy";
        }
        else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
        {
            hv_EvaluationComparisonKeys = "mean_iou";
        }
        else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
        {
            hv_EvaluationComparisonKeys = "mean_iou";
        }
    }

    if (0 != (int(hv_ModelType!=HTuple("ocr_detection"))))
    {
        //If the evaluation metric is 'precision', 'recall', 'f_score', or
        //'soap' we always take the mean value.
        hv_ConvertToMean.Clear();
        hv_ConvertToMean[0] = "precision";
        hv_ConvertToMean[1] = "recall";
        hv_ConvertToMean[2] = "f_score";
        hv_ConvertToMean[3] = "soap";
        {
            HTuple end_val193 = (hv_ConvertToMean.TupleLength())-1;
            HTuple step_val193 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val193, step_val193); hv_Index += step_val193)
            {
                hv_FoundIndices = (hv_EvaluationComparisonKeys.TupleEqualElem(HTuple(hv_ConvertToMean[hv_Index]))).TupleFind(1);
                if (0 != (int(hv_FoundIndices!=-1)))
                {
                    hv_EvaluationComparisonKeys[hv_FoundIndices] = "mean_"+HTuple(hv_EvaluationComparisonKeys[hv_FoundIndices]);
                    if (0 != (int(HTuple(hv_ConvertToMean[hv_Index])==HTuple("soap"))))
                    {
                        hv_EvaluationComparisonKeys[hv_FoundIndices] = HTuple(hv_EvaluationComparisonKeys[hv_FoundIndices])+"_tp";
                    }
                }
            }
        }
    }
    //
    SetDictTuple((*hv_TrainParam), "evaluation_comparison_keys", hv_EvaluationComparisonKeys);
    //
    //Number of samples used to average the loss during training. Note, this is used for display
    //and information calculation only and does not have an effect on training the model.
    SetDictTuple((*hv_TrainParam), "num_samples_mean_loss", 1000);
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Generate a dictionary EvalParams, which contains default values for evaluation parameters.
void HalxAI:: create_evaluation_default_param (HTuple hv_EvaluationType, HTuple hv_ClassIDsModel,
                                               HTuple *hv_EvalParams)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_AvailableEvaluationTypes, hv_EvaluationTypesStr;
    HTuple  hv_Indices, hv_EvaluateInstances, hv_Measures, hv_GrippingPointParams;
    HTuple  hv_AreaRanges, hv_AllocationBlockLength;

    //
    //This procedure generates a dictionary EvalParams,
    //which contains default values for evaluation parameters.
    //Depending on the evaluation type, the corresponding default parameters and values are set.
    //The class IDs that the model can predict must be given via ClassIDsModel.
    //
    //Check inputs.
    hv_AvailableEvaluationTypes.Clear();
    hv_AvailableEvaluationTypes[0] = "3d_gripping_point_detection";
    hv_AvailableEvaluationTypes[1] = "anomaly_detection";
    hv_AvailableEvaluationTypes[2] = "classification";
    hv_AvailableEvaluationTypes[3] = "detection";
    hv_AvailableEvaluationTypes[4] = "gc_anomaly_detection";
    hv_AvailableEvaluationTypes[5] = "ocr_detection";
    hv_AvailableEvaluationTypes[6] = "ocr_recognition";
    hv_AvailableEvaluationTypes[7] = "segmentation";
    TupleGenConst((2*(hv_AvailableEvaluationTypes.TupleLength()))-1, HTuple("','"),
                  &hv_EvaluationTypesStr);
    hv_EvaluationTypesStr[HTuple::TupleGenSequence(0,hv_EvaluationTypesStr.TupleLength(),2)] = hv_AvailableEvaluationTypes;
    hv_EvaluationTypesStr = hv_EvaluationTypesStr.TupleSum();
    TupleFind(hv_AvailableEvaluationTypes, hv_EvaluationType, &hv_Indices);
    if (0 != (HTuple(int(hv_Indices==-1)).TupleOr(int(hv_Indices==HTuple()))))
    {
        throw HException(((("Unknown evaluation_type: "+hv_EvaluationType)+". Choose one of ['")+hv_EvaluationTypesStr)+"']");
    }
    //
    if (0 != (int((hv_ClassIDsModel.TupleLength())<1)))
    {
        if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
        {
            hv_ClassIDsModel = 0;
        }
        else
        {
            throw HException("ClassIDsModel should have at least one entry");
        }
    }
    //
    //Initialize EvalParams.
    CreateDict(&(*hv_EvalParams));
    SetDictTuple((*hv_EvalParams), "evaluation_type", hv_EvaluationType);
    //
    //Set the class IDs.
    SetDictTuple((*hv_EvalParams), "class_ids", hv_ClassIDsModel);
    SetDictTuple((*hv_EvalParams), "num_classes", hv_ClassIDsModel.TupleLength());
    //
    //Set specific parameters depending on the evaluation type.
    hv_EvaluateInstances = 0;
    if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
    {
        //
        //Set default 3D Gripping Point Detection measures.
        hv_Measures.Clear();
        hv_Measures[0] = "mean_pro";
        hv_Measures[1] = "mean_precision";
        hv_Measures[2] = "mean_iou";
        //
        //There are no ignored classes for this model type.
        SetDictTuple((*hv_EvalParams), "ignore_class_ids", HTuple());
        //
        //Set default 3D gripping point generation parameters.
        CreateDict(&hv_GrippingPointParams);
        check_dl_3d_gripping_points_and_poses_params(hv_GrippingPointParams);
        SetDictTuple((*hv_EvalParams), "gripping_point_params", hv_GrippingPointParams);
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
    {
        //
        //Set default image level measures.
        hv_Measures = "anomaly_score_histogram";
    }
    else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
    {
        //
        //Set default classification measures.
        hv_Measures = "top1_error";
        //
        //Per default all classes are used for evaluation.
        SetDictTuple((*hv_EvalParams), "class_ids_to_evaluate", "global");
    }
    else if (0 != (int(hv_EvaluationType==HTuple("detection"))))
    {
        //
        //Set default detection measures.
        hv_Measures = "mean_ap";
        //
        //Set detection-specific default values.
        hv_EvaluateInstances = 1;
        SetDictTuple((*hv_EvalParams), "instance_type", "rectangle1");
        //Generate ten IoU-thresholds from 0.5 to 0.95 in steps of 0.05.
        SetDictTuple((*hv_EvalParams), "iou_threshold", HTuple::TupleGenSequence(0.5,0.96,0.05));
        //Set maximal number of detections to -1, i.e. all results per image will be evaluated.
        SetDictTuple((*hv_EvalParams), "max_num_detections", -1);
        //Set default area range named 'all', thus areas from 0 to a value larger than all likely occurring values.
        CreateDict(&hv_AreaRanges);
        SetDictTuple(hv_AreaRanges, "name", "all");
        SetDictTuple(hv_AreaRanges, "min", 0);
        SetDictTuple(hv_AreaRanges, "max", 2e8);
        SetDictTuple((*hv_EvalParams), "area_ranges", hv_AreaRanges);
        //Some tuples are changing their length during the evaluation. As this slows down the
        //evaluation process they are allocated in blocks of AllocationBlockLength.
        hv_AllocationBlockLength = 200;
        SetDictTuple((*hv_EvalParams), "allocation_block_length", hv_AllocationBlockLength);
        //Detailed evaluation is not switched on per default, as it slows down the evaluation-process.
        SetDictTuple((*hv_EvalParams), "detailed_evaluation", 0);
        //Interpolate the precision-recall curves per default.
        SetDictTuple((*hv_EvalParams), "interpolate_pr_curves", 1);
    }
    else if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
    {
        //
        //Set default pixel measures.
        hv_Measures.Clear();
        hv_Measures[0] = "pixel_accuracy";
        hv_Measures[1] = "mean_accuracy";
        hv_Measures[2] = "mean_iou";
        //
        //Per default there are no ignored classes.
        SetDictTuple((*hv_EvalParams), "ignore_class_ids", HTuple());
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
    {
        //
        //Set default OCR recognition measures
        hv_Measures = "accuracy";
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
    {
        //
        //Set default ocr_detection measures.
        hv_Measures = "f_score";
        SetDictTuple((*hv_EvalParams), "detailed_evaluation", 1);
        SetDictTuple((*hv_EvalParams), "iou_threshold", 0.5);
        SetDictTuple((*hv_EvalParams), "max_num_detections", -1);
        SetDictTuple((*hv_EvalParams), "instance_type", "rectangle2");
        SetDictTuple((*hv_EvalParams), "allocation_block_length", 100);
        //
        //Configure area constraints.
        CreateDict(&hv_AreaRanges);
        SetDictTuple(hv_AreaRanges, "name", "all");
        SetDictTuple(hv_AreaRanges, "min", 0);
        SetDictTuple(hv_AreaRanges, "max", HTuple::TupleConstant("H_INT_MAX"));
        SetDictTuple((*hv_EvalParams), "area_ranges", hv_AreaRanges);
    }
    //
    SetDictTuple((*hv_EvalParams), "evaluate_instances", hv_EvaluateInstances);
    SetDictTuple((*hv_EvalParams), "measures", hv_Measures);
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Display a map of the confidences.
void HalxAI:: dev_display_confidence_regions (HObject ho_ImageConfidence, HTuple hv_DrawTransparency,
                                              HTuple *hv_Colors)
{

    // Local iconic variables
    HObject  ho_Region;

    // Local control variables
    HTuple  hv_NumColors, hv_WeightsColorsAlpha, hv_ColorIndex;
    HTuple  hv_Threshold, hv_MinGray, hv_MaxGray;

    //
    //This procedure displays a map of the confidences
    //given in ImageConfidence as regions.
    //DrawTransparency determines the alpha value of the colors.
    //The used colors are returned.
    //
    //Define colors.
    hv_NumColors = 20;
    get_distinct_colors(hv_NumColors, 0, 0, 100, &(*hv_Colors));
    hv_WeightsColorsAlpha = (*hv_Colors)+hv_DrawTransparency;
    hv_ColorIndex = 0;
    //
    //Threshold the image according to
    //the number of colors and
    //display resulting regions.
    {
        HTuple end_val15 = hv_NumColors-1;
        HTuple step_val15 = 1;
        for (hv_ColorIndex=0; hv_ColorIndex.Continue(end_val15, step_val15); hv_ColorIndex += step_val15)
        {
            hv_Threshold = hv_ColorIndex*(1.0/hv_NumColors);
            hv_MinGray = hv_Threshold;
            hv_MaxGray = hv_Threshold+(1/hv_NumColors);
            Threshold(ho_ImageConfidence, &ho_Region, hv_Threshold, hv_Threshold+(1.0/hv_NumColors));
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),HTuple(hv_WeightsColorsAlpha[hv_ColorIndex]));
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Region, HDevWindowStack::GetActive());
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Visualize different images, annotations and inference results for a sample.
void HalxAI:: dev_display_dl_data (HTuple hv_DLSample, HTuple hv_DLResult, HTuple hv_DLDatasetInfo,
                                   HTuple hv_KeysForDisplay, HTuple hv_GenParam, HTuple hv_WindowHandleDict)
{

    // Local iconic variables
    HObject  ho_Image, ho_Domain, ho_GrippingMapImageResult;
    HObject  ho_Cross, ho_GrippingMapGroundTruth, ho_X, ho_Y;
    HObject  ho_Z, ho_AnomalyImage, ho_AnomalyRegion, ho_ConfidenceImage;
    HObject  ho_HeatmapScene, ho_ScoreMaps, ho_CharacterScoreMap;
    HObject  ho_LinkScoreMap, ho_OrientationSinScoreMap, ho_OrientationCosScoreMap;
    HObject  ho_ScoreMap, ho_OrientationScoreMap, ho_PredictionColorFrame;
    HObject  ho_ImageHeatmap, ho_PredictionSymbol, ho_CrossLineH;
    HObject  ho_CrossLineV, ho_ImageConfidence, ho_SegmentationImagGroundTruth;
    HObject  ho_SegmentationImageResult, ho_ImageAbsDiff, ho_DiffRegion;
    HObject  ho_ImageWeight;

    // Local control variables
    HTuple  hv_Params, hv_GenParamNames, hv_ParamIndex;
    HTuple  hv_GenParamName, hv_KeyExists, hv_SampleKeys, hv_ResultKeys;
    HTuple  hv_ImageIDExists, hv_ImageID, hv_ImageIDString;
    HTuple  hv_ImageIDStringBraces, hv_ImageIDStringCapital;
    HTuple  hv_IsOCRDetection, hv_AdditionalGreenClassNames;
    HTuple  hv_KeyIndex, hv_OcrResult, hv_MaxClassIdSample;
    HTuple  hv_EmptySample, hv_MaxClassIdResult, hv_EmptyResult;
    HTuple  hv_MaxClassId, hv_ClassNames, hv_ClassIDs, hv_ClassNameKey;
    HTuple  hv_ClassIdKey, hv_ResultClassNames, hv_ResultClassIds;
    HTuple  hv_SortIndices, hv_UniqueClassIds, hv_UniqueClassNames;
    HTuple  hv_Colors, hv_ClassesLegend, hv_InvalidInput, hv_ClassKeys;
    HTuple  hv_ClassKeysExist, hv_DLDatasetInfoKeys, hv_Index;
    HTuple  hv_PrevWindowCoordinates, hv_Keys, hv_Exception;
    HTuple  hv_MetaInfoExists, hv_FlushValues, hv_WindowHandleKeys;
    HTuple  hv_WindowHandles, hv_WindowIndex, hv_FlushValue;
    HTuple  hv_WidthImage, hv_HeightImage, hv_CurrentWindowHandle;
    HTuple  hv_WindowImageRatio, hv_ColorsGrippingGroundTruth;
    HTuple  hv_ImageClassIDs, hv_GrippingPointsExists, hv_Rows;
    HTuple  hv_Columns, hv_AnomalyImages, hv_PossibleKeysForDisplay;
    HTuple  hv_AddDisplayKey, hv_AnomalyLabelGroundTruth, hv_AnomalyLabelIDGroundTruth;
    HTuple  hv_AnomalyResultPostfix, hv_AnomalyScore, hv_AnomalyClassID;
    HTuple  hv_AnomalyClassThresholdDisplay, hv_AnomalyRegionThresholdDisplay;
    HTuple  hv_WindowHandleName, hv_AnomalyRegionGroundTruthExists;
    HTuple  hv_Text, hv_PredictionColor, hv_LineColors, hv_ResultColorOffset;
    HTuple  hv_AnomalyRegionExists, hv_AnomalyImageKey, hv_AnomalyScoreKey;
    HTuple  hv_AnomalyResultKey, hv_AnomalyRegionKey, hv_DisplayDirectionTemp;
    HTuple  hv_BboxLabelIndex, hv_BboxConfidences, hv_TextConf;
    HTuple  hv_BboxClassIndex, hv_BboxColorsBoth, hv_BboxClassLabelIndexUniq;
    HTuple  hv_BboxIDs, hv_BboxColors, hv_BboxIDsUniq, hv_BboxColorsResults;
    HTuple  hv_BboxClassIndexUniq, hv_ClassificationLabelIDGroundTruth;
    HTuple  hv_ClassificationLabelIDResult, hv_PredictionText;
    HTuple  hv_BoarderOffset, hv_MetaInfo, hv_WindowImageRatioHeight;
    HTuple  hv_WindowImageRatioWidth, hv_BoarderOffsetRow, hv_BoarderOffsetCol;
    HTuple  hv_MarginBottom, hv_WindowCoordinates, hv_CurrentWindowHeight;
    HTuple  hv__, hv_MaxHeight, hv_SelectedHeatmapMethod, hv_DictHeatmap;
    HTuple  hv_MethodName, hv_HeatmapKeys, hv_HeatmapImageName;
    HTuple  hv_TargetClassID, hv_Confidences, hv_MaxDeviation;
    HTuple  hv_ClassificationLabelNameResult, hv_TargetClassConfidence;
    HTuple  hv_ClassificationLabelNamesGroundTruth, hv_ShowGT;
    HTuple  hv_ShowResult, hv_NumLines, hv_Type, hv_GTWordKeyExists;
    HTuple  hv_HeightWindow, hv_HeightMarginBottom, hv_Size;
    HTuple  hv_Length, hv_Row, hv_Column, hv_HomMat2DIdentity;
    HTuple  hv_HomMat2DRotate, hv_HomMat2DCompose, hv_PredictionForegroundColor;
    HTuple  hv_PredictionBackgroundColor, hv_Spaces, hv_ConfidenceColors;
    HTuple  hv_ColorsResults, hv_GroundTruthIDs, hv_ResultIDs;
    HTuple  hv_ImageClassIDsUniq, hv_ImageClassIDsIndices, hv_ImageClassIDsIndex;
    HTuple  hv_StringSegExcludeClassIDs, hv_StringIndex, hv_Min;
    HTuple  hv_Max, hv_Range, hv_ColorsSegmentation, hv_DrawMode;
    HTuple  hv_Width, hv_MinWeight, hv_WeightsColors, hv_Indices;
    HTuple  hv_WindowHandleKeysNew, hv___Tmp_Ctrl_Dict_Init_1;
    HTuple  hv___Tmp_Ctrl_Dict_Init_2, hv___Tmp_Ctrl_Dict_Init_3;
    HTuple  hv___Tmp_Ctrl_Dict_Init_4, hv___Tmp_Ctrl_Dict_Init_5;
    HTuple  hv___Tmp_Ctrl_Dict_Init_6, hv___Tmp_Ctrl_Dict_Init_7;
    HTuple  hv___Tmp_Ctrl_1, hv___Tmp_Ctrl_Type;

    //
    //This procedure displays the content of the provided DLSample and/or DLResult
    //depending on the input string KeysForDisplay.
    //DLDatasetInfo is a dictionary containing the information about the dataset.
    //The visualization can be adapted with GenParam.
    //
    //** Set the default values: ***
    CreateDict(&hv_Params);
    //
    //Define the screen width when a new window row is started.
    SetDictTuple(hv_Params, "threshold_width", 1024);
    //Since potentially a lot of windows are opened,
    //scale the windows consistently.
    SetDictTuple(hv_Params, "scale_windows", 0.8);
    //Set a font and a font size.
    SetDictTuple(hv_Params, "font", "mono");
    SetDictTuple(hv_Params, "font_size", 14);
    //
    SetDictTuple(hv_Params, "line_width", 2);
    SetDictTuple(hv_Params, "map_transparency", "cc");
    SetDictTuple(hv_Params, "map_color_bar_width", 140);
    //
    //Define parameter values specifically for 3d_gripping_point_detection
    SetDictTuple(hv_Params, "gripping_point_color", "#00FF0099");
    SetDictTuple(hv_Params, "gripping_point_size", 6);
    SetDictTuple(hv_Params, "region_color", "#FF000040");
    SetDictTuple(hv_Params, "gripping_point_map_color", "#83000080");
    SetDictTuple(hv_Params, "gripping_point_background_color", "#00007F80");
    //
    //Define parameter values specifically for anomaly detection
    //and Global Context Anomaly Detection.
    SetDictTuple(hv_Params, "anomaly_region_threshold", -1);
    SetDictTuple(hv_Params, "anomaly_classification_threshold", -1);
    SetDictTuple(hv_Params, "anomaly_region_label_color", "#40e0d0");
    SetDictTuple(hv_Params, "anomaly_color_transparency", "40");
    SetDictTuple(hv_Params, "anomaly_region_result_color", "#ff0000c0");
    //
    //Define segmentation-specific parameter values.
    SetDictTuple(hv_Params, "segmentation_max_weight", 0);
    SetDictTuple(hv_Params, "segmentation_draw", "fill");
    SetDictTuple(hv_Params, "segmentation_transparency", "aa");
    SetDictTuple(hv_Params, "segmentation_exclude_class_ids", HTuple());
    //
    //Define bounding box-specific parameter values.
    SetDictTuple(hv_Params, "bbox_label_color", HTuple("#000000")+"99");
    SetDictTuple(hv_Params, "bbox_display_confidence", 1);
    SetDictTuple(hv_Params, "bbox_text_color", "#eeeeee");
    //
    //By default, display a description on the bottom.
    SetDictTuple(hv_Params, "display_bottom_desc", 1);
    //
    //By default, show a legend with class IDs.
    SetDictTuple(hv_Params, "display_legend", 1);
    //
    //By default, show the anomaly ground truth regions.
    SetDictTuple(hv_Params, "display_ground_truth_anomaly_regions", 1);
    //
    //By default, show class IDs and color frames for classification ground truth/results.
    SetDictTuple(hv_Params, "display_classification_ids", 1);
    SetDictTuple(hv_Params, "display_classification_color_frame", 1);
    //
    //By default, show class labels for detection ground truth/results.
    SetDictTuple(hv_Params, "display_labels", 1);
    //
    //By default, show direction of the ground truth/results instances for detection with instance_type 'rectangle2'.
    SetDictTuple(hv_Params, "display_direction", 1);
    //
    //By default, use color scheme 'Jet' for the heatmap display.
    SetDictTuple(hv_Params, "heatmap_color_scheme", "jet");
    //** Set user-defined values: ***
    //
    //Overwrite default values by given generic parameters.
    if (0 != (int(hv_GenParam!=HTuple())))
    {
        GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamNames);
        {
            HTuple end_val74 = (hv_GenParamNames.TupleLength())-1;
            HTuple step_val74 = 1;
            for (hv_ParamIndex=0; hv_ParamIndex.Continue(end_val74, step_val74); hv_ParamIndex += step_val74)
            {
                hv_GenParamName = HTuple(hv_GenParamNames[hv_ParamIndex]);
                GetDictParam(hv_Params, "key_exists", hv_GenParamName, &hv_KeyExists);
                if (0 != (hv_KeyExists.TupleNot()))
                {
                    throw HException(("Unknown generic parameter: "+hv_GenParamName)+".");
                }
                GetDictParam(hv_GenParam, "key_data_type", hv_GenParamName, &hv___Tmp_Ctrl_Type);
                if (0 != (int(hv___Tmp_Ctrl_Type==HTuple("object"))))
                {
                    SetDictObject(hv_GenParam.TupleGetDictObject(hv_GenParamName), hv_Params,
                                  hv_GenParamName);
                }
                else
                {
                    SetDictTuple(hv_Params, hv_GenParamName, hv_GenParam.TupleGetDictTuple(hv_GenParamName));
                }
            }
        }
    }
    //
    if (0 != (HTuple(int((hv_DLSample.TupleLength())>1)).TupleOr(int((hv_DLResult.TupleLength())>1))))
    {
        throw HException("Only a single dictionary for DLSample and DLResult is allowed");
    }
    //
    //Get the dictionary keys.
    GetDictParam(hv_DLSample, "keys", HTuple(), &hv_SampleKeys);
    if (0 != (int(hv_DLResult!=HTuple())))
    {
        GetDictParam(hv_DLResult, "keys", HTuple(), &hv_ResultKeys);
    }
    //
    //Get image ID if it is available.
    GetDictParam(hv_DLSample, "key_exists", "image_id", &hv_ImageIDExists);
    if (0 != hv_ImageIDExists)
    {
        GetDictTuple(hv_DLSample, "image_id", &hv_ImageID);
        hv_ImageIDString = "image ID "+hv_ImageID;
        hv_ImageIDStringBraces = ("(image ID "+hv_ImageID)+")";
        hv_ImageIDStringCapital = "Image ID "+hv_ImageID;
    }
    else
    {
        hv_ImageIDString = "";
        hv_ImageIDStringBraces = hv_ImageIDString;
        hv_ImageIDStringCapital = hv_ImageIDString;
    }
    //
    //** Convert a Deep OCR Detection result to an Object Detection result if necessary ***
    //
    hv_IsOCRDetection = 0;
    hv_AdditionalGreenClassNames = HTuple();
    hv_KeyIndex = 0;
    {
        HTuple end_val117 = (hv_KeysForDisplay.TupleLength())-1;
        HTuple step_val117 = 1;
        for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val117, step_val117); hv_KeyIndex += step_val117)
        {
            //Check if Deep OCR Detection case
            TupleStrstr(HTuple(hv_KeysForDisplay[hv_KeyIndex]), "ocr_detection", &hv_IsOCRDetection);
            hv_IsOCRDetection = int(hv_IsOCRDetection==0);
            if (0 != hv_IsOCRDetection)
            {
                //Turn off labels
                SetDictTuple(hv_Params, "bbox_display_confidence", 0);
                SetDictTuple(hv_Params, "display_labels", 0);
                //Mark the class 'word' as green
                hv_AdditionalGreenClassNames = "word";
                if (0 != (int(hv_DLResult!=HTuple())))
                {
                    hv_OcrResult = hv_DLResult;
                    convert_ocr_detection_result_to_object_detection(hv_OcrResult, &hv_DLResult);
                    GetDictParam(hv_DLResult, "keys", HTuple(), &hv_ResultKeys);
                    break;
                }
            }
        }
    }
    //
    //Check if DLDatasetInfo is valid.
    //
    if (0 != (int(hv_DLDatasetInfo==HTuple())))
    {
        dev_display_dl_data_get_max_class_id(hv_DLSample, &hv_MaxClassIdSample, &hv_EmptySample);
        dev_display_dl_data_get_max_class_id(hv_DLResult, &hv_MaxClassIdResult, &hv_EmptyResult);
        hv_MaxClassId = hv_MaxClassIdSample.TupleMax2(hv_MaxClassIdResult);
        if (0 != (hv_EmptySample.TupleAnd(hv_EmptyResult)))
        {
            hv_MaxClassId = 1;
        }
        if (0 != (int(hv_MaxClassId==-1)))
        {
            hv_MaxClassId = 1000;
        }
        if (0 != hv_IsOCRDetection)
        {
            hv_ClassNames.Clear();
            hv_ClassNames[0] = "word";
            hv_ClassNames[1] = "char";
            hv_ClassNames[2] = "ignore";
            TupleGenSequence(0, (hv_ClassNames.TupleLength())-1, 1, &hv_ClassIDs);
        }
        else
        {
            TupleGenSequence(0, hv_MaxClassId, 1, &hv_ClassIDs);
            TupleGenConst(hv_MaxClassId+1, "unknown", &hv_ClassNames);
        }
        //Try to get the class names from the result dictionary.
        //This works only for detection and classification results.
        if (0 != (int(hv_DLResult!=HTuple())))
        {
            TupleRegexpSelect(hv_ResultKeys, ".*class_name.*", &hv_ClassNameKey);
            TupleRegexpSelect(hv_ResultKeys, ".*class_id.*", &hv_ClassIdKey);
            if (0 != (HTuple(int((hv_ClassNameKey.TupleLength())==1)).TupleAnd(int((hv_ClassIdKey.TupleLength())==1))))
            {
                GetDictTuple(hv_DLResult, hv_ClassNameKey, &hv_ResultClassNames);
                GetDictTuple(hv_DLResult, hv_ClassIdKey, &hv_ResultClassIds);
                TupleSortIndex(hv_ResultClassIds, &hv_SortIndices);
                TupleUniq(HTuple(hv_ResultClassIds[hv_SortIndices]), &hv_UniqueClassIds);
                TupleUniq(HTuple(hv_ResultClassNames[hv_SortIndices]), &hv_UniqueClassNames);
                hv_ClassNames[hv_UniqueClassIds] = hv_UniqueClassNames;
            }
        }
        get_dl_class_colors(hv_ClassNames, hv_AdditionalGreenClassNames, &hv_Colors);
        hv_ClassesLegend = (hv_ClassIDs+" : ")+hv_ClassNames;
        hv_InvalidInput = 0;
    }
    else
    {
        //Check if DLDatasetInfo contains necessary keys.
        hv_ClassKeys.Clear();
        hv_ClassKeys[0] = "class_names";
        hv_ClassKeys[1] = "class_ids";
        GetHandleParam(hv_DLDatasetInfo, "key_exists", hv_ClassKeys, &hv_ClassKeysExist);
        if (0 != (int((hv_ClassKeysExist.TupleMin())==0)))
        {
            //In that case we expect that the class names and ids are never used.
        }
        else
        {
            GetHandleParam(hv_DLDatasetInfo, "keys", HTuple(), &hv_DLDatasetInfoKeys);
            {
                HTuple end_val180 = (hv_ClassKeys.TupleLength())-1;
                HTuple step_val180 = 1;
                for (hv_Index=0; hv_Index.Continue(end_val180, step_val180); hv_Index += step_val180)
                {
                    if (0 != (int((hv_DLDatasetInfoKeys.TupleFindFirst(HTuple(hv_ClassKeys[hv_Index])))==-1)))
                    {
                        throw HException(("Key "+HTuple(hv_ClassKeys[hv_Index]))+" is missing in DLDatasetInfo.");
                    }
                }
            }
            //
            //Get the general dataset information, if available.
            GetHandleTuple(hv_DLDatasetInfo, "class_names", &hv_ClassNames);
            GetHandleTuple(hv_DLDatasetInfo, "class_ids", &hv_ClassIDs);
            //
            //Define distinct colors for the classes.
            get_dl_class_colors(hv_ClassNames, hv_AdditionalGreenClassNames, &hv_Colors);
            //
            hv_ClassesLegend = (hv_ClassIDs+" : ")+hv_ClassNames;
        }
    }
    //
    //** Set window parameters: ***
    //
    //Set previous window coordinates.
    hv_PrevWindowCoordinates.Clear();
    hv_PrevWindowCoordinates[0] = 0;
    hv_PrevWindowCoordinates[1] = 0;
    hv_PrevWindowCoordinates[2] = 0;
    hv_PrevWindowCoordinates[3] = 0;
    //
    //Check that the WindowHandleDict is of type dictionary.
    try
    {
        GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_Keys);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (int(HTuple(hv_Exception[0])==1401)))
        {
            throw HException("WindowHandleDict has to be of type dictionary. Use create_dict to create an empty dictionary.");
        }
        else
        {
            throw HException(hv_Exception);
        }
    }
    //For better usage, add meta information about the window handles in WindowHandleDict.
    GetDictParam(hv_WindowHandleDict, "key_exists", "meta_information", &hv_MetaInfoExists);
    if (0 != (hv_MetaInfoExists.TupleNot()))
    {
        CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
        SetDictTuple(hv_WindowHandleDict, "meta_information", hv___Tmp_Ctrl_Dict_Init_1);
        hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
    }
    //
    //For each window, set 'flush' to 'false' to avoid HalxAI:: flickering.
    hv_FlushValues = HTuple();
    GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeys);
    {
        HTuple end_val223 = (hv_WindowHandleKeys.TupleLength())-1;
        HTuple step_val223 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val223, step_val223); hv_Index += step_val223)
        {
            //Only consider the WindowHandleKeys that are needed for the current visualization.
            hv_KeyIndex = hv_KeysForDisplay.TupleFind(HTuple(hv_WindowHandleKeys[hv_Index]));
            if (0 != (HTuple(int(hv_KeyIndex!=-1)).TupleAnd(int(hv_KeyIndex!=HTuple()))))
            {
                GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]), &hv_WindowHandles);
                {
                    HTuple end_val228 = (hv_WindowHandles.TupleLength())-1;
                    HTuple step_val228 = 1;
                    for (hv_WindowIndex=0; hv_WindowIndex.Continue(end_val228, step_val228); hv_WindowIndex += step_val228)
                    {
                        GetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", &hv_FlushValue);
                        hv_FlushValues = hv_FlushValues.TupleConcat(hv_FlushValue);
                        SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", "false");
                    }
                }
            }
        }
    }
    //
    //** Display the data: ***
    //
    //Display data dictionaries.
    hv_KeyIndex = 0;
    while (0 != (int(hv_KeyIndex<(hv_KeysForDisplay.TupleLength()))))
    {
        //
        //Is it an Deep OCR detection case?
        TupleStrstr(HTuple(hv_KeysForDisplay[hv_KeyIndex]), "ocr_detection", &hv_IsOCRDetection);
        hv_IsOCRDetection = int(hv_IsOCRDetection==0);
        //
        if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("image"))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, HTuple(hv_KeysForDisplay[hv_KeyIndex]));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("image_with_domain"))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            GetDomain(ho_Image, &ho_Domain);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("region_color"));
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Domain, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("normals"))))
        {
            //
            //Normal image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, HTuple(hv_KeysForDisplay[hv_KeyIndex]));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("gripping_confidence"))))
        {
            //
            //Confidence image.
            if (0 != (int(hv_DLResult==HTuple())))
            {
                throw HException("DLResult dict is empty.");
            }
            if (0 != (int((hv_ResultKeys.TupleFind(HTuple(hv_KeysForDisplay[hv_KeyIndex])))!=-1)))
            {
                GetDictObject(&ho_Image, hv_DLResult, HTuple(hv_KeysForDisplay[hv_KeyIndex]));
            }
            else
            {
                throw HException(("Image with key '"+HTuple(hv_KeysForDisplay[hv_KeyIndex]))+"' could not be found in DLResult.");
            }
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),"Gripping confidence", "window", "top",
                         "left", "black", "box", "true");
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("gripping_map"))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Gripping map image result.
            if (0 != (int(hv_DLResult==HTuple())))
            {
                throw HException("DLResult dict is empty.");
            }
            if (0 != (int((hv_ResultKeys.TupleFind("gripping_map"))!=-1)))
            {
                GetDictObject(&ho_GrippingMapImageResult, hv_DLResult, "gripping_map");
            }
            else
            {
                throw HException(HTuple(HTuple("Image with key '")+"gripping_map")+"' could not be found in DLResult.");
            }
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            SetWindowParam(hv_CurrentWindowHandle, "background_color", "#000000");
            if (HDevWindowStack::IsOpen())
                ClearWindow(HDevWindowStack::GetActive());
            GetDomain(ho_GrippingMapImageResult, &ho_Domain);
            ReduceDomain(ho_Image, ho_Domain, &ho_Image);
            //
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //Display gripping regions.
            hv_ColorsGrippingGroundTruth.Clear();
            hv_ColorsGrippingGroundTruth.Append(hv_Params.TupleGetDictTuple("gripping_point_map_color"));
            hv_ColorsGrippingGroundTruth.Append(hv_Params.TupleGetDictTuple("gripping_point_background_color"));
            dev_display_segmentation_regions(ho_GrippingMapImageResult, (HTuple(1).Append(0)),
                                             hv_ColorsGrippingGroundTruth, HTuple(), &hv_ImageClassIDs);
            //Display gripping points.
            GetDictParam(hv_DLResult, "key_exists", "gripping_points", &hv_GrippingPointsExists);
            if (0 != hv_GrippingPointsExists)
            {
                get_gripping_points_from_dict(hv_DLResult, &hv_Rows, &hv_Columns);
                GenCrossContourXld(&ho_Cross, hv_Rows, hv_Columns, hv_Params.TupleGetDictTuple("gripping_point_size"),
                                   0.785398);
                if (HDevWindowStack::IsOpen())
                    SetLineWidth(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("line_width"));
                if (HDevWindowStack::IsOpen())
                    SetColor(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("gripping_point_color"));
                if (HDevWindowStack::IsOpen())
                    DispObj(ho_Cross, HDevWindowStack::GetActive());
            }
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
            //
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("gripping_map_ground_truth"))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Gripping map ground truth.
            if (0 != (int((hv_SampleKeys.TupleFind("segmentation_image"))!=-1)))
            {
                GetDictObject(&ho_GrippingMapGroundTruth, hv_DLSample, "segmentation_image");
            }
            else
            {
                throw HException(HTuple(HTuple("Image with key '")+"segmentation_image")+"' could not be found in DLSample.");
            }
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display gripping regions.
            hv_ColorsGrippingGroundTruth.Clear();
            hv_ColorsGrippingGroundTruth.Append(hv_Params.TupleGetDictTuple("gripping_point_map_color"));
            hv_ColorsGrippingGroundTruth.Append(hv_Params.TupleGetDictTuple("gripping_point_background_color"));
            dev_display_segmentation_regions(ho_GrippingMapGroundTruth, hv_ClassIDs, hv_ColorsGrippingGroundTruth,
                                             HTuple(), &hv_ImageClassIDs);
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),"Gripping map ground truth", "window",
                         "top", "left", "black", "box", "true");
            //
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("x"))))
        {
            //
            //X.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, HTuple(hv_KeysForDisplay[hv_KeyIndex]));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("xyz"))))
        {
            //
            //XYZ.
            get_dl_sample_image(&ho_X, hv_SampleKeys, hv_DLSample, "x");
            get_dl_sample_image(&ho_Y, hv_SampleKeys, hv_DLSample, "y");
            get_dl_sample_image(&ho_Z, hv_SampleKeys, hv_DLSample, "z");
            Compose3(ho_X, ho_Y, ho_Z, &ho_Image);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("y"))))
        {
            //
            //Y.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, HTuple(hv_KeysForDisplay[hv_KeyIndex]));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("z"))))
        {
            //
            //Z.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, HTuple(hv_KeysForDisplay[hv_KeyIndex]));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("gripping_point_cloud"))))
        {
            //
            //In case of 'gripping_point_cloud' provide a window that can be used by the procedure
            //dev_display_dl_3d_data. No actual drawing happens  in this procedure to keep it
            //free from operators not belonging either to the Foundation or Deep Learning
            //license modules.
            GetDictParam(hv_DLSample, "keys", HTuple(), &hv_SampleKeys);
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Do nothing here and draw later
            //
        }
        else if (0 != (HTuple(HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_both"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_both_local")))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_both_global")))))
        {
            //
            //In case of 'anomaly_both', also plot 'anomaly_both_local'
            //and 'anomaly_both_global', if available.
            TupleRegexpSelect(hv_ResultKeys, ".*anomaly_image.*", &hv_AnomalyImages);
            if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_both"))))
            {
                TupleRegexpReplace(hv_AnomalyImages, "image", "both", &hv_PossibleKeysForDisplay);
                hv_AddDisplayKey = 0;
                {
                    HTuple end_val464 = (hv_PossibleKeysForDisplay.TupleLength())-1;
                    HTuple step_val464 = 1;
                    for (hv_Index=0; hv_Index.Continue(end_val464, step_val464); hv_Index += step_val464)
                    {
                        if (0 != (int((hv_KeysForDisplay.TupleFindFirst(HTuple(hv_PossibleKeysForDisplay[hv_Index])))==-1)))
                        {
                            hv_KeysForDisplay = hv_KeysForDisplay.TupleConcat(HTuple(hv_PossibleKeysForDisplay[hv_Index]));
                            hv_AddDisplayKey = 1;
                        }
                    }
                }
                //
                //Display not possible for 'anomaly_both' if key 'anomaly_image' is missing.
                if (0 != (HTuple(int((hv_PossibleKeysForDisplay.TupleFindFirst(HTuple(hv_KeysForDisplay[hv_KeyIndex])))==-1)).TupleAnd(hv_AddDisplayKey)))
                {
                    hv_KeyIndex += 1;
                    continue;
                }
            }
            //
            //Get image and ground truth.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_anomaly_ground_truth_label(hv_SampleKeys, hv_DLSample, &hv_AnomalyLabelGroundTruth,
                                           &hv_AnomalyLabelIDGroundTruth);
            //
            //Get the anomaly results either by applying the specified thresholds or out of DLResult.
            TupleRegexpMatch(HTuple(hv_KeysForDisplay[hv_KeyIndex]), "anomaly_both(.*)",
                             &hv_AnomalyResultPostfix);
            get_anomaly_result(&ho_AnomalyImage, &ho_AnomalyRegion, hv_DLResult, hv_Params.TupleGetDictTuple("anomaly_classification_threshold"),
                               hv_Params.TupleGetDictTuple("anomaly_region_threshold"), hv_AnomalyResultPostfix,
                               &hv_AnomalyScore, &hv_AnomalyClassID, &hv_AnomalyClassThresholdDisplay,
                               &hv_AnomalyRegionThresholdDisplay);
            //
            //Get open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            hv_WindowHandleName = HTuple(hv_KeysForDisplay[hv_KeyIndex]);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, hv_WindowHandleName, &hv_CurrentWindowHandle,
                            &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualize image, ground truth (if available), and result regions.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            hv_AnomalyRegionGroundTruthExists = "false";
            if (0 != (hv_Params.TupleGetDictTuple("display_ground_truth_anomaly_regions")))
            {
                dev_display_ground_truth_anomaly_regions(hv_SampleKeys, hv_DLSample, hv_CurrentWindowHandle,
                                                         hv_Params.TupleGetDictTuple("line_width"), hv_Params.TupleGetDictTuple("anomaly_region_label_color"),
                                                         hv_Params.TupleGetDictTuple("anomaly_color_transparency"), &hv_AnomalyRegionGroundTruthExists);
            }
            //
            //Display anomaly regions defined by the specified threshold or out of DLResult.
            CreateDict(&hv___Tmp_Ctrl_Dict_Init_2);
            SetDictTuple(hv___Tmp_Ctrl_Dict_Init_2, "comp", -1);
            if (0 != (HTuple(((hv_Params.TupleConcat(hv___Tmp_Ctrl_Dict_Init_2)).TupleTestEqualDictItem("anomaly_region_threshold","comp")).TupleNot()).TupleOr(int((hv_ResultKeys.TupleFind("anomaly_region"+hv_AnomalyResultPostfix))!=-1))))
            {
                dev_display_result_anomaly_regions(ho_AnomalyRegion, hv_CurrentWindowHandle,
                                                   hv_Params.TupleGetDictTuple("line_width"), hv_Params.TupleGetDictTuple("anomaly_region_result_color"));
            }
            hv___Tmp_Ctrl_Dict_Init_2 = HTuple::TupleConstant("HNULL");
            //
            hv_Text = "GT and detected anomalies "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Get prediction color.
            hv_PredictionColor = "white";
            if (0 != (int(hv_AnomalyLabelIDGroundTruth==hv_AnomalyClassID)))
            {
                hv_PredictionColor = "green";
            }
            else if (0 != (int(hv_AnomalyClassID!=-1)))
            {
                hv_PredictionColor = "red";
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "---------------";
                hv_Text[hv_Text.TupleLength()] = "Ground truth ";
                hv_Text[hv_Text.TupleLength()] = "---------------";
                hv_Text[hv_Text.TupleLength()] = ((hv_AnomalyLabelIDGroundTruth+" : '")+hv_AnomalyLabelGroundTruth)+"'";
                if (0 != (HTuple(HTuple(int(hv_AnomalyRegionGroundTruthExists==HTuple("false"))).TupleAnd(int(hv_AnomalyLabelIDGroundTruth==1))).TupleAnd(hv_Params.TupleGetDictTuple("display_ground_truth_anomaly_regions"))))
                {
                    hv_Text[hv_Text.TupleLength()] = "";
                    hv_Text[hv_Text.TupleLength()] = "No segmentation ground truth found";
                }
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "---------------";
                hv_Text[hv_Text.TupleLength()] = "Results ";
                hv_Text[hv_Text.TupleLength()] = "---------------";
                if (0 != (int(hv_AnomalyClassID==1)))
                {
                    hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'nok'";
                }
                else if (0 != (int(hv_AnomalyClassID==0)))
                {
                    hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'ok'";
                }
                else
                {
                    hv_Text[hv_Text.TupleLength()] = "No classification result found";
                }
                CreateDict(&hv___Tmp_Ctrl_Dict_Init_3);
                SetDictTuple(hv___Tmp_Ctrl_Dict_Init_3, "comp", -1);
                if (0 != (((hv_Params.TupleConcat(hv___Tmp_Ctrl_Dict_Init_3)).TupleTestEqualDictItem("anomaly_region_threshold","comp")).TupleAnd(int((hv_ResultKeys.TupleFind("anomaly_region"+hv_AnomalyResultPostfix))==-1))))
                {
                    hv_Text[hv_Text.TupleLength()] = "";
                    hv_Text[hv_Text.TupleLength()] = "No segmentation result found";
                }
                hv___Tmp_Ctrl_Dict_Init_3 = HTuple::TupleConstant("HNULL");
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = (("anomaly_score"+hv_AnomalyResultPostfix)+": ")+(hv_AnomalyScore.TupleString(".3f"));
                hv_Text[hv_Text.TupleLength()] = "";
                if (0 != (HTuple(int(hv_AnomalyClassThresholdDisplay!=-1)).TupleOr(int(hv_AnomalyRegionThresholdDisplay!=-1))))
                {
                    hv_Text[hv_Text.TupleLength()] = "---------------";
                    hv_Text[hv_Text.TupleLength()] = "Thresholds ";
                    hv_Text[hv_Text.TupleLength()] = "---------------";
                }
                //
                if (0 != (int(hv_AnomalyClassThresholdDisplay!=-1)))
                {
                    hv_Text[hv_Text.TupleLength()] = "Classification: "+(hv_AnomalyClassThresholdDisplay.TupleString(".3f"));
                    hv_Text[hv_Text.TupleLength()] = "";
                }
                if (0 != (int(hv_AnomalyRegionThresholdDisplay!=-1)))
                {
                    hv_Text[hv_Text.TupleLength()] = "Segmentation: "+(hv_AnomalyRegionThresholdDisplay.TupleString(".3f"));
                    hv_Text[hv_Text.TupleLength()] = "";
                }
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, hv_WindowHandleName,
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                TupleGenConst(hv_Text.TupleLength(), "white", &hv_LineColors);
                hv_ResultColorOffset = 10;
                if (0 != (HTuple(HTuple(int(hv_AnomalyRegionGroundTruthExists==HTuple("false"))).TupleAnd(int(hv_AnomalyLabelIDGroundTruth==1))).TupleAnd(hv_Params.TupleGetDictTuple("display_ground_truth_anomaly_regions"))))
                {
                    hv_ResultColorOffset += 2;
                }
                hv_LineColors[hv_ResultColorOffset] = hv_PredictionColor;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             hv_LineColors, "box", "false");
            }
            //
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_ground_truth"))))
        {
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_anomaly_ground_truth_label(hv_SampleKeys, hv_DLSample, &hv_AnomalyLabelGroundTruth,
                                           &hv_AnomalyLabelIDGroundTruth);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            hv_AnomalyRegionExists = "false";
            if (0 != (hv_Params.TupleGetDictTuple("display_ground_truth_anomaly_regions")))
            {
                //Show the ground truth region.
                dev_display_ground_truth_anomaly_regions(hv_SampleKeys, hv_DLSample, hv_CurrentWindowHandle,
                                                         hv_Params.TupleGetDictTuple("line_width"), hv_Params.TupleGetDictTuple("anomaly_region_label_color"),
                                                         hv_Params.TupleGetDictTuple("anomaly_color_transparency"), &hv_AnomalyRegionExists);
            }
            //
            hv_Text = "Ground truth anomalies "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = ((hv_AnomalyLabelIDGroundTruth+" : '")+hv_AnomalyLabelGroundTruth)+"'";
                if (0 != (HTuple(HTuple(int(hv_AnomalyRegionExists==HTuple("false"))).TupleAnd(int(hv_AnomalyLabelIDGroundTruth==1))).TupleAnd(hv_Params.TupleGetDictTuple("display_ground_truth_anomaly_regions"))))
                {
                    hv_Text[hv_Text.TupleLength()] = "";
                    hv_Text[hv_Text.TupleLength()] = "No 'anomaly_ground_truth' exists!";
                }
                //
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             "white", "box", "false");
            }
        }
        else if (0 != (HTuple(HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_image"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_image_local")))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_image_global")))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get the anomaly results either by applying the specified thresholds or out of DLResult.
            hv_AnomalyImageKey = HTuple(hv_KeysForDisplay[hv_KeyIndex]);
            TupleRegexpMatch(hv_AnomalyImageKey, "anomaly_image(.*)", &hv_AnomalyResultPostfix);
            get_anomaly_result(&ho_AnomalyImage, &ho_AnomalyRegion, hv_DLResult, hv_Params.TupleGetDictTuple("anomaly_classification_threshold"),
                               hv_Params.TupleGetDictTuple("anomaly_region_threshold"), hv_AnomalyResultPostfix,
                               &hv_AnomalyScore, &hv_AnomalyClassID, &hv_AnomalyClassThresholdDisplay,
                               &hv_AnomalyRegionThresholdDisplay);
            //
            //Read in input image.
            GetDictObject(&ho_Image, hv_DLSample, "image");
            //Add the anomaly image to the input image.
            add_colormap_to_image(ho_AnomalyImage, ho_Image, &ho_AnomalyImage, hv_Params.TupleGetDictTuple("heatmap_color_scheme"));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (HDevWindowStack::IsOpen())
                DispObj(ho_AnomalyImage, HDevWindowStack::GetActive());
            hv_Text = hv_AnomalyImageKey;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            TupleRegexpReplace(hv_AnomalyImageKey, "image", "score", &hv_AnomalyScoreKey);
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text[hv_Text.TupleLength()] = "";
                if (0 != (int(hv_AnomalyClassID==1)))
                {
                    hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'nok'";
                }
                else if (0 != (int(hv_AnomalyClassID==0)))
                {
                    hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'ok'";
                }
                else
                {
                    hv_Text[hv_Text.TupleLength()] = "No classification result found";
                }
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = (hv_AnomalyScoreKey+": ")+(hv_AnomalyScore.TupleString(".3f"));
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             "white", "box", "false");
            }
        }
        else if (0 != (HTuple(HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_result"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_result_local")))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("anomaly_result_global")))))
        {
            //
            //Get image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get the anomaly results either by applying the specified thresholds or out of DLResult.
            hv_AnomalyResultKey = HTuple(hv_KeysForDisplay[hv_KeyIndex]);
            TupleRegexpMatch(hv_AnomalyResultKey, "anomaly_result(.*)", &hv_AnomalyResultPostfix);
            get_anomaly_result(&ho_AnomalyImage, &ho_AnomalyRegion, hv_DLResult, hv_Params.TupleGetDictTuple("anomaly_classification_threshold"),
                               hv_Params.TupleGetDictTuple("anomaly_region_threshold"), hv_AnomalyResultPostfix,
                               &hv_AnomalyScore, &hv_AnomalyClassID, &hv_AnomalyClassThresholdDisplay,
                               &hv_AnomalyRegionThresholdDisplay);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display anomaly regions defined by the specified threshold or out of DLResult.
            TupleRegexpReplace(hv_AnomalyResultKey, "result", "region", &hv_AnomalyRegionKey);
            CreateDict(&hv___Tmp_Ctrl_Dict_Init_4);
            SetDictTuple(hv___Tmp_Ctrl_Dict_Init_4, "comp", -1);
            if (0 != (HTuple(((hv_Params.TupleConcat(hv___Tmp_Ctrl_Dict_Init_4)).TupleTestEqualDictItem("anomaly_region_threshold","comp")).TupleNot()).TupleOr(int((hv_ResultKeys.TupleFind(hv_AnomalyRegionKey))!=-1))))
            {
                dev_display_result_anomaly_regions(ho_AnomalyRegion, hv_CurrentWindowHandle,
                                                   hv_Params.TupleGetDictTuple("line_width"), hv_Params.TupleGetDictTuple("anomaly_region_result_color"));
            }
            hv___Tmp_Ctrl_Dict_Init_4 = HTuple::TupleConstant("HNULL");
            //
            TupleRegexpReplace(hv_AnomalyResultKey, "result", "score", &hv_AnomalyScoreKey);
            //
            hv_Text = "Detected anomalies "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "---------------";
                hv_Text[hv_Text.TupleLength()] = "Results ";
                hv_Text[hv_Text.TupleLength()] = "---------------";
                if (0 != (int(hv_AnomalyClassID==1)))
                {
                    hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'nok'";
                }
                else if (0 != (int(hv_AnomalyClassID==0)))
                {
                    hv_Text[hv_Text.TupleLength()] = hv_AnomalyClassID+" : 'ok'";
                }
                else
                {
                    hv_Text[hv_Text.TupleLength()] = "No classification result found";
                }
                CreateDict(&hv___Tmp_Ctrl_Dict_Init_5);
                SetDictTuple(hv___Tmp_Ctrl_Dict_Init_5, "comp", -1);
                if (0 != (((hv_Params.TupleConcat(hv___Tmp_Ctrl_Dict_Init_5)).TupleTestEqualDictItem("anomaly_region_threshold","comp")).TupleAnd(int((hv_ResultKeys.TupleFind(hv_AnomalyRegionKey))==-1))))
                {
                    hv_Text[hv_Text.TupleLength()] = "";
                    hv_Text[hv_Text.TupleLength()] = "No segmentation result found";
                }
                hv___Tmp_Ctrl_Dict_Init_5 = HTuple::TupleConstant("HNULL");
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = (hv_AnomalyScoreKey+": ")+(hv_AnomalyScore.TupleString(".3f"));
                hv_Text[hv_Text.TupleLength()] = "";
                if (0 != (HTuple(int(hv_AnomalyClassThresholdDisplay!=-1)).TupleOr(int(hv_AnomalyRegionThresholdDisplay!=-1))))
                {
                    hv_Text[hv_Text.TupleLength()] = "---------------";
                    hv_Text[hv_Text.TupleLength()] = "Thresholds ";
                    hv_Text[hv_Text.TupleLength()] = "---------------";
                }
                //
                if (0 != (int(hv_AnomalyClassThresholdDisplay!=-1)))
                {
                    hv_Text[hv_Text.TupleLength()] = "Classification: "+(hv_AnomalyClassThresholdDisplay.TupleString(".3f"));
                    hv_Text[hv_Text.TupleLength()] = "";
                }
                if (0 != (int(hv_AnomalyRegionThresholdDisplay!=-1)))
                {
                    hv_Text[hv_Text.TupleLength()] = "Segmentation: "+(hv_AnomalyRegionThresholdDisplay.TupleString(".3f"));
                    hv_Text[hv_Text.TupleLength()] = "";
                }
                //
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             "white", "box", "false");
            }
            //
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("gripping_heatmap"))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get gripping points
            get_gripping_points_from_dict(hv_DLResult, &hv_Rows, &hv_Columns);
            //
            //Confidence image.
            if (0 != (int((hv_ResultKeys.TupleFind("gripping_confidence"))!=-1)))
            {
                GetDictObject(&ho_ConfidenceImage, hv_DLResult, "gripping_confidence");
            }
            else
            {
                throw HException("Image with key 'gripping_confidence' could not be found in DLResult.");
            }
            add_colormap_to_image(ho_ConfidenceImage, ho_Image, &ho_HeatmapScene, hv_Params.TupleGetDictTuple("heatmap_color_scheme"));
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (HDevWindowStack::IsOpen())
                DispObj(ho_HeatmapScene, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),"Gripping heatmap", "window", "top",
                         "left", "black", "box", "true");
            //
            GenCrossContourXld(&ho_Cross, hv_Rows, hv_Columns, hv_Params.TupleGetDictTuple("gripping_point_size"),
                               0.785398);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("line_width"));
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("gripping_point_color"));
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Cross, HDevWindowStack::GetActive());
            //
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("gripping_points"))))
        {
            //
            //Image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get gripping points
            get_gripping_points_from_dict(hv_DLResult, &hv_Rows, &hv_Columns);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            FullDomain(ho_Image, &ho_Image);
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ImageIDStringCapital, "window",
                             "bottom", "left", "white", "box", "false");
            }
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),"Gripping points", "window", "top",
                         "left", "black", "box", "true");
            //
            GenCrossContourXld(&ho_Cross, hv_Rows, hv_Columns, hv_Params.TupleGetDictTuple("gripping_point_size"),
                               0.785398);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("line_width"));
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("gripping_point_color"));
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Cross, HDevWindowStack::GetActive());
            //
        }
        else if (0 != (HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("bbox_both"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_both")))))
        {
            //
            //Ground truth and result bounding boxes on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (0 != hv_IsOCRDetection)
            {
                FullDomain(ho_Image, &ho_Image);
            }
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Visualization.
            //
            hv_DisplayDirectionTemp = hv_Params.TupleGetDictTuple("display_direction");
            if (0 != ((hv_Params.TupleGetDictTuple("display_direction")).TupleAnd(hv_IsOCRDetection)))
            {
                hv_DisplayDirectionTemp = -1;
            }
            dev_display_ground_truth_detection(hv_DLSample, hv_SampleKeys, hv_Params.TupleGetDictTuple("line_width"),
                                               hv_ClassIDs, hv_Colors, hv_Params.TupleGetDictTuple("bbox_label_color"),
                                               hv_WindowImageRatio, hv_Params.TupleGetDictTuple("bbox_text_color"), hv_Params.TupleGetDictTuple("display_labels"),
                                               hv_DisplayDirectionTemp, hv_CurrentWindowHandle, &hv_BboxLabelIndex);
            if (0 != (int((hv_ResultKeys.TupleFind("bbox_confidence"))!=-1)))
            {
                GetDictTuple(hv_DLResult, "bbox_confidence", &hv_BboxConfidences);
            }
            else
            {
                throw HException("Result data could not be found in DLResult.");
            }
            if (0 != (hv_Params.TupleGetDictTuple("bbox_display_confidence")))
            {
                hv_TextConf = (" ("+(hv_BboxConfidences.TupleString(".2f")))+")";
            }
            else
            {
                hv_TextConf = HTuple(hv_BboxConfidences.TupleLength(),"");
            }
            dev_display_result_detection(hv_DLResult, hv_ResultKeys, hv_Params.TupleGetDictTuple("line_width"),
                                         hv_ClassIDs, hv_TextConf, hv_Colors, hv_Params.TupleGetDictTuple("bbox_label_color"),
                                         hv_WindowImageRatio, "bottom", hv_Params.TupleGetDictTuple("bbox_text_color"),
                                         hv_Params.TupleGetDictTuple("display_labels"), hv_DisplayDirectionTemp,
                                         hv_CurrentWindowHandle, &hv_BboxClassIndex);
            hv_Text = "Ground truth and results "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            hv_Text = "Ground truth and";
            hv_Text[hv_Text.TupleLength()] = "results "+hv_ImageIDStringBraces;
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_BboxColorsBoth.Clear();
                hv_BboxColorsBoth[0] = "white";
                hv_BboxColorsBoth[1] = "white";
                if (0 != (int(((hv_BboxClassIndex.TupleLength())+(hv_BboxLabelIndex.TupleLength()))>0)))
                {
                    hv_BboxClassLabelIndexUniq = ((hv_BboxClassIndex.TupleConcat(hv_BboxLabelIndex)).TupleSort()).TupleUniq();
                    hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_BboxClassLabelIndexUniq]));
                    hv_BboxColorsBoth = hv_BboxColorsBoth.TupleConcat(HTuple(hv_Colors[hv_BboxClassLabelIndexUniq]));
                }
                else
                {
                    hv_Text = hv_Text.TupleConcat("No ground truth nor results present.");
                }
                //
                //Get or open next child window.
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             hv_BboxColorsBoth, "box", "false");
            }
        }
        else if (0 != (HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("bbox_ground_truth"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_ground_truth")))))
        {
            //
            //Sample bounding boxes on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (0 != hv_IsOCRDetection)
            {
                FullDomain(ho_Image, &ho_Image);
            }
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display smaller arrow for ocr_detection
            hv_DisplayDirectionTemp = hv_Params.TupleGetDictTuple("display_direction");
            if (0 != ((hv_Params.TupleGetDictTuple("display_direction")).TupleAnd(hv_IsOCRDetection)))
            {
                hv_DisplayDirectionTemp = -1;
            }
            //
            dev_display_ground_truth_detection(hv_DLSample, hv_SampleKeys, hv_Params.TupleGetDictTuple("line_width"),
                                               hv_ClassIDs, hv_Colors, hv_Params.TupleGetDictTuple("bbox_label_color"),
                                               hv_WindowImageRatio, hv_Params.TupleGetDictTuple("bbox_text_color"), hv_Params.TupleGetDictTuple("display_labels"),
                                               hv_DisplayDirectionTemp, hv_CurrentWindowHandle, &hv_BboxIDs);
            hv_Text = "Ground truth "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_BboxColors = "white";
                if (0 != (hv_BboxIDs.TupleLength()))
                {
                    hv_BboxIDsUniq = (hv_BboxIDs.TupleSort()).TupleUniq();
                    hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_BboxIDsUniq]));
                    hv_BboxColors = hv_BboxColors.TupleConcat(HTuple(hv_Colors[hv_BboxIDsUniq]));
                }
                else
                {
                    hv_Text = hv_Text.TupleConcat("No ground truth present.");
                }
                //
                //Get or open next child window.
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             hv_BboxColors, "box", "false");
            }
        }
        else if (0 != (HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("bbox_result"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_result")))))
        {
            //
            //Result bounding boxes on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (0 != hv_IsOCRDetection)
            {
                FullDomain(ho_Image, &ho_Image);
            }
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display smaller arrow for ocr_detection
            hv_DisplayDirectionTemp = hv_Params.TupleGetDictTuple("display_direction");
            if (0 != ((hv_Params.TupleGetDictTuple("display_direction")).TupleAnd(hv_IsOCRDetection)))
            {
                hv_DisplayDirectionTemp = -1;
            }
            //
            if (0 != (int((hv_ResultKeys.TupleFind("bbox_confidence"))!=-1)))
            {
                GetDictTuple(hv_DLResult, "bbox_confidence", &hv_BboxConfidences);
            }
            else
            {
                throw HException("Result data could not be found in DLResult.");
            }
            if (0 != (hv_Params.TupleGetDictTuple("bbox_display_confidence")))
            {
                hv_TextConf = (" ("+(hv_BboxConfidences.TupleString(".2f")))+")";
            }
            else
            {
                hv_TextConf = HTuple(hv_BboxConfidences.TupleLength(),"");
            }
            dev_display_result_detection(hv_DLResult, hv_ResultKeys, hv_Params.TupleGetDictTuple("line_width"),
                                         hv_ClassIDs, hv_TextConf, hv_Colors, hv_Params.TupleGetDictTuple("bbox_label_color"),
                                         hv_WindowImageRatio, "top", hv_Params.TupleGetDictTuple("bbox_text_color"),
                                         hv_Params.TupleGetDictTuple("display_labels"), hv_DisplayDirectionTemp,
                                         hv_CurrentWindowHandle, &hv_BboxClassIndex);
            hv_Text = "Result "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_BboxColorsResults = "white";
                if (0 != (int((hv_BboxClassIndex.TupleLength())>0)))
                {
                    hv_BboxClassIndexUniq = (hv_BboxClassIndex.TupleSort()).TupleUniq();
                    hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_BboxClassIndexUniq]));
                    hv_BboxColorsResults = hv_BboxColorsResults.TupleConcat(HTuple(hv_Colors[hv_BboxClassIndexUniq]));
                }
                else
                {
                    hv_Text = hv_Text.TupleConcat("No results present.");
                }
                //
                //Get or open next child window.
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             hv_BboxColorsResults, "box", "false");
            }
        }
        else if (0 != (HTuple(HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_score_map_character"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_score_map_link")))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_score_map_orientation")))))
        {
            //
            //Extract score maps
            ho_ScoreMaps = hv_OcrResult.TupleGetDictObject("score_maps");
            Decompose4(ho_ScoreMaps, &ho_CharacterScoreMap, &ho_LinkScoreMap, &ho_OrientationSinScoreMap,
                       &ho_OrientationCosScoreMap);
            //
            //Select score map to display
            if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_score_map_character"))))
            {
                ho_ScoreMap = ho_CharacterScoreMap;
                hv_Text = "Character score "+hv_ImageIDStringBraces;
            }
            else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_score_map_link"))))
            {
                ho_ScoreMap = ho_LinkScoreMap;
                hv_Text = "Link score "+hv_ImageIDStringBraces;
            }
            else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_detection_score_map_orientation"))))
            {
                Compose2(ho_OrientationSinScoreMap, ho_OrientationCosScoreMap, &ho_OrientationScoreMap
                         );
                ho_ScoreMap = ho_OrientationScoreMap;
                hv_Text = HTuple("Orientation (sin,cos) ")+hv_ImageIDStringBraces;
            }
            //Get or open next window.
            GetImageSize(ho_ScoreMap, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Make sure the minimum and maximum gray values of the score map image
            //are 0 and 1, respectively. This is necessary to get the correct color
            //range from the 'jet' color map.
            SetGrayval(ho_ScoreMap, HTuple(0).TupleConcat(hv_HeightImage-1), HTuple(0).TupleConcat(hv_WidthImage-1),
                       (HTuple(0).Append(1)));
            //
            //Display the score maps using the 'jet' color map.
            SetLut(hv_CurrentWindowHandle, "jet");
            if (HDevWindowStack::IsOpen())
                DispObj(ho_ScoreMap, HDevWindowStack::GetActive());
            //
            //Display text
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("classification_both"))))
        {
            //
            //Ground truth and result classification image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            get_classification_ground_truth(hv_SampleKeys, hv_DLSample, &hv_ClassificationLabelIDGroundTruth);
            get_classification_result(hv_ResultKeys, hv_DLResult, &hv_ClassificationLabelIDResult);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Get prediction color.
            hv_PredictionColor = "white";
            if (0 != (int(hv_ClassificationLabelIDGroundTruth==hv_ClassificationLabelIDResult)))
            {
                hv_PredictionText = "Correct";
                hv_PredictionColor = "green";
            }
            else
            {
                hv_PredictionText = "Wrong";
                hv_PredictionColor = "red";
            }
            //
            //Generate prediction color frame and show image.
            if (0 != (hv_Params.TupleGetDictTuple("display_classification_color_frame")))
            {
                //Create a frame with line width 7 that is completely displayed in the window.
                hv_BoarderOffset = 7/2.;
                GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
                GetDictTuple(hv_MetaInfo, "classification_both_window_image_ratio_height",
                             &hv_WindowImageRatioHeight);
                GetDictTuple(hv_MetaInfo, "classification_both_window_image_ratio_width",
                             &hv_WindowImageRatioWidth);
                hv_BoarderOffsetRow = hv_BoarderOffset/hv_WindowImageRatioHeight;
                hv_BoarderOffsetCol = hv_BoarderOffset/hv_WindowImageRatioWidth;
                GenContourPolygonXld(&ho_PredictionColorFrame, ((((hv_BoarderOffsetRow-0.5).TupleConcat(hv_BoarderOffsetRow-0.5)).TupleConcat((hv_HeightImage+0.5)-hv_BoarderOffsetRow)).TupleConcat((hv_HeightImage+0.5)-hv_BoarderOffsetRow)).TupleConcat(hv_BoarderOffsetRow-0.5),
                                     ((((hv_BoarderOffsetCol-0.5).TupleConcat((hv_WidthImage+0.5)-hv_BoarderOffsetCol)).TupleConcat((hv_WidthImage+0.5)-hv_BoarderOffsetCol)).TupleConcat(hv_BoarderOffsetCol-0.5)).TupleConcat(hv_BoarderOffsetCol-0.5));
                if (HDevWindowStack::IsOpen())
                    SetLineWidth(HDevWindowStack::GetActive(),7);
                if (HDevWindowStack::IsOpen())
                    SetColor(HDevWindowStack::GetActive(),hv_PredictionColor);
                if (HDevWindowStack::IsOpen())
                    DispObj(ho_Image, HDevWindowStack::GetActive());
                if (HDevWindowStack::IsOpen())
                    DispObj(ho_PredictionColorFrame, HDevWindowStack::GetActive());
            }
            else
            {
                if (HDevWindowStack::IsOpen())
                    DispObj(ho_Image, HDevWindowStack::GetActive());
            }
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_classification_ids")))
            {
                GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
                GetDictTuple(hv_MetaInfo, HTuple(hv_KeysForDisplay[hv_KeyIndex])+"_margin_bottom",
                             &hv_MarginBottom);
                GetDictTuple(hv_MetaInfo, HTuple(hv_KeysForDisplay[hv_KeyIndex])+"_window_coordinates",
                             &hv_WindowCoordinates);
                hv_CurrentWindowHeight = HTuple(hv_WindowCoordinates[3])-HTuple(hv_WindowCoordinates[0]);
                GetFontExtents(hv_CurrentWindowHandle, &hv__, &hv__, &hv__, &hv_MaxHeight);
                hv_Text = "GT label ID: "+hv_ClassificationLabelIDGroundTruth;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             "white", "box", "false");
                hv_Text = "Result class ID: "+hv_ClassificationLabelIDResult;
                if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
                {
                    if (HDevWindowStack::IsOpen())
                        DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_CurrentWindowHeight-((hv_MarginBottom+hv_MaxHeight)+10),
                                 "left", "white", "box", "false");
                }
                else
                {
                    if (HDevWindowStack::IsOpen())
                        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                                 "white", "box", "false");
                }
            }
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                hv_Text = "Result/GT classification "+hv_ImageIDStringBraces;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text = "Ground truth class ID "+hv_ImageIDStringBraces;
                hv_Text[hv_Text.TupleLength()] = HTuple(hv_ClassesLegend[hv_ClassificationLabelIDGroundTruth]);
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "Result class ID";
                if (0 != (int(hv_ClassificationLabelIDResult==HTuple())))
                {
                    hv_Text[hv_Text.TupleLength()] = "No classification result is given!";
                }
                else
                {
                    hv_Text[hv_Text.TupleLength()] = HTuple(hv_ClassesLegend[hv_ClassificationLabelIDResult]);
                    hv_Text[hv_Text.TupleLength()] = "";
                    hv_Text[hv_Text.TupleLength()] = "";
                    hv_Text[hv_Text.TupleLength()] = "Prediction ";
                    hv_Text[hv_Text.TupleLength()] = hv_PredictionText;
                }
                //
                //Get or open next child window.
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                TupleGenConst(hv_Text.TupleLength(), "white", &hv_LineColors);
                hv_LineColors[1] = HTuple(hv_Colors[hv_ClassificationLabelIDGroundTruth]);
                if (0 != (int(hv_ClassificationLabelIDResult!=HTuple())))
                {
                    hv_LineColors[5] = HTuple(hv_Colors[hv_ClassificationLabelIDResult]);
                    hv_LineColors[9] = hv_PredictionColor;
                }
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             hv_LineColors, "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("classification_ground_truth"))))
        {
            //
            //Ground truth classification image and class label.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            get_classification_ground_truth(hv_SampleKeys, hv_DLSample, &hv_ClassificationLabelIDGroundTruth);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_classification_ids")))
            {
                hv_Text = "GT label ID: "+hv_ClassificationLabelIDGroundTruth;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             "white", "box", "false");
            }
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                hv_Text = "Ground truth classification "+hv_ImageIDStringBraces;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text = "Ground truth class ID "+hv_ImageIDStringBraces;
                hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ClassificationLabelIDGroundTruth]));
                //
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ClassificationLabelIDGroundTruth])),
                             "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("classification_result"))))
        {
            //
            //Ground truth classification image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            get_classification_result(hv_ResultKeys, hv_DLResult, &hv_ClassificationLabelIDResult);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display the class IDs.
            if (0 != (hv_Params.TupleGetDictTuple("display_classification_ids")))
            {
                GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
                GetDictTuple(hv_MetaInfo, "classification_result_margin_bottom", &hv_MarginBottom);
                GetDictTuple(hv_MetaInfo, "classification_result_window_coordinates", &hv_WindowCoordinates);
                hv_CurrentWindowHeight = HTuple(hv_WindowCoordinates[3])-HTuple(hv_WindowCoordinates[0]);
                GetFontExtents(hv_CurrentWindowHandle, &hv__, &hv__, &hv__, &hv_MaxHeight);
                hv_Text = "Result class ID: "+hv_ClassificationLabelIDResult;
                if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
                {
                    if (HDevWindowStack::IsOpen())
                        DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_CurrentWindowHeight-((hv_MarginBottom+hv_MaxHeight)+10),
                                 "left", "white", "box", "false");
                }
                else
                {
                    if (HDevWindowStack::IsOpen())
                        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                                 "white", "box", "false");
                }
            }
            //
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                hv_Text = "Result classification "+hv_ImageIDStringBraces;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_Text = "Result class ID "+hv_ImageIDStringBraces;
                if (0 != (int(hv_ClassificationLabelIDResult==HTuple())))
                {
                    hv_Text[hv_Text.TupleLength()] = "No classification result is given!";
                }
                else
                {
                    hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ClassificationLabelIDResult]));
                }
                //
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ClassificationLabelIDResult])),
                             "box", "false");
            }
        }
        else if (0 != (HTuple(HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("heatmap_grad_cam"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("heatmap_guided_grad_cam")))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("heatmap_confidence_based")))))
        {
            //
            //Display the heatmap image (method 'heatmap_grad_cam', 'heatmap_guided_grad_cam',
            //or 'heatmap_confidence_based') in the selected color scheme.
            //Retrieve heatmap image, inferred image, and inference results.
            hv_SelectedHeatmapMethod = HTuple(hv_KeysForDisplay[hv_KeyIndex]);
            if (0 != (HTuple(HTuple(int((hv_ResultKeys.TupleFind("heatmap_grad_cam"))!=-1)).TupleOr(int((hv_ResultKeys.TupleFind("heatmap_guided_grad_cam"))!=-1))).TupleOr(int((hv_ResultKeys.TupleFind("heatmap_confidence_based"))!=-1))))
            {
                if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_grad_cam"))))
                {
                    GetDictTuple(hv_DLResult, "heatmap_grad_cam", &hv_DictHeatmap);
                    hv_MethodName = "Grad-CAM";
                }
                else if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_guided_grad_cam"))))
                {
                    GetDictTuple(hv_DLResult, "heatmap_guided_grad_cam", &hv_DictHeatmap);
                    hv_MethodName = "Guided-Grad-CAM";
                }
                else
                {
                    GetDictTuple(hv_DLResult, "heatmap_confidence_based", &hv_DictHeatmap);
                    hv_MethodName = "Confidence based";
                }
                GetDictParam(hv_DictHeatmap, "keys", HTuple(), &hv_HeatmapKeys);
                //
                if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_guided_grad_cam"))))
                {
                    hv_HeatmapImageName = hv_HeatmapKeys.TupleRegexpSelect("guided_grad_cam_image_class_[0-9]*");
                    hv_TargetClassID = hv_HeatmapImageName.TupleRegexpMatch("guided_grad_cam_image_class_([0-9]+)$");
                }
                else
                {
                    hv_HeatmapImageName = hv_HeatmapKeys.TupleRegexpSelect("heatmap_image_class_[0-9]*");
                    hv_TargetClassID = hv_HeatmapImageName.TupleRegexpMatch("heatmap_image_class_([0-9]+)$");
                }
                GetDictObject(&ho_ImageHeatmap, hv_DictHeatmap, hv_HeatmapImageName);
            }
            else
            {
                throw HException("Heatmap image could not be found in DLResult.");
            }
            //
            //Only for the Grad-Cam heatmap the input image is shown.
            if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_grad_cam"))))
            {
                //Read in input image.
                GetDictObject(&ho_Image, hv_DLSample, "image");
                //Add the heatmap to the input image.
                add_colormap_to_image(ho_ImageHeatmap, ho_Image, &ho_ImageHeatmap, hv_Params.TupleGetDictTuple("heatmap_color_scheme"));
            }
            //
            //Get or open next window.
            GetImageSize(ho_ImageHeatmap, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (HDevWindowStack::IsOpen())
                DispObj(ho_ImageHeatmap, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                hv_Text = "Classification heatmap "+hv_ImageIDStringBraces;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                GetDictTuple(hv_DLResult, "classification_class_names", &hv_ClassNames);
                GetDictTuple(hv_DLResult, "classification_class_ids", &hv_ClassIDs);
                GetDictTuple(hv_DLResult, "classification_confidences", &hv_Confidences);
                if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_confidence_based"))))
                {
                    GetDictTuple(hv_DictHeatmap, "classification_heatmap_maxdeviation", &hv_MaxDeviation);
                }
                hv_ClassificationLabelNameResult = ((const HTuple&)hv_ClassNames)[0];
                hv_ClassificationLabelIDResult = ((const HTuple&)hv_ClassIDs)[0];
                hv_TargetClassConfidence = HTuple(hv_Confidences[hv_ClassIDs.TupleFind(hv_TargetClassID.TupleNumber())]);
                hv_Text = "--------- ";
                hv_Text[hv_Text.TupleLength()] = "Image ";
                hv_Text[hv_Text.TupleLength()] = "--------- ";
                hv_Text[hv_Text.TupleLength()] = "";
                if (0 != (int((hv_SampleKeys.TupleFind("image_label_id"))!=-1)))
                {
                    GetDictTuple(hv_DLSample, "image_label_id", &hv_ClassificationLabelIDGroundTruth);
                    GetDictTuple(hv_DLDatasetInfo, "class_names", &hv_ClassificationLabelNamesGroundTruth);
                    //Get prediction color.
                    if (0 != (int(hv_ClassificationLabelIDGroundTruth==hv_ClassificationLabelIDResult)))
                    {
                        hv_PredictionColor = "green";
                    }
                    else
                    {
                        hv_PredictionColor = "red";
                    }
                    hv_Text[hv_Text.TupleLength()] = "Ground truth class: ";
                    hv_Text[hv_Text.TupleLength()] = HTuple(hv_ClassificationLabelNamesGroundTruth[hv_ClassificationLabelIDGroundTruth]);
                    hv_Text[hv_Text.TupleLength()] = "";
                }
                hv_Text[hv_Text.TupleLength()] = "Predicted class: ";
                hv_Text[hv_Text.TupleLength()] = hv_ClassificationLabelNameResult;
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "Confidence: "+(HTuple(hv_Confidences[0]).TupleString(".2f"));
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "--------- ";
                hv_Text[hv_Text.TupleLength()] = "Heatmap ";
                hv_Text[hv_Text.TupleLength()] = "--------- ";
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "Method: "+hv_MethodName;
                hv_Text[hv_Text.TupleLength()] = "Target class: "+hv_TargetClassID;
                hv_Text[hv_Text.TupleLength()] = "";
                hv_Text[hv_Text.TupleLength()] = "Target class confidence: "+(hv_TargetClassConfidence.TupleString(".2f"));
                if (0 != (int(hv_SelectedHeatmapMethod==HTuple("heatmap_confidence_based"))))
                {
                    hv_Text[hv_Text.TupleLength()] = "Maximum deviation: "+(hv_MaxDeviation.TupleString(".2f"));
                }
                //
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                TupleGenConst(hv_Text.TupleLength(), "white", &hv_LineColors);
                if (0 != (int((hv_SampleKeys.TupleFind("image_label_id"))!=-1)))
                {
                    hv_LineColors[8] = hv_PredictionColor;
                }
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             hv_LineColors, "box", "false");
            }
        }
        else if (0 != (HTuple(HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_ground_truth"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_result")))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_both")))))
        {
            //
            //OCR Recognition.
            hv_ShowGT = HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_both"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_ground_truth")));
            hv_ShowResult = HTuple(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_both"))).TupleOr(int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("ocr_recognition_result")));
            hv_NumLines = hv_ShowGT+hv_ShowResult;
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_NumLines*(hv_Params.TupleGetDictTuple("display_bottom_desc")), hv_WidthImage,
                            hv_HeightImage, 0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            FullDomain(ho_Image, &ho_Image);
            GetImageType(ho_Image, &hv_Type);
            if (0 != (int(hv_Type==HTuple("real"))))
            {
                //We assume that real images have been preprocessed
                //to the range -1,1 already. Hence, we need to rescale
                //them back to a visible range in byte.
                ScaleImage(ho_Image, &ho_Image, 255.0/2, 127);
                ConvertImageType(ho_Image, &ho_Image, "byte");
            }
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                hv_Text = HTuple();
                //Ground truth.
                if (0 != hv_ShowGT)
                {
                    hv_Text[hv_Text.TupleLength()] = (("Ground truth: \""+(hv_DLSample.TupleGetDictTuple("word")))+"\" ")+hv_ImageIDStringBraces;
                }
                //Result.
                if (0 != hv_ShowResult)
                {
                    GetDictParam(hv_DLSample, "key_exists", "word", &hv_GTWordKeyExists);
                    if (0 != hv_GTWordKeyExists)
                    {
                        GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
                        GetDictTuple(hv_MetaInfo, HTuple(hv_KeysForDisplay[hv_KeyIndex])+"_window_coordinates",
                                     &hv_WindowCoordinates);
                        GetDictTuple(hv_MetaInfo, HTuple(hv_KeysForDisplay[hv_KeyIndex])+"_margin_bottom",
                                     &hv_MarginBottom);
                        hv_HeightWindow = ((const HTuple&)hv_WindowCoordinates)[3];
                        hv_HeightMarginBottom = (hv_HeightImage*hv_MarginBottom)/(hv_HeightWindow-hv_MarginBottom);
                        hv_Size = hv_HeightMarginBottom/2;
                        hv_Length = hv_Size/2;
                        hv_Row = hv_HeightImage+(hv_HeightMarginBottom/2);
                        hv_Column = hv_WidthImage-(1.5*hv_Size);
                        HomMat2dIdentity(&hv_HomMat2DIdentity);
                        HomMat2dRotate(hv_HomMat2DIdentity, HTuple(45).TupleRad(), 0, 0, &hv_HomMat2DRotate);
                        HomMat2dTranslate(hv_HomMat2DRotate, hv_Row, hv_Column, &hv_HomMat2DCompose);
                        if (0 != ((hv_DLResult.TupleConcat(hv_DLSample)).TupleTestEqualDictItem("word","word")))
                        {
                            hv_PredictionForegroundColor = "green";
                            hv_PredictionBackgroundColor = "#008000";
                            GenContourPolygonXld(&ho_PredictionSymbol, (-0.75*hv_Length).TupleConcat((HTuple(0).Append(0))),
                                                 ((-hv_Length).TupleConcat(-hv_Length)).TupleConcat(hv_Length));
                        }
                        else
                        {
                            hv_PredictionForegroundColor = "red";
                            hv_PredictionBackgroundColor = "#800000";
                            GenContourPolygonXld(&ho_CrossLineH, (HTuple(0).Append(0)), (-hv_Length).TupleConcat(hv_Length));
                            GenContourPolygonXld(&ho_CrossLineV, (-hv_Length).TupleConcat(hv_Length),
                                                 (HTuple(0).Append(0)));
                            ConcatObj(ho_CrossLineH, ho_CrossLineV, &ho_PredictionSymbol);
                        }
                        AffineTransContourXld(ho_PredictionSymbol, &ho_PredictionSymbol, hv_HomMat2DCompose);
                        SetWindowParam(hv_CurrentWindowHandle, "background_color", hv_PredictionBackgroundColor);
                        if (HDevWindowStack::IsOpen())
                            ClearWindow(HDevWindowStack::GetActive());
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_Image, HDevWindowStack::GetActive());
                        if (HDevWindowStack::IsOpen())
                            SetLineWidth(HDevWindowStack::GetActive(),5);
                        if (HDevWindowStack::IsOpen())
                            SetColor(HDevWindowStack::GetActive(),hv_PredictionForegroundColor);
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_PredictionSymbol, HDevWindowStack::GetActive());
                    }
                    else
                    {
                        hv_PredictionForegroundColor = "white";
                    }
                    if (0 != hv_ShowGT)
                    {
                        hv_Spaces = "    ";
                    }
                    else
                    {
                        hv_Spaces = "";
                    }
                    hv_Text[hv_Text.TupleLength()] = ((("Deep OCR:"+hv_Spaces)+" \"")+(hv_DLResult.TupleGetDictTuple("word")))+"\"";
                }
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_confidence"))))
        {
            //
            //Segmentation confidences.
            get_confidence_image(&ho_ImageConfidence, hv_ResultKeys, hv_DLResult);
            //
            //Get or open next window.
            GetImageSize(ho_ImageConfidence, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (HDevWindowStack::IsOpen())
                DispObj(ho_ImageConfidence, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),"Confidence image "+hv_ImageIDStringBraces,
                             "window", "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_confidence_map"))))
        {
            //
            //Segmentation confidence map on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_confidence_image(&ho_ImageConfidence, hv_ResultKeys, hv_DLResult);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            hv_Params.TupleGetDictTuple("map_color_bar_width"), hv_Params.TupleGetDictTuple("scale_windows"),
                            hv_Params.TupleGetDictTuple("threshold_width"), hv_PrevWindowCoordinates,
                            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle,
                            &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            dev_display_confidence_regions(ho_ImageConfidence, hv_Params.TupleGetDictTuple("map_transparency"),
                                           &hv_ConfidenceColors);
            dev_display_map_color_bar(hv_WidthImage, hv_HeightImage, hv_Params.TupleGetDictTuple("map_color_bar_width"),
                                      hv_ConfidenceColors, 1.0, hv_WindowImageRatio, hv_CurrentWindowHandle);
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),"Confidence map "+hv_ImageIDStringBraces,
                             "window", "bottom", "left", "white", "box", "false");
            }
            //
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_both"))))
        {
            //
            //Ground truth and result segmentation on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_segmentation_image_ground_truth(&ho_SegmentationImagGroundTruth, hv_SampleKeys,
                                                hv_DLSample);
            get_segmentation_image_result(&ho_SegmentationImageResult, hv_ResultKeys, hv_DLResult);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display regions.
            hv_ColorsResults = hv_Colors+(hv_Params.TupleGetDictTuple("segmentation_transparency"));
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),"margin");
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),2);
            dev_display_segmentation_regions(ho_SegmentationImagGroundTruth, hv_ClassIDs,
                                             hv_ColorsResults, hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids"),
                                             &hv_GroundTruthIDs);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),6);
            dev_display_segmentation_regions(ho_SegmentationImageResult, hv_ClassIDs, hv_ColorsResults,
                                             hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids"), &hv_ResultIDs);
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),"fill");
            hv_Text = "Ground truth and result segmentation "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_ImageClassIDsUniq = ((hv_GroundTruthIDs.TupleConcat(hv_ResultIDs)).TupleSort()).TupleUniq();
                //Get Indices according to image class IDs.
                TupleGenConst(hv_ImageClassIDsUniq.TupleLength(), 0, &hv_ImageClassIDsIndices);
                {
                    HTuple end_val1378 = (hv_ImageClassIDsUniq.TupleLength())-1;
                    HTuple step_val1378 = 1;
                    for (hv_ImageClassIDsIndex=0; hv_ImageClassIDsIndex.Continue(end_val1378, step_val1378); hv_ImageClassIDsIndex += step_val1378)
                    {
                        hv_ImageClassIDsIndices[hv_ImageClassIDsIndex] = hv_ClassIDs.TupleFindFirst(HTuple(hv_ImageClassIDsUniq[hv_ImageClassIDsIndex]));
                    }
                }
                hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ImageClassIDsIndices]));
                hv_Text[(hv_Text.TupleLength())+1] = HTuple("- thicker line: result, thinner lines: ground truth");
                hv_Text[hv_Text.TupleLength()] = "  (you may have to zoom in for a more detailed view)";
                hv_StringSegExcludeClassIDs = "";
                {
                    HTuple end_val1385 = ((hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids")).TupleLength())-1;
                    HTuple step_val1385 = 1;
                    for (hv_StringIndex=0; hv_StringIndex.Continue(end_val1385, step_val1385); hv_StringIndex += step_val1385)
                    {
                        if (0 != (int(hv_StringIndex==(((hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids")).TupleLength())-1))))
                        {
                            hv_StringSegExcludeClassIDs += HTuple((hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids"))[hv_StringIndex]);
                        }
                        else
                        {
                            hv_StringSegExcludeClassIDs = (hv_StringSegExcludeClassIDs+HTuple((hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids"))[hv_StringIndex]))+HTuple(", ");
                        }
                    }
                }
                CreateDict(&hv___Tmp_Ctrl_Dict_Init_6);
                SetDictTuple(hv___Tmp_Ctrl_Dict_Init_6, "comp", HTuple());
                if (0 != (((hv_Params.TupleConcat(hv___Tmp_Ctrl_Dict_Init_6)).TupleTestEqualDictItem("segmentation_exclude_class_ids","comp")).TupleNot()))
                {
                    hv_Text[hv_Text.TupleLength()] = ("- (excluded classID(s) "+hv_StringSegExcludeClassIDs)+" from visualization)";
                }
                hv___Tmp_Ctrl_Dict_Init_6 = HTuple::TupleConstant("HNULL");
                //
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             (HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ImageClassIDsIndices]))).TupleConcat(((HTuple("white").Append("white")).Append("white"))),
                             "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_diff"))))
        {
            //
            //Difference of ground truth and result segmentation on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_segmentation_image_ground_truth(&ho_SegmentationImagGroundTruth, hv_SampleKeys,
                                                hv_DLSample);
            get_segmentation_image_result(&ho_SegmentationImageResult, hv_ResultKeys, hv_DLResult);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            AbsDiffImage(ho_SegmentationImagGroundTruth, ho_SegmentationImageResult, &ho_ImageAbsDiff,
                         1);
            MinMaxGray(ho_SegmentationImageResult, ho_ImageAbsDiff, 0, &hv_Min, &hv_Max,
                       &hv_Range);
            if (0 != (int(hv_Min!=hv_Max)))
            {
                Threshold(ho_ImageAbsDiff, &ho_DiffRegion, 0.00001, hv_Max);
                if (HDevWindowStack::IsOpen())
                    SetColor(HDevWindowStack::GetActive(),"#ff0000"+(hv_Params.TupleGetDictTuple("segmentation_transparency")));
                if (HDevWindowStack::IsOpen())
                    DispObj(ho_DiffRegion, HDevWindowStack::GetActive());
            }
            else
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),"No difference found.", "window",
                             "top", "left", "black", HTuple(), HTuple());
            }
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                hv_Text = "Difference of ground truth and result segmentation "+hv_ImageIDStringBraces;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_ground_truth"))))
        {
            //
            //Ground truth segmentation image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_segmentation_image_ground_truth(&ho_SegmentationImagGroundTruth, hv_SampleKeys,
                                                hv_DLSample);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display segmentation regions.
            hv_ColorsSegmentation = hv_Colors+(hv_Params.TupleGetDictTuple("segmentation_transparency"));
            GetDraw(hv_CurrentWindowHandle, &hv_DrawMode);
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("segmentation_draw"));
            GetLineWidth(hv_CurrentWindowHandle, &hv_Width);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("line_width"));
            dev_display_segmentation_regions(ho_SegmentationImagGroundTruth, hv_ClassIDs,
                                             hv_ColorsSegmentation, hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids"),
                                             &hv_ImageClassIDs);
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),hv_Width.TupleInt());
            hv_Text = "Ground truth segmentation "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_ImageClassIDsUniq = (hv_ImageClassIDs.TupleSort()).TupleUniq();
                //Get Indices according to image class IDs.
                TupleGenConst(hv_ImageClassIDsUniq.TupleLength(), 0, &hv_ImageClassIDsIndices);
                {
                    HTuple end_val1460 = (hv_ImageClassIDsUniq.TupleLength())-1;
                    HTuple step_val1460 = 1;
                    for (hv_ImageClassIDsIndex=0; hv_ImageClassIDsIndex.Continue(end_val1460, step_val1460); hv_ImageClassIDsIndex += step_val1460)
                    {
                        hv_ImageClassIDsIndices[hv_ImageClassIDsIndex] = hv_ClassIDs.TupleFindFirst(HTuple(hv_ImageClassIDsUniq[hv_ImageClassIDsIndex]));
                    }
                }
                hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ImageClassIDsIndices]));
                //
                //Get or open next child window
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ImageClassIDsIndices])),
                             "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_image_result"))))
        {
            //
            //Result segmentation on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_segmentation_image_result(&ho_SegmentationImageResult, hv_ResultKeys, hv_DLResult);
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            //
            //Display result segmentation regions.
            hv_ColorsResults = hv_Colors+(hv_Params.TupleGetDictTuple("segmentation_transparency"));
            GetDraw(hv_CurrentWindowHandle, &hv_DrawMode);
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("segmentation_draw"));
            GetLineWidth(hv_CurrentWindowHandle, &hv_Width);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),hv_Params.TupleGetDictTuple("line_width"));
            dev_display_segmentation_regions(ho_SegmentationImageResult, hv_ClassIDs, hv_ColorsResults,
                                             hv_Params.TupleGetDictTuple("segmentation_exclude_class_ids"), &hv_ImageClassIDs);
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
            if (HDevWindowStack::IsOpen())
                SetLineWidth(HDevWindowStack::GetActive(),hv_Width.TupleInt());
            hv_Text = "Result segmentation "+hv_ImageIDStringBraces;
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "bottom", "left",
                             "white", "box", "false");
            }
            //
            //Display the legend.
            if (0 != (hv_Params.TupleGetDictTuple("display_legend")))
            {
                hv_ImageClassIDsUniq = (hv_ImageClassIDs.TupleSort()).TupleUniq();
                //Get Indices according to image class IDs.
                TupleGenConst(hv_ImageClassIDsUniq.TupleLength(), 0, &hv_ImageClassIDsIndices);
                {
                    HTuple end_val1501 = (hv_ImageClassIDsUniq.TupleLength())-1;
                    HTuple step_val1501 = 1;
                    for (hv_ImageClassIDsIndex=0; hv_ImageClassIDsIndex.Continue(end_val1501, step_val1501); hv_ImageClassIDsIndex += step_val1501)
                    {
                        hv_ImageClassIDsIndices[hv_ImageClassIDsIndex] = hv_ClassIDs.TupleFindFirst(HTuple(hv_ImageClassIDsUniq[hv_ImageClassIDsIndex]));
                    }
                }
                hv_Text = hv_Text.TupleConcat(HTuple(hv_ClassesLegend[hv_ImageClassIDsIndices]));
                //
                //Get or open next child window.
                get_child_window(hv_HeightImage, hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                                 hv_Text, hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                                 &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left",
                             HTuple("white").TupleConcat(HTuple(hv_Colors[hv_ImageClassIDsIndices])),
                             "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_weight"))))
        {
            //
            //Weight image.
            get_weight_image(&ho_ImageWeight, hv_SampleKeys, hv_DLSample);
            //
            //Get or open next window.
            GetImageSize(ho_ImageWeight, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            0, hv_Params.TupleGetDictTuple("scale_windows"), hv_Params.TupleGetDictTuple("threshold_width"),
                            hv_PrevWindowCoordinates, hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]),
                            &hv_CurrentWindowHandle, &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            if (HDevWindowStack::IsOpen())
                DispObj(ho_ImageWeight, HDevWindowStack::GetActive());
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),"Weight image "+hv_ImageIDStringBraces,
                             "window", "bottom", "left", "white", "box", "false");
            }
        }
        else if (0 != (int(HTuple(hv_KeysForDisplay[hv_KeyIndex])==HTuple("segmentation_weight_map"))))
        {
            //
            //Weight map on image.
            get_dl_sample_image(&ho_Image, hv_SampleKeys, hv_DLSample, "image");
            get_weight_image(&ho_ImageWeight, hv_SampleKeys, hv_DLSample);
            //
            CreateDict(&hv___Tmp_Ctrl_Dict_Init_7);
            SetDictTuple(hv___Tmp_Ctrl_Dict_Init_7, "comp", 0);
            if (0 != ((hv_Params.TupleConcat(hv___Tmp_Ctrl_Dict_Init_7)).TupleTestEqualDictItem("segmentation_max_weight","comp")))
            {
                //Calculate SegMaxWeight if not given in GenParam.
                MinMaxGray(ho_ImageWeight, ho_ImageWeight, 0, &hv_MinWeight, &hv___Tmp_Ctrl_1,
                           &hv_Range);
                SetDictTuple(hv_Params, "segmentation_max_weight", hv___Tmp_Ctrl_1);
            }
            hv___Tmp_Ctrl_Dict_Init_7 = HTuple::TupleConstant("HNULL");
            //
            //Get or open next window.
            GetImageSize(ho_Image, &hv_WidthImage, &hv_HeightImage);
            get_next_window(hv_Params.TupleGetDictTuple("font"), hv_Params.TupleGetDictTuple("font_size"),
                            hv_Params.TupleGetDictTuple("display_bottom_desc"), hv_WidthImage, hv_HeightImage,
                            hv_Params.TupleGetDictTuple("map_color_bar_width"), hv_Params.TupleGetDictTuple("scale_windows"),
                            hv_Params.TupleGetDictTuple("threshold_width"), hv_PrevWindowCoordinates,
                            hv_WindowHandleDict, HTuple(hv_KeysForDisplay[hv_KeyIndex]), &hv_CurrentWindowHandle,
                            &hv_WindowImageRatio, &hv_PrevWindowCoordinates);
            //
            //Visualization.
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Image, HDevWindowStack::GetActive());
            dev_display_weight_regions(ho_ImageWeight, hv_Params.TupleGetDictTuple("map_transparency"),
                                       hv_Params.TupleGetDictTuple("segmentation_max_weight"), &hv_WeightsColors);
            dev_display_map_color_bar(hv_WidthImage, hv_HeightImage, hv_Params.TupleGetDictTuple("map_color_bar_width"),
                                      hv_WeightsColors, hv_Params.TupleGetDictTuple("segmentation_max_weight"),
                                      hv_WindowImageRatio, hv_CurrentWindowHandle);
            if (0 != (hv_Params.TupleGetDictTuple("display_bottom_desc")))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),"Weight map "+hv_ImageIDStringBraces,
                             "window", "bottom", "left", "white", "box", "false");
            }
        }
        else
        {
            //Reset flush buffer of existing windows before throwing an exception.
            GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeys);
            {
                HTuple end_val1552 = (hv_WindowHandleKeys.TupleLength())-1;
                HTuple step_val1552 = 1;
                for (hv_Index=0; hv_Index.Continue(end_val1552, step_val1552); hv_Index += step_val1552)
                {
                    //Only consider the WindowHandleKeys that are needed for the current visualization.
                    hv_Indices = hv_KeysForDisplay.TupleFind(HTuple(hv_WindowHandleKeys[hv_Index]));
                    if (0 != (HTuple(int(hv_Indices!=-1)).TupleAnd(int(hv_Indices!=HTuple()))))
                    {
                        GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeys[hv_Index]),
                                     &hv_WindowHandles);
                        {
                            HTuple end_val1557 = (hv_WindowHandles.TupleLength())-1;
                            HTuple step_val1557 = 1;
                            for (hv_WindowIndex=0; hv_WindowIndex.Continue(end_val1557, step_val1557); hv_WindowIndex += step_val1557)
                            {
                                //Reset values of windows that have been changed temporarily.
                                SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", HTuple(hv_FlushValues[hv_Index]));
                            }
                        }
                    }
                }
            }
            throw HException("Key for display unknown: "+HTuple(hv_KeysForDisplay[hv_KeyIndex]));
        }
        //
        hv_KeyIndex += 1;
    }
    //
    //Display results.
    GetDictParam(hv_WindowHandleDict, "keys", HTuple(), &hv_WindowHandleKeysNew);
    {
        HTuple end_val1571 = (hv_WindowHandleKeysNew.TupleLength())-1;
        HTuple step_val1571 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val1571, step_val1571); hv_Index += step_val1571)
        {
            //Only consider the WindowHandleKeys that are needed for the current visualization.
            hv_KeyIndex = hv_KeysForDisplay.TupleFind(HTuple(hv_WindowHandleKeysNew[hv_Index]));
            if (0 != (HTuple(int(hv_KeyIndex!=-1)).TupleAnd(int(hv_KeyIndex!=HTuple()))))
            {
                GetDictTuple(hv_WindowHandleDict, HTuple(hv_WindowHandleKeysNew[hv_Index]),
                             &hv_WindowHandles);
                {
                    HTuple end_val1576 = (hv_WindowHandles.TupleLength())-1;
                    HTuple step_val1576 = 1;
                    for (hv_WindowIndex=0; hv_WindowIndex.Continue(end_val1576, step_val1576); hv_WindowIndex += step_val1576)
                    {
                        //Display content of window handle.
                        if (0 != (int((hv_WindowHandleKeys.TupleLength())==(hv_WindowHandleKeysNew.TupleLength()))))
                        {
                            //Reset values of windows that have been changed temporarily.
                            if (0 != (int(HTuple(hv_FlushValues[hv_WindowIndex])==HTuple("true"))))
                            {
                                FlushBuffer(HTuple(hv_WindowHandles[hv_WindowIndex]));
                            }
                            SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", HTuple(hv_FlushValues[hv_WindowIndex]));
                        }
                        else
                        {
                            //Per default, 'flush' of new windows should be set to 'true'.
                            FlushBuffer(HTuple(hv_WindowHandles[hv_WindowIndex]));
                            SetWindowParam(HTuple(hv_WindowHandles[hv_WindowIndex]), "flush", "true");
                        }
                    }
                }
            }
        }
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Try to guess the maximum class id based on the given sample/result.
void HalxAI:: dev_display_dl_data_get_max_class_id (HTuple hv_DLSample, HTuple *hv_MaxClassId,
                                                    HTuple *hv_Empty)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Keys, hv_Matches, hv_Length, hv_Greatereq;
    HTuple  hv_Indices, hv_LengthAll, hv_KeyIndex, hv_Key, hv_KeyType;
    HTuple  hv_Tuple, hv_MaxTuple, hv_Exception;

    (*hv_MaxClassId) = -1;
    (*hv_Empty) = 0;
    try
    {
        GetDictParam(hv_DLSample, "keys", HTuple(), &hv_Keys);
        //Find keys that end on '_id'. (They contain ids!)
        TupleRegexpMatch(hv_Keys, "_id", &hv_Matches);
        TupleStrlen(hv_Matches, &hv_Length);
        TupleGreaterEqualElem(hv_Length, 1, &hv_Greatereq);
        TupleFind(hv_Greatereq, 1, &hv_Indices);
        if (0 != (int(hv_Indices>-1)))
        {
            //Find the maximum given class id.
            hv_LengthAll = 0;
            {
                HTuple end_val12 = (hv_Indices.TupleLength())-1;
                HTuple step_val12 = 1;
                for (hv_KeyIndex=0; hv_KeyIndex.Continue(end_val12, step_val12); hv_KeyIndex += step_val12)
                {
                    hv_Key = HTuple(hv_Keys[HTuple(hv_Indices[hv_KeyIndex])]);
                    //Skip image_id.
                    if (0 != (int(hv_Key==HTuple("image_id"))))
                    {
                        continue;
                    }
                    GetDictParam(hv_DLSample, "key_data_type", hv_Key, &hv_KeyType);
                    if (0 != (int(hv_KeyType!=HTuple("tuple"))))
                    {
                        continue;
                    }
                    GetDictTuple(hv_DLSample, hv_Key, &hv_Tuple);
                    hv_LengthAll += hv_Tuple.TupleLength();
                    if (0 != (int((hv_Tuple.TupleLength())==0)))
                    {
                        continue;
                    }
                    TupleMax(hv_Tuple, &hv_MaxTuple);
                    if (0 != (int(hv_MaxTuple>(*hv_MaxClassId))))
                    {
                        (*hv_MaxClassId) = hv_MaxTuple;
                    }
                }
            }
            if (0 != (int(hv_LengthAll==0)))
            {
                (*hv_Empty) = 1;
            }
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        //Ignore any exception.
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Visualize for a given number of samples the raw image, ground truth annotation, and inferred results.
void HalxAI:: dev_display_dl_data_tiled (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_NumSamples,
                                         HTuple hv_Split, HTuple hv_GenParam, HTuple hv_WindowHandle, HTuple *hv_WindowHandleOut)
{

    // Local iconic variables
    HObject  ho_FinalRows, ho_SampleImages, ho_SampleImage;
    HObject  ho_FirstChannel, ho_ImageScaled, ho_ImageConverted;
    HObject  ho_TiledImageRow, ho_TiledImage, ho_Domain, ho_RegionComplement;
    HObject  ho_InstanceMasks, ho_InstanceMask, ho_ResInstanceMasks;
    HObject  ho_Image, ho_ImageCleared, ho_Regions, ho_TiledResult;

    // Local control variables
    HTuple  hv_BackGroundColor, hv_SpacingRow, hv_SpacingCol;
    HTuple  hv_WindowRow, hv_WindowCol, hv_WindowWidth, hv_WindowHeight;
    HTuple  hv_IncludeImage, hv_IncludeGroundTruth, hv_IncludeResults;
    HTuple  hv_Keys, hv_Index, hv_Key, hv_Value, hv_ModelType;
    HTuple  hv_Samples, hv_AnomalyLabelExists, hv_OCRLabelExists;
    HTuple  hv_ClassificationLabelExists, hv_DetectionLabelExists;
    HTuple  hv_SegmentationLabelExists, hv_XYZExists, hv_OCRDetectionLabelExists;
    HTuple  hv_DLSamples, hv_SampleIndices, hv_DLResult, hv_ClassIdsExist;
    HTuple  hv_ClassIDs, hv_BackGroundClass, hv_RGB, hv_Scale;
    HTuple  hv_Shift, hv_KeyExists, hv_DLDatasetPreprocessParam;
    HTuple  hv_NormType, hv_KeyMinExists, hv_KeyMaxExists, hv_ImageRangeMin;
    HTuple  hv_ImageRangeMax, hv_Channels, hv_Width, hv_Height;
    HTuple  hv_Crop, hv_OffsetRow, hv_TiledWidth, hv_TiledHeight;
    HTuple  hv_NumResult, hv_PredictionsCorrect, hv_ImageConfidences;
    HTuple  hv_ResClassIndices, hv_ResClasses, hv_ImageIDs;
    HTuple  hv_ImageLabelIDs, hv_IndexResult, hv_ImageConfidence;
    HTuple  hv_ResClassIndex, hv_ResClass, hv_ImageID, hv_ImageLabelID;
    HTuple  hv_PredictionCorrect, hv_TextImageRows, hv_TextImageColumns;
    HTuple  hv_TextImageWidth, hv_TextImageHeight, hv_TopOffset;
    HTuple  hv_InstanceType, hv_Rect1KeyExists, hv_Rect2KeyExists;
    HTuple  hv_MasksExist, hv_GTLabel, hv_GTCol1, hv_GTRow1;
    HTuple  hv_GTCol2, hv_GTRow2, hv_GTCol, hv_GTRow, hv_GTLength1;
    HTuple  hv_GTLength2, hv_GTPhi, hv_LeftOffset, hv_LabelId;
    HTuple  hv_Col1, hv_Row1, hv_Col2, hv_Row2, hv_Col, hv_Row;
    HTuple  hv_Length1, hv_Length2, hv_Phi, hv_ResConfidence;
    HTuple  hv_ResCol1, hv_ResRow1, hv_ResCol2, hv_ResRow2;
    HTuple  hv_ResCol, hv_ResRow, hv_ResLength1, hv_ResLength2;
    HTuple  hv_ResPhi, hv_CurrentResult, hv_ClassId, hv_Confidence;
    HTuple  hv_ResultMaskExists, hv_ResWords, hv_GTWord, hv_ResWord;
    HTuple  hv_TiledDLSample, hv_CharIndices, hv_TiledDLResult;
    HTuple  hv_Words, hv_DisplayGenParam, hv_IgnoreDirection;
    HTuple  hv_WindowHandleDict, hv_NoInputWindow, hv_Flush;
    HTuple  hv_KeyForDisplay, hv_GTText, hv_PredictionText;
    HTuple  hv__, hv_GTWidth, hv_TextHeight, hv_PredictionWidth;
    HTuple  hv_WindowImageRatio, hv_WindowWidthMax, hv_WindowHeightMax;
    HTuple  hv_Ratio, hv_ImageWidth, hv_ImageHeight, hv_ImageWindowWidthRatio;
    HTuple  hv_ImageWindowHeightRatio, hv_CharWindowWidth, hv_CharWindowHeight;
    HTuple  hv_CharImageWidth, hv_CharImageHeight, hv_ImageRow;
    HTuple  hv_ImageColumn, hv_String, hv_StringWindowWidth;
    HTuple  hv_StringImageWidth;

    //
    //This procedure visualizes samples, their ground truth annotations, and,
    //if not deactivated, the results obtained by applying the model given by DLModelHandle.
    //
    //** Set the default values for all the generic parameters: ***
    //
    hv_BackGroundColor = "#ffffff";
    hv_SpacingRow = 0;
    hv_SpacingCol = 0;
    hv_WindowRow = 0;
    hv_WindowCol = 0;
    hv_WindowWidth = 640;
    hv_WindowHeight = 480;
    //
    //For a model of type '3d_gripping_point detection', 'detection', and 'segmentation', it is displayed:
    //- the plain input images in the first row,
    //- the image and their ground truth annotations in the second row,
    //- the image and their inference results in the third row.
    //
    //For models of type 'classification', it is displayed:
    //- the input image with a prediction box.
    //
    //For models of type 'gc_anomaly_detection' no results are displayed.
    //
    hv_IncludeImage = 1;
    hv_IncludeGroundTruth = 1;
    hv_IncludeResults = 1;
    //
    if (0 != (int((hv_GenParam.TupleLength())==1)))
    {
        GetDictParam(hv_GenParam, "keys", HTuple(), &hv_Keys);
        {
            HTuple end_val30 = (hv_Keys.TupleLength())-1;
            HTuple step_val30 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val30, step_val30); hv_Index += step_val30)
            {
                hv_Key = HTuple(hv_Keys[hv_Index]);
                GetDictTuple(hv_GenParam, hv_Key, &hv_Value);
                if (0 != (int(hv_Key==HTuple("background_color"))))
                {
                    hv_BackGroundColor = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("spacing_row"))))
                {
                    hv_SpacingRow = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("spacing_col"))))
                {
                    hv_SpacingCol = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("window_width"))))
                {
                    hv_WindowWidth = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("window_height"))))
                {
                    hv_WindowHeight = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("window_row"))))
                {
                    hv_WindowRow = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("window_col"))))
                {
                    hv_WindowCol = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("display_input"))))
                {
                    hv_IncludeImage = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("display_ground_truth"))))
                {
                    hv_IncludeGroundTruth = hv_Value;
                }
                else if (0 != (int(hv_Key==HTuple("display_result"))))
                {
                    hv_IncludeResults = hv_Value;
                }
            }
        }
    }
    //
    //If a model was handed over, get model type.
    if (0 != (int(hv_DLModelHandle!=HTuple())))
    {
        GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
        if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("classification"))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
        {
            throw HException("Invalid model type");
        }
        if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            hv_IncludeResults = 0;
        }
    }
    else
    {
        //
        //If no model was handed over, results are not displayed.
        hv_IncludeResults = 0;
        //Conclude the model type from the existing keys
        GetDictTuple(hv_DLDataset, "samples", &hv_Samples);
        GetDictParam(HTuple(hv_Samples[0]), "key_exists", "anomaly_label", &hv_AnomalyLabelExists);
        GetDictParam(HTuple(hv_Samples[0]), "key_exists", "word", &hv_OCRLabelExists);
        GetDictParam(HTuple(hv_Samples[0]), "key_exists", "image_label_id", &hv_ClassificationLabelExists);
        GetDictParam(HTuple(hv_Samples[0]), "key_exists", "bbox_label_id", &hv_DetectionLabelExists);
        GetDictParam(HTuple(hv_Samples[0]), "key_exists", "segmentation_file_name", &hv_SegmentationLabelExists);
        GetDictParam(HTuple(hv_Samples[0]), "key_exists", "xyz_file_name", &hv_XYZExists);
        if (0 != hv_AnomalyLabelExists)
        {
            hv_ModelType = "gc_anomaly_detction";
        }
        else if (0 != hv_ClassificationLabelExists)
        {
            hv_ModelType = "classification";
        }
        else if (0 != hv_OCRLabelExists)
        {
            GetDictParam(HTuple(hv_Samples[0]), "key_exists", "bbox_label_id", &hv_OCRDetectionLabelExists);
            if (0 != hv_OCRDetectionLabelExists)
            {
                throw HException("The model handle is required for Deep OCR detection.");
            }
            else
            {
                throw HException("The model handle is required for Deep OCR recognition.");
            }
        }
        else if (0 != hv_DetectionLabelExists)
        {
            hv_ModelType = "detection";
        }
        else if (0 != hv_SegmentationLabelExists)
        {
            if (0 != hv_XYZExists)
            {
                hv_ModelType = "3d_gripping_point_detection";
            }
            else
            {
                hv_ModelType = "segmentation";
            }
        }
        else
        {
            throw HException("Cannot conclude model type from DLDataset.");
        }
    }
    //
    //** Generate results for a random subset of NumSamples-many samples: ***
    //
    //Select random samples.
    GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
    find_dl_samples(hv_DLSamples, "split", hv_Split, "or", &hv_SampleIndices);
    tuple_shuffle(hv_SampleIndices, &hv_SampleIndices);
    //
    //Make sure that NumSamples is not bigger than the found number of SampleIndices
    hv_NumSamples = hv_NumSamples.TupleMin2(hv_SampleIndices.TupleLength());
    //Calculate the result for the selected samples.
    hv_SampleIndices = hv_SampleIndices.TupleSelectRange(0,hv_NumSamples-1);
    //
    if (0 != hv_IncludeResults)
    {
        read_dl_samples(hv_DLDataset, hv_SampleIndices, &hv_DLSamples);
        ApplyDlModel(hv_DLModelHandle, hv_DLSamples, HTuple(), &hv_DLResult);
        hv_DLResult = hv_DLResult.TupleSelectRange(0,hv_NumSamples-1);
        hv_DLSamples = hv_DLSamples.TupleSelectRange(0,hv_NumSamples-1);
    }
    else
    {
        read_dl_samples(hv_DLDataset, hv_SampleIndices, &hv_DLSamples);
    }
    //
    //** Generate the tiled image and the tiled result data: ***
    //
    GetDictParam(hv_DLDataset, "key_exists", "class_ids", &hv_ClassIdsExist);
    if (0 != hv_ClassIdsExist)
    {
        GetDictTuple(hv_DLDataset, "class_ids", &hv_ClassIDs);
        //For segmentation models, we need a class ID that is not present in class_ids, to
        //mark regions without region visualization.
        hv_BackGroundClass = (hv_ClassIDs.TupleMax())+1;
    }
    hv_RGB.Clear();
    hv_RGB.Append(("0x"+(hv_BackGroundColor.TupleSubstr(1,2))).TupleNumber());
    hv_RGB.Append(("0x"+(hv_BackGroundColor.TupleSubstr(3,4))).TupleNumber());
    hv_RGB.Append(("0x"+(hv_BackGroundColor.TupleSubstr(5,6))).TupleNumber());
    //
    GenEmptyObj(&ho_FinalRows);
    //
    //Generate the tiled sample image.
    //For the visualization it is better to use byte images.
    //The problem is that if you don't convert to bytes the range used to display is dynamic.
    //That means there can be strong fluctuations between several images, especially if there are "outliers" in the images.
    //By default expected range of the input image is [-127,128], but this is not the case for the normalization type 'constant_values'.
    hv_Scale = 1.0;
    hv_Shift = 127.0;
    GetDictParam(hv_DLDataset, "key_exists", "preprocess_param", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
        GetDictTuple(hv_DLDataset, "preprocess_param", &hv_DLDatasetPreprocessParam);
        GetDictParam(hv_DLDatasetPreprocessParam, "key_exists", "normalization_type",
                     &hv_KeyExists);
        if (0 != hv_KeyExists)
        {
            GetDictTuple(hv_DLDatasetPreprocessParam, "normalization_type", &hv_NormType);

            GetDictParam(hv_DLDatasetPreprocessParam, "key_exists", "image_range_min",
                         &hv_KeyMinExists);
            GetDictParam(hv_DLDatasetPreprocessParam, "key_exists", "image_range_min",
                         &hv_KeyMaxExists);
            if (0 != (hv_KeyMinExists.TupleAnd(hv_KeyMaxExists)))
            {
                GetDictTuple(hv_DLDatasetPreprocessParam, "image_range_min", &hv_ImageRangeMin);
                GetDictTuple(hv_DLDatasetPreprocessParam, "image_range_max", &hv_ImageRangeMax);
            }
            else
            {
                if (0 != (int(hv_NormType==HTuple("constant_values"))))
                {
                    hv_ImageRangeMin = -2.0;
                    hv_ImageRangeMax = 2.0;
                }
                else
                {
                    hv_ImageRangeMin = -127.0;
                    hv_ImageRangeMax = 128.0;
                }
            }
            if (0 != (int((hv_ImageRangeMax-hv_ImageRangeMin)==0)))
            {
                hv_Scale = 1.0;
            }
            else
            {
                hv_Scale = 255.0/(hv_ImageRangeMax-hv_ImageRangeMin);
            }
            hv_Shift = (-hv_Scale)*hv_ImageRangeMin;
        }
    }
    GenEmptyObj(&ho_SampleImages);
    {
        HTuple end_val173 = hv_NumSamples-1;
        HTuple step_val173 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val173, step_val173); hv_Index += step_val173)
        {
            GetDictObject(&ho_SampleImage, HTuple(hv_DLSamples[hv_Index]), "image");
            CountChannels(ho_SampleImage, &hv_Channels);
            if (0 != (int(hv_Channels!=3)))
            {
                //For any number of channels, that is not three, just use the first channel.
                AccessChannel(ho_SampleImage, &ho_FirstChannel, 1);
                Compose3(ho_FirstChannel, ho_FirstChannel, ho_FirstChannel, &ho_SampleImage
                         );
            }
            //Convert the images back to byte.
            ScaleImage(ho_SampleImage, &ho_ImageScaled, hv_Scale, hv_Shift);
            ConvertImageType(ho_ImageScaled, &ho_ImageConverted, "byte");
            //Add the image to the tuple SampleImages.
            ConcatObj(ho_SampleImages, ho_ImageConverted, &ho_SampleImages);
        }
    }
    //Tile the images in a row.
    GetImageSize(ho_SampleImages, &hv_Width, &hv_Height);
    TupleGenConst(hv_Width.TupleLength(), -1, &hv_Crop);
    TupleGenConst(hv_Width.TupleLength(), 0, &hv_OffsetRow);

    if (0 != (HTuple(HTuple(HTuple(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("segmentation")))).TupleOr(int(hv_ModelType==HTuple("ocr_detection")))).TupleOr(int(hv_ModelType==HTuple("ocr_recognition")))).TupleOr(int(hv_ModelType==HTuple("3d_gripping_point_detection")))))
    {
        TileImagesOffset(ho_SampleImages, &ho_TiledImageRow, hv_OffsetRow, (HTuple(0).TupleConcat((hv_Width+hv_SpacingCol).TupleCumul())).TupleSelectRange(0,(hv_Width.TupleLength())-1),
                         hv_Crop, hv_Crop, hv_Crop, hv_Crop, HTuple(((hv_Width+hv_SpacingCol).TupleCumul())[(hv_Width.TupleLength())-1])-hv_SpacingCol,
                hv_Height.TupleMax());
    }
    //
    //Generate the columns of images for the tiled output.
    if (0 != hv_IncludeImage)
    {
        if (0 != (int(hv_ModelType==HTuple("classification"))))
        {
            throw HException("The key 'display_input' cannot be set for model type classification.");
            return;
        }
        ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
    }
    if (0 != hv_IncludeGroundTruth)
    {
        if (0 != (int(hv_ModelType==HTuple("classification"))))
        {
            throw HException("The key 'display_ground_truth' cannot be set for model type classification.");
            return;
        }
        ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
    }
    if (0 != (HTuple(HTuple(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("segmentation")))).TupleOr(int(hv_ModelType==HTuple("ocr_detection")))).TupleOr(int(hv_ModelType==HTuple("3d_gripping_point_detection")))))
    {
        if (0 != hv_IncludeResults)
        {
            ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
        }
        GetImageSize(ho_FinalRows, &hv_TiledWidth, &hv_TiledHeight);
        TileImagesOffset(ho_FinalRows, &ho_TiledImage, (HTuple(0).TupleConcat((hv_TiledHeight+hv_SpacingRow).TupleCumul())).TupleSelectRange(0,(hv_TiledHeight.TupleLength())-1),
                         HTuple(hv_TiledHeight.TupleLength(),0), HTuple(hv_TiledHeight.TupleLength(),-1),
                         HTuple(hv_TiledHeight.TupleLength(),-1), HTuple(hv_TiledHeight.TupleLength(),-1),
                         HTuple(hv_TiledHeight.TupleLength(),-1), hv_TiledWidth.TupleMax(), HTuple(((hv_TiledHeight+hv_SpacingRow).TupleCumul())[(hv_TiledHeight.TupleLength())-1])-hv_SpacingRow);
        //Fill up with the background color.
        if (0 != (int(hv_ModelType!=HTuple("3d_gripping_point_detection"))))
        {
            GetDomain(ho_TiledImage, &ho_Domain);
            FullDomain(ho_TiledImage, &ho_TiledImage);
            Complement(ho_Domain, &ho_RegionComplement);
            OverpaintRegion(ho_TiledImage, ho_RegionComplement, hv_RGB, "fill");
        }
    }
    //
    //Generate the tiled data (classification prediction / detection bounding boxes /
    //ocr colored bar / segmentation regions ).
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        //
        //For classification results the image is shown within a colored frame.
        //
        GenEmptyObj(&ho_FinalRows);
        //
        if (0 != hv_IncludeResults)
        {
            TupleLength(hv_DLResult, &hv_NumResult);
            hv_PredictionsCorrect = HTuple();
            hv_ImageConfidences = HTuple();
            hv_ResClassIndices = HTuple();
            hv_ResClasses = HTuple();
            hv_ImageIDs = HTuple();
            hv_ImageLabelIDs = HTuple();
            //
            {
                HTuple end_val243 = hv_NumResult-1;
                HTuple step_val243 = 1;
                for (hv_IndexResult=0; hv_IndexResult.Continue(end_val243, step_val243); hv_IndexResult += step_val243)
                {
                    //
                    //Get labels and classes.
                    GetDictTuple(HTuple(hv_DLResult[hv_IndexResult]), "classification_confidences",
                                 &hv_ImageConfidence);
                    GetDictTuple(HTuple(hv_DLResult[hv_IndexResult]), "classification_class_ids",
                                 &hv_ResClassIndex);
                    GetDictTuple(HTuple(hv_DLResult[hv_IndexResult]), "classification_class_names",
                                 &hv_ResClass);
                    GetDictTuple(HTuple(hv_DLSamples[hv_IndexResult]), "image_id", &hv_ImageID);
                    GetDictTuple(HTuple(hv_DLSamples[hv_IndexResult]), "image_label_id", &hv_ImageLabelID);
                    //
                    //Check whether the actual sample prediction is false or correct.
                    hv_PredictionCorrect = int(HTuple(hv_ResClassIndex[0])==hv_ImageLabelID);
                    hv_PredictionsCorrect = hv_PredictionsCorrect.TupleConcat(hv_PredictionCorrect);
                    hv_ImageConfidences = hv_ImageConfidences.TupleConcat(HTuple(hv_ImageConfidence[0]));
                    hv_ResClassIndices = hv_ResClassIndices.TupleConcat(HTuple(hv_ResClassIndex[0]));
                    hv_ResClasses = hv_ResClasses.TupleConcat(HTuple(hv_ResClass[0]));
                    hv_ImageIDs = hv_ImageIDs.TupleConcat(hv_ImageID);
                    hv_ImageLabelIDs = hv_ImageLabelIDs.TupleConcat(hv_ImageLabelID);
                }
            }
            //
            //Tile the sample images.
            gen_tiled_classification_image_result(&ho_TiledImageRow, hv_DLSamples, hv_SpacingCol,
                                                  hv_PredictionsCorrect, hv_ResClasses, &hv_TextImageRows, &hv_TextImageColumns,
                                                  &hv_TextImageWidth, &hv_TextImageHeight);
            ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
        }
        GetImageSize(ho_FinalRows, &hv_TiledWidth, &hv_TiledHeight);
        ho_TiledImage = ho_TiledImageRow;
        //
    }
    else if (0 != (HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection")))))
    {
        //
        //For detection results the detected boxes must be moved
        //to the positions of the respective image.
        hv_TopOffset = 0;
        if (0 != hv_IncludeImage)
        {
            hv_TopOffset = (hv_TopOffset+hv_SpacingRow)+HTuple(hv_TiledHeight[0]);
        }
        //Check the detection type.
        if (0 != (HTuple(int((hv_DLModelHandle.TupleLength())>0)).TupleAnd(int(hv_ModelType==HTuple("detection")))))
        {
            GetDlModelParam(hv_DLModelHandle, "instance_type", &hv_InstanceType);
        }
        else
        {
            GetDictParam(HTuple(hv_DLSamples[0]), "key_exists", "bbox_row1", &hv_Rect1KeyExists);
            if (0 != hv_Rect1KeyExists)
            {
                hv_InstanceType = "rectangle1";
            }
            else
            {
                GetDictParam(HTuple(hv_DLSamples[0]), "key_exists", "bbox_phi", &hv_Rect2KeyExists);
                if (0 != hv_Rect2KeyExists)
                {
                    hv_InstanceType = "rectangle2";
                }
                else
                {
                    throw HException("Not suitable sample keys!");
                }
            }
        }
        //Check if masks exist.
        GetDictParam(HTuple(hv_DLSamples[0]), "key_exists", "mask", &hv_MasksExist);
        if (0 != hv_MasksExist)
        {
            GenEmptyObj(&ho_InstanceMasks);
        }
        //Move the ground truth labels.
        hv_GTLabel = HTuple();
        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
        {
            hv_GTCol1 = HTuple();
            hv_GTRow1 = HTuple();
            hv_GTCol2 = HTuple();
            hv_GTRow2 = HTuple();
        }
        else
        {
            hv_GTCol = HTuple();
            hv_GTRow = HTuple();
            hv_GTLength1 = HTuple();
            hv_GTLength2 = HTuple();
            hv_GTPhi = HTuple();
        }
        if (0 != hv_IncludeGroundTruth)
        {
            hv_LeftOffset = 0;
            {
                HTuple end_val314 = hv_NumSamples-1;
                HTuple step_val314 = 1;
                for (hv_Index=0; hv_Index.Continue(end_val314, step_val314); hv_Index += step_val314)
                {
                    GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_label_id", &hv_LabelId);
                    hv_GTLabel = hv_GTLabel.TupleConcat(hv_LabelId);
                    if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
                    {
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_col1", &hv_Col1);
                        hv_GTCol1 = hv_GTCol1.TupleConcat(hv_Col1+hv_LeftOffset);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_row1", &hv_Row1);
                        hv_GTRow1 = hv_GTRow1.TupleConcat(hv_Row1+hv_TopOffset);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_col2", &hv_Col2);
                        hv_GTCol2 = hv_GTCol2.TupleConcat(hv_Col2+hv_LeftOffset);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_row2", &hv_Row2);
                        hv_GTRow2 = hv_GTRow2.TupleConcat(hv_Row2+hv_TopOffset);
                    }
                    else
                    {
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_col", &hv_Col);
                        hv_GTCol = hv_GTCol.TupleConcat(hv_Col+hv_LeftOffset);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_row", &hv_Row);
                        hv_GTRow = hv_GTRow.TupleConcat(hv_Row+hv_TopOffset);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_length1", &hv_Length1);
                        hv_GTLength1 = hv_GTLength1.TupleConcat(hv_Length1);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_length2", &hv_Length2);
                        hv_GTLength2 = hv_GTLength2.TupleConcat(hv_Length2);
                        GetDictTuple(HTuple(hv_DLSamples[hv_Index]), "bbox_phi", &hv_Phi);
                        hv_GTPhi = hv_GTPhi.TupleConcat(hv_Phi);
                    }
                    if (0 != hv_MasksExist)
                    {
                        GetDictObject(&ho_InstanceMask, HTuple(hv_DLSamples[hv_Index]), "mask");
                        MoveRegion(ho_InstanceMask, &ho_InstanceMask, hv_TopOffset, hv_LeftOffset);
                        ConcatObj(ho_InstanceMasks, ho_InstanceMask, &ho_InstanceMasks);
                    }
                    hv_LeftOffset = (hv_LeftOffset+hv_SpacingCol)+HTuple(hv_Width[hv_Index]);
                }
            }
            hv_TopOffset = (hv_TopOffset+hv_SpacingRow)+HTuple(hv_TiledHeight[0]);
        }
        hv_ResClass = HTuple();
        hv_ResConfidence = HTuple();
        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
        {
            hv_ResCol1 = HTuple();
            hv_ResRow1 = HTuple();
            hv_ResCol2 = HTuple();
            hv_ResRow2 = HTuple();
        }
        else
        {
            hv_ResCol = HTuple();
            hv_ResRow = HTuple();
            hv_ResLength1 = HTuple();
            hv_ResLength2 = HTuple();
            hv_ResPhi = HTuple();
        }
        if (0 != hv_MasksExist)
        {
            GenEmptyObj(&ho_ResInstanceMasks);
        }
        //Move the result classes.
        if (0 != hv_IncludeResults)
        {
            hv_LeftOffset = 0;
            {
                HTuple end_val367 = hv_NumSamples-1;
                HTuple step_val367 = 1;
                for (hv_Index=0; hv_Index.Continue(end_val367, step_val367); hv_Index += step_val367)
                {
                    if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
                    {
                        hv_CurrentResult = HTuple(hv_DLResult[hv_Index]);
                        hv_CurrentResult = hv_CurrentResult.TupleGetDictTuple("words");
                        GetDictTuple(hv_CurrentResult, "col", &hv_Col);
                        hv_ResCol = hv_ResCol.TupleConcat(hv_Col+hv_LeftOffset);
                        GetDictTuple(hv_CurrentResult, "row", &hv_Row);
                        hv_ResRow = hv_ResRow.TupleConcat(hv_Row+hv_TopOffset);
                        GetDictTuple(hv_CurrentResult, "length1", &hv_Length1);
                        hv_ResLength1 = hv_ResLength1.TupleConcat(hv_Length1);
                        GetDictTuple(hv_CurrentResult, "length2", &hv_Length2);
                        hv_ResLength2 = hv_ResLength2.TupleConcat(hv_Length2);
                        GetDictTuple(hv_CurrentResult, "phi", &hv_Phi);
                        hv_ResPhi = hv_ResPhi.TupleConcat(hv_Phi);
                    }
                    else
                    {
                        GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_class_id", &hv_ClassId);
                        hv_ResClass = hv_ResClass.TupleConcat(hv_ClassId);
                        GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_confidence", &hv_Confidence);
                        hv_ResConfidence = hv_ResConfidence.TupleConcat(hv_Confidence);
                        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
                        {
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_col1", &hv_Col1);
                            hv_ResCol1 = hv_ResCol1.TupleConcat(hv_Col1+hv_LeftOffset);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_row1", &hv_Row1);
                            hv_ResRow1 = hv_ResRow1.TupleConcat(hv_Row1+hv_TopOffset);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_col2", &hv_Col2);
                            hv_ResCol2 = hv_ResCol2.TupleConcat(hv_Col2+hv_LeftOffset);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_row2", &hv_Row2);
                            hv_ResRow2 = hv_ResRow2.TupleConcat(hv_Row2+hv_TopOffset);
                        }
                        else
                        {
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_col", &hv_Col);
                            hv_ResCol = hv_ResCol.TupleConcat(hv_Col+hv_LeftOffset);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_row", &hv_Row);
                            hv_ResRow = hv_ResRow.TupleConcat(hv_Row+hv_TopOffset);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_length1", &hv_Length1);
                            hv_ResLength1 = hv_ResLength1.TupleConcat(hv_Length1);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_length2", &hv_Length2);
                            hv_ResLength2 = hv_ResLength2.TupleConcat(hv_Length2);
                            GetDictTuple(HTuple(hv_DLResult[hv_Index]), "bbox_phi", &hv_Phi);
                            hv_ResPhi = hv_ResPhi.TupleConcat(hv_Phi);
                        }
                    }
                    if (0 != hv_MasksExist)
                    {
                        GetDictParam(HTuple(hv_DLResult[hv_Index]), "key_exists", "mask", &hv_ResultMaskExists);
                        if (0 != hv_ResultMaskExists)
                        {
                            GetDictObject(&ho_InstanceMask, HTuple(hv_DLResult[hv_Index]), "mask");
                            MoveRegion(ho_InstanceMask, &ho_InstanceMask, hv_TopOffset, hv_LeftOffset);
                            ConcatObj(ho_ResInstanceMasks, ho_InstanceMask, &ho_ResInstanceMasks);
                        }
                    }
                    hv_LeftOffset = (hv_LeftOffset+hv_SpacingCol)+HTuple(hv_Width[hv_Index]);
                }
            }
        }
        //
    }
    else if (0 != (HTuple(int(hv_ModelType==HTuple("segmentation"))).TupleOr(int(hv_ModelType==HTuple("3d_gripping_point_detection")))))
    {
        //
        //The tiled segmentation result image is constructed in the same way as the tiled sample image.
        GenEmptyObj(&ho_FinalRows);
        if (0 != hv_IncludeImage)
        {
            GenImageConst(&ho_Image, "real", HTuple(hv_TiledWidth[0]), HTuple(hv_TiledHeight[0]));
            //For the top (image) row, set the (virtual) background class as segmentation result.
            GenImageProto(ho_Image, &ho_ImageCleared, hv_BackGroundClass);
            ConcatObj(ho_FinalRows, ho_ImageCleared, &ho_FinalRows);
        }
        //
        if (0 != hv_IncludeGroundTruth)
        {
            gen_tiled_segmentation_image(&ho_TiledImageRow, hv_DLSamples, hv_SpacingCol,
                                         hv_Width, hv_Height);
            if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
            {
                //Map the ground truth class IDs to [1, 0].
                Threshold(ho_TiledImageRow, &ho_Regions, hv_ClassIDs, hv_ClassIDs);
                OverpaintRegion(ho_TiledImageRow, ho_Regions, (HTuple(1).Append(0)), "fill");
            }
            ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
        }
        //
        if (0 != hv_IncludeResults)
        {
            gen_tiled_segmentation_image(&ho_TiledImageRow, hv_DLResult, hv_SpacingCol,
                                         hv_Width, hv_Height);
            ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
        }
        GetImageSize(ho_FinalRows, &hv_TiledWidth, &hv_TiledHeight);
        TileImagesOffset(ho_FinalRows, &ho_TiledResult, (HTuple(0).TupleConcat((hv_TiledHeight+hv_SpacingRow).TupleCumul())).TupleSelectRange(0,(hv_TiledHeight.TupleLength())-1),
                         HTuple(hv_TiledHeight.TupleLength(),0), HTuple(hv_TiledHeight.TupleLength(),-1),
                         HTuple(hv_TiledHeight.TupleLength(),-1), HTuple(hv_TiledHeight.TupleLength(),-1),
                         HTuple(hv_TiledHeight.TupleLength(),-1), hv_TiledWidth.TupleMax(), HTuple(((hv_TiledHeight+hv_SpacingRow).TupleCumul())[(hv_TiledHeight.TupleLength())-1])-hv_SpacingRow);
        //Fill up with the background color.
        if (0 != (int(hv_ModelType!=HTuple("3d_gripping_point_detection"))))
        {
            GetDomain(ho_TiledResult, &ho_Domain);
            FullDomain(ho_TiledResult, &ho_TiledResult);
            Complement(ho_Domain, &ho_RegionComplement);
            OverpaintRegion(ho_TiledResult, ho_RegionComplement, hv_BackGroundClass, "fill");
        }
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        //
        //For ocr_recognition the results are shown within a colored bar below the images.
        GenEmptyObj(&ho_FinalRows);
        //
        if (0 != hv_IncludeResults)
        {
            TupleLength(hv_DLResult, &hv_NumResult);
            hv_PredictionsCorrect = HTuple();
            hv_ResWords = HTuple();
            //
            {
                HTuple end_val464 = hv_NumResult-1;
                HTuple step_val464 = 1;
                for (hv_IndexResult=0; hv_IndexResult.Continue(end_val464, step_val464); hv_IndexResult += step_val464)
                {
                    //
                    //Get ground truth word and resulting word.
                    GetDictTuple(HTuple(hv_DLSamples[hv_IndexResult]), "word", &hv_GTWord);
                    GetDictTuple(HTuple(hv_DLResult[hv_IndexResult]), "word", &hv_ResWord);
                    //
                    //Check whether the sample prediction is correct or not.
                    hv_PredictionCorrect = int(hv_ResWord==hv_GTWord);
                    hv_ResWords = hv_ResWords.TupleConcat(hv_ResWord);
                    hv_PredictionsCorrect = hv_PredictionsCorrect.TupleConcat(hv_PredictionCorrect);
                }
            }
            //
            //Tile the sample images.
            gen_tiled_ocr_recognition_image_result(&ho_TiledImageRow, hv_DLSamples, hv_PredictionsCorrect,
                                                   &hv_TextImageRows, &hv_TextImageColumns, &hv_TextImageWidth, &hv_TextImageHeight);
            ConcatObj(ho_FinalRows, ho_TiledImageRow, &ho_FinalRows);
        }
        GetImageSize(ho_FinalRows, &hv_TiledWidth, &hv_TiledHeight);
        ho_TiledImage = ho_TiledImageRow;
    }
    //
    //** Generate a TiledDLSample and a TiledDLResult to display them with dev_display_dl_data: ***
    //
    //Generate a tiled DLSample.
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        gen_dl_samples_from_images(ho_TiledImage, &hv_TiledDLSample);
        SetDictTuple(hv_TiledDLSample, "image_id", hv_ImageID);
        SetDictTuple(hv_TiledDLSample, "image_label_id", hv_ImageLabelID);
    }
    else if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        gen_dl_samples_from_images(ho_TiledImage, &hv_TiledDLSample);
        SetDictTuple(hv_TiledDLSample, "bbox_label_id", hv_GTLabel);
        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
        {
            SetDictTuple(hv_TiledDLSample, "bbox_col1", hv_GTCol1);
            SetDictTuple(hv_TiledDLSample, "bbox_row1", hv_GTRow1);
            SetDictTuple(hv_TiledDLSample, "bbox_col2", hv_GTCol2);
            SetDictTuple(hv_TiledDLSample, "bbox_row2", hv_GTRow2);
        }
        else
        {
            SetDictTuple(hv_TiledDLSample, "bbox_col", hv_GTCol);
            SetDictTuple(hv_TiledDLSample, "bbox_row", hv_GTRow);
            SetDictTuple(hv_TiledDLSample, "bbox_length1", hv_GTLength1);
            SetDictTuple(hv_TiledDLSample, "bbox_length2", hv_GTLength2);
            SetDictTuple(hv_TiledDLSample, "bbox_phi", hv_GTPhi);
        }
        if (0 != hv_MasksExist)
        {
            SetDictObject(ho_InstanceMasks, hv_TiledDLSample, "mask");
        }
    }
    else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
    {
        gen_dl_samples_from_images(ho_TiledImage, &hv_TiledDLSample);
    }
    else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
        gen_dl_samples_from_images(ho_TiledImage, &hv_TiledDLSample);
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        gen_dl_samples_from_images(ho_TiledImage, &hv_TiledDLSample);
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
    {
        gen_dl_samples_from_images(ho_TiledImage, &hv_TiledDLSample);
        TupleFind(hv_GTLabel, 1, &hv_CharIndices);
        TupleRemove(hv_GTLabel, hv_CharIndices, &hv_GTLabel);
        SetDictTuple(hv_TiledDLSample, "bbox_label_id", hv_GTLabel);
        TupleRemove(hv_GTCol, hv_CharIndices, &hv_GTCol);
        SetDictTuple(hv_TiledDLSample, "bbox_col", hv_GTCol);
        TupleRemove(hv_GTRow, hv_CharIndices, &hv_GTRow);
        SetDictTuple(hv_TiledDLSample, "bbox_row", hv_GTRow);
        TupleRemove(hv_GTLength1, hv_CharIndices, &hv_GTLength1);
        SetDictTuple(hv_TiledDLSample, "bbox_length1", hv_GTLength1);
        TupleRemove(hv_GTLength2, hv_CharIndices, &hv_GTLength2);
        SetDictTuple(hv_TiledDLSample, "bbox_length2", hv_GTLength2);
        TupleRemove(hv_GTPhi, hv_CharIndices, &hv_GTPhi);
        SetDictTuple(hv_TiledDLSample, "bbox_phi", hv_GTPhi);
    }
    //
    //Generate a tiled DLResult.
    CreateDict(&hv_TiledDLResult);
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        SetDictTuple(hv_TiledDLResult, "image_class_id", HTuple(hv_ResClassIndices[0]));
        SetDictTuple(hv_TiledDLResult, "image_confidence", hv_ImageConfidences);
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        SetDictTuple(hv_TiledDLResult, "word", hv_ResWords);
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
    {
        CreateDict(&hv_Words);
        SetDictTuple(hv_TiledDLResult, "words", hv_Words);
        SetDictTuple(hv_Words, "col", hv_ResCol);
        SetDictTuple(hv_Words, "row", hv_ResRow);
        SetDictTuple(hv_Words, "length1", hv_ResLength1);
        SetDictTuple(hv_Words, "length2", hv_ResLength2);
        SetDictTuple(hv_Words, "phi", hv_ResPhi);
    }
    else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
    {
        SetDictObject(ho_TiledResult, hv_TiledDLResult, "segmentation_image");
    }
    else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
        SetDictObject(ho_TiledResult, hv_TiledDLResult, "gripping_map");
    }
    else if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        SetDictTuple(hv_TiledDLResult, "bbox_class_id", hv_ResClass);
        SetDictTuple(hv_TiledDLResult, "bbox_confidence", hv_ResConfidence);
        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
        {
            SetDictTuple(hv_TiledDLResult, "bbox_col1", hv_ResCol1);
            SetDictTuple(hv_TiledDLResult, "bbox_row1", hv_ResRow1);
            SetDictTuple(hv_TiledDLResult, "bbox_col2", hv_ResCol2);
            SetDictTuple(hv_TiledDLResult, "bbox_row2", hv_ResRow2);
        }
        else
        {
            SetDictTuple(hv_TiledDLResult, "bbox_col", hv_ResCol);
            SetDictTuple(hv_TiledDLResult, "bbox_row", hv_ResRow);
            SetDictTuple(hv_TiledDLResult, "bbox_length1", hv_ResLength1);
            SetDictTuple(hv_TiledDLResult, "bbox_length2", hv_ResLength2);
            SetDictTuple(hv_TiledDLResult, "bbox_phi", hv_ResPhi);
        }
        if (0 != hv_MasksExist)
        {
            SetDictObject(ho_ResInstanceMasks, hv_TiledDLResult, "mask");
        }
    }
    //
    //Set display parameters.
    CreateDict(&hv_DisplayGenParam);
    //Pinch off all text display from dev_display_dl_data for a visualization without clutter.
    SetDictTuple(hv_DisplayGenParam, "display_bottom_desc", 0);
    SetDictTuple(hv_DisplayGenParam, "display_legend", 0);
    SetDictTuple(hv_DisplayGenParam, "display_labels", 0);
    if (0 != (HTuple(int(hv_ModelType==HTuple("detection"))).TupleAnd(int((hv_DLModelHandle.TupleLength())>0))))
    {
        //Don't display directions if 'ignore_direction' is set to 'true'.
        GetDlModelParam(hv_DLModelHandle, "ignore_direction", &hv_IgnoreDirection);
        if (0 != (int(hv_IgnoreDirection==HTuple("true"))))
        {
            SetDictTuple(hv_DisplayGenParam, "display_direction", 0);
        }
    }
    //
    //Initialize the window for displaying the tiled comparison of input and result.
    CreateDict(&hv_WindowHandleDict);
    hv_NoInputWindow = int((hv_WindowHandle.TupleLength())==0);
    if (0 != hv_NoInputWindow)
    {
        GetImageSize(ho_TiledImage, &hv_Width, &hv_Height);
        dev_open_window_fit_size(hv_WindowRow, hv_WindowCol, hv_Width, hv_Height, hv_WindowWidth,
                                 hv_WindowHeight, &hv_WindowHandle);
    }
    GetWindowParam(hv_WindowHandle, "flush", &hv_Flush);
    if (0 != (int(hv_Flush==HTuple("true"))))
    {
        SetWindowParam(hv_WindowHandle, "flush", "false");
    }
    SetWindowParam(hv_WindowHandle, "background_color", hv_BackGroundColor);
    HDevWindowStack::SetActive(hv_WindowHandle);
    if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
    (*hv_WindowHandleOut) = hv_WindowHandle;
    //
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        hv_KeyForDisplay = "image";
    }
    else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
    {
        hv_KeyForDisplay = "segmentation_image_result";
    }
    else if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        hv_KeyForDisplay = "bbox_both";
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        hv_KeyForDisplay = "image";
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
    {
        hv_KeyForDisplay = "ocr_detection_both";
    }
    else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
        hv_KeyForDisplay = "gripping_map";
    }
    //
    SetDictTuple(hv_WindowHandleDict, hv_KeyForDisplay, hv_WindowHandle);
    //
    //Display the tiled image.
    dev_display_dl_data(hv_TiledDLSample, hv_TiledDLResult, hv_DLDataset, hv_KeyForDisplay,
                        hv_DisplayGenParam, hv_WindowHandleDict);
    //
    //For classification and ocr_recognition, display additional text.
    if (0 != (HTuple(int(hv_ModelType==HTuple("classification"))).TupleAnd(hv_IncludeResults)))
    {
        GetImageSize(ho_TiledImage, &hv_Width, &hv_Height);
        {
            HTuple end_val623 = hv_NumSamples-1;
            HTuple step_val623 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val623, step_val623); hv_Index += step_val623)
            {
                hv_GTText = "Ground truth: "+HTuple(hv_ImageLabelIDs[hv_Index]);
                hv_PredictionText = "Prediction: "+HTuple(hv_ResClassIndices[hv_Index]);
                GetStringExtents(hv_WindowHandle, hv_GTText, &hv__, &hv__, &hv_GTWidth, &hv_TextHeight);
                GetStringExtents(hv_WindowHandle, hv_PredictionText, &hv__, &hv__, &hv_PredictionWidth,
                                 &hv__);
                //Get ratio between image and window coordinate system.
                GetWindowExtents(hv_WindowHandle, &hv__, &hv__, &hv_WindowWidth, &hv_WindowHeight);
                //Adapt widths of texts to plot it correctly in window coordinate system.
                if (0 != (int((hv_Height/(hv_Width.TupleReal()))>(hv_WindowHeight/(hv_WindowWidth.TupleReal())))))
                {
                    hv_WindowImageRatio = 1.0/(hv_WindowHeight/(HTuple(hv_Height[0]).TupleReal()));
                }
                else
                {
                    hv_WindowImageRatio = 1.0/(hv_WindowWidth/(HTuple(hv_Width[0]).TupleReal()));
                }
                if (0 != (int(hv_TextImageWidth<(((hv_GTWidth+hv_PredictionWidth)*hv_WindowImageRatio)+30))))
                {
                    //Make shorter text.
                    hv_GTText = "GT: "+HTuple(hv_ImageLabelIDs[hv_Index]);
                    hv_PredictionText = "Pred.: "+HTuple(hv_ResClassIndices[hv_Index]);
                    GetStringExtents(hv_WindowHandle, hv_GTText, &hv__, &hv__, &hv_GTWidth, &hv_TextHeight);
                    GetStringExtents(hv_WindowHandle, hv_PredictionText, &hv__, &hv__, &hv_PredictionWidth,
                                     &hv__);
                }
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_GTText, "image", (HTuple(hv_TextImageRows[hv_Index])+(hv_TextImageHeight/2))-hv_TextHeight,
                             HTuple(hv_TextImageColumns[hv_Index])+10, "white", "box", "false");
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_PredictionText, "image", (HTuple(hv_TextImageRows[hv_Index])+(hv_TextImageHeight/2))-hv_TextHeight,
                             ((HTuple(hv_TextImageColumns[hv_Index])+hv_TextImageWidth)-(hv_PredictionWidth*hv_WindowImageRatio))-10,
                             "white", "box", "false");
            }
        }
    }
    else if (0 != (HTuple(int(hv_ModelType==HTuple("ocr_recognition"))).TupleAnd(hv_IncludeResults)))
    {
        //Get the actual window dimensions.
        hv_WindowWidthMax = hv_WindowWidth;
        hv_WindowHeightMax = hv_WindowHeight;
        GetWindowExtents(hv_WindowHandle, &hv__, &hv__, &hv_WindowWidth, &hv_WindowHeight);
        //If the window was created here increase its size fitting the specified limits and keeping its aspect ratio.
        if (0 != (HTuple(hv_NoInputWindow.TupleAnd(int(hv_WindowWidth<hv_WindowWidthMax))).TupleAnd(int(hv_WindowHeight<hv_WindowHeightMax))))
        {
            hv_Ratio = ((hv_WindowWidthMax.TupleReal())/hv_WindowWidth).TupleMin2((hv_WindowHeightMax.TupleReal())/hv_WindowHeight);
            hv_WindowWidth = (hv_Ratio*hv_WindowWidth).TupleRound();
            hv_WindowHeight = (hv_Ratio*hv_WindowHeight).TupleRound();
            if (HDevWindowStack::IsOpen())
                SetWindowExtents(HDevWindowStack::GetActive(),-1, -1, hv_WindowWidth, hv_WindowHeight);
        }
        //Calculate window/image size ratios.
        GetImageSize(ho_TiledImage, &hv_ImageWidth, &hv_ImageHeight);
        hv_ImageWindowWidthRatio = (hv_ImageWidth.TupleReal())/hv_WindowWidth;
        hv_ImageWindowHeightRatio = (hv_ImageHeight.TupleReal())/hv_WindowHeight;
        //Calculate character image size.
        GetStringExtents(hv_WindowHandle, "H", &hv__, &hv__, &hv_CharWindowWidth, &hv_CharWindowHeight);
        hv_CharImageWidth = hv_CharWindowWidth*hv_ImageWindowWidthRatio;
        hv_CharImageHeight = hv_CharWindowHeight*hv_ImageWindowHeightRatio;
        //Display resulting words.
        {
            HTuple end_val667 = hv_NumSamples-1;
            HTuple step_val667 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val667, step_val667); hv_Index += step_val667)
            {
                hv_ImageRow = ((HTuple(hv_TextImageRows[hv_Index])+(0.5*hv_TextImageHeight))-hv_CharImageHeight)+1;
                hv_ImageColumn = HTuple(hv_TextImageColumns[hv_Index])+(0.5*hv_CharImageWidth);
                hv_String = ("\""+HTuple(hv_ResWords[hv_Index]))+"\"";
                //Reduce string length if it is too long.
                GetStringExtents(hv_WindowHandle, hv_String, &hv__, &hv__, &hv_StringWindowWidth,
                                 &hv__);
                hv_StringImageWidth = hv_StringWindowWidth*hv_ImageWindowWidthRatio;
                while (0 != (HTuple(int((hv_String.TupleStrlen())>5)).TupleAnd(int(hv_StringImageWidth>(0.8*hv_TextImageWidth)))))
                {
                    hv_String = (hv_String.TupleStrFirstN((hv_String.TupleStrlen())-5))+"...";
                    GetStringExtents(hv_WindowHandle, hv_String, &hv__, &hv__, &hv_StringWindowWidth,
                                     &hv__);
                    hv_StringImageWidth = hv_StringWindowWidth*hv_ImageWindowWidthRatio;
                }
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_String, "image", hv_ImageRow, hv_ImageColumn,
                             "white", "box", "false");
            }
        }
    }
    //
    if (0 != (int(hv_Flush==HTuple("true"))))
    {
        //Only flush the window, if 'flush' is 'true'. Otherwise the caller
        //(who set flush to 'false' on purpose) is responsible for flushing.
        FlushBuffer(hv_WindowHandle);
    }
    SetWindowParam(hv_WindowHandle, "flush", hv_Flush);
    //
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Display the ground truth anomaly regions of the given DLSample.
void HalxAI:: dev_display_ground_truth_anomaly_regions (HTuple hv_SampleKeys, HTuple hv_DLSample,
                                                        HTuple hv_CurrentWindowHandle, HTuple hv_LineWidth, HTuple hv_AnomalyRegionLabelColor,
                                                        HTuple hv_AnomalyColorTransparency, HTuple *hv_AnomalyRegionExists)
{

    // Local iconic variables
    HObject  ho_AnomalyImage, ho_AnomalyRegion;

    // Local control variables
    HTuple  hv_Red, hv_Green, hv_Blue, hv_Alpha, hv_InitialColor;
    HTuple  hv_IndexColor, hv_Color_RGBA, hv_Area;

    //
    //This procedure visualizes the ground truth anomalies
    //if there is an anomaly_ground_truth in DLSample.
    //
    //Get current set color.
    GetRgba(hv_CurrentWindowHandle, &hv_Red, &hv_Green, &hv_Blue, &hv_Alpha);
    hv_InitialColor = HTuple();
    {
        HTuple end_val7 = (hv_Red.TupleLength())-1;
        HTuple step_val7 = 1;
        for (hv_IndexColor=0; hv_IndexColor.Continue(end_val7, step_val7); hv_IndexColor += step_val7)
        {
            hv_Color_RGBA = ((("#"+(HTuple(hv_Red[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Green[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Blue[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Alpha[hv_IndexColor]).TupleString("2x"));
            TupleRegexpReplace(hv_Color_RGBA, (HTuple(" ").Append("replace_all")), "0", &hv_Color_RGBA);
            hv_InitialColor = hv_InitialColor.TupleConcat(hv_Color_RGBA);
        }
    }
    //
    if (0 != (int((hv_SampleKeys.TupleFind("anomaly_ground_truth"))!=-1)))
    {
        GetDictObject(&ho_AnomalyImage, hv_DLSample, "anomaly_ground_truth");
        Threshold(ho_AnomalyImage, &ho_AnomalyRegion, 1, 255);
        //Get non-empty regions.
        RegionFeatures(ho_AnomalyRegion, "area", &hv_Area);
        if (0 != (int(hv_Area>0)))
        {
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),hv_AnomalyRegionLabelColor+hv_AnomalyColorTransparency);
            //Display the anomaly region.
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),"fill");
            if (HDevWindowStack::IsOpen())
                DispObj(ho_AnomalyRegion, HDevWindowStack::GetActive());
        }
        (*hv_AnomalyRegionExists) = "true";
    }
    else
    {
        (*hv_AnomalyRegionExists) = "false";
    }
    //
    //Reset colors.
    if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),hv_InitialColor);
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Display the ground truth bounding boxes of DLSample.
void HalxAI:: dev_display_ground_truth_detection (HTuple hv_DLSample, HTuple hv_SampleKeys,
                                                  HTuple hv_LineWidthBbox, HTuple hv_ClassIDs, HTuple hv_BboxColors, HTuple hv_BboxLabelColor,
                                                  HTuple hv_WindowImageRatio, HTuple hv_TextColor, HTuple hv_ShowLabels, HTuple hv_ShowDirection,
                                                  HTuple hv_WindowHandle, HTuple *hv_BboxIDs)
{

    // Local iconic variables
    HObject  ho_InstanceMask, ho_BboxRectangle, ho_OrientationArrows;
    HObject  ho_RectangleSelected, ho_MaskSelected, ho_ArrowSelected;

    // Local control variables
    HTuple  hv_InstanceType, hv_MaskExists, hv_BboxRow1;
    HTuple  hv_BboxCol1, hv_BboxRow2, hv_BboxCol2, hv_BboxRow;
    HTuple  hv_BboxCol, hv_BboxLength1, hv_BboxLength2, hv_BboxPhi;
    HTuple  hv_BboxLabels, hv_Text, hv_Ascent, hv_Descent, hv__;
    HTuple  hv_TextOffset, hv_LabelRow, hv_LabelCol, hv_ArrowSizeFactorLength;
    HTuple  hv_ArrowSizeFactorHead, hv_MaxLengthArrow, hv_HalfLengthArrow;
    HTuple  hv_ArrowBaseRow, hv_ArrowBaseCol, hv_ArrowHeadRow;
    HTuple  hv_ArrowHeadCol, hv_ArrowHeadSize, hv_ContourStyle;
    HTuple  hv_Style, hv_IndexBbox, hv_ClassID, hv_TextColorClasses;

    //
    //This procedure displays the ground truth bounding boxes and masks (if present) of a DLSample.
    //
    hv_InstanceType = "";
    hv_MaskExists = 0;
    if (0 != (int((hv_SampleKeys.TupleFind("bbox_row1"))!=-1)))
    {
        GetDictTuple(hv_DLSample, "bbox_row1", &hv_BboxRow1);
        GetDictTuple(hv_DLSample, "bbox_col1", &hv_BboxCol1);
        GetDictTuple(hv_DLSample, "bbox_row2", &hv_BboxRow2);
        GetDictTuple(hv_DLSample, "bbox_col2", &hv_BboxCol2);
        hv_InstanceType = "rectangle1";
    }
    else if (0 != (int((hv_SampleKeys.TupleFind("bbox_phi"))!=-1)))
    {
        GetDictTuple(hv_DLSample, "bbox_row", &hv_BboxRow);
        GetDictTuple(hv_DLSample, "bbox_col", &hv_BboxCol);
        GetDictTuple(hv_DLSample, "bbox_length1", &hv_BboxLength1);
        GetDictTuple(hv_DLSample, "bbox_length2", &hv_BboxLength2);
        GetDictTuple(hv_DLSample, "bbox_phi", &hv_BboxPhi);
        hv_InstanceType = "rectangle2";
    }
    else
    {
        throw HException("Ground truth bounding box data could not be found in DLSample.");
    }
    if (0 != (int((hv_SampleKeys.TupleFind("mask"))!=-1)))
    {
        GetDictObject(&ho_InstanceMask, hv_DLSample, "mask");
        hv_MaskExists = 1;
    }
    if (0 != (HTuple(HTuple(int(hv_InstanceType!=HTuple("rectangle1"))).TupleAnd(int(hv_InstanceType!=HTuple("rectangle2")))).TupleAnd(hv_MaskExists.TupleNot())))
    {
        throw HException("Ground truth bounding box or mask data could not be found in DLSample.");
    }
    GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BboxLabels);
    if (0 != (int((hv_BboxLabels.TupleLength())>0)))
    {
        //
        //Get text and text size for correct positioning of label IDs.
        if (0 != hv_ShowLabels)
        {
            hv_Text = hv_BboxLabels;
            GetStringExtents(hv_WindowHandle, hv_Text, &hv_Ascent, &hv_Descent, &hv__,
                             &hv__);
            hv_TextOffset = (hv_Ascent+hv_Descent)/hv_WindowImageRatio;
        }
        //
        //Generate bounding box XLDs.
        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
        {
            TupleGenConst(hv_BboxRow1.TupleLength(), 0.0, &hv_BboxPhi);
            GenRectangle2ContourXld(&ho_BboxRectangle, 0.5*(hv_BboxRow1+hv_BboxRow2), 0.5*(hv_BboxCol1+hv_BboxCol2),
                                    hv_BboxPhi, 0.5*(hv_BboxCol2-hv_BboxCol1), 0.5*(hv_BboxRow2-hv_BboxRow1));
            if (0 != hv_ShowLabels)
            {
                hv_LabelRow = hv_BboxRow1;
                hv_LabelCol = hv_BboxCol1;
            }
        }
        else if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
        {
            GenRectangle2ContourXld(&ho_BboxRectangle, hv_BboxRow, hv_BboxCol, hv_BboxPhi,
                                    hv_BboxLength1, hv_BboxLength2);
            if (0 != hv_ShowLabels)
            {
                hv_LabelRow = hv_BboxRow-hv_TextOffset;
                hv_LabelCol = hv_BboxCol;
            }
            if (0 != hv_ShowDirection)
            {
                if (0 != (int(hv_ShowDirection==-1)))
                {
                    hv_ArrowSizeFactorLength = 0.4;
                    hv_ArrowSizeFactorHead = 0.2;
                    hv_MaxLengthArrow = 20;
                    hv_HalfLengthArrow = hv_MaxLengthArrow.TupleMin2(hv_BboxLength1*hv_ArrowSizeFactorLength);
                    hv_ArrowBaseRow = hv_BboxRow-((hv_BboxLength1-hv_HalfLengthArrow)*(hv_BboxPhi.TupleSin()));
                    hv_ArrowBaseCol = hv_BboxCol+((hv_BboxLength1-hv_HalfLengthArrow)*(hv_BboxPhi.TupleCos()));
                    hv_ArrowHeadRow = hv_BboxRow-((hv_BboxLength1+hv_HalfLengthArrow)*(hv_BboxPhi.TupleSin()));
                    hv_ArrowHeadCol = hv_BboxCol+((hv_BboxLength1+hv_HalfLengthArrow)*(hv_BboxPhi.TupleCos()));
                    hv_ArrowHeadSize = (hv_MaxLengthArrow.TupleMin2(hv_BboxLength1.TupleMin2(hv_BboxLength2)))*hv_ArrowSizeFactorHead;
                }
                else
                {
                    hv_ArrowHeadSize = 20.0;
                    hv_ArrowBaseRow = hv_BboxRow;
                    hv_ArrowBaseCol = hv_BboxCol;
                    hv_ArrowHeadRow = hv_BboxRow-((hv_BboxLength1+hv_ArrowHeadSize)*(hv_BboxPhi.TupleSin()));
                    hv_ArrowHeadCol = hv_BboxCol+((hv_BboxLength1+hv_ArrowHeadSize)*(hv_BboxPhi.TupleCos()));
                }
                gen_arrow_contour_xld(&ho_OrientationArrows, hv_ArrowBaseRow, hv_ArrowBaseCol,
                                      hv_ArrowHeadRow, hv_ArrowHeadCol, hv_ArrowHeadSize, hv_ArrowHeadSize);
            }
        }
        else if (0 != hv_MaskExists)
        {
            if (0 != hv_ShowLabels)
            {
                AreaCenter(ho_InstanceMask, &hv__, &hv_LabelRow, &hv_LabelCol);
            }
        }
        else
        {
            throw HException("Unknown instance_type: "+hv_InstanceType);
        }
        //
        //Collect the ClassIDs of the bounding boxes.
        TupleGenConst(hv_BboxLabels.TupleLength(), 0, &(*hv_BboxIDs));
        //
        //Draw the bounding boxes.
        GetContourStyle(hv_WindowHandle, &hv_ContourStyle);
        if (HDevWindowStack::IsOpen())
            SetContourStyle(HDevWindowStack::GetActive(),"stroke_and_fill");
        GetLineStyle(hv_WindowHandle, &hv_Style);
        if (HDevWindowStack::IsOpen())
            SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidthBbox);
        {
            HTuple end_val88 = (hv_BboxLabels.TupleLength())-1;
            HTuple step_val88 = 1;
            for (hv_IndexBbox=0; hv_IndexBbox.Continue(end_val88, step_val88); hv_IndexBbox += step_val88)
            {
                SelectObj(ho_BboxRectangle, &ho_RectangleSelected, hv_IndexBbox+1);
                hv_ClassID = hv_ClassIDs.TupleFind(HTuple(hv_BboxLabels[hv_IndexBbox]));
                (*hv_BboxIDs)[hv_IndexBbox] = hv_ClassID;
                if (HDevWindowStack::IsOpen())
                    SetColor(HDevWindowStack::GetActive(),HTuple(hv_BboxColors[hv_ClassID])+"60");
                if (0 != hv_MaskExists)
                {
                    if (HDevWindowStack::IsOpen())
                        SetDraw(HDevWindowStack::GetActive(),"fill");
                    SelectObj(ho_InstanceMask, &ho_MaskSelected, hv_IndexBbox+1);
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_MaskSelected, HDevWindowStack::GetActive());
                    if (HDevWindowStack::IsOpen())
                        SetContourStyle(HDevWindowStack::GetActive(),"stroke");
                }
                if (0 != (int(hv_InstanceType!=HTuple(""))))
                {
                    SelectObj(ho_BboxRectangle, &ho_RectangleSelected, hv_IndexBbox+1);
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_RectangleSelected, HDevWindowStack::GetActive());
                    if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(hv_ShowDirection)))
                    {
                        SelectObj(ho_OrientationArrows, &ho_ArrowSelected, hv_IndexBbox+1);
                        if (HDevWindowStack::IsOpen())
                            SetColor(HDevWindowStack::GetActive(),HTuple(hv_BboxColors[hv_ClassID])+"FF");
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_ArrowSelected, HDevWindowStack::GetActive());
                        if (HDevWindowStack::IsOpen())
                            SetColor(HDevWindowStack::GetActive(),HTuple(hv_BboxColors[hv_ClassID])+"60");
                    }
                }
            }
        }
        //
        //Write text to the bounding boxes.
        if (0 != hv_ShowLabels)
        {
            //For better visibility the text is displayed after all bounding boxes are drawn.
            //Select text color.
            if (0 != (int(hv_TextColor==HTuple(""))))
            {
                hv_TextColorClasses = HTuple(hv_BboxColors[(*hv_BboxIDs)]);
            }
            else
            {
                TupleGenConst((*hv_BboxIDs).TupleLength(), hv_TextColor, &hv_TextColorClasses);
            }
            //Display text.
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),hv_BboxLabels, "image", hv_LabelRow,
                         hv_LabelCol, hv_TextColorClasses, ((HTuple("box_color").Append("shadow")).Append("border_radius")),
                         hv_BboxLabelColor.TupleConcat((HTuple("false").Append(0))));
        }
        //
        if (HDevWindowStack::IsOpen())
            SetContourStyle(HDevWindowStack::GetActive(),hv_ContourStyle);
        SetLineStyle(hv_WindowHandle, hv_Style);
    }
    else
    {
        //Do nothing if there are no ground truth bounding boxes.
        (*hv_BboxIDs) = HTuple();
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize the visualization of the training progress. This includes setting default values for visualization parameters.
void HalxAI:: dev_display_init_train_dl_model (HTuple hv_DLModelHandle, HTuple hv_TrainParam,
                                               HTuple *hv_DisplayData)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ModelType, hv_DisplayParam, hv_DisplayEnabled;
    HTuple  hv_UpdateImagesIntervalEpochs, hv_NumImagesPreview;
    HTuple  hv_ChangePlotIntervalSeconds, hv_SelectedPercentageTrainSamples;
    HTuple  hv_XAxisLabel, hv_DisplayParamNames, hv_DisplayDefaultValues;
    HTuple  hv_Index, hv_KeyExists, hv_DisplayIntervalSeconds;
    HTuple  hv_Time, hv_StatusModelParamNames, hv_WindowTextWidth;
    HTuple  hv_WindowTextHeight, hv_WindowImagesWidth, hv_WindowImagesHeight;
    HTuple  hv_WindowBGColor, hv_WindowHandleText, hv_WindowImagesRow;
    HTuple  hv_WindowImagesCol, hv_TiledParam, hv_Exception;
    HTuple  hv_TiledParamNames, hv_TiledDefaultValues;

    //
    //This procedure initializes the visualization of the training progress.
    //This includes setting default values for visualization parameters.
    //
    //Get the actual model type.
    if (0 != (int(hv_DLModelHandle!=HTuple())))
    {
        GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    }
    else
    {
        GetDictTuple(hv_TrainParam, "type", &hv_ModelType);
    }
    //
    //Initialize display data.
    CreateDict(&(*hv_DisplayData));
    GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
    SetDictTuple((*hv_DisplayData), "display_param", hv_DisplayParam);
    GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
    SetDictTuple((*hv_DisplayData), "enabled", hv_DisplayEnabled);
    //
    //Set default values if not set by the user.
    //
    //Default interval (in epochs) for the preview update
    //depending on the model type.
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        hv_UpdateImagesIntervalEpochs = 4;
    }
    else
    {
        hv_UpdateImagesIntervalEpochs = 0.5;
    }
    //
    //Default number of images to display in the images preview.
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        hv_NumImagesPreview = 6;
    }
    else if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        hv_NumImagesPreview = 2;
    }
    else if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
        //No images are displayed in case of
        //model type 'gc_anomaly_detection'.
        hv_NumImagesPreview = 0;
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
    {
        hv_NumImagesPreview = 2;
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        hv_NumImagesPreview = 12;
    }
    else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
    {
        hv_NumImagesPreview = 4;
    }
    else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
        hv_NumImagesPreview = 4;
    }
    //
    //Default interval (in seconds) to switch between plots.
    hv_ChangePlotIntervalSeconds = 10;
    //
    //Default percentage of images that is used for evaluation on training set.
    //If set to zero no evaluation on training set is done.
    hv_SelectedPercentageTrainSamples = 0;
    //
    //Default x_axis_label: Show 'iterations' or 'epochs' as x-values in plots.
    hv_XAxisLabel = "epochs";
    //
    //Collect all display params and overwrite if user values are given.
    //Note, some parameters are also used for the evaluation.
    //Thus, write its value even for DisplayEnabled = false.
    hv_DisplayParamNames.Clear();
    hv_DisplayParamNames[0] = "change_plot_interval_seconds";
    hv_DisplayParamNames[1] = "num_images";
    hv_DisplayParamNames[2] = "selected_percentage_train_samples";
    hv_DisplayParamNames[3] = "update_images_interval_epochs";
    hv_DisplayParamNames[4] = "x_axis_label";
    hv_DisplayDefaultValues.Clear();
    hv_DisplayDefaultValues.Append(hv_ChangePlotIntervalSeconds);
    hv_DisplayDefaultValues.Append(hv_NumImagesPreview);
    hv_DisplayDefaultValues.Append(hv_SelectedPercentageTrainSamples);
    hv_DisplayDefaultValues.Append(hv_UpdateImagesIntervalEpochs);
    hv_DisplayDefaultValues.Append(hv_XAxisLabel);
    {
        HTuple end_val62 = (hv_DisplayParamNames.TupleLength())-1;
        HTuple step_val62 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val62, step_val62); hv_Index += step_val62)
        {
            GetDictParam(hv_DisplayParam, "key_exists", HTuple(hv_DisplayParamNames[hv_Index]),
                         &hv_KeyExists);
            if (0 != (hv_KeyExists.TupleNot()))
            {
                SetDictTuple(hv_DisplayParam, HTuple(hv_DisplayParamNames[hv_Index]), HTuple(hv_DisplayDefaultValues[hv_Index]));
            }
        }
    }
    //
    //Set last_update, which is needed to determine when updates are needed.
    GetDictTuple(hv_TrainParam, "update_interval_seconds", &hv_DisplayIntervalSeconds);
    CountSeconds(&hv_Time);
    SetDictTuple((*hv_DisplayData), "last_update", hv_Time-(hv_DisplayIntervalSeconds*2));
    //
    //Some entries in DisplayParam are also needed in case of disabled display.
    //They are all set yet.
    if (0 != (hv_DisplayEnabled.TupleNot()))
    {
        return;
    }
    //
    //Separate handling for parameters that are specified by tuples.
    //
    //These model parameters are displayed in the text window if available.
    hv_StatusModelParamNames.Clear();
    hv_StatusModelParamNames[0] = "learning_rate";
    hv_StatusModelParamNames[1] = "batch_size";
    hv_StatusModelParamNames[2] = "batch_size_multiplier";
    hv_StatusModelParamNames[3] = "momentum";
    hv_StatusModelParamNames[4] = "weight_prior";
    hv_StatusModelParamNames[5] = "image_dimensions";
    GetDictParam(hv_DisplayParam, "key_exists", "status_model_params", &hv_KeyExists);
    if (0 != (hv_KeyExists.TupleNot()))
    {
        SetDictTuple(hv_DisplayParam, "status_model_params", hv_StatusModelParamNames);
    }
    //
    //
    //Setup and open text window.
    hv_WindowTextWidth = 700;
    hv_WindowTextHeight = 750;
    hv_WindowImagesWidth = 1200-hv_WindowTextWidth;
    hv_WindowImagesHeight = hv_WindowTextHeight;
    hv_WindowBGColor = "light gray";
    //
    SetWindowAttr("background_color",hv_WindowBGColor);
    OpenWindow(0,0,hv_WindowTextWidth,hv_WindowTextHeight,0,"visible","",&hv_WindowHandleText);
    HDevWindowStack::Push(hv_WindowHandleText);
    set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
    SetDictTuple((*hv_DisplayData), "window_text", hv_WindowHandleText);
    SetDictTuple((*hv_DisplayData), "window_text_width", hv_WindowTextWidth);
    SetDictTuple((*hv_DisplayData), "window_text_height", hv_WindowTextHeight);
    //
    //Configure images window, which is opened later by another procedure.
    hv_WindowImagesRow = 0;
    hv_WindowImagesCol = hv_WindowTextWidth+10;
    SetDictTuple((*hv_DisplayData), "window_images", HTuple());
    //
    //Set user specified parameters used for the display of tiled images.
    try
    {
        GetDictTuple(hv_DisplayParam, "tiled_param", &hv_TiledParam);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        CreateDict(&hv_TiledParam);
        SetDictTuple(hv_DisplayParam, "tiled_param", hv_TiledParam);
    }
    //
    //Only set values if they are not already given.
    if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        hv_WindowImagesHeight = 500;
    }
    hv_TiledParamNames.Clear();
    hv_TiledParamNames[0] = "window_row";
    hv_TiledParamNames[1] = "window_col";
    hv_TiledParamNames[2] = "window_width";
    hv_TiledParamNames[3] = "window_height";
    hv_TiledDefaultValues.Clear();
    hv_TiledDefaultValues.Append(hv_WindowImagesRow);
    hv_TiledDefaultValues.Append(hv_WindowImagesCol);
    hv_TiledDefaultValues.Append(hv_WindowImagesWidth);
    hv_TiledDefaultValues.Append(hv_WindowImagesHeight);
    {
        HTuple end_val122 = (hv_TiledParamNames.TupleLength())-1;
        HTuple step_val122 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val122, step_val122); hv_Index += step_val122)
        {
            GetDictParam(hv_TiledParam, "key_exists", HTuple(hv_TiledParamNames[hv_Index]),
                         &hv_KeyExists);
            if (0 != (hv_KeyExists.TupleNot()))
            {
                SetDictTuple(hv_TiledParam, HTuple(hv_TiledParamNames[hv_Index]), HTuple(hv_TiledDefaultValues[hv_Index]));
            }
        }
    }
    //
    //Set specific display parameters for all available model types.
    if (0 != (int(hv_ModelType==HTuple("classification"))))
    {
        SetDictTuple(hv_TiledParam, "display_input", 0);
        SetDictTuple(hv_TiledParam, "display_ground_truth", 0);
        SetDictTuple(hv_TiledParam, "display_legend", 0);
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        SetDictTuple(hv_TiledParam, "display_input", 0);
        SetDictTuple(hv_TiledParam, "display_ground_truth", 0);
        SetDictTuple(hv_TiledParam, "display_legend", 0);
    }
    //
    //
    //Start with loss plot since usually no evaluation is available in the beginning.
    SetDictTuple((*hv_DisplayData), "last_change_plot", hv_Time);
    SetDictTuple((*hv_DisplayData), "plot_eval", 0);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Display a color bar next to an image.
void HalxAI:: dev_display_map_color_bar (HTuple hv_ImageWidth, HTuple hv_ImageHeight, HTuple hv_MapColorBarWidth,
                                         HTuple hv_Colors, HTuple hv_MaxValue, HTuple hv_WindowImageRatio, HTuple hv_WindowHandle)
{

    // Local iconic variables
    HObject  ho_Rectangle;

    // Local control variables
    HTuple  hv_ClipRegion, hv_ColorIndex, hv_RectHeight;
    HTuple  hv_DrawMode, hv_Row, hv_Row1, hv_Column1, hv_Row2;
    HTuple  hv_Column2, hv__, hv_TextHeight, hv_Index, hv_Text;

    //
    //This procedure displays a color bar next to the image
    //specified with ImageWidth and ImageHeight.
    //
    GetSystem("clip_region", &hv_ClipRegion);
    SetSystem("clip_region", "false");
    //
    //Display the color bar.
    hv_ColorIndex = 0;
    hv_RectHeight = (1.0*hv_ImageHeight)/(hv_Colors.TupleLength());
    //Set draw mode to fill
    GetDraw(hv_WindowHandle, &hv_DrawMode);
    if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),"fill");
    {
        HTuple end_val13 = 0;
        HTuple step_val13 = -hv_RectHeight;
        for (hv_Row=hv_ImageHeight-1; hv_Row.Continue(end_val13, step_val13); hv_Row += step_val13)
        {
            //The color bar consists of multiple rectangle1.
            hv_Row1 = hv_Row-hv_RectHeight;
            hv_Column1 = hv_ImageWidth+(20/hv_WindowImageRatio);
            hv_Row2 = hv_Row;
            hv_Column2 = (hv_ImageWidth+20)+(hv_MapColorBarWidth/hv_WindowImageRatio);
            GenRectangle1(&ho_Rectangle, hv_Row1, hv_Column1, hv_Row2, hv_Column2);
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_ColorIndex]));
            if (HDevWindowStack::IsOpen())
                DispObj(ho_Rectangle, HDevWindowStack::GetActive());
            hv_ColorIndex += 1;
        }
    }
    //
    //Display labels for color bar.
    GetStringExtents(hv_WindowHandle, "0123456789", &hv__, &hv__, &hv__, &hv_TextHeight);
    for (hv_Index=0; hv_Index<=1; hv_Index+=0.2)
    {
        hv_Text = (hv_MaxValue-(hv_Index*hv_MaxValue)).TupleString(".1f");
        if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_Text, "image", hv_Index*(hv_ImageHeight-(2*(hv_TextHeight/hv_WindowImageRatio))),
                     hv_ImageWidth+(40/hv_WindowImageRatio), "black", "box", "false");
    }
    //
    SetSystem("clip_region", hv_ClipRegion);
    if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Display the detected anomaly regions.
void HalxAI:: dev_display_result_anomaly_regions (HObject ho_AnomalyRegion, HTuple hv_CurrentWindowHandle,
                                                  HTuple hv_LineWidth, HTuple hv_AnomalyRegionResultColor)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Red, hv_Green, hv_Blue, hv_Alpha, hv_InitialColor;
    HTuple  hv_IndexColor, hv_Color_RGBA, hv_Area;

    //
    //This procedure displays the result anomaly regions.
    //
    //Get current set color.
    GetRgba(hv_CurrentWindowHandle, &hv_Red, &hv_Green, &hv_Blue, &hv_Alpha);
    hv_InitialColor = HTuple();
    {
        HTuple end_val6 = (hv_Red.TupleLength())-1;
        HTuple step_val6 = 1;
        for (hv_IndexColor=0; hv_IndexColor.Continue(end_val6, step_val6); hv_IndexColor += step_val6)
        {
            hv_Color_RGBA = ((("#"+(HTuple(hv_Red[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Green[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Blue[hv_IndexColor]).TupleString("2x")))+(HTuple(hv_Alpha[hv_IndexColor]).TupleString("2x"));
            TupleRegexpReplace(hv_Color_RGBA, (HTuple(" ").Append("replace_all")), "0", &hv_Color_RGBA);
            hv_InitialColor = hv_InitialColor.TupleConcat(hv_Color_RGBA);
        }
    }
    //
    //Display anomaly regions.
    //Get non-empty regions.
    RegionFeatures(ho_AnomalyRegion, "area", &hv_Area);
    //
    //Display all non-empty class regions in distinct colors.
    if (0 != (int(hv_Area>0)))
    {
        if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),hv_AnomalyRegionResultColor);
        if (HDevWindowStack::IsOpen())
            SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth);
        if (HDevWindowStack::IsOpen())
            SetDraw(HDevWindowStack::GetActive(),"margin");
        if (HDevWindowStack::IsOpen())
            DispObj(ho_AnomalyRegion, HDevWindowStack::GetActive());
    }
    //
    //Reset colors.
    if (HDevWindowStack::IsOpen())
        SetColor(HDevWindowStack::GetActive(),hv_InitialColor);
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Display result bounding boxes.
void HalxAI:: dev_display_result_detection (HTuple hv_DLResult, HTuple hv_ResultKeys, HTuple hv_LineWidthBbox,
                                            HTuple hv_ClassIDs, HTuple hv_TextConf, HTuple hv_Colors, HTuple hv_BoxLabelColor,
                                            HTuple hv_WindowImageRatio, HTuple hv_TextPositionRow, HTuple hv_TextColor, HTuple hv_ShowLabels,
                                            HTuple hv_ShowDirection, HTuple hv_WindowHandle, HTuple *hv_BboxClassIndices)
{

    // Local iconic variables
    HObject  ho_InstanceMask, ho_BboxRectangle, ho_OrientationArrows;
    HObject  ho_MaskSelected, ho_RectangleSelected, ho_ArrowSelected;

    // Local control variables
    HTuple  hv_InstanceType, hv_MaskExists, hv_BboxRow1;
    HTuple  hv_BboxCol1, hv_BboxRow2, hv_BboxCol2, hv_BboxRow;
    HTuple  hv_BboxCol, hv_BboxLength1, hv_BboxLength2, hv_BboxPhi;
    HTuple  hv_BboxClasses, hv_Text, hv_Ascent, hv_Descent;
    HTuple  hv__, hv_TextOffset, hv_LabelRowTop, hv_LabelRowBottom;
    HTuple  hv_LabelCol, hv_ArrowSizeFactorLength, hv_ArrowSizeFactorHead;
    HTuple  hv_MaxLengthArrow, hv_HalfLengthArrow, hv_ArrowBaseRow;
    HTuple  hv_ArrowBaseCol, hv_ArrowHeadRow, hv_ArrowHeadCol;
    HTuple  hv_ArrowHeadSize, hv_MaskRow, hv_MaskCol, hv_ContourStyle;
    HTuple  hv_Style, hv_LineWidths, hv_IndexBbox, hv_ClassID;
    HTuple  hv_CurrentColors, hv_IndexStyle, hv_TextColorClasses;
    HTuple  hv_LabelRow;

    //
    //This procedure displays the bounding boxes and masks (if present) defined by a DLResult.
    //The ClassIDs are necessary to display bounding boxes from the same class
    //always with the same color.
    //
    hv_InstanceType = "";
    hv_MaskExists = 0;
    if (0 != (int((hv_ResultKeys.TupleFind("bbox_row1"))!=-1)))
    {
        GetDictTuple(hv_DLResult, "bbox_row1", &hv_BboxRow1);
        GetDictTuple(hv_DLResult, "bbox_col1", &hv_BboxCol1);
        GetDictTuple(hv_DLResult, "bbox_row2", &hv_BboxRow2);
        GetDictTuple(hv_DLResult, "bbox_col2", &hv_BboxCol2);
        hv_InstanceType = "rectangle1";
    }
    else if (0 != (int((hv_ResultKeys.TupleFind("bbox_phi"))!=-1)))
    {
        GetDictTuple(hv_DLResult, "bbox_row", &hv_BboxRow);
        GetDictTuple(hv_DLResult, "bbox_col", &hv_BboxCol);
        GetDictTuple(hv_DLResult, "bbox_length1", &hv_BboxLength1);
        GetDictTuple(hv_DLResult, "bbox_length2", &hv_BboxLength2);
        GetDictTuple(hv_DLResult, "bbox_phi", &hv_BboxPhi);
        GetDictTuple(hv_DLResult, "bbox_class_id", &hv_BboxClasses);
        hv_InstanceType = "rectangle2";
    }
    else
    {
        throw HException("Result bounding box data could not be found in DLResult.");
    }
    if (0 != (int((hv_ResultKeys.TupleFind("mask"))!=-1)))
    {
        GetDictObject(&ho_InstanceMask, hv_DLResult, "mask");
        hv_MaskExists = 1;
    }
    if (0 != (HTuple(HTuple(int(hv_InstanceType!=HTuple("rectangle1"))).TupleAnd(int(hv_InstanceType!=HTuple("rectangle2")))).TupleAnd(hv_MaskExists.TupleNot())))
    {
        throw HException("Result bounding box or mask data could not be found in DLSample.");
    }
    GetDictTuple(hv_DLResult, "bbox_class_id", &hv_BboxClasses);
    if (0 != (int((hv_BboxClasses.TupleLength())>0)))
    {
        //
        //Get text and text size for correct positioning of result class IDs.
        if (0 != hv_ShowLabels)
        {
            hv_Text = hv_BboxClasses+hv_TextConf;
            GetStringExtents(hv_WindowHandle, hv_Text, &hv_Ascent, &hv_Descent, &hv__,
                             &hv__);
            hv_TextOffset = (hv_Ascent+hv_Descent)/hv_WindowImageRatio;
        }
        //
        //Generate bounding box XLDs.
        if (0 != (int(hv_InstanceType==HTuple("rectangle1"))))
        {
            TupleGenConst(hv_BboxRow1.TupleLength(), 0.0, &hv_BboxPhi);
            GenRectangle2ContourXld(&ho_BboxRectangle, 0.5*(hv_BboxRow1+hv_BboxRow2), 0.5*(hv_BboxCol1+hv_BboxCol2),
                                    hv_BboxPhi, 0.5*(hv_BboxCol2-hv_BboxCol1), 0.5*(hv_BboxRow2-hv_BboxRow1));
            if (0 != hv_ShowLabels)
            {
                hv_LabelRowTop = hv_BboxRow1;
                hv_LabelRowBottom = hv_BboxRow2-hv_TextOffset;
                hv_LabelCol = hv_BboxCol1;
            }
        }
        else if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
        {
            GenRectangle2ContourXld(&ho_BboxRectangle, hv_BboxRow, hv_BboxCol, hv_BboxPhi,
                                    hv_BboxLength1, hv_BboxLength2);
            if (0 != hv_ShowLabels)
            {
                hv_LabelRowTop = hv_BboxRow-hv_TextOffset;
                hv_LabelRowBottom = hv_BboxRow;
                hv_LabelCol = hv_BboxCol;
            }
            if (0 != hv_ShowDirection)
            {
                if (0 != (int(hv_ShowDirection==-1)))
                {
                    hv_ArrowSizeFactorLength = 0.4;
                    hv_ArrowSizeFactorHead = 0.2;
                    hv_MaxLengthArrow = 20;
                    hv_HalfLengthArrow = hv_MaxLengthArrow.TupleMin2(hv_BboxLength1*hv_ArrowSizeFactorLength);
                    hv_ArrowBaseRow = hv_BboxRow-((hv_BboxLength1-hv_HalfLengthArrow)*(hv_BboxPhi.TupleSin()));
                    hv_ArrowBaseCol = hv_BboxCol+((hv_BboxLength1-hv_HalfLengthArrow)*(hv_BboxPhi.TupleCos()));
                    hv_ArrowHeadRow = hv_BboxRow-((hv_BboxLength1+hv_HalfLengthArrow)*(hv_BboxPhi.TupleSin()));
                    hv_ArrowHeadCol = hv_BboxCol+((hv_BboxLength1+hv_HalfLengthArrow)*(hv_BboxPhi.TupleCos()));
                    hv_ArrowHeadSize = (hv_MaxLengthArrow.TupleMin2(hv_BboxLength1.TupleMin2(hv_BboxLength2)))*hv_ArrowSizeFactorHead;
                }
                else
                {
                    hv_ArrowHeadSize = 20.0;
                    hv_ArrowBaseRow = hv_BboxRow;
                    hv_ArrowBaseCol = hv_BboxCol;
                    hv_ArrowHeadRow = hv_BboxRow-((hv_BboxLength1+hv_ArrowHeadSize)*(hv_BboxPhi.TupleSin()));
                    hv_ArrowHeadCol = hv_BboxCol+((hv_BboxLength1+hv_ArrowHeadSize)*(hv_BboxPhi.TupleCos()));
                }
                gen_arrow_contour_xld(&ho_OrientationArrows, hv_ArrowBaseRow, hv_ArrowBaseCol,
                                      hv_ArrowHeadRow, hv_ArrowHeadCol, hv_ArrowHeadSize, hv_ArrowHeadSize);
            }
        }
        else if (0 != hv_MaskExists)
        {
            AreaCenter(ho_InstanceMask, &hv__, &hv_MaskRow, &hv_MaskCol);
            hv_LabelRowTop = hv_MaskRow-hv_TextOffset;
            hv_LabelRowBottom = hv_MaskRow;
            hv_LabelCol = hv_MaskCol;
        }
        else
        {
            throw HException("Unknown instance_type: "+hv_InstanceType);
        }
        //
        GetContourStyle(hv_WindowHandle, &hv_ContourStyle);
        if (HDevWindowStack::IsOpen())
            SetContourStyle(HDevWindowStack::GetActive(),"stroke");
        GetLineStyle(hv_WindowHandle, &hv_Style);
        hv_LineWidths.Clear();
        hv_LineWidths.Append(hv_LineWidthBbox+2);
        hv_LineWidths.Append(hv_LineWidthBbox);
        if (HDevWindowStack::IsOpen())
            SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidthBbox);
        //
        //Collect ClassIDs of the bounding boxes.
        TupleGenConst(hv_BboxClasses.TupleLength(), 0, &(*hv_BboxClassIndices));
        //
        //Draw bounding boxes.
        {
            HTuple end_val96 = (hv_BboxClasses.TupleLength())-1;
            HTuple step_val96 = 1;
            for (hv_IndexBbox=0; hv_IndexBbox.Continue(end_val96, step_val96); hv_IndexBbox += step_val96)
            {
                hv_ClassID = hv_ClassIDs.TupleFind(HTuple(hv_BboxClasses[hv_IndexBbox]));
                (*hv_BboxClassIndices)[hv_IndexBbox] = hv_ClassID;
                //First draw in black to make the class-color visible.
                hv_CurrentColors.Clear();
                hv_CurrentColors[0] = "black";
                hv_CurrentColors.Append(HTuple(hv_Colors[hv_ClassID]));
                if (0 != hv_MaskExists)
                {
                    SelectObj(ho_InstanceMask, &ho_MaskSelected, hv_IndexBbox+1);
                    if (HDevWindowStack::IsOpen())
                        SetDraw(HDevWindowStack::GetActive(),"fill");
                    if (HDevWindowStack::IsOpen())
                        SetColor(HDevWindowStack::GetActive(),HTuple(hv_Colors[hv_ClassID])+"80");
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_MaskSelected, HDevWindowStack::GetActive());
                    if (HDevWindowStack::IsOpen())
                        SetDraw(HDevWindowStack::GetActive(),"margin");
                }
                {
                    HTuple end_val108 = (hv_CurrentColors.TupleLength())-1;
                    HTuple step_val108 = 1;
                    for (hv_IndexStyle=0; hv_IndexStyle.Continue(end_val108, step_val108); hv_IndexStyle += step_val108)
                    {
                        if (HDevWindowStack::IsOpen())
                            SetColor(HDevWindowStack::GetActive(),HTuple(hv_CurrentColors[hv_IndexStyle]));
                        if (HDevWindowStack::IsOpen())
                            SetLineWidth(HDevWindowStack::GetActive(),HTuple(hv_LineWidths[hv_IndexStyle]));
                        if (0 != (int(hv_InstanceType!=HTuple(""))))
                        {
                            SelectObj(ho_BboxRectangle, &ho_RectangleSelected, hv_IndexBbox+1);
                            if (HDevWindowStack::IsOpen())
                                DispObj(ho_RectangleSelected, HDevWindowStack::GetActive());
                            if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(hv_ShowDirection)))
                            {
                                SelectObj(ho_OrientationArrows, &ho_ArrowSelected, hv_IndexBbox+1);
                                if (HDevWindowStack::IsOpen())
                                    DispObj(ho_ArrowSelected, HDevWindowStack::GetActive());
                            }
                        }
                    }
                }
            }
        }
        //
        //Draw text of bounding boxes.
        if (0 != hv_ShowLabels)
        {
            //For better visibility the text is displayed after all bounding boxes are drawn.
            //Get text and text size for correct positioning of result class IDs.
            hv_Text = hv_BboxClasses+hv_TextConf;
            //Select text color.
            if (0 != (int(hv_TextColor==HTuple(""))))
            {
                hv_TextColorClasses = HTuple(hv_Colors[(*hv_BboxClassIndices)]);
            }
            else
            {
                TupleGenConst((*hv_BboxClassIndices).TupleLength(), hv_TextColor, &hv_TextColorClasses);
            }
            //Select correct position of the text.
            hv_LabelRow = hv_LabelRowTop;
            if (0 != (int(hv_TextPositionRow==HTuple("bottom"))))
            {
                hv_LabelRow = hv_LabelRowBottom;
            }
            //Display text.
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),hv_Text, "image", hv_LabelRow, hv_LabelCol,
                         hv_TextColorClasses, ((HTuple("box_color").Append("shadow")).Append("border_radius")),
                         hv_BoxLabelColor.TupleConcat((HTuple("false").Append(0))));
        }
        //
        if (HDevWindowStack::IsOpen())
            SetContourStyle(HDevWindowStack::GetActive(),hv_ContourStyle);
        SetLineStyle(hv_WindowHandle, hv_Style);
    }
    else
    {
        //Do nothing if no results are present.
        (*hv_BboxClassIndices) = HTuple();
    }
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Display the ground truth/result segmentation as regions.
void HalxAI:: dev_display_segmentation_regions (HObject ho_SegmentationImage, HTuple hv_ClassIDs,
                                                HTuple hv_ColorsSegmentation, HTuple hv_ExcludeClassIDs, HTuple *hv_ImageClassIDs)
{

    // Local iconic variables
    HObject  ho_Regions, ho_SelectedRegion;

    // Local control variables
    HTuple  hv_IncludedClassIDs, hv_Area, hv_Index;
    HTuple  hv_ClassID, hv_IndexColor;

    //
    //This procedure displays the ground truth/result segmentation
    //given in SegmentationImage as regions. The ClassIDs are necessary to
    //display ground truth/result segmentations from the same class
    //always with the same color. It is possible to exclude certain ClassIDs
    //from being displayed. The displayed classes are returned in ImageClassIDs.
    //
    //
    //Remove excluded class IDs from the list.
    hv_IncludedClassIDs = hv_ClassIDs.TupleDifference(hv_ExcludeClassIDs);
    //
    //Get a region for each class ID.
    Threshold(ho_SegmentationImage, &ho_Regions, hv_IncludedClassIDs, hv_IncludedClassIDs);
    //
    //Get classes with non-empty regions.
    RegionFeatures(ho_Regions, "area", &hv_Area);
    if (0 != (int((hv_Area.TupleLength())!=(hv_IncludedClassIDs.TupleLength()))))
    {
        throw HException("No equal number of class IDs and segmentation regions.");
    }
    TupleSelectMask(hv_IncludedClassIDs, hv_Area.TupleGreaterElem(0), &(*hv_ImageClassIDs));
    //
    //Display all non-empty class regions in distinct colors.
    {
        HTuple end_val22 = (hv_IncludedClassIDs.TupleLength())-1;
        HTuple step_val22 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val22, step_val22); hv_Index += step_val22)
        {
            if (0 != (int(HTuple(hv_Area[hv_Index])>0)))
            {
                //Use class ID to determine region color.
                hv_ClassID = HTuple(hv_IncludedClassIDs[hv_Index]);
                hv_IndexColor = hv_ClassIDs.TupleFindFirst(hv_ClassID);
                if (HDevWindowStack::IsOpen())
                    SetColor(HDevWindowStack::GetActive(),HTuple(hv_ColorsSegmentation[hv_IndexColor]));
                //Display the segmentation region.
                SelectObj(ho_Regions, &ho_SelectedRegion, hv_Index+1);
                if (HDevWindowStack::IsOpen())
                    DispObj(ho_SelectedRegion, HDevWindowStack::GetActive());
            }
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Display a legend according to the generic parameters.
void HalxAI:: dev_display_tiled_legend (HTuple hv_WindowImages, HTuple hv_GenParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_DisplayLegend, hv_Exception, hv_LegendText;
    HTuple  hv_Flag, hv_PosTexts, hv_Text;

    //
    //This procedure displays a legend of dev_display_dl_data_tiled
    //according to the generic parameters.
    //
    try
    {
        GetDictTuple(hv_GenParam, "display_legend", &hv_DisplayLegend);
        if (0 != (hv_DisplayLegend.TupleNot()))
        {
            return;
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    hv_LegendText = HTuple();
    try
    {
        GetDictTuple(hv_GenParam, "display_input", &hv_Flag);
        if (0 != hv_Flag)
        {
            hv_LegendText = hv_LegendText.TupleConcat("input");
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_LegendText = hv_LegendText.TupleConcat("input");
    }
    try
    {
        GetDictTuple(hv_GenParam, "display_ground_truth", &hv_Flag);
        if (0 != hv_Flag)
        {
            hv_LegendText = hv_LegendText.TupleConcat("ground truth");
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_LegendText = hv_LegendText.TupleConcat("ground truth");
    }
    try
    {
        GetDictTuple(hv_GenParam, "display_result", &hv_Flag);
        if (0 != hv_Flag)
        {
            hv_LegendText = hv_LegendText.TupleConcat("result");
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_LegendText = hv_LegendText.TupleConcat("result");
    }
    if (0 != (int((hv_LegendText.TupleLength())==3)))
    {
        hv_PosTexts.Clear();
        hv_PosTexts[0] = "Top:    ";
        hv_PosTexts[1] = "Center: ";
        hv_PosTexts[2] = "Bottom: ";
    }
    else if (0 != (int((hv_LegendText.TupleLength())==2)))
    {
        hv_PosTexts.Clear();
        hv_PosTexts[0] = "Top:    ";
        hv_PosTexts[1] = "Bottom: ";
    }
    else
    {
        hv_PosTexts = "";
    }
    HDevWindowStack::SetActive(hv_WindowImages);
    hv_Text = hv_PosTexts+hv_LegendText;
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "right", "black",
                 HTuple(), HTuple());
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Display information about the training of an anomaly detection model.
void HalxAI:: dev_display_train_info_anomaly_detection (HTuple hv_TrainParam, HTuple *hv_WindowHandleInfo)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_DisplayParam, hv_DisplayEnabled, hv_WindowWidth;
    HTuple  hv_WindowHeight, hv_WindowBGColor, hv_TrainParamAnomaly;
    HTuple  hv_DomainRatio, hv_ErrorThreshold, hv_RegularizationNoise;
    HTuple  hv_MaxNumEpochs, hv_TrainInformationLeft, hv_TrainInformationRight;

    //
    //This procedure displays information about the training parameters of an anomaly detection model.
    //
    //Initialize display data.
    GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
    GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
    //
    if (0 != (hv_DisplayEnabled.TupleNot()))
    {
        return;
    }
    //
    hv_WindowWidth = 500;
    hv_WindowHeight = 230;
    hv_WindowBGColor = "light gray";
    //
    //Open and setup text window.
    SetWindowAttr("background_color",hv_WindowBGColor);
    OpenWindow(0,0,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandleInfo));
    HDevWindowStack::Push((*hv_WindowHandleInfo));
    set_display_font((*hv_WindowHandleInfo), 16, "mono", "true", "false");
    HDevWindowStack::SetActive((*hv_WindowHandleInfo));
    //
    //Display information.
    GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
    GetDictTuple(hv_TrainParamAnomaly, "domain_ratio", &hv_DomainRatio);
    GetDictTuple(hv_TrainParamAnomaly, "error_threshold", &hv_ErrorThreshold);
    GetDictTuple(hv_TrainParamAnomaly, "regularization_noise", &hv_RegularizationNoise);
    GetDictTuple(hv_TrainParamAnomaly, "max_num_epochs", &hv_MaxNumEpochs);
    hv_TrainInformationLeft.Clear();
    hv_TrainInformationLeft[0] = "Training anomaly detection model.";
    hv_TrainInformationLeft[1] = "";
    hv_TrainInformationLeft[2] = "Max. number of epochs:";
    hv_TrainInformationLeft[3] = "Domain ratio:";
    hv_TrainInformationLeft[4] = "Error threshold:";
    hv_TrainInformationLeft[5] = "Regularization noise:";
    hv_TrainInformationLeft[6] = "";
    hv_TrainInformationLeft[7] = "This may take some time...";
    hv_TrainInformationRight.Clear();
    hv_TrainInformationRight[0] = "";
    hv_TrainInformationRight[1] = "";
    hv_TrainInformationRight.Append(hv_MaxNumEpochs);
    hv_TrainInformationRight.Append(hv_DomainRatio.TupleString(".4f"));
    hv_TrainInformationRight.Append(hv_ErrorThreshold.TupleString(".4f"));
    hv_TrainInformationRight.Append(hv_RegularizationNoise.TupleString(".4f"));
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_TrainInformationLeft, "window", "top",
                 "left", "black", "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_TrainInformationRight, "window", "top",
                 "right", "black", "box", "false");
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Update the various texts and plots during training.
void HalxAI:: dev_display_update_train_dl_model (HTuple hv_TrainParam, HTuple hv_DisplayData,
                                                 HTuple hv_TrainInfo, HTuple hv_Epochs, HTuple hv_Loss, HTuple hv_LearningRate,
                                                 HTuple hv_EvalEpochs, HTuple hv_EvalValues, HTuple hv_EvalValuesTrain)
{

    // Local iconic variables
    HObject  ho_PlotBackground;

    // Local control variables
    HTuple  hv_DisplayEnabled, hv_DisplayParam, hv_WindowText;
    HTuple  hv_WindowHandle, hv_ChangePlotIntervalSeconds, hv_LastChange;
    HTuple  hv_Seconds, hv_PlotEval, hv_PlotFunctionExists;
    HTuple  hv_PlotFunction, hv_ModelType, hv_TextPlot, hv_PlotTrainEval;
    HTuple  hv_HeadlineText, hv_Indices, hv_Index, hv_PartRow1;
    HTuple  hv_PartColumn1, hv_PartRow2, hv_PartColumn2, hv__;
    HTuple  hv_Width, hv_Height, hv_ClipRegionValue, hv_PlotHeight;
    HTuple  hv_LegendRow, hv_LegendDistanceLeft, hv_LegendDistanceRight;
    HTuple  hv_PlotLearningRateStrategy, hv_RightMargin, hv_ChangeStrategies;
    HTuple  hv_Idx, hv_ChangeStrategy, hv_ChangeStrategyName;
    HTuple  hv_ChangeStrategiesValues, hv_ChangeStrategiesInitial;
    HTuple  hv_StrategyMin, hv_StrategyMax, hv_LogLRMin, hv_LogLRMax;
    HTuple  hv_LRScale, hv_LROffset, hv_LogLROffset, hv_StartYLearningRate;
    HTuple  hv_EndYLearningRate, hv_TicksYLearningRate, hv_LogYLearningRate;
    HTuple  hv_LRColor, hv_LRLineWidth, hv_LRTextLegend, hv_TopMarginPlots;
    HTuple  hv_NumIterationsPerEpoch, hv_Iterations, hv_NumEpochs;
    HTuple  hv_NumIterations, hv_CurrentIteration, hv_XAxisLabel;
    HTuple  hv_ValuesX, hv_TicksX, hv_EvalValuesX, hv_EvalTicksX;
    HTuple  hv_TitleX, hv_EvalIterations, hv_EvalValuesMin;
    HTuple  hv_EvalValuesMax, hv_TicksY, hv_StartY, hv_EndY;
    HTuple  hv_YAxisLabel, hv_BestEvaluationData, hv_BestEvaluationComparisonKeys;
    HTuple  hv_StringExtendsLegendRight, hv_Bullet, hv_Line;
    HTuple  hv_YAxisTitle, hv_Offset, hv_LogMin, hv_LogMax;
    HTuple  hv_Scale, hv_LogOffset, hv_LogY, hv_TextModelParams;
    HTuple  hv_ModelParams, hv_StatusModelParamsLeft, hv_StatusModelParamsRight;
    HTuple  hv_ParName, hv_Tuple, hv_Exception, hv_TupleStr;
    HTuple  hv_StatusEvaluationLeft, hv_StatusEvaluationRight;
    HTuple  hv_BestEvaluationValue, hv_BestEvaluationInfo, hv_BestEvaluationEpoch;
    HTuple  hv_BestTrainEvaluationValue, hv_BestTrainEvaluationInfo;
    HTuple  hv_BestTrainEvaluationEpoch, hv_BestEvaluationComparisonKeysStr;
    HTuple  hv_StatusTrainLeft, hv_StatusTrainRight, hv_EpochReal;
    HTuple  hv_MeanLoss, hv_MeanLossStr, hv_TimeElapsedExists;
    HTuple  hv_StartEpoch, hv_StartTime, hv_SecondsElapsed;
    HTuple  hv_SecondsRemaining, hv_ProgressPercent, hv_ProgressPerSecond;
    HTuple  hv_TimeElapsedString, hv_TimeRemainingString, hv_DeviceNameExists;
    HTuple  hv_DeviceName, hv_StatusLeft, hv_StatusRight, hv_MaxChars;
    HTuple  hv_Str, hv_IsString, hv_Length, hv_SubStr, hv_Row1;
    HTuple  hv_Column1, hv_Row2, hv_Column2, hv_WindowTextWidth;
    HTuple  hv_WindowTextHeight;

    //
    //This procedure updates the various texts and plots.
    //It uses precomputed information (TrainInfo, EvaluationInfos,...).
    //
    GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
    if (0 != (hv_DisplayEnabled.TupleNot()))
    {
        return;
    }
    //
    GetDictTuple(hv_DisplayData, "display_param", &hv_DisplayParam);
    //
    GetDictTuple(hv_DisplayData, "window_text", &hv_WindowText);
    SetWindowParam(hv_WindowText, "flush", "false");
    //Only switch to window if the current window is not the text window (performance).
    if (HDevWindowStack::IsOpen())
        hv_WindowHandle = HDevWindowStack::GetActive();
    if (0 != (int(hv_WindowHandle!=hv_WindowText)))
    {
        HDevWindowStack::SetActive(hv_WindowText);
        hv_WindowHandle = hv_WindowText;
    }
    if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
    //
    GetDictTuple(hv_DisplayParam, "change_plot_interval_seconds", &hv_ChangePlotIntervalSeconds);
    GetDictTuple(hv_DisplayData, "last_change_plot", &hv_LastChange);
    CountSeconds(&hv_Seconds);
    GetDictTuple(hv_DisplayData, "plot_eval", &hv_PlotEval);
    if (0 != (int((hv_Seconds-hv_LastChange)>=hv_ChangePlotIntervalSeconds)))
    {
        hv_PlotEval = HTuple(hv_PlotEval.TupleNot()).TupleAnd(int((hv_EvalEpochs.TupleLength())>=2));
        SetDictTuple(hv_DisplayData, "plot_eval", hv_PlotEval);
        SetDictTuple(hv_DisplayData, "last_change_plot", hv_Seconds);
    }
    //This procedure can also be called after a training.
    //In such a case the parameter plot_function can be set to determine,
    //which plot shall be displayed.
    GetDictParam(hv_DisplayData, "key_exists", "plot_function", &hv_PlotFunctionExists);
    if (0 != hv_PlotFunctionExists)
    {
        GetDictTuple(hv_DisplayData, "plot_function", &hv_PlotFunction);
        hv_PlotEval = hv_PlotEval.TupleOr(int(hv_PlotFunction==HTuple("evaluation")));
    }
    //
    hv_ModelType = (hv_TrainInfo.TupleGetDictTuple("model_params")).TupleGetDictTuple("type");
    if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
        //For models of type 'gc_anomaly_detection'
        //no evaluation is shown.
        hv_TextPlot = "1/1";
    }
    else
    {
        if (0 != hv_PlotEval)
        {
            hv_TextPlot = "2/2";
        }
        else
        {
            hv_TextPlot = "1/2";
            hv_PlotTrainEval = 0;
        }
    }

    hv_HeadlineText = ("Showing plot "+hv_TextPlot)+":";
    //
    //Shall the training evaluation be plotted?
    hv_PlotTrainEval = 0;
    //
    //In case there are missing evaluation values (-1),
    //we just reuse the previous values.
    if (0 != (hv_EvalValuesTrain.TupleLength()))
    {
        hv_PlotTrainEval = int((hv_EvalValuesTrain.TupleMax())!=-1);
        if (0 != hv_PlotTrainEval)
        {
            TupleFind(hv_EvalValuesTrain, -1, &hv_Indices);
            if (0 != (HTuple(int(hv_Indices!=-1)).TupleAnd(int(hv_Indices!=HTuple()))))
            {
                {
                    HTuple end_val65 = (hv_Indices.TupleLength())-1;
                    HTuple step_val65 = 1;
                    for (hv_Index=0; hv_Index.Continue(end_val65, step_val65); hv_Index += step_val65)
                    {
                        if (0 != (int(HTuple(hv_Indices[hv_Index])==0)))
                        {
                            hv_EvalValuesTrain[0] = 0.0;
                        }
                        else
                        {
                            hv_EvalValuesTrain[HTuple(hv_Indices[hv_Index])] = HTuple(hv_EvalValuesTrain[HTuple(hv_Indices[hv_Index])-1]);
                        }
                    }
                }
            }
        }
    }
    //
    GetPart(hv_WindowText, &hv_PartRow1, &hv_PartColumn1, &hv_PartRow2, &hv_PartColumn2);
    GetWindowExtents(hv_WindowHandle, &hv__, &hv__, &hv_Width, &hv_Height);
    //Generate a background rectangle for the plot.
    //For a correct visualization of the rectangle, the region
    //may not be cut off.
    GetSystem("clip_region", &hv_ClipRegionValue);
    SetSystem("clip_region", "false");
    GenRectangle1(&ho_PlotBackground, 470, 9, hv_PartRow2-6, hv_PartColumn2-10);
    SetSystem("clip_region", hv_ClipRegionValue);
    //
    hv_PlotHeight = (((hv_PartRow2-30)-480)*hv_Height)/((hv_PartRow2-hv_PartRow1)+1);
    hv_LegendRow = 479;
    hv_LegendDistanceLeft = 65;
    hv_LegendDistanceRight = 85;
    //
    //Get change strategy parameters and check if a learning rate strategy exits
    hv_PlotLearningRateStrategy = 0;
    hv_RightMargin = 35;
    GetDictTuple(hv_TrainParam, "change_strategies", &hv_ChangeStrategies);
    if (0 != (int((hv_ChangeStrategies.TupleLength())>0)))
    {
        {
            HTuple end_val96 = (hv_ChangeStrategies.TupleLength())-1;
            HTuple step_val96 = 1;
            for (hv_Idx=0; hv_Idx.Continue(end_val96, step_val96); hv_Idx += step_val96)
            {
                hv_ChangeStrategy = HTuple(hv_ChangeStrategies[hv_Idx]);
                GetDictTuple(hv_ChangeStrategy, "model_param", &hv_ChangeStrategyName);
                if (0 != (int(hv_ChangeStrategyName==HTuple("learning_rate"))))
                {
                    hv_PlotLearningRateStrategy = 1;
                    GetDictTuple(hv_ChangeStrategy, "values", &hv_ChangeStrategiesValues);
                    GetDictTuple(hv_ChangeStrategy, "initial_value", &hv_ChangeStrategiesInitial);
                    //
                    //Plot parameters for the learning rate
                    hv_StrategyMin = hv_LearningRate.TupleMin();
                    hv_StrategyMax = hv_LearningRate.TupleMax();
                    hv_LogLRMin = (HTuple(1e-8).TupleMax2(hv_StrategyMin)).TupleLog10();
                    hv_LogLRMax = (HTuple(1e-8).TupleMax2(hv_StrategyMax)).TupleLog10();
                    //
                    if (0 != (int(((hv_LogLRMax-hv_LogLRMin).TupleFabs())<1e-4)))
                    {
                        hv_LogLRMin = hv_LogLRMin-5e-5;
                        hv_LogLRMax += 5e-5;
                    }
                    //
                    hv_LRScale = (hv_LogLRMax-hv_LogLRMin)/hv_PlotHeight;
                    hv_LROffset = 15;
                    hv_LogLROffset = hv_LROffset*hv_LRScale;
                    //
                    hv_StartYLearningRate = HTuple(10).TuplePow(hv_LogLRMin-(1.0*hv_LogLROffset));
                    hv_EndYLearningRate = HTuple(10).TuplePow(hv_LogLRMax+(1.0*hv_LogLROffset));
                    hv_TicksYLearningRate = (hv_PlotHeight/5)*hv_LRScale;
                    //
                    hv_LogYLearningRate = "true";
                    hv_RightMargin = 75;
                }
            }
        }
    }
    hv_LRColor = "#1332ffdd";
    hv_LRLineWidth = 2;
    hv_LRTextLegend = "'learning_rate'";
    //Space for legends
    hv_TopMarginPlots = 480+20;
    //
    //Determine current number of iterations.
    GetDictTuple(hv_TrainInfo, "num_iterations_per_epoch", &hv_NumIterationsPerEpoch);
    hv_Iterations = ((hv_Epochs*hv_NumIterationsPerEpoch).TupleCeil()).TupleInt();
    GetDictTuple(hv_TrainInfo, "num_epochs", &hv_NumEpochs);
    hv_NumIterations = ((hv_NumEpochs*hv_NumIterationsPerEpoch).TupleCeil()).TupleInt();
    hv_CurrentIteration = ((const HTuple&)hv_Iterations)[(hv_Iterations.TupleLength())-1];
    //
    //Determine x-axis values.
    GetDictTuple(hv_DisplayParam, "x_axis_label", &hv_XAxisLabel);
    if (0 != (int(hv_XAxisLabel==HTuple("epochs"))))
    {
        hv_ValuesX = hv_Epochs;
        hv_TicksX = HTuple(0.1).TupleMax2(((hv_Epochs.TupleMax())-(hv_Epochs.TupleMin()))*0.15);
        if (0 != (int(hv_EvalEpochs!=HTuple())))
        {
            hv_EvalValuesX = hv_EvalEpochs;
            hv_EvalTicksX = HTuple(0.1).TupleMax2(((hv_EvalEpochs.TupleMax())-(hv_EvalEpochs.TupleMin()))*0.15);
        }
        hv_TitleX = "Epochs";
    }
    else if (0 != (int(hv_XAxisLabel==HTuple("iterations"))))
    {
        hv_ValuesX = hv_Iterations;
        hv_TicksX = (HTuple(2).TupleMax2(((hv_Iterations.TupleMax())-(hv_Iterations.TupleMin()))*0.15)).TupleInt();
        if (0 != (int(hv_EvalEpochs!=HTuple())))
        {
            hv_EvalIterations = (hv_EvalEpochs*hv_NumIterationsPerEpoch).TupleCeil();
            hv_EvalValuesX = hv_EvalIterations;
            hv_EvalTicksX = (HTuple(2).TupleMax2(((hv_EvalIterations.TupleMax())-(hv_EvalIterations.TupleMin()))*0.15)).TupleInt();
        }
        hv_TitleX = "Iterations";
    }
    //
    //Determine y-axis values and plot the function as well as its texts.
    if (0 != hv_PlotEval)
    {
        if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),"white");
        if (HDevWindowStack::IsOpen())
            SetDraw(HDevWindowStack::GetActive(),"fill");
        if (HDevWindowStack::IsOpen())
            DispObj(ho_PlotBackground, HDevWindowStack::GetActive());
        hv_EvalValuesMin = (hv_EvalValues.TupleConcat(HTuple(0.0).TupleMax2(hv_EvalValuesTrain))).TupleMin();
        hv_EvalValuesMax = (hv_EvalValues.TupleConcat(hv_EvalValuesTrain)).TupleMax();
        if (0 != (int(((hv_EvalValuesMax-hv_EvalValuesMin).TupleAbs())<1e-3)))
        {
            hv_EvalValuesMin = hv_EvalValuesMin-5e-4;
            hv_EvalValuesMax += 5e-4;
        }
        hv_TicksY = (hv_EvalValuesMax-hv_EvalValuesMin)*0.1;
        hv_StartY = hv_EvalValuesMin-((hv_EvalValuesMax-hv_EvalValuesMin)*0.1);
        hv_EndY = hv_EvalValuesMax+((hv_EvalValuesMax-hv_EvalValuesMin)*0.1);
        //
        hv_YAxisLabel = "Evaluation value";
        GetDictTuple(hv_TrainInfo, "best_evaluation", &hv_BestEvaluationData);
        if (0 != (int((hv_BestEvaluationData.TupleLength())>0)))
        {
            GetDictTuple(hv_BestEvaluationData, "comparison_keys", &hv_BestEvaluationComparisonKeys);
            hv_YAxisLabel = "Evaluation value";
            if (0 != (int((hv_BestEvaluationComparisonKeys.TupleLength())>1)))
            {
                pretty_print_tuple(hv_BestEvaluationComparisonKeys, &hv_YAxisLabel);
                hv_YAxisLabel = ("mean("+hv_YAxisLabel)+")";
            }
            else
            {
                hv_YAxisLabel = hv_BestEvaluationComparisonKeys;
            }
        }
        //Use a smaller, non-bold font for the plot.
        set_display_font(hv_WindowText, 12, "mono", "false", "false");
        //Plot learning rate if the corresponding strategy exists.
        if (0 != hv_PlotLearningRateStrategy)
        {
            //
            //Display current values in appropriate colors.
            GetStringExtents(hv_WindowText, hv_LRTextLegend, &hv__, &hv__, &hv_StringExtendsLegendRight,
                             &hv__);
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),hv_LRTextLegend, "image", hv_LegendRow,
                         (hv_Width-hv_StringExtendsLegendRight)-hv_LegendDistanceRight, hv_LRColor,
                         "box", "false");
            plot_tuple_no_window_handling(hv_WindowText, hv_ValuesX, hv_LearningRate, "",
                                          "", hv_LRColor, ((((((((((((HTuple("log_y").Append("axes_color")).Append("start_y")).Append("end_y")).Append("ticks_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")).Append("axis_location_y")).Append("format_y")),
                                          ((((((((hv_LogYLearningRate.TupleConcat("black")).TupleConcat(hv_StartYLearningRate)).TupleConcat(hv_EndYLearningRate)).TupleConcat(hv_TicksYLearningRate)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat(hv_LRLineWidth)).TupleConcat(((HTuple("#898b8f").Append("right")).Append(".1e"))));
        }
        //Plot validation evaluation values.
        plot_tuple_no_window_handling(hv_WindowText, hv_EvalValuesX, hv_EvalValues, hv_TitleX,
                                      "", "#36a2eb", ((((((((((HTuple("axes_color").Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")),
                                      (((((((HTuple("black").TupleConcat(hv_EvalTicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
        //Plot train evaluation values.
        if (0 != hv_PlotTrainEval)
        {
            hv_Bullet = //'бё'
                    "\342\227\217";
            hv_Line = //'иD'
                    "\342\200\225";
            hv_YAxisTitle = ((((("  '"+hv_YAxisLabel)+"' (")+hv_Line)+HTuple(" validation, "))+hv_Bullet)+"-- training)";
            plot_tuple_no_window_handling(hv_WindowText, hv_EvalValuesX, hv_EvalValuesTrain,
                                          hv_TitleX, "", "#36a2eb", (((((((((((HTuple("style").Append("axes_color")).Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")),
                                          ((((((((HTuple(20).Append("black")).TupleConcat(hv_EvalTicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
            plot_tuple_no_window_handling(hv_WindowText, hv_EvalValuesX, hv_EvalValuesTrain,
                                          hv_TitleX, "", "#36a2eb", (((((((((((HTuple("style").Append("axes_color")).Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")),
                                          ((((((((HTuple("circle").Append("black")).TupleConcat(hv_EvalTicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
        }
        else
        {
            hv_YAxisTitle = ("  '"+hv_YAxisLabel)+"'";
        }
        //Display title of y-axis.
        if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_YAxisTitle, "image", hv_LegendRow,
                     hv_LegendDistanceLeft, "#36a2eb", "box", "false");
        //Reset font.
        set_display_font(hv_WindowText, 16, "mono", "true", "false");
    }
    else
    {
        if (0 != (int((hv_Epochs.TupleLength())>3)))
        {
            if (HDevWindowStack::IsOpen())
                SetColor(HDevWindowStack::GetActive(),"white");
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),"fill");
            if (HDevWindowStack::IsOpen())
                DispObj(ho_PlotBackground, HDevWindowStack::GetActive());
            //
            //Set StartY and EndY, such that there is a margin on top and bottom to
            //avoid HalxAI:: that the plot overlaps with the axis captions. (With respect to
            //the logarithmic plotting of the Loss function)
            //Set this offset in window coordinates:
            hv_Offset = 15;
            //Calculate min max values to determine the correct offset in log
            //coordinates.
            hv_LogMin = (HTuple(0.00001).TupleMax2(hv_Loss.TupleMin())).TupleLog10();
            hv_LogMax = (HTuple(0.00001).TupleMax2(hv_Loss.TupleMax())).TupleLog10();
            //
            if (0 != (int(((hv_LogMax-hv_LogMin).TupleFabs())<0.0001)))
            {
                hv_LogMin = hv_LogMin-0.00005;
                hv_LogMax += 0.00005;
            }
            //
            hv_Scale = (hv_LogMax-hv_LogMin)/hv_PlotHeight;
            hv_LogOffset = hv_Offset*hv_Scale;
            hv_StartY = HTuple(10).TuplePow(hv_LogMin-hv_LogOffset);
            hv_EndY = HTuple(10).TuplePow(hv_LogMax+hv_LogOffset);
            hv_TicksY = (hv_PlotHeight/10)*hv_Scale;
            //
            //Use a smaller, non-bold font for the plot.
            set_display_font(hv_WindowText, 12, "mono", "false", "false");
            hv_LogY = "true";
            //Plot learning rate if the corresponding strategy exists.
            if (0 != hv_PlotLearningRateStrategy)
            {
                //
                //Display current values in appropriate colors.
                GetStringExtents(hv_WindowText, hv_LRTextLegend, &hv__, &hv__, &hv_StringExtendsLegendRight,
                                 &hv__);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_LRTextLegend, "image", hv_LegendRow,
                             (hv_Width-hv_StringExtendsLegendRight)-hv_LegendDistanceRight, hv_LRColor,
                             "box", "false");
                plot_tuple_no_window_handling(hv_WindowText, hv_ValuesX, hv_LearningRate,
                                              "", "", hv_LRColor, ((((((((((((HTuple("log_y").Append("axes_color")).Append("start_y")).Append("end_y")).Append("ticks_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")).Append("axis_location_y")).Append("format_y")),
                                              ((((((((hv_LogY.TupleConcat("black")).TupleConcat(hv_StartYLearningRate)).TupleConcat(hv_EndYLearningRate)).TupleConcat(hv_TicksYLearningRate)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat(hv_LRLineWidth)).TupleConcat(((HTuple("#898b8f").Append("right")).Append(".1e"))));
            }
            hv_YAxisLabel = "Loss";
            if (HDevWindowStack::IsOpen())
                DispText(HDevWindowStack::GetActive(),"  "+hv_YAxisLabel, "image", hv_LegendRow,
                         hv_LegendDistanceLeft, "#ff6384", "box", "false");
            plot_tuple_no_window_handling(hv_WindowText, hv_ValuesX, hv_Loss, hv_TitleX,
                                          "", "#ff6384", (((((((((((HTuple("log_y").Append("axes_color")).Append("ticks_x")).Append("ticks_y")).Append("start_y")).Append("end_y")).Append("margin_top")).Append("margin_bottom")).Append("margin_left")).Append("margin_right")).Append("line_width")).Append("axes_color")),
                                          ((((((((hv_LogY.TupleConcat("black")).TupleConcat(hv_TicksX)).TupleConcat(hv_TicksY)).TupleConcat(hv_StartY)).TupleConcat(hv_EndY)).TupleConcat(hv_TopMarginPlots)).TupleConcat((HTuple(30).Append(65)))).TupleConcat(hv_RightMargin)).TupleConcat((HTuple(3).Append("#898b8f"))));
            set_display_font(hv_WindowText, 16, "mono", "true", "false");
        }
        else
        {
            hv_HeadlineText = "Waiting for data to initialize the plot...";
        }
    }

    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_HeadlineText, "image", 445, 9, "black",
                 "box", "false");
    //
    //Model parameter status.
    GetDictTuple(hv_DisplayParam, "status_model_params", &hv_TextModelParams);
    GetDictTuple(hv_TrainInfo, "model_params", &hv_ModelParams);
    hv_StatusModelParamsLeft = HTuple();
    hv_StatusModelParamsRight = HTuple();
    {
        HTuple end_val269 = (hv_TextModelParams.TupleLength())-1;
        HTuple step_val269 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val269, step_val269); hv_Index += step_val269)
        {
            hv_ParName = HTuple(hv_TextModelParams[hv_Index]);
            try
            {
                GetDictTuple(hv_ModelParams, hv_ParName, &hv_Tuple);
            }
            // catch (Exception)
            catch (HException &HDevExpDefaultException)
            {
                HDevExpDefaultException.ToHTuple(&hv_Exception);
                continue;
            }
            if (0 != (HTuple(int(hv_ParName==HTuple("batch_size_multiplier"))).TupleAnd(int(hv_Tuple==1))))
            {
                continue;
            }
            hv_StatusModelParamsLeft = hv_StatusModelParamsLeft.TupleConcat(("'"+hv_ParName)+"'");

            pretty_print_tuple(hv_Tuple, &hv_TupleStr);
            hv_StatusModelParamsRight = hv_StatusModelParamsRight.TupleConcat(hv_TupleStr);
        }
    }
    if (0 != (int((hv_StatusModelParamsLeft.TupleLength())>0)))
    {
        hv_StatusModelParamsLeft = HTuple("Model parameters:").TupleConcat("  "+hv_StatusModelParamsLeft);
        hv_StatusModelParamsRight = HTuple(" ").TupleConcat(hv_StatusModelParamsRight);
    }
    //
    //Evaluation status.
    hv_StatusEvaluationLeft = HTuple();
    hv_StatusEvaluationRight = HTuple();
    GetDictTuple(hv_TrainInfo, "best_evaluation", &hv_BestEvaluationData);
    if (0 != (int((hv_BestEvaluationData.TupleLength())>0)))
    {
        GetDictTuple(hv_BestEvaluationData, "comparison_keys", &hv_BestEvaluationComparisonKeys);
        GetDictTuple(hv_BestEvaluationData, "best_value", &hv_BestEvaluationValue);
        GetDictTuple(hv_BestEvaluationData, "best_info", &hv_BestEvaluationInfo);
        GetDictTuple(hv_BestEvaluationInfo, "epoch", &hv_BestEvaluationEpoch);
        GetDictTuple(hv_BestEvaluationData, "best_value_train", &hv_BestTrainEvaluationValue);
        GetDictTuple(hv_BestEvaluationData, "best_info_train", &hv_BestTrainEvaluationInfo);
        GetDictTuple(hv_BestTrainEvaluationInfo, "epoch", &hv_BestTrainEvaluationEpoch);
        if (0 != (int((hv_BestEvaluationComparisonKeys.TupleLength())>1)))
        {
            hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Measures");
            hv_BestEvaluationComparisonKeysStr = HTuple(HTuple("multiple (")+(hv_BestEvaluationComparisonKeys.TupleLength()))+")";
        }
        else
        {
            hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Measure");
            hv_BestEvaluationComparisonKeysStr = ("'"+hv_BestEvaluationComparisonKeys)+"'";
        }
        //
        hv_StatusEvaluationRight = hv_StatusEvaluationRight.TupleConcat(hv_BestEvaluationComparisonKeysStr);
        //Validation value.
        hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Best validation (value / epoch)");
        hv_StatusEvaluationRight = hv_StatusEvaluationRight.TupleConcat(((hv_BestEvaluationValue.TupleString("0.3f"))+" / ")+(hv_BestEvaluationEpoch.TupleString("0.1f")));
        //Training value.
        if (0 != hv_PlotTrainEval)
        {
            hv_StatusEvaluationLeft = hv_StatusEvaluationLeft.TupleConcat("Best training (value / epoch)");
            hv_StatusEvaluationRight = hv_StatusEvaluationRight.TupleConcat(((hv_BestTrainEvaluationValue.TupleString("0.3f"))+" / ")+(hv_BestTrainEvaluationEpoch.TupleString("0.1f")));
        }
        //
        hv_StatusEvaluationLeft = HTuple("Evaluation:").TupleConcat("  "+hv_StatusEvaluationLeft);
        hv_StatusEvaluationRight = HTuple(" ").TupleConcat(hv_StatusEvaluationRight);
    }
    //
    //Train status.
    hv_StatusTrainLeft = HTuple();
    hv_StatusTrainRight = HTuple();
    GetDictTuple(hv_TrainInfo, "epoch", &hv_EpochReal);
    GetDictTuple(hv_TrainInfo, "num_epochs", &hv_NumEpochs);
    hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Epoch");
    hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat(((hv_EpochReal.TupleString(".1f"))+" of ")+(hv_NumEpochs.TupleString(".1f")));
    hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Iteration");
    hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat((hv_CurrentIteration+" of ")+hv_NumIterations);
    GetDictTuple(hv_TrainInfo, "mean_loss", &hv_MeanLoss);
    if (0 != (int((hv_MeanLoss.TupleLength())==0)))
    {
        hv_MeanLossStr = "";
    }
    else
    {
        hv_MeanLossStr = hv_MeanLoss.TupleString("0.4f");
    }
    hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Loss");
    hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat(hv_MeanLossStr);
    //
    //Elapsed and remaining time.
    GetDictParam(hv_DisplayData, "key_exists", "time_elapsed", &hv_TimeElapsedExists);
    if (0 != (hv_TimeElapsedExists.TupleNot()))
    {
        //During training the key is not set and the time has to be determined.
        GetDictTuple(hv_TrainInfo, "start_epoch", &hv_StartEpoch);
        GetDictTuple(hv_TrainInfo, "start_time", &hv_StartTime);
        estimate_progress(hv_StartTime, hv_StartEpoch, hv_EpochReal, hv_NumEpochs, &hv_SecondsElapsed,
                          &hv_SecondsRemaining, &hv_ProgressPercent, &hv_ProgressPerSecond);
        timespan_string(hv_SecondsElapsed, "auto", &hv_TimeElapsedString);
        timespan_string(hv_SecondsRemaining, "top2", &hv_TimeRemainingString);
        hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat((HTuple("Time elapsed").Append("Time left")));
        hv_StatusTrainRight = (hv_StatusTrainRight.TupleConcat(hv_TimeElapsedString)).TupleConcat(hv_TimeRemainingString);
    }
    else
    {
        //For display after the finished training the key may be set.
        //In case of a given value, display it.
        GetDictTuple(hv_DisplayData, "time_elapsed", &hv_TimeElapsedString);
        if (0 != (int(hv_TimeElapsedString!=HTuple(""))))
        {
            hv_StatusTrainLeft = hv_StatusTrainLeft.TupleConcat("Time elapsed");
            hv_StatusTrainRight = hv_StatusTrainRight.TupleConcat(hv_TimeElapsedString);
        }
    }
    //
    //Check if Device Status is there and combine it all together.
    GetDictParam(hv_ModelParams, "key_exists", "device_name", &hv_DeviceNameExists);
    if (0 != hv_DeviceNameExists)
    {
        GetDictTuple(hv_ModelParams, "device_name", &hv_DeviceName);
        //Combine all with device name.
        hv_StatusLeft.Clear();
        hv_StatusLeft[0] = "train_dl_model";
        hv_StatusLeft[1] = " ";
        hv_StatusLeft[2] = " ";
        hv_StatusLeft.Append(hv_StatusTrainLeft);
        hv_StatusLeft.Append(" ");
        hv_StatusLeft.Append(hv_StatusEvaluationLeft);
        hv_StatusLeft.Append(" ");
        hv_StatusLeft.Append(hv_StatusModelParamsLeft);
        hv_StatusLeft.Append(" ");
        hv_StatusRight.Clear();
        hv_StatusRight[0] = "Used Device:";
        hv_StatusRight.Append(hv_DeviceName);
        hv_StatusRight.Append(" ");
        hv_StatusRight.Append(hv_StatusTrainRight);
        hv_StatusRight.Append(" ");
        hv_StatusRight.Append(hv_StatusEvaluationRight);
        hv_StatusRight.Append(" ");
        hv_StatusRight.Append(hv_StatusModelParamsRight);
        hv_StatusRight.Append(" ");
    }
    else
    {
        //Combine all without device name.
        hv_StatusLeft.Clear();
        hv_StatusLeft[0] = "train_dl_model";
        hv_StatusLeft[1] = " ";
        hv_StatusLeft[2] = " ";
        hv_StatusLeft.Append(hv_StatusTrainLeft);
        hv_StatusLeft.Append(" ");
        hv_StatusLeft.Append(hv_StatusEvaluationLeft);
        hv_StatusLeft.Append(" ");
        hv_StatusLeft.Append(hv_StatusModelParamsLeft);
        hv_StatusLeft.Append(" ");
        hv_StatusRight.Clear();
        hv_StatusRight[0] = " ";
        hv_StatusRight[1] = " ";
        hv_StatusRight[2] = " ";
        hv_StatusRight.Append(hv_StatusTrainRight);
        hv_StatusRight.Append(" ");
        hv_StatusRight.Append(hv_StatusEvaluationRight);
        hv_StatusRight.Append(" ");
        hv_StatusRight.Append(hv_StatusModelParamsRight);
        hv_StatusRight.Append(" ");
    }
    //
    //Cut strings with too many chars.
    hv_MaxChars = 20;
    {
        HTuple end_val377 = (hv_StatusRight.TupleLength())-1;
        HTuple step_val377 = 1;
        for (hv_Index=1; hv_Index.Continue(end_val377, step_val377); hv_Index += step_val377)
        {
            hv_Str = HTuple(hv_StatusRight[hv_Index]);
            TupleIsString(hv_Str, &hv_IsString);
            if (0 != hv_IsString)
            {
                TupleStrlen(hv_Str, &hv_Length);
                if (0 != (int(hv_Length>hv_MaxChars)))
                {
                    hv_SubStr = (hv_Str.TupleSubstr(0,hv_MaxChars-3))+"...";
                    hv_StatusRight[hv_Index] = hv_SubStr;
                }
            }
        }
    }
    //
    //Display the text.
    GetDictTuple(hv_DisplayData, "window_text", &hv_WindowText);
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_StatusLeft, "window", "top", "left",
                 "black", "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_StatusRight, "window", "top", "right",
                 "black", "box", "false");
    FlushBuffer(hv_WindowText);
    SetWindowParam(hv_WindowText, "flush", "true");
    GetPart(hv_WindowText, &hv_Row1, &hv_Column1, &hv_Row2, &hv_Column2);
    GetDictTuple(hv_DisplayData, "window_text_width", &hv_WindowTextWidth);
    GetDictTuple(hv_DisplayData, "window_text_height", &hv_WindowTextHeight);
    if (0 != (HTuple(int((hv_WindowTextWidth-1)!=(hv_Column2-hv_Column1))).TupleOr(int((hv_WindowTextHeight-1)!=(hv_Row2-hv_Row1)))))
    {
        if (HDevWindowStack::IsOpen())
            SetPart(HDevWindowStack::GetActive(),hv_Row1, hv_Column1, (hv_Row1+hv_WindowTextHeight)-1,
                    (hv_Column1+hv_WindowTextWidth)-1);
    }
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Display a map of weights.
void HalxAI:: dev_display_weight_regions (HObject ho_ImageWeight, HTuple hv_DrawTransparency,
                                          HTuple hv_SegMaxWeight, HTuple *hv_Colors)
{

    // Local iconic variables
    HObject  ho_Domain, ho_WeightsRegion;

    // Local control variables
    HTuple  hv_NumColors, hv_WeightsColorsAlpha, hv_Rows;
    HTuple  hv_Columns, hv_GrayVal, hv_GrayValWeight, hv_ColorIndex;
    HTuple  hv_ClassColor;

    //
    //This procedure displays a map of the weights
    //given in ImageWeight as regions.
    //The transparency can be adjusted.
    //The used colors are returned.
    //
    //Define colors.
    hv_NumColors = 20;
    get_distinct_colors(hv_NumColors, 0, 0, 160, &(*hv_Colors));
    TupleInverse((*hv_Colors), &(*hv_Colors));
    hv_WeightsColorsAlpha = (*hv_Colors)+hv_DrawTransparency;
    //
    //Get gay values of ImageWeight.
    GetDomain(ho_ImageWeight, &ho_Domain);
    GetRegionPoints(ho_Domain, &hv_Rows, &hv_Columns);
    GetGrayval(ho_ImageWeight, hv_Rows, hv_Columns, &hv_GrayVal);
    //
    //Check that the gray values of the image
    //are below the specified maximum.
    if (0 != (int((hv_GrayVal.TupleMax())>hv_SegMaxWeight)))
    {
        throw HException(((("The maximum weight ("+(hv_GrayVal.TupleMax()))+") in the weight image is greater than the given SegMaxWeight (")+hv_SegMaxWeight)+").");
    }
    //
    while (0 != (int(hv_GrayVal!=HTuple())))
    {
        //Go through all gray value 'groups',
        //starting from the maximum.
        hv_GrayValWeight = hv_GrayVal.TupleMax();
        hv_GrayVal = hv_GrayVal.TupleRemove(hv_GrayVal.TupleFind(hv_GrayValWeight));
        Threshold(ho_ImageWeight, &ho_WeightsRegion, hv_GrayValWeight, hv_GrayValWeight);
        //
        //Visualize the respective group.
        hv_ColorIndex = (((hv_GrayValWeight/hv_SegMaxWeight)*(hv_NumColors-1)).TupleCeil()).TupleInt();
        hv_ClassColor = HTuple(hv_WeightsColorsAlpha[hv_ColorIndex]);
        if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),hv_ClassColor);
        if (HDevWindowStack::IsOpen())
            DispObj(ho_WeightsRegion, HDevWindowStack::GetActive());
    }
    return;
}

// Chapter: Develop
// Short Description: Open a new graphics window that preserves the aspect ratio of the given image size.
void HalxAI:: dev_open_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width,
                                        HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit, HTuple *hv_WindowHandle)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
    HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
    HTuple  hv_WindowWidth, hv_WindowHeight;

    //This procedure open a new graphic window
    //such that it fits into the limits specified by WidthLimit
    //and HeightLimit, but also maintains the correct aspect ratio
    //given by Width and Height.
    //
    //If it is impossible to match the minimum and maximum extent requirements
    //at the same time (f.e. if the image is very long but narrow),
    //the maximum value gets a higher priority.
    //
    //Parse input tuple WidthLimit
    if (0 != (HTuple(int((hv_WidthLimit.TupleLength())==0)).TupleOr(int(hv_WidthLimit<0))))
    {
        hv_MinWidth = 500;
        hv_MaxWidth = 800;
    }
    else if (0 != (int((hv_WidthLimit.TupleLength())==1)))
    {
        hv_MinWidth = 0;
        hv_MaxWidth = hv_WidthLimit;
    }
    else
    {
        hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
        hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
    }
    //Parse input tuple HeightLimit
    if (0 != (HTuple(int((hv_HeightLimit.TupleLength())==0)).TupleOr(int(hv_HeightLimit<0))))
    {
        hv_MinHeight = 400;
        hv_MaxHeight = 600;
    }
    else if (0 != (int((hv_HeightLimit.TupleLength())==1)))
    {
        hv_MinHeight = 0;
        hv_MaxHeight = hv_HeightLimit;
    }
    else
    {
        hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
        hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
    }
    //
    //Test, if window size has to be changed.
    hv_ResizeFactor = 1;
    //First, expand window to the minimum extents (if necessary).
    if (0 != (HTuple(int(hv_MinWidth>hv_Width)).TupleOr(int(hv_MinHeight>hv_Height))))
    {
        hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
    }
    hv_TempWidth = hv_Width*hv_ResizeFactor;
    hv_TempHeight = hv_Height*hv_ResizeFactor;
    //Then, shrink window to maximum extents (if necessary).
    if (0 != (HTuple(int(hv_MaxWidth<hv_TempWidth)).TupleOr(int(hv_MaxHeight<hv_TempHeight))))
    {
        hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
    }
    hv_WindowWidth = hv_Width*hv_ResizeFactor;
    hv_WindowHeight = hv_Height*hv_ResizeFactor;
    //Resize window
    SetWindowAttr("background_color","black");
    OpenWindow(hv_Row,hv_Column,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandle));
    HDevWindowStack::Push((*hv_WindowHandle));
    if (HDevWindowStack::IsOpen())
        SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
    return;
}

// Chapter: Develop
// Short Description: Resize a graphics window with a given maximum extent such that it preserves the aspect ratio of a given width and height
void HalxAI:: dev_resize_window_fit_size (HTuple hv_Row, HTuple hv_Column, HTuple hv_Width,
                                          HTuple hv_Height, HTuple hv_WidthLimit, HTuple hv_HeightLimit)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_MinWidth, hv_MaxWidth, hv_MinHeight;
    HTuple  hv_MaxHeight, hv_ResizeFactor, hv_TempWidth, hv_TempHeight;
    HTuple  hv_WindowWidth, hv_WindowHeight;

    //This procedure adjusts the size of the current window
    //such that it fits into the limits specified by WidthLimit
    //and HeightLimit, but also maintains the correct aspect ratio
    //given by Width and Height.
    //
    //If it is impossible to match the minimum and maximum extent requirements
    //at the same time (f.e. if the image is very long but narrow),
    //the maximum value gets a higher priority.
    //
    //Parse input tuple WidthLimit
    if (0 != (HTuple(int((hv_WidthLimit.TupleLength())==0)).TupleOr(int(hv_WidthLimit<0))))
    {
        hv_MinWidth = 500;
        hv_MaxWidth = 800;
    }
    else if (0 != (int((hv_WidthLimit.TupleLength())==1)))
    {
        hv_MinWidth = 0;
        hv_MaxWidth = hv_WidthLimit;
    }
    else
    {
        hv_MinWidth = ((const HTuple&)hv_WidthLimit)[0];
        hv_MaxWidth = ((const HTuple&)hv_WidthLimit)[1];
    }
    //Parse input tuple HeightLimit
    if (0 != (HTuple(int((hv_HeightLimit.TupleLength())==0)).TupleOr(int(hv_HeightLimit<0))))
    {
        hv_MinHeight = 400;
        hv_MaxHeight = 600;
    }
    else if (0 != (int((hv_HeightLimit.TupleLength())==1)))
    {
        hv_MinHeight = 0;
        hv_MaxHeight = hv_HeightLimit;
    }
    else
    {
        hv_MinHeight = ((const HTuple&)hv_HeightLimit)[0];
        hv_MaxHeight = ((const HTuple&)hv_HeightLimit)[1];
    }
    //
    //Test, if window size has to be changed.
    hv_ResizeFactor = 1;
    //First, expand window to the minimum extents (if necessary).
    if (0 != (HTuple(int(hv_MinWidth>hv_Width)).TupleOr(int(hv_MinHeight>hv_Height))))
    {
        hv_ResizeFactor = (((hv_MinWidth.TupleReal())/hv_Width).TupleConcat((hv_MinHeight.TupleReal())/hv_Height)).TupleMax();
    }
    hv_TempWidth = hv_Width*hv_ResizeFactor;
    hv_TempHeight = hv_Height*hv_ResizeFactor;
    //Then, shrink window to maximum extents (if necessary).
    if (0 != (HTuple(int(hv_MaxWidth<hv_TempWidth)).TupleOr(int(hv_MaxHeight<hv_TempHeight))))
    {
        hv_ResizeFactor = hv_ResizeFactor*((((hv_MaxWidth.TupleReal())/hv_TempWidth).TupleConcat((hv_MaxHeight.TupleReal())/hv_TempHeight)).TupleMin());
    }
    hv_WindowWidth = hv_Width*hv_ResizeFactor;
    hv_WindowHeight = hv_Height*hv_ResizeFactor;
    //Resize window
    if (HDevWindowStack::IsOpen())
        SetWindowExtents(HDevWindowStack::GetActive(),hv_Row, hv_Column, hv_WindowWidth,
                         hv_WindowHeight);
    if (HDevWindowStack::IsOpen())
        SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
    return;
}

// Chapter: Develop
// Short Description: Switch dev_update_pc, dev_update_var, and dev_update_window to 'off'.
void HalxAI:: dev_update_off ()
{

    //This procedure sets different update settings to 'off'.
    //This is useful to get the best performance and reduce overhead.
    //
    // dev_update_pc(...); only in hdevelop
    // dev_update_var(...); only in hdevelop
    // dev_update_window(...); only in hdevelop
    return;
}

// Chapter: System / Operating System
// Short Description: Estimate the remaining time for a task given the current progress.
void HalxAI:: estimate_progress (HTuple hv_SecondsStart, HTuple hv_ProgressMin, HTuple hv_ProgressCurrent,
                                 HTuple hv_ProgressMax, HTuple *hv_SecondsElapsed, HTuple *hv_SecondsRemaining,
                                 HTuple *hv_ProgressPercent, HTuple *hv_ProgressPerSecond)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_SecondsNow, hv_Epsilon, hv_ProgressRemaining;

    //
    //This procedure estimates the remaining time in seconds,
    //given a start time and a progress value.
    //
    //Get current time.
    CountSeconds(&hv_SecondsNow);
    //
    //Get elapsed time span.
    (*hv_SecondsElapsed) = hv_SecondsNow-hv_SecondsStart;
    //
    //A very small additive constant to avoid HalxAI:: division by zero.
    hv_Epsilon = 1e-6;
    //
    //Estimate remaining time based on elapsed time.
    hv_ProgressRemaining = hv_ProgressMax-hv_ProgressCurrent;
    (*hv_ProgressPerSecond) = ((hv_ProgressCurrent-hv_ProgressMin).TupleReal())/(((*hv_SecondsElapsed).TupleReal())+hv_Epsilon);
    (*hv_SecondsRemaining) = hv_ProgressRemaining/((*hv_ProgressPerSecond)+hv_Epsilon);
    //
    //Get current progress in percent.
    (*hv_ProgressPercent) = (100*((hv_ProgressCurrent-hv_ProgressMin).TupleReal()))/(((hv_ProgressMax-hv_ProgressMin).TupleReal())+hv_Epsilon);
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Evaluate the model given by DLModelHandle on the selected samples of DLDataset.
void HalxAI:: evaluate_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_SampleSelectMethod,
                                 HTuple hv_SampleSelectValues, HTuple hv_GenParam, HTuple *hv_EvaluationResult,
                                 HTuple *hv_EvalParams)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ModelType, hv_ClassIDs, hv_ClassNames;
    HTuple  hv_Alphabet, hv_BatchSize, hv_InstanceTypeModel;
    HTuple  hv_Exception, hv_IsInstanceSegmentation, hv_InstanceType;
    HTuple  hv_ModelIgnoreClassIDs, hv_ShowProgress, hv_GenParamKeys;
    HTuple  hv_OptionalKeyNames, hv_GenParamIndex, hv_IoUThreshold;
    HTuple  hv_MaxNumDetections, hv_AreaRanges, hv_DetailedEvaluation;
    HTuple  hv_AllocationBlockLength, hv_IgnoreClassIDs, hv_AllIgnoreClassIDs;
    HTuple  hv_EvaluateClassIDs, hv_ClassesToEvaluate, hv_KeyExists;
    HTuple  hv_ClassIDsToEvaluate, hv_AnomalyClassificationThresholds;
    HTuple  hv_EvaluateMask, hv_Value, hv_Measures, hv_IgnoreDirection;
    HTuple  hv_ClassInfoExists, hv_DatasetClassIDs, hv_ClassIDsToClassNames;
    HTuple  hv_EvaluateClassNames, hv_DLSamples, hv_SampleIndices;
    HTuple  hv_NumSamples, hv_NumBatches, hv_RunningMeasures;
    HTuple  hv_Outputs, hv_EvalGCAnomalyNetworks, hv_ModelGCAnomalyNetworks;
    HTuple  hv_DefaultRequested, hv_EvalAnomalyNetworkIndex;
    HTuple  hv_EvalGCAnomalyNetwork, hv_FindIndex, hv_Progress;
    HTuple  hv_TaskInfo, hv_SecondsStart, hv_BatchIndex, hv_BatchStart;
    HTuple  hv_BatchEnd, hv_SamplesIndicesBatch, hv_DLSamplesBatch;
    HTuple  hv_DLResultsBatch, hv_SecondsElapsed, hv_SecondsRemaining;
    HTuple  hv_ProgressPercent, hv_ProgressPerSecond, hv_TimeElapsedString;
    HTuple  hv_TimeRemainingString;

    //This procedure applies the model given by DLModelHandle on the selected samples
    //of DLDataset and evaluates the results against the ground truth annotations
    //to calculate evaluation measures.
    //
    //Input:
    // - DLDataset.
    // - DLModelHandle.
    // - SampleSelectMethod: Method by which the samples are selected.
    // - SampleSelectValues: Identifier used to retrieve the samples from the DLDataset
    //                       for the corresponding selection method.
    // - GenParam: Parameters of the evaluation that should be changed from the default.
    //
    //Output:
    // - EvaluationResult: Dictionary containing the output measures.
    // - EvalParams: Dictionary with the used evaluation parameters.
    //
    //** Initialization: ***
    //
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("3d_gripping_point_detection"))).TupleAnd(int(hv_ModelType!=HTuple("anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))))
    {
        throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
    }
    //
    //Check if model has been normalized, if required by model type.
    if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
        check_dl_gc_anomaly_scores_normalization(hv_DLModelHandle, HTuple());
    }
    //
    //Get the class IDs as set in the model.
    if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
        //Only the gripping_map class is evaluated.
        GetDlModelParam(hv_DLModelHandle, "class_ids", &hv_ClassIDs);
        GetDlModelParam(hv_DLModelHandle, "class_names", &hv_ClassNames);
        hv_ClassIDs = HTuple(hv_ClassIDs[hv_ClassNames.TupleFind("gripping_map")]);
    }
    else if (0 != (HTuple(int(hv_ModelType==HTuple("anomaly_detection"))).TupleOr(int(hv_ModelType==HTuple("gc_anomaly_detection")))))
    {
        //Default for anomaly detection and Global Context Anomaly Detection is 0,1.
        hv_ClassIDs.Clear();
        hv_ClassIDs[0] = 0;
        hv_ClassIDs[1] = 1;
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
    {
        //No Class IDs in case of ocr_recognition models
        GetDlModelParam(hv_DLModelHandle, "alphabet", &hv_Alphabet);
        TupleGenSequence(0, hv_Alphabet.TupleLength(), 1, &hv_ClassIDs);
    }
    else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
    {
        //Default for ocr_detection. Only evaluate word.
        //0: word, 1: char, 2: ignore
        hv_ClassIDs = 0;
    }
    else
    {
        GetDlModelParam(hv_DLModelHandle, "class_ids", &hv_ClassIDs);
    }
    //
    //Get the batch size as set in the model.
    GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSize);
    //
    //Generate default parameters.
    create_evaluation_default_param(hv_ModelType, hv_ClassIDs, &(*hv_EvalParams));
    //
    //Get model specific information.
    if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        try
        {
            GetDlModelParam(hv_DLModelHandle, "instance_type", &hv_InstanceTypeModel);
        }
        // catch (Exception)
        catch (HException &HDevExpDefaultException)
        {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            hv_InstanceTypeModel = "rectangle1";
        }
        GetDlModelParam(hv_DLModelHandle, "instance_segmentation", &hv_IsInstanceSegmentation);
        if (0 != (int(hv_IsInstanceSegmentation==HTuple("true"))))
        {
            hv_InstanceType = "mask";
        }
        else
        {
            hv_InstanceType = hv_InstanceTypeModel;
        }
        //Note, these are the defaults. If the user specifies
        //'evaluate_mask' as false, the evaluation will use
        //the instance type of the model (InstanceTypeModel).
    }
    else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
    {
        GetDlModelParam(hv_DLModelHandle, "ignore_class_ids", &hv_ModelIgnoreClassIDs);
    }
    //
    //By default we do not show the progress of evaluation.
    hv_ShowProgress = 0;
    //
    //Set user specified parameters.
    if (0 != (int(hv_GenParam!=HTuple())))
    {
        GetDictParam(hv_GenParam, "keys", HTuple(), &hv_GenParamKeys);
        hv_OptionalKeyNames.Clear();
        hv_OptionalKeyNames[0] = "measures";
        hv_OptionalKeyNames[1] = "evaluation_type";
        hv_OptionalKeyNames[2] = "class_ids";
        hv_OptionalKeyNames[3] = "num_classes";
        hv_OptionalKeyNames[4] = "evaluate_instances";
        hv_OptionalKeyNames[5] = "gc_anomaly_networks";
        hv_OptionalKeyNames[6] = "gripping_point_params";
        {
            HTuple end_val82 = (hv_GenParamKeys.TupleLength())-1;
            HTuple step_val82 = 1;
            for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val82, step_val82); hv_GenParamIndex += step_val82)
            {
                if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("show_progress"))))
                {
                    //Show the progress of the evaluation.
                    GetDictTuple(hv_GenParam, "show_progress", &hv_ShowProgress);
                    hv_ShowProgress = HTuple(int(hv_ShowProgress==HTuple("true"))).TupleOr(int(hv_ShowProgress==1));
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("iou_threshold"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
                {
                    //Set IoU threshold.
                    GetDictTuple(hv_GenParam, "iou_threshold", &hv_IoUThreshold);
                    SetDictTuple((*hv_EvalParams), "iou_threshold", hv_IoUThreshold);
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("max_num_detections"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
                {
                    //Set maximal number detections.
                    GetDictTuple(hv_GenParam, "max_num_detections", &hv_MaxNumDetections);
                    SetDictTuple((*hv_EvalParams), "max_num_detections", hv_MaxNumDetections);
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("area_ranges"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
                {
                    //Set area ranges.
                    GetDictTuple(hv_GenParam, "area_ranges", &hv_AreaRanges);
                    SetDictTuple((*hv_EvalParams), "area_ranges", hv_AreaRanges);
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("detailed_evaluation"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
                {
                    //Set detailed evaluation.
                    GetDictTuple(hv_GenParam, "detailed_evaluation", &hv_DetailedEvaluation);
                    SetDictTuple((*hv_EvalParams), "detailed_evaluation", hv_DetailedEvaluation);
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("allocation_block_length"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
                {
                    //Set length of blocks that are allocated during evaluation.
                    GetDictTuple(hv_GenParam, "allocation_block_length", &hv_AllocationBlockLength);
                    SetDictTuple((*hv_EvalParams), "allocation_block_length", hv_AllocationBlockLength);
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("interpolate_pr_curves"))).TupleAnd(HTuple(int(hv_ModelType==HTuple("detection"))).TupleOr(int(hv_ModelType==HTuple("ocr_detection"))))))
                {
                    //Set interpolation of precision-recall curves.
                    GetDictTuple(hv_GenParam, "interpolate_pr_curves", &hv_DetailedEvaluation);
                    SetDictTuple((*hv_EvalParams), "interpolate_pr_curves", hv_DetailedEvaluation);
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("ignore_class_ids"))).TupleAnd(int(hv_ModelType==HTuple("segmentation")))))
                {
                    //Set ignore class IDs.
                    GetDictTuple(hv_GenParam, "ignore_class_ids", &hv_IgnoreClassIDs);
                    //Merge the specified ignore class IDs with the model ignore class IDs.
                    hv_AllIgnoreClassIDs = ((hv_ModelIgnoreClassIDs.TupleConcat(hv_IgnoreClassIDs)).TupleSort()).TupleUniq();
                    SetDictTuple((*hv_EvalParams), "ignore_class_ids", hv_AllIgnoreClassIDs);
                    //Remove the ignore class IDs from the model class IDs.
                    TupleDifference(hv_ClassIDs, hv_IgnoreClassIDs, &hv_EvaluateClassIDs);
                    SetDictTuple((*hv_EvalParams), "class_ids", hv_EvaluateClassIDs);
                    SetDictTuple((*hv_EvalParams), "num_classes", hv_EvaluateClassIDs.TupleLength());
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("class_names_to_evaluate"))).TupleAnd(int(hv_ModelType==HTuple("classification")))))
                {
                    //Class names to be used in evaluation.
                    //To transform the names to IDs later, one has to remember the class names.
                    GetDictTuple(hv_GenParam, "class_names_to_evaluate", &hv_ClassesToEvaluate);
                    GetDlModelParam(hv_DLModelHandle, "class_names", &hv_ClassNames);
                    SetDictTuple((*hv_EvalParams), "class_names_to_evaluate", hv_ClassesToEvaluate);
                    SetDictTuple((*hv_EvalParams), "class_names", hv_ClassNames);
                    GetDictParam((*hv_EvalParams), "key_exists", "class_ids_to_evaluate", &hv_KeyExists);
                    if (0 != hv_KeyExists)
                    {
                        //To avoid HalxAI:: inconsistent class names/IDs, remove the older ones.
                        RemoveDictKey((*hv_EvalParams), "class_ids_to_evaluate");
                    }
                }
                else if (0 != (HTuple(int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("class_ids_to_evaluate"))).TupleAnd(int(hv_ModelType==HTuple("classification")))))
                {
                    //Class IDs to be used in evaluation.
                    GetDictTuple(hv_GenParam, "class_ids_to_evaluate", &hv_ClassIDsToEvaluate);
                    SetDictTuple((*hv_EvalParams), "class_ids_to_evaluate", hv_ClassIDsToEvaluate);
                    GetDictParam((*hv_EvalParams), "key_exists", "class_names_to_evaluate", &hv_KeyExists);
                    if (0 != hv_KeyExists)
                    {
                        //To avoid HalxAI:: inconsistent class names/IDs, remove the older ones.
                        RemoveDictKey((*hv_EvalParams), "class_names_to_evaluate");
                    }
                }
                else if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("anomaly_classification_thresholds"))))
                {
                    //Set anomaly classification threshold for confusion matrices.
                    GetDictTuple(hv_GenParam, "anomaly_classification_thresholds", &hv_AnomalyClassificationThresholds);
                    SetDictTuple((*hv_EvalParams), "anomaly_classification_thresholds", hv_AnomalyClassificationThresholds);
                }
                else if (0 != (int(HTuple(hv_GenParamKeys[hv_GenParamIndex])==HTuple("evaluate_mask"))))
                {
                    GetDictTuple(hv_GenParam, "evaluate_mask", &hv_EvaluateMask);
                    if (0 != (hv_EvaluateMask.TupleNot()))
                    {
                        hv_InstanceType = hv_InstanceTypeModel;
                    }
                }
                else if (0 != (int((hv_OptionalKeyNames.TupleFind(HTuple(hv_GenParamKeys[hv_GenParamIndex])))!=-1)))
                {
                    GetDictTuple(hv_GenParam, HTuple(hv_GenParamKeys[hv_GenParamIndex]), &hv_Value);
                    SetDictTuple((*hv_EvalParams), HTuple(hv_GenParamKeys[hv_GenParamIndex]),
                                 hv_Value);
                }
                else
                {
                    throw HException(("Unknown parameter : '"+HTuple(hv_GenParamKeys[hv_GenParamIndex]))+"'");
                }
            }
        }
    }
    //
    //Finally specify the detection evaluation based on all given parameters and defaults.
    if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        if (0 != (int(hv_InstanceType==HTuple("mask"))))
        {
            SetDictTuple((*hv_EvalParams), "evaluate_mask", 1);
            GetDictTuple((*hv_EvalParams), "measures", &hv_Measures);
            SetDictTuple((*hv_EvalParams), "measures", hv_Measures.TupleDifference("soap"));
        }
        else
        {
            SetDictTuple((*hv_EvalParams), "evaluate_mask", 0);
        }
        //Overwrite instance_type
        SetDictTuple((*hv_EvalParams), "instance_type", hv_InstanceType);
        //For rectangle2 detection with ignore_direction set to false, we also evaluate the
        //precision of the predicted angle using the Score of Angle Precision (SoAP).
        if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
        {
            GetDlModelParam(hv_DLModelHandle, "ignore_direction", &hv_IgnoreDirection);
            if (0 != (int(hv_IgnoreDirection==HTuple("false"))))
            {
                GetDictTuple((*hv_EvalParams), "measures", &hv_Measures);
                SetDictTuple((*hv_EvalParams), "measures", hv_Measures.TupleConcat("soap"));
            }
        }
    }
    //
    //Set class names.
    if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
    {
        SetDictTuple((*hv_EvalParams), "class_names", "gripping_map");
    }
    else
    {
        //Get the class names from the dataset if present.
        GetDictParam(hv_DLDataset, "key_exists", (HTuple("class_names").Append("class_ids")),
                     &hv_ClassInfoExists);
        if (0 != (int((hv_ClassInfoExists.TupleSum())==(hv_ClassInfoExists.TupleLength()))))
        {
            GetDictTuple(hv_DLDataset, "class_names", &hv_ClassNames);
            GetDictTuple(hv_DLDataset, "class_ids", &hv_DatasetClassIDs);
            //Set the class names only for the class IDs that are evaluated.
            GetDictTuple((*hv_EvalParams), "class_ids", &hv_EvaluateClassIDs);
            hv_ClassIDsToClassNames = HTuple((hv_DatasetClassIDs.TupleMax())+1,"");
            hv_ClassIDsToClassNames[hv_DatasetClassIDs] = hv_ClassNames;
            if (0 != (int((hv_EvaluateClassIDs.TupleLength())==(hv_ClassNames.TupleLength()))))
            {
                hv_EvaluateClassNames = HTuple(hv_ClassIDsToClassNames[hv_EvaluateClassIDs]);
                //Set the class names to EvalParams.
                SetDictTuple((*hv_EvalParams), "class_names", hv_EvaluateClassNames);
            }
        }
    }
    //
    //Get indices of samples to read from the dataset.
    GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
    //
    //Check if there are samples present in the dataset.
    if (0 != (int((hv_DLSamples.TupleLength())==0)))
    {
        throw HException("The provided set of samples in the dataset must be non-empty.");
    }
    //
    //Check for empty SampleSelectValues.
    if (0 != (int((hv_SampleSelectValues.TupleLength())==0)))
    {
        if (0 != (int(hv_SampleSelectMethod==HTuple("image_ids"))))
        {
            throw HException("The provided set of samples of the 'image_ids' selection must be non-empty.");
        }
        else if (0 != (int(hv_SampleSelectMethod==HTuple("sample_indices"))))
        {
            throw HException("The provided set of samples of the 'sample_indices' selection must be non-empty.");
        }
        else
        {
            throw HException("Provide a name for 'split' selection.");
        }
    }
    //
    //
    //Get the sample indices according to the sample selection method.
    hv_SampleIndices = HTuple();
    if (0 != (int(hv_SampleSelectMethod==HTuple("split"))))
    {
        //Get the samples of the split specified.
        find_dl_samples(hv_DLSamples, "split", hv_SampleSelectValues, "or", &hv_SampleIndices);
    }
    else if (0 != (int(hv_SampleSelectMethod==HTuple("image_ids"))))
    {
        //Get the samples specified by 'image_ids'.
        if (0 != (int((hv_SampleSelectValues.TupleLength())>(hv_DLSamples.TupleLength()))))
        {
            throw HException("The number of the image ids provided through 'image_id' is invalid.");
        }
        find_dl_samples(hv_DLSamples, "image_id", hv_SampleSelectValues, "or", &hv_SampleIndices);
    }
    else if (0 != (int(hv_SampleSelectMethod==HTuple("sample_indices"))))
    {
        //Get the samples specified by 'sample_indices'.
        if (0 != (HTuple(int((hv_SampleSelectValues.TupleMin())<0)).TupleOr(int((hv_SampleSelectValues.TupleMax())>((hv_DLSamples.TupleLength())-1)))))
        {
            throw HException("The range of the indices provided through 'sample_indices' is invalid.");
        }
        hv_SampleIndices = hv_SampleSelectValues;
    }
    else
    {
        throw HException(("Unknown sample selection method : '"+hv_SampleSelectMethod)+"'");
    }
    //
    //Get the number of batches.
    hv_NumSamples = hv_SampleIndices.TupleLength();
    hv_NumBatches = ((hv_NumSamples/(hv_BatchSize.TupleReal())).TupleCeil()).TupleInt();
    //
    //Check for empty samples selected by the selection method.
    if (0 != (int(hv_NumSamples==0)))
    {
        throw HException(("No samples present in the dataset that are part of the '"+hv_SampleSelectMethod)+"' selection.");
    }
    //
    //
    //** Running measures are initialized according to evaluation method.
    //
    init_running_evaluation_measures((*hv_EvalParams), &hv_RunningMeasures);
    //
    //
    //** Apply model to each image and gather evaluation information: ***
    //
    //Use alternative outputs if requested.
    hv_Outputs = HTuple();
    //
    if (0 != (HTuple(int(hv_ModelType==HTuple("gc_anomaly_detection"))).TupleAnd(int(hv_GenParam!=HTuple()))))
    {
        //
        GetDictParam(hv_GenParam, "key_exists", "gc_anomaly_networks", &hv_KeyExists);
        if (0 != hv_KeyExists)
        {
            GetDictTuple(hv_GenParam, "gc_anomaly_networks", &hv_EvalGCAnomalyNetworks);
            hv_EvalGCAnomalyNetworks = hv_EvalGCAnomalyNetworks.TupleSort();
            GetDlModelParam(hv_DLModelHandle, "gc_anomaly_networks", &hv_ModelGCAnomalyNetworks);
            hv_ModelGCAnomalyNetworks = hv_ModelGCAnomalyNetworks.TupleSort();
            //
            hv_DefaultRequested = HTuple(int((hv_EvalGCAnomalyNetworks.TupleLength())==0)).TupleOr(int(hv_EvalGCAnomalyNetworks==hv_ModelGCAnomalyNetworks));
            {
                HTuple end_val274 = (hv_EvalGCAnomalyNetworks.TupleLength())-1;
                HTuple step_val274 = 1;
                for (hv_EvalAnomalyNetworkIndex=0; hv_EvalAnomalyNetworkIndex.Continue(end_val274, step_val274); hv_EvalAnomalyNetworkIndex += step_val274)
                {
                    hv_EvalGCAnomalyNetwork = HTuple(hv_EvalGCAnomalyNetworks[hv_EvalAnomalyNetworkIndex]);
                    hv_FindIndex = hv_ModelGCAnomalyNetworks.TupleFind(hv_EvalGCAnomalyNetwork);
                    if (0 != (HTuple(int(hv_FindIndex==HTuple())).TupleOr(int(hv_FindIndex==-1))))
                    {
                        throw HException(("Invalid 'gc_anomaly_networks' requested. Model does not contain a "+hv_EvalGCAnomalyNetwork)+" network.");
                    }
                    if (0 != (hv_DefaultRequested.TupleNot()))
                    {
                        hv_Outputs = hv_Outputs.TupleConcat("anomaly_image_"+hv_EvalGCAnomalyNetwork);
                    }
                }
            }
        }
    }
    //
    //Initialize progress variables.
    if (0 != hv_ShowProgress)
    {
        hv_Progress.Clear();
        hv_Progress[0] = "Procedure: evaluate_dl_model";
        hv_Progress[1] = "";
        hv_Progress[2] = "";
        hv_Progress[3] = "";
        if (0 != (int(hv_ModelType==HTuple("detection"))))
        {
            hv_TaskInfo = "Task: 1/2: Applying the model and collecting running evaluation measures";
            hv_Progress = hv_Progress.TupleConcat(hv_TaskInfo);
        }
        CountSeconds(&hv_SecondsStart);
        // dev_inspect_ctrl(...); only in hdevelop
    }
    //
    //Loop batchwise over the samples to be evaluated.
    {
        HTuple end_val299 = hv_NumBatches-1;
        HTuple step_val299 = 1;
        for (hv_BatchIndex=0; hv_BatchIndex.Continue(end_val299, step_val299); hv_BatchIndex += step_val299)
        {
            hv_BatchStart = hv_BatchIndex*hv_BatchSize;
            hv_BatchEnd = ((hv_BatchStart+hv_BatchSize)-1).TupleMin2(hv_NumSamples-1);
            hv_SamplesIndicesBatch = hv_SampleIndices.TupleSelectRange(hv_BatchStart,hv_BatchEnd);
            //
            //Read samples
            read_dl_samples(hv_DLDataset, hv_SamplesIndicesBatch, &hv_DLSamplesBatch);
            //
            //Apply the model.
            ApplyDlModel(hv_DLModelHandle, hv_DLSamplesBatch, hv_Outputs, &hv_DLResultsBatch);
            //
            //Update the running measures.
            update_running_evaluation_measures(hv_DLSamplesBatch, hv_DLResultsBatch, (*hv_EvalParams),
                                               hv_RunningMeasures);
            //
            //Provide progress information.
            if (0 != hv_ShowProgress)
            {
                if (0 != (HTuple(int((hv_BatchIndex%10)==1)).TupleOr(int(hv_BatchIndex==(hv_NumBatches-1)))))
                {
                    estimate_progress(hv_SecondsStart, 0, hv_BatchIndex, hv_NumBatches-1, &hv_SecondsElapsed,
                                      &hv_SecondsRemaining, &hv_ProgressPercent, &hv_ProgressPerSecond);
                    timespan_string(hv_SecondsElapsed, "auto", &hv_TimeElapsedString);
                    timespan_string(hv_SecondsRemaining, "top2", &hv_TimeRemainingString);
                    hv_Progress[1] = ("Progress: "+(hv_ProgressPercent.TupleRound()))+" %";
                    hv_Progress[2] = "Time elapsed: "+hv_TimeElapsedString;
                    hv_Progress[3] = "Time left: "+hv_TimeRemainingString;
                }
            }
        }
    }
    //
    //Provide progress information.
    if (0 != (hv_ShowProgress.TupleAnd(int(hv_ModelType==HTuple("detection")))))
    {
        hv_Progress.Clear();
        hv_Progress[0] = "Procedure: evaluate_dl_model";
        hv_Progress[1] = "";
        hv_Progress[2] = "";
        hv_Progress[1] = "Please wait...";
        hv_Progress[2] = "Task: 2/2: Calculating final evaluation measures";
    }
    //
    //
    //** Do the actual calculation of measures: ***
    //
    calculate_evaluation_measures(hv_RunningMeasures, (*hv_EvalParams), &(*hv_EvaluationResult));
    //
    //Close progress inspect.
    if (0 != hv_ShowProgress)
    {
        hv_Progress = "Done.";
        // dev_close_inspect_ctrl(...); only in hdevelop
    }
    //
    return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Filter the instance segmentation masks of a DL sample based on a given selection.
void HalxAI:: filter_dl_sample_instance_segmentation_masks (HTuple hv_DLSample, HTuple hv_BBoxSelectionMask)
{

    // Local iconic variables
    HObject  ho_EmptyMasks, ho_Masks;

    // Local control variables
    HTuple  hv_MaskKeyExists, hv_Indices;

    GetDictParam(hv_DLSample, "key_exists", "mask", &hv_MaskKeyExists);
    if (0 != hv_MaskKeyExists)
    {
        //Only if masks exist (-> instance segmentation).
        TupleFind(hv_BBoxSelectionMask, 1, &hv_Indices);
        if (0 != (int(hv_Indices==-1)))
        {
            //We define here that this case will result in an empty object value
            //for the mask key. Another option would be to remove the
            //key 'mask'. However, this would be an unwanted big change in the dictionary.
            GenEmptyObj(&ho_EmptyMasks);
            SetDictObject(ho_EmptyMasks, hv_DLSample, "mask");
        }
        else
        {
            GetDictObject(&ho_Masks, hv_DLSample, "mask");
            //Remove all unused masks.
            SelectObj(ho_Masks, &ho_Masks, hv_Indices+1);
            SetDictObject(ho_Masks, hv_DLSample, "mask");
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Retrieve the indices of Samples that contain KeyName matching KeyValue according to the Mode set.
void HalxAI:: find_dl_samples (HTuple hv_Samples, HTuple hv_KeyName, HTuple hv_KeyValue, HTuple hv_Mode,
                               HTuple *hv_SampleIndices)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_NumKeyValues, hv_NumFound, hv_SampleIndex;
    HTuple  hv_Sample, hv_KeyExists, hv_Tuple, hv_Hit, hv_ValueIndex;
    HTuple  hv_Value;

    //
    //This procedure gets the indices of the samples that contain the
    //requested KeyName matching the requested KeyValue according to the Mode.
    //If there is no match, an empty tuple [] will be returned.
    //
    //Check input parameters.
    if (0 != (int((hv_KeyName.TupleLength())!=1)))
    {
        throw HException(HTuple("Invalid KeyName size: ")+(hv_KeyName.TupleLength()));
    }
    if (0 != (int((hv_Mode.TupleLength())!=1)))
    {
        throw HException(HTuple("Invalid Mode size: ")+(hv_Mode.TupleLength()));
    }
    if (0 != (HTuple(HTuple(int(hv_Mode!=HTuple("match"))).TupleAnd(int(hv_Mode!=HTuple("or")))).TupleAnd(int(hv_Mode!=HTuple("contain")))))
    {
        throw HException("Invalid Mode value: "+hv_Mode);
    }
    hv_NumKeyValues = hv_KeyValue.TupleLength();
    if (0 != (HTuple(int(hv_Mode==HTuple("contain"))).TupleAnd(int(hv_NumKeyValues<1))))
    {
        throw HException("Invalid KeyValue size for contain Mode: "+hv_NumKeyValues);
    }
    //
    //Find the indices.
    (*hv_SampleIndices) = HTuple(hv_Samples.TupleLength(),0);
    hv_NumFound = 0;
    //
    {
        HTuple end_val24 = (hv_Samples.TupleLength())-1;
        HTuple step_val24 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val24, step_val24); hv_SampleIndex += step_val24)
        {
            hv_Sample = HTuple(hv_Samples[hv_SampleIndex]);
            GetDictParam(hv_Sample, "key_exists", hv_KeyName, &hv_KeyExists);
            if (0 != hv_KeyExists)
            {
                GetDictTuple(hv_Sample, hv_KeyName, &hv_Tuple);
                if (0 != (int(hv_Mode==HTuple("match"))))
                {
                    //Mode 'match': Tuple must be equal KeyValue.
                    hv_Hit = int(hv_Tuple==hv_KeyValue);
                }
                else if (0 != (HTuple(int(hv_Mode==HTuple("or"))).TupleAnd(int((hv_Tuple.TupleLength())==1))))
                {
                    //Mode 'or': Tuple must have only 1 element and it has to be equal to any of KeyValues elements.
                    hv_Hit = int((hv_KeyValue.TupleFindFirst(hv_Tuple))>=0);
                }
                else if (0 != (int(hv_Mode==HTuple("contain"))))
                {
                    //Mode 'contain': Tuple must contain any of the elements in KeyValue.
                    {
                        HTuple end_val37 = hv_NumKeyValues-1;
                        HTuple step_val37 = 1;
                        for (hv_ValueIndex=0; hv_ValueIndex.Continue(end_val37, step_val37); hv_ValueIndex += step_val37)
                        {
                            hv_Value = HTuple(hv_KeyValue[hv_ValueIndex]);
                            hv_Hit = int((hv_Tuple.TupleFindFirst(hv_Value))>=0);
                            if (0 != hv_Hit)
                            {
                                break;
                            }
                        }
                    }
                }
                else
                {
                    //Unsupported configuration.
                    hv_Hit = 0;
                }
                if (0 != hv_Hit)
                {
                    (*hv_SampleIndices)[hv_NumFound] = hv_SampleIndex;
                    hv_NumFound += 1;
                }
            }
        }
    }
    (*hv_SampleIndices) = (*hv_SampleIndices).TupleSelectRange(0,hv_NumFound-1);
    return;
}

// Chapter: XLD / Creation
// Short Description: Create an arrow shaped XLD contour.
void HalxAI:: gen_arrow_contour_xld (HObject *ho_Arrow, HTuple hv_Row1, HTuple hv_Column1,
                                     HTuple hv_Row2, HTuple hv_Column2, HTuple hv_HeadLength, HTuple hv_HeadWidth)
{

    // Local iconic variables
    HObject  ho_TempArrow;

    // Local control variables
    HTuple  hv_Length, hv_ZeroLengthIndices, hv_DR;
    HTuple  hv_DC, hv_HalfHeadWidth, hv_RowP1, hv_ColP1, hv_RowP2;
    HTuple  hv_ColP2, hv_Index;

    //This procedure generates arrow shaped XLD contours,
    //pointing from (Row1, Column1) to (Row2, Column2).
    //If starting and end point are identical, a contour consisting
    //of a single point is returned.
    //
    //input parameters:
    //Row1, Column1: Coordinates of the arrows' starting points
    //Row2, Column2: Coordinates of the arrows' end points
    //HeadLength, HeadWidth: Size of the arrow heads in pixels
    //
    //output parameter:
    //Arrow: The resulting XLD contour
    //
    //The input tuples Row1, Column1, Row2, and Column2 have to be of
    //the same length.
    //HeadLength and HeadWidth either have to be of the same length as
    //Row1, Column1, Row2, and Column2 or have to be a single element.
    //If one of the above restrictions is violated, an error will occur.
    //
    //
    //Initialization.
    GenEmptyObj(&(*ho_Arrow));
    //
    //Calculate the arrow length
    DistancePp(hv_Row1, hv_Column1, hv_Row2, hv_Column2, &hv_Length);
    //
    //Mark arrows with identical start and end point
    //(set Length to -1 to avoid HalxAI:: division-by-zero exception)
    hv_ZeroLengthIndices = hv_Length.TupleFind(0);
    if (0 != (int(hv_ZeroLengthIndices!=-1)))
    {
        hv_Length[hv_ZeroLengthIndices] = -1;
    }
    //
    //Calculate auxiliary variables.
    hv_DR = (1.0*(hv_Row2-hv_Row1))/hv_Length;
    hv_DC = (1.0*(hv_Column2-hv_Column1))/hv_Length;
    hv_HalfHeadWidth = hv_HeadWidth/2.0;
    //
    //Calculate end points of the arrow head.
    hv_RowP1 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))+(hv_HalfHeadWidth*hv_DC);
    hv_ColP1 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))-(hv_HalfHeadWidth*hv_DR);
    hv_RowP2 = (hv_Row1+((hv_Length-hv_HeadLength)*hv_DR))-(hv_HalfHeadWidth*hv_DC);
    hv_ColP2 = (hv_Column1+((hv_Length-hv_HeadLength)*hv_DC))+(hv_HalfHeadWidth*hv_DR);
    //
    //Finally create output XLD contour for each input point pair
    {
        HTuple end_val45 = (hv_Length.TupleLength())-1;
        HTuple step_val45 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val45, step_val45); hv_Index += step_val45)
        {
            if (0 != (int(HTuple(hv_Length[hv_Index])==-1)))
            {
                //Create_ single points for arrows with identical start and end point
                GenContourPolygonXld(&ho_TempArrow, HTuple(hv_Row1[hv_Index]), HTuple(hv_Column1[hv_Index]));
            }
            else
            {
                //Create arrow contour
                GenContourPolygonXld(&ho_TempArrow, ((((HTuple(hv_Row1[hv_Index]).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP1[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index]))).TupleConcat(HTuple(hv_RowP2[hv_Index]))).TupleConcat(HTuple(hv_Row2[hv_Index])),
                                     ((((HTuple(hv_Column1[hv_Index]).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP1[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index]))).TupleConcat(HTuple(hv_ColP2[hv_Index]))).TupleConcat(HTuple(hv_Column2[hv_Index])));
            }
            ConcatObj((*ho_Arrow), ho_TempArrow, &(*ho_Arrow));
        }
    }
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Compute a confusion matrix, which an be visualized and/or returned.
void HalxAI:: gen_confusion_matrix (HTuple hv_GroundTruthLabels, HTuple hv_PredictedClasses,
                                    HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple hv_WindowHandle, HTuple *hv_ConfusionMatrix)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_DisplayMatrix, hv_ReturnMatrix, hv_DisplayColor;
    HTuple  hv_DisplayColumnWidth, hv_GenParamIndex, hv_CalculateRelativeMatrix;
    HTuple  hv_Classes, hv_NumClasses, hv_AbsoluteMatrixID;
    HTuple  hv_RelativeMatrixID, hv_ColumnMatrix, hv_Class;
    HTuple  hv_ThisLabel, hv_NumClassGroundTruth, hv_RowMatrix;
    HTuple  hv_PredictedClass, hv_ThisPredictedClass, hv_NumMatches;
    HTuple  hv_RelativeError, hv_StringWidths, hv_StringIndex;
    HTuple  hv_String, hv_Ascent, hv_Descent, hv_StringWidth;
    HTuple  hv_StringHeight, hv_MaxStringWidth, hv_RowStart;
    HTuple  hv_RowDistance, hv_RowEnd, hv_ColumnStart, hv_ColumnOffset;
    HTuple  hv_ColumnEnd, hv_Width, hv_Height, hv_WidthLimit;
    HTuple  hv_HeightLimit, hv_TextRow, hv_TextColumn, hv_Index;
    HTuple  hv_Text, hv_Row, hv_Column, hv_AbsoluteTransposedMatrixID;
    HTuple  hv_MatrixText, hv_MatrixMaxID, hv_MaxValue, hv_StringConversion;
    HTuple  hv_RelativeTransposedMatrixID, hv_TextColor, hv_RelativeValues;
    HTuple  hv_Thresholds, hv_Colors, hv_Greater, hv_Indices;
    HTuple  hv_DiagonalIndex, hv_Value;

    //This procedure computes a confusion matrix.
    //Therefore, it compares the classes
    //assigned in GroundTruthLabels and PredictedClasses.
    //The resulting confusion matrix can be
    //visualized, returned, or both.
    //In each case, the output can be changed
    //via generic parameters using GenParamName and GenParamValue.
    //For the visualization, the graphics window
    //must be specified with WindowHandle.
    //
    if (0 != (int((hv_GroundTruthLabels.TupleLength())!=(hv_PredictedClasses.TupleLength()))))
    {
        throw HException("Number of ground truth labels and predicted classes must be equal.");
    }
    //
    //Set generic parameter defaults.
    hv_DisplayMatrix = "absolute";
    hv_ReturnMatrix = "absolute";
    hv_DisplayColor = "true";
    hv_DisplayColumnWidth = "minimal";
    //
    //Parse generic parameters.
    {
        HTuple end_val21 = (hv_GenParamName.TupleLength())-1;
        HTuple step_val21 = 1;
        for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val21, step_val21); hv_GenParamIndex += step_val21)
        {
            if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_matrix"))))
            {
                //Set 'display_matrix'.
                hv_DisplayMatrix = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("return_matrix"))))
            {
                //Set 'return_matrix'.
                hv_ReturnMatrix = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_color"))))
            {
                //Set 'display_color'.
                hv_DisplayColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("display_column_width"))))
            {
                //Set 'display_column_width'.
                hv_DisplayColumnWidth = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else
            {
                throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
            }
        }
    }
    //
    if (0 != (HTuple(HTuple(int(hv_DisplayMatrix==HTuple("relative"))).TupleOr(int(hv_ReturnMatrix==HTuple("relative")))).TupleOr(int(hv_DisplayColor==HTuple("true")))))
    {
        hv_CalculateRelativeMatrix = 1;
    }
    else
    {
        hv_CalculateRelativeMatrix = 0;
    }
    //
    //Calculate the confusion matrix with absolute values
    //and the confusion matrix with relative errors.
    //We start with an empty matrix
    //and add the number of matching labels.
    hv_Classes = (hv_GroundTruthLabels.TupleSort()).TupleUniq();
    hv_NumClasses = hv_Classes.TupleLength();
    CreateMatrix(hv_NumClasses, hv_NumClasses, 0, &hv_AbsoluteMatrixID);
    if (0 != hv_CalculateRelativeMatrix)
    {
        CreateMatrix(hv_NumClasses, hv_NumClasses, 0, &hv_RelativeMatrixID);
    }
    {
        HTuple end_val55 = hv_NumClasses-1;
        HTuple step_val55 = 1;
        for (hv_ColumnMatrix=0; hv_ColumnMatrix.Continue(end_val55, step_val55); hv_ColumnMatrix += step_val55)
        {
            hv_Class = HTuple(hv_Classes[hv_ColumnMatrix]);
            hv_ThisLabel = hv_GroundTruthLabels.TupleEqualElem(hv_Class);
            if (0 != hv_CalculateRelativeMatrix)
            {
                //Obtain the number of ground truth labels per class.
                hv_NumClassGroundTruth = hv_ThisLabel.TupleSum();
            }
            {
                HTuple end_val62 = hv_NumClasses-1;
                HTuple step_val62 = 1;
                for (hv_RowMatrix=0; hv_RowMatrix.Continue(end_val62, step_val62); hv_RowMatrix += step_val62)
                {
                    //Select classes for this row/column.
                    hv_PredictedClass = HTuple(hv_Classes[hv_RowMatrix]);
                    //Check whether the input data
                    //corresponds to these classes.
                    hv_ThisPredictedClass = hv_PredictedClasses.TupleEqualElem(hv_PredictedClass);
                    //Count the number of elements where the predicted class
                    //matches the ground truth label.
                    hv_NumMatches = ((hv_ThisLabel+hv_ThisPredictedClass).TupleEqualElem(2)).TupleSum();
                    //Set value in matrix.
                    SetValueMatrix(hv_AbsoluteMatrixID, hv_RowMatrix, hv_ColumnMatrix, hv_NumMatches);
                    if (0 != hv_CalculateRelativeMatrix)
                    {
                        if (0 != (int(hv_NumClassGroundTruth>0)))
                        {
                            hv_RelativeError = (hv_NumMatches.TupleReal())/hv_NumClassGroundTruth;
                        }
                        else
                        {
                            hv_RelativeError = 0;
                        }
                        SetValueMatrix(hv_RelativeMatrixID, hv_RowMatrix, hv_ColumnMatrix, hv_RelativeError);
                    }
                }
            }
        }
    }
    //
    //Return the result.
    if (0 != (int(hv_ReturnMatrix==HTuple("absolute"))))
    {
        CopyMatrix(hv_AbsoluteMatrixID, &(*hv_ConfusionMatrix));
    }
    else if (0 != (int(hv_ReturnMatrix==HTuple("relative"))))
    {
        CopyMatrix(hv_RelativeMatrixID, &(*hv_ConfusionMatrix));
    }
    else if (0 != (int(hv_ReturnMatrix==HTuple("none"))))
    {
        //No matrix is returned.
    }
    else
    {
        throw HException("Unsupported mode for 'return_matrix'");
    }
    //
    //Display the matrix.
    if (0 != (int(hv_DisplayMatrix!=HTuple("none"))))
    {
        //
        //Find maximal string width and set display position parameters.
        hv_StringWidths = HTuple();
        //Get the string width of each class.
        {
            HTuple end_val101 = (hv_Classes.TupleLength())-1;
            HTuple step_val101 = 1;
            for (hv_StringIndex=0; hv_StringIndex.Continue(end_val101, step_val101); hv_StringIndex += step_val101)
            {
                hv_String = HTuple(hv_Classes[hv_StringIndex]);
                GetStringExtents(hv_WindowHandle, hv_String, &hv_Ascent, &hv_Descent, &hv_StringWidth,
                                 &hv_StringHeight);
                hv_StringWidths = hv_StringWidths.TupleConcat(hv_StringWidth);
            }
        }
        //The columns should have a minimum width for 4 characters.
        GetStringExtents(hv_WindowHandle, "test", &hv_Ascent, &hv_Descent, &hv_StringWidth,
                         &hv_StringHeight);
        hv_MaxStringWidth = (hv_StringWidths.TupleMax()).TupleMax2(hv_StringWidth);
        //Get the maximum string width
        //and resize the window accordingly.
        hv_RowStart = 80;
        hv_RowDistance = hv_StringHeight+10;
        hv_RowEnd = hv_StringHeight*7;
        hv_ColumnStart = 50+hv_MaxStringWidth;
        hv_ColumnOffset = 20;
        hv_ColumnEnd = hv_ColumnOffset;
        //
        //Adapt the window size to fit the confusion matrix.
        if (0 != (int(hv_DisplayColumnWidth==HTuple("minimal"))))
        {
            //Every column of the confusion matrix is as narrow as possible
            //based to the respective string widths.
            hv_Width = (((hv_StringWidths.TupleSum())+(hv_ColumnOffset*hv_NumClasses))+hv_ColumnStart)+hv_ColumnEnd;
        }
        else if (0 != (int(hv_DisplayColumnWidth==HTuple("equal"))))
        {
            //Every column of the confusion matrix should have the same width.
            //based on the maximum string width.
            hv_Width = (((hv_MaxStringWidth+hv_ColumnOffset)*hv_NumClasses)+hv_ColumnStart)+hv_ColumnEnd;
        }
        else
        {
            throw HException("");
        }
        hv_Height = ((hv_RowDistance*hv_NumClasses)+hv_RowStart)+hv_RowEnd;
        HDevWindowStack::SetActive(hv_WindowHandle);
        if (HDevWindowStack::IsOpen())
            ClearWindow(HDevWindowStack::GetActive());
        //
        //Set reasonable limits for graphics window (adapt if necessary).
        hv_WidthLimit.Clear();
        hv_WidthLimit[0] = 450;
        hv_WidthLimit[1] = 1920;
        hv_HeightLimit.Clear();
        hv_HeightLimit[0] = 250;
        hv_HeightLimit[1] = 1080;
        if (0 != (HTuple(int(hv_Width>HTuple(hv_WidthLimit[1]))).TupleOr(int(hv_Height>HTuple(hv_HeightLimit[1])))))
        {
            throw HException("Confusion Matrix does not fit into graphics window. Please adapt font and/or size limits.");
        }
        dev_resize_window_fit_size(0, 0, hv_Width, hv_Height, hv_WidthLimit, hv_HeightLimit);
        //
        //Get display coordinates.
        //Get row coordinates for display.
        hv_TextRow = HTuple();
        {
            HTuple end_val145 = hv_NumClasses-1;
            HTuple step_val145 = 1;
            for (hv_ColumnMatrix=0; hv_ColumnMatrix.Continue(end_val145, step_val145); hv_ColumnMatrix += step_val145)
            {
                hv_TextRow = hv_TextRow.TupleConcat(HTuple::TupleGenSequence(0,(hv_NumClasses-1)*hv_RowDistance,hv_RowDistance));
            }
        }
        //Get column coordinates for display.
        hv_TextColumn = HTuple();
        {
            HTuple end_val150 = hv_NumClasses-1;
            HTuple step_val150 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val150, step_val150); hv_Index += step_val150)
            {
                hv_TextColumn = hv_TextColumn.TupleConcat(HTuple(hv_NumClasses,hv_ColumnStart));
                if (0 != (int(hv_DisplayColumnWidth==HTuple("minimal"))))
                {
                    hv_ColumnStart = (hv_ColumnStart+HTuple(hv_StringWidths[hv_Index]))+hv_ColumnOffset;
                }
                else if (0 != (int(hv_DisplayColumnWidth==HTuple("equal"))))
                {
                    hv_ColumnStart = (hv_ColumnStart+hv_MaxStringWidth)+hv_ColumnOffset;
                }
            }
        }
        //Display the confusion matrix with a margin from the top.
        hv_TextRow += hv_RowStart;
        //Display axis titles.
        if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),"Ground truth labels", "window", "top",
                     "right", "white", "box", "false");
        if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),"Predicted classes", "window", "bottom",
                     "left", "white", "box", "false");
        {
            HTuple end_val163 = (hv_Classes.TupleLength())-1;
            HTuple step_val163 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val163, step_val163); hv_Index += step_val163)
            {
                hv_Text = HTuple(hv_Classes[hv_Index]);
                //Display predicted class names.
                hv_Row = HTuple(hv_TextRow[hv_Index]);
                hv_Column = (HTuple(hv_TextColumn[0])-hv_MaxStringWidth)-hv_ColumnOffset;
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_Row, hv_Column,
                             "light gray", "box", "false");
                //Display ground truth label names.
                hv_Row = HTuple(hv_TextRow[0])-hv_RowDistance;
                hv_Column = HTuple(hv_TextColumn[hv_Index*hv_NumClasses]);
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_Text, "window", hv_Row, hv_Column,
                             "light gray", "box", "false");
            }
        }
        //
        //Get the confusion matrix values for display.
        if (0 != (int(hv_DisplayMatrix==HTuple("absolute"))))
        {
            //Displayed matrix corresponds to the transposed returned matrix.
            TransposeMatrix(hv_AbsoluteMatrixID, &hv_AbsoluteTransposedMatrixID);
            GetFullMatrix(hv_AbsoluteTransposedMatrixID, &hv_MatrixText);
            ClearMatrix(hv_AbsoluteTransposedMatrixID);
            //Align the numbers right.
            MaxMatrix(hv_AbsoluteMatrixID, "full", &hv_MatrixMaxID);
            GetFullMatrix(hv_MatrixMaxID, &hv_MaxValue);
            ClearMatrix(hv_MatrixMaxID);
            hv_StringConversion = (((hv_MaxValue.TupleLog10()).TupleCeil()).TupleInt())+".0f";
            hv_MatrixText = hv_MatrixText.TupleString(hv_StringConversion);
        }
        else
        {
            //Displayed matrix corresponds to the transposed returned matrix.
            TransposeMatrix(hv_RelativeMatrixID, &hv_RelativeTransposedMatrixID);
            GetFullMatrix(hv_RelativeTransposedMatrixID, &hv_MatrixText);
            ClearMatrix(hv_RelativeTransposedMatrixID);
            hv_MatrixText = hv_MatrixText.TupleString(".2f");
        }
        //Set color for displayed confusion matrix.
        if (0 != (int(hv_DisplayColor==HTuple("true"))))
        {
            TupleGenConst(hv_MatrixText.TupleLength(), "#666666", &hv_TextColor);
            //Use the relative values to adapt the color of the text.
            TransposeMatrix(hv_RelativeMatrixID, &hv_RelativeTransposedMatrixID);
            GetFullMatrix(hv_RelativeTransposedMatrixID, &hv_RelativeValues);
            ClearMatrix(hv_RelativeTransposedMatrixID);
            //Set the colors and respective thresholds for the off-diagonal values.
            hv_Thresholds.Clear();
            hv_Thresholds[0] = 0.0;
            hv_Thresholds[1] = 0.05;
            hv_Thresholds[2] = 0.1;
            hv_Thresholds[3] = 0.2;
            hv_Colors.Clear();
            hv_Colors[0] = "#8C4D4D";
            hv_Colors[1] = "#B33333";
            hv_Colors[2] = "#D91A1A";
            hv_Colors[3] = "#FF0000";
            {
                HTuple end_val204 = (hv_Thresholds.TupleLength())-1;
                HTuple step_val204 = 1;
                for (hv_Index=0; hv_Index.Continue(end_val204, step_val204); hv_Index += step_val204)
                {
                    TupleGreaterElem(hv_RelativeValues, HTuple(hv_Thresholds[hv_Index]), &hv_Greater);
                    TupleFind(hv_Greater, 1, &hv_Indices);
                    if (0 != (int(hv_Indices!=-1)))
                    {
                        TupleReplace(hv_TextColor, hv_Indices, HTuple(hv_Colors[hv_Index]), &hv_TextColor);
                    }
                    else
                    {
                        break;
                    }
                }
            }
            //Set the colors and respective thresholds for the diagonal values.
            hv_Thresholds.Clear();
            hv_Thresholds[0] = -0.01;
            hv_Thresholds[1] = 0.60;
            hv_Thresholds[2] = 0.80;
            hv_Thresholds[3] = 0.90;
            hv_Thresholds[4] = 0.95;
            hv_Thresholds[5] = 0.98;
            hv_Colors.Clear();
            hv_Colors[0] = "#666666";
            hv_Colors[1] = "#508650";
            hv_Colors[2] = "#419C41";
            hv_Colors[3] = "#2BBD2B";
            hv_Colors[4] = "#15DE15";
            hv_Colors[5] = "#00FF00";
            {
                HTuple end_val216 = hv_NumClasses-1;
                HTuple step_val216 = 1;
                for (hv_DiagonalIndex=0; hv_DiagonalIndex.Continue(end_val216, step_val216); hv_DiagonalIndex += step_val216)
                {
                    GetValueMatrix(hv_RelativeMatrixID, hv_DiagonalIndex, hv_DiagonalIndex, &hv_Value);
                    {
                        HTuple end_val218 = (hv_Thresholds.TupleLength())-1;
                        HTuple step_val218 = 1;
                        for (hv_Index=0; hv_Index.Continue(end_val218, step_val218); hv_Index += step_val218)
                        {
                            if (0 != (int(hv_Value>HTuple(hv_Thresholds[hv_Index]))))
                            {
                                hv_TextColor[hv_DiagonalIndex*(hv_NumClasses+1)] = HTuple(hv_Colors[hv_Index]);
                            }
                            else
                            {
                                break;
                            }
                        }
                    }
                }
            }
        }
        else
        {
            //Default value for the text color.
            TupleGenConst(hv_MatrixText.TupleLength(), "white", &hv_TextColor);
        }
        //
        //Display confusion matrix.
        if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_MatrixText, "window", hv_TextRow,
                     hv_TextColumn, hv_TextColor, "box", "false");
        //
        //Clean up.
        if (0 != hv_CalculateRelativeMatrix)
        {
            ClearMatrix(hv_RelativeMatrixID);
        }
        ClearMatrix(hv_AbsoluteMatrixID);
    }
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Generate gripping points for connected regions of high gripping confidence.
void HalxAI:: gen_dl_3d_gripping_point_image_coord (HObject ho_GrippingMap, HObject *ho_Regions,
                                                    HTuple hv_MinAreaSize, HTuple *hv_Rows, HTuple *hv_Columns)
{

    // Local iconic variables
    HObject  ho_TmpRegions, ho_FilteredRegions, ho_ConnectedRegions;
    HObject  ho_SelectedRegions, ho_Skeletons, ho_OrigRegion;
    HObject  ho_Skeleton, ho_SkeletonIntersection, ho_Contours;
    HObject  ho_ContourRegions, ho_ContourSelected, ho_RegionSelected;
    HObject  ho_CenterRegion;

    // Local control variables
    HTuple  hv_GapClosingRadius, hv_NumDilationRuns;
    HTuple  hv_NumRegions, hv_RegionIdx, hv_Area, hv_Row1, hv_Column1;
    HTuple  hv_Radius, hv_RadiusIndex, hv_Dilation, hv_Rows1;
    HTuple  hv_Columns1, hv_RowOut, hv_Indices, hv_SelectedColumns;
    HTuple  hv_ColumnOut, hv_NumContours, hv_CandidateRows;
    HTuple  hv_CandidateCols, hv_ContourIdx, hv_Row, hv_Column;
    HTuple  hv_MinDistance, hv_RowCandidate, hv_ColumnCandidate;
    HTuple  hv_RowUnused, hv_ColumnUnused, hv_MinDist, hv_MaxDist;
    HTuple  hv_Indices1;

    //
    //This procedure extracts connected regions from the gripping
    //map and generates a single gripping point near the center
    //of each of those regions.
    //
    hv_GapClosingRadius = 3.5;
    hv_NumDilationRuns = 5;
    //
    //Compute regions (connected components).
    Threshold(ho_GrippingMap, &ho_TmpRegions, 0.5, 1);
    //
    //Close small gaps inside regions to get a nicer skeleton.
    ClosingCircle(ho_TmpRegions, &ho_FilteredRegions, hv_GapClosingRadius);
    //
    Connection(ho_FilteredRegions, &ho_ConnectedRegions);
    //
    //Filter for regions smaller than RegionThreshold.
    SelectShape(ho_ConnectedRegions, &ho_SelectedRegions, "area", "and", hv_MinAreaSize,
                "max");
    CountObj(ho_SelectedRegions, &hv_NumRegions);
    if (0 != (int(hv_NumRegions<1)))
    {
        GenEmptyObj(&(*ho_Regions));
        (*hv_Rows) = HTuple();
        (*hv_Columns) = HTuple();
        return;
    }
    //
    //Determine gripping point based on skeleton per region.
    Skeleton(ho_SelectedRegions, &ho_Skeletons);
    TupleGenConst(hv_NumRegions, 0, &(*hv_Rows));
    TupleGenConst(hv_NumRegions, 0, &(*hv_Columns));
    GenEmptyObj(&(*ho_Regions));
    {
        HTuple end_val31 = hv_NumRegions;
        HTuple step_val31 = 1;
        for (hv_RegionIdx=1; hv_RegionIdx.Continue(end_val31, step_val31); hv_RegionIdx += step_val31)
        {
            SelectObj(ho_SelectedRegions, &ho_OrigRegion, hv_RegionIdx);
            Intersection(ho_OrigRegion, ho_TmpRegions, &ho_OrigRegion);
            SelectObj(ho_Skeletons, &ho_Skeleton, hv_RegionIdx);
            //
            //Reduce skeleton and region produced by contours by original
            //region (if skeleton used pixels added by closing circle).
            Intersection(ho_Skeleton, ho_OrigRegion, &ho_SkeletonIntersection);
            //
            //Check if skeleton lies outside valid region
            AreaCenter(ho_SkeletonIntersection, &hv_Area, &hv_Row1, &hv_Column1);
            if (0 != (int(hv_Area==0)))
            {
                //Skeleton outside valid region -> use simple median row pixel and
                //fixing this row, the median column pixel. This case should be
                //extremely rare.
                RegionFeatures(ho_OrigRegion, "outer_radius", &hv_Radius);
                {
                    HTuple end_val47 = hv_NumDilationRuns-1;
                    HTuple step_val47 = 1;
                    for (hv_RadiusIndex=0; hv_RadiusIndex.Continue(end_val47, step_val47); hv_RadiusIndex += step_val47)
                    {
                        hv_Dilation = (hv_Radius/hv_NumDilationRuns).TupleMax2(1.5);
                        DilationCircle(ho_Skeleton, &ho_Skeleton, hv_Dilation);
                        Intersection(ho_Skeleton, ho_OrigRegion, &ho_SkeletonIntersection);
                        AreaCenter(ho_SkeletonIntersection, &hv_Area, &hv_Row1, &hv_Column1);
                        if (0 != (int(hv_Area>0)))
                        {
                            break;
                        }
                    }
                }
                GetRegionPoints(ho_SkeletonIntersection, &hv_Rows1, &hv_Columns1);
                TupleMedian(hv_Rows1, &hv_RowOut);
                TupleFind(hv_Rows1, hv_RowOut, &hv_Indices);
                TupleSelect(hv_Columns1, hv_Indices, &hv_SelectedColumns);
                TupleMedian(hv_SelectedColumns, &hv_ColumnOut);
            }
            else
            {
                //Skeleton inside valid region -> use skeleton
                GenContoursSkeletonXld(ho_SkeletonIntersection, &ho_Contours, 1, "filter");
                GenRegionContourXld(ho_Contours, &ho_ContourRegions, "margin");
                Intersection(ho_ContourRegions, ho_SkeletonIntersection, &ho_ContourRegions
                             );
                //
                //From every contour select middle point as candidate.
                CountObj(ho_Contours, &hv_NumContours);
                TupleGenConst(hv_NumContours, 0, &hv_CandidateRows);
                TupleGenConst(hv_NumContours, 0, &hv_CandidateCols);
                {
                    HTuple end_val71 = hv_NumContours;
                    HTuple step_val71 = 1;
                    for (hv_ContourIdx=1; hv_ContourIdx.Continue(end_val71, step_val71); hv_ContourIdx += step_val71)
                    {
                        SelectObj(ho_Contours, &ho_ContourSelected, hv_ContourIdx);
                        SelectObj(ho_ContourRegions, &ho_RegionSelected, hv_ContourIdx);
                        //
                        //Select point in RegionSelected closest to middle
                        //of the contour.
                        GetContourXld(ho_ContourSelected, &hv_Row, &hv_Column);
                        GenRegionRuns(&ho_CenterRegion, HTuple(hv_Row[(hv_Row.TupleLength())/2]),
                                HTuple(hv_Column[(hv_Column.TupleLength())/2]), HTuple(hv_Column[(hv_Column.TupleLength())/2]));
                        //
                        //Make sure the selected point is always inside
                        //the region.
                        DistanceRrMin(ho_RegionSelected, ho_CenterRegion, &hv_MinDistance, &hv_RowCandidate,
                                      &hv_ColumnCandidate, &hv_RowUnused, &hv_ColumnUnused);
                        //
                        hv_CandidateRows[hv_ContourIdx-1] = hv_RowCandidate;
                        hv_CandidateCols[hv_ContourIdx-1] = hv_ColumnCandidate;
                    }
                }
                //
                //Find candidate with minimum maximum distance to any
                //point in SkeletonIntersection.
                DistancePr(ho_SkeletonIntersection, hv_CandidateRows, hv_CandidateCols, &hv_MinDist,
                           &hv_MaxDist);
                TupleSortIndex(hv_MaxDist, &hv_Indices1);
                hv_RowOut = HTuple(hv_CandidateRows[HTuple(hv_Indices1[0])]);
                hv_ColumnOut = HTuple(hv_CandidateCols[HTuple(hv_Indices1[0])]);
            }
            //
            //Collect output.
            (*hv_Rows)[hv_RegionIdx-1] = hv_RowOut;
            (*hv_Columns)[hv_RegionIdx-1] = hv_ColumnOut;
            ConcatObj((*ho_Regions), ho_OrigRegion, &(*ho_Regions));
        }
    }
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Extract gripping points based on a 3D gripping point detection model output.
void HalxAI:: gen_dl_3d_gripping_points_and_poses (HTuple hv_DLSampleBatch, HTuple hv_DLGrippingPointParams,
                                                   HTuple hv_DLResultBatch)
{

    // Local iconic variables
    HObject  ho_Regions, ho___Tmp_Obj_0;

    // Local control variables
    HTuple  hv_MinAreaSize, hv_SortingDirection, hv_SampleIndex;
    HTuple  hv_DLSample, hv_DLResult, hv_Rows, hv_Columns, hv_HasXYZ;
    HTuple  hv_X, hv_Y, hv_Z, hv_NormalsXYZ, hv_NX, hv_NY, hv_NZ;
    HTuple  hv_DLResultUnsorted, hv_Index, hv_GrippingPoint;
    HTuple  hv_Depths, hv_AscendingIndices, hv___Tmp_Ctrl_0;

    //Extracts gripping points from connected regions in the
    //'gripping_map' image of the items in DLResultBatch.
    //Stores gripping points in a dict containing
    //row, column, region and pose.
    //
    if (0 != (int((hv_DLGrippingPointParams.TupleLength())==0)))
    {
        CreateDict(&hv_DLGrippingPointParams);
    }
    //
    check_dl_3d_gripping_points_and_poses_params(hv_DLGrippingPointParams);
    //
    hv_MinAreaSize = hv_DLGrippingPointParams.TupleGetDictTuple("min_area_size");
    hv_SortingDirection = hv_DLGrippingPointParams.TupleGetDictTuple("sorting_direction");
    //
    //Preprocess the sample entries.
    {
        HTuple end_val15 = (hv_DLSampleBatch.TupleLength())-1;
        HTuple step_val15 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val15, step_val15); hv_SampleIndex += step_val15)
        {
            hv_DLSample = HTuple(hv_DLSampleBatch[hv_SampleIndex]);
            hv_DLResult = HTuple(hv_DLResultBatch[hv_SampleIndex]);
            //
            gen_dl_3d_gripping_point_image_coord(hv_DLResult.TupleGetDictObject("gripping_map"),
                                                 &ho_Regions, hv_MinAreaSize, &hv_Rows, &hv_Columns);
            if (0 != (int((hv_Rows.TupleLength())<1)))
            {
                SetDictTuple(hv_DLResult, "gripping_points", HTuple());
                continue;
            }
            //
            //Convert to output.
            GetDictParam(hv_DLSample, "key_exists", ((HTuple("x").Append("y")).Append("z")),
                         &hv_HasXYZ);
            TupleMin(hv_HasXYZ, &hv_HasXYZ);
            if (0 != hv_HasXYZ)
            {
                GetGrayval(hv_DLSample.TupleGetDictObject("x"), hv_Rows, hv_Columns, &hv_X);
                GetGrayval(hv_DLSample.TupleGetDictObject("y"), hv_Rows, hv_Columns, &hv_Y);
                GetGrayval(hv_DLSample.TupleGetDictObject("z"), hv_Rows, hv_Columns, &hv_Z);
                GetGrayval(hv_DLSample.TupleGetDictObject("normals"), hv_Rows, hv_Columns,
                           &hv_NormalsXYZ);
                hv_NX = ((const HTuple&)hv_NormalsXYZ)[HTuple::TupleGenSequence(0,(hv_NormalsXYZ.TupleLength())-1,3)];
                hv_NY = ((const HTuple&)hv_NormalsXYZ)[HTuple::TupleGenSequence(1,(hv_NormalsXYZ.TupleLength())-1,3)];
                hv_NZ = ((const HTuple&)hv_NormalsXYZ)[HTuple::TupleGenSequence(2,(hv_NormalsXYZ.TupleLength())-1,3)];
            }
            //
            TupleGenConst(hv_Rows.TupleLength(), HTuple::TupleConstant("HNULL"), &hv_DLResultUnsorted);
            {
                HTuple end_val39 = (hv_Rows.TupleLength())-1;
                HTuple step_val39 = 1;
                for (hv_Index=0; hv_Index.Continue(end_val39, step_val39); hv_Index += step_val39)
                {
                    CreateDict(&hv_GrippingPoint);
                    hv_DLResultUnsorted[hv_Index] = hv_GrippingPoint;
                    SetDictTuple(hv_GrippingPoint, "row", HTuple(hv_Rows[hv_Index]));
                    SetDictTuple(hv_GrippingPoint, "column", HTuple(hv_Columns[hv_Index]));
                    SelectObj(ho_Regions, &ho___Tmp_Obj_0, hv_Index+1);
                    SetDictObject(ho___Tmp_Obj_0, hv_GrippingPoint, "region");
                    if (0 != hv_HasXYZ)
                    {
                        convert_dl_3d_gripping_point_to_pose(HTuple(hv_X[hv_Index]), HTuple(hv_Y[hv_Index]),
                                                             HTuple(hv_Z[hv_Index]), HTuple(hv_NX[hv_Index]), HTuple(hv_NY[hv_Index]),
                                                             HTuple(hv_NZ[hv_Index]), &hv___Tmp_Ctrl_0);
                        SetDictTuple(hv_GrippingPoint, "pose", hv___Tmp_Ctrl_0);
                    }
                    hv_DLResultUnsorted[hv_Index] = hv_GrippingPoint;
                }
            }
            //
            //Sort by ascending depth (closer objects first).
            if (0 != hv_HasXYZ)
            {
                hv_Depths = ((hv_X*HTuple(hv_SortingDirection[0]))+(hv_Y*HTuple(hv_SortingDirection[1])))+(hv_Z*HTuple(hv_SortingDirection[2]));
            }
            else
            {
                GetGrayval(hv_DLSample.TupleGetDictObject("z"), hv_Rows, hv_Columns, &hv_Depths);
            }
            TupleSortIndex(hv_Depths, &hv_AscendingIndices);
            TupleGenConst(hv_Rows.TupleLength(), HTuple::TupleConstant("HNULL"), &hv___Tmp_Ctrl_0);
            SetDictTuple(hv_DLResult, "gripping_points", hv___Tmp_Ctrl_0);
            SetDictTuple(hv_DLResult, "gripping_points", HTuple(hv_DLResultUnsorted[hv_AscendingIndices]));
        }
    }
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate ground truth characters if they don't exist and words to characters mapping.
void HalxAI:: gen_dl_ocr_detection_gt_chars (HTuple hv_DLSampleTargets, HTuple hv_DLSample,
                                             HTuple hv_ScaleWidth, HTuple hv_ScaleHeight, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_WordsCharsMapping)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_CharBoxIndex, hv_WordLengths, hv_J;
    HTuple  hv_Start, hv_End, hv_SplitRow, hv_SplitColumn, hv_SplitPhi;
    HTuple  hv_SplitLength1, hv_SplitLength2, hv_CharsIds, hv_EmptyWordStrings;

    (*hvec_WordsCharsMapping)[0] = HTupleVector(HTuple());
    if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
    {
        //Check if chars GT exist otherwise generate them.
        TupleFindFirst(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_CharBoxIndex);
        if (0 != (int(hv_CharBoxIndex==-1)))
        {
            hv_WordLengths = (hv_DLSample.TupleGetDictTuple("word")).TupleStrlen();
            (*hvec_WordsCharsMapping)[((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1] = HTupleVector(HTuple());
            {
                HTuple end_val7 = ((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
                HTuple step_val7 = 1;
                for (hv_J=0; hv_J.Continue(end_val7, step_val7); hv_J += step_val7)
                {
                    //For each word box
                    if (0 != (int(HTuple((hv_DLSample.TupleGetDictTuple("bbox_label_id"))[hv_J])==0)))
                    {
                        if (0 != (int(HTuple(hv_WordLengths[hv_J])!=0)))
                        {
                            hv_Start = (hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleLength();
                            hv_End = (((hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleLength())-1)+HTuple(hv_WordLengths[hv_J]);
                            (*hvec_WordsCharsMapping)[hv_J] = HTupleVector(HTuple::TupleGenSequence(hv_Start,hv_End,1));
                            split_rectangle2(HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_J]),
                                             HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_J]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_J]),
                                             HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_J]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_J]),
                                             HTuple(hv_WordLengths[hv_J]), &hv_SplitRow, &hv_SplitColumn, &hv_SplitPhi,
                                             &hv_SplitLength1, &hv_SplitLength2);
                            TupleGenConst(HTuple(hv_WordLengths[hv_J]), 1, &hv_CharsIds);
                            TupleGenConst(HTuple(hv_WordLengths[hv_J]), "", &hv_EmptyWordStrings);
                            SetDictTuple(hv_DLSampleTargets, "bbox_label_id", (hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleConcat(hv_CharsIds));
                            SetDictTuple(hv_DLSampleTargets, "bbox_row", (hv_DLSampleTargets.TupleGetDictTuple("bbox_row")).TupleConcat(hv_SplitRow));
                            SetDictTuple(hv_DLSampleTargets, "bbox_col", (hv_DLSampleTargets.TupleGetDictTuple("bbox_col")).TupleConcat(hv_SplitColumn));
                            SetDictTuple(hv_DLSampleTargets, "bbox_phi", (hv_DLSampleTargets.TupleGetDictTuple("bbox_phi")).TupleConcat(hv_SplitPhi));
                            SetDictTuple(hv_DLSampleTargets, "bbox_length1", (hv_DLSampleTargets.TupleGetDictTuple("bbox_length1")).TupleConcat(hv_SplitLength1*hv_ScaleWidth));
                            SetDictTuple(hv_DLSampleTargets, "bbox_length2", (hv_DLSampleTargets.TupleGetDictTuple("bbox_length2")).TupleConcat(hv_SplitLength2*hv_ScaleHeight));
                            SetDictTuple(hv_DLSampleTargets, "word", (hv_DLSampleTargets.TupleGetDictTuple("word")).TupleConcat(hv_EmptyWordStrings));
                        }
                        else
                        {
                            throw HException(((("Sample with image id "+(hv_DLSample.TupleGetDictTuple("image_id")))+" is not valid. The word bounding box at index ")+hv_J)+" has an empty string as the ground truth. This is not allowed. Please assign a word label to every word bounding box.");
                        }
                    }
                }
            }
        }
        else
        {
            gen_words_chars_mapping(hv_DLSample, &(*hvec_WordsCharsMapping));
        }
    }
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate target link score map for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_gt_link_map (HObject *ho_GtLinkMap, HTuple hv_ImageWidth,
                                                HTuple hv_ImageHeight, HTuple hv_DLSampleTargets, HTupleVector/*{eTupleVector,Dim=1}*/ hvec_WordToCharVec,
                                                HTuple hv_Alpha)
{

    // Local iconic variables
    HObject  ho_Lines, ho_Line, ho_LineDilated;

    // Local control variables
    HTuple  hv_InitImage, hv_CRow, hv_CCol, hv_DiameterC;
    HTuple  hv_IndexW, hv_CharBoxIndices, hv_CharCRows, hv_CharCCols;
    HTuple  hv_CharDistToWordCenter, hv_ExtremeCharIndex, hv_DistToExtreme;
    HTuple  hv_CharIndexSorted, hv_Box1Idx, hv_Box2Idx, hv_Diameter1;
    HTuple  hv_Diameter2, hv_DilationRadius, hv_NumLines, hv_Index;

    GenImageConst(&(*ho_GtLinkMap), "real", hv_ImageWidth, hv_ImageHeight);
    GetSystem("init_new_image", &hv_InitImage);
    if (0 != (int(hv_InitImage==HTuple("false"))))
    {
        OverpaintRegion((*ho_GtLinkMap), (*ho_GtLinkMap), 0.0, "fill");
    }
    //Compute box centers.
    hv_CRow = hv_DLSampleTargets.TupleGetDictTuple("bbox_row");
    hv_CCol = hv_DLSampleTargets.TupleGetDictTuple("bbox_col");
    hv_DiameterC = 2*((hv_DLSampleTargets.TupleGetDictTuple("bbox_length1")).TupleHypot(hv_DLSampleTargets.TupleGetDictTuple("bbox_length2")));
    //Loop over word boxes.
    {
        HTuple end_val10 = ((hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
        HTuple step_val10 = 1;
        for (hv_IndexW=0; hv_IndexW.Continue(end_val10, step_val10); hv_IndexW += step_val10)
        {
            //For each word box
            if (0 != (int(HTuple((hv_DLSampleTargets.TupleGetDictTuple("bbox_label_id"))[hv_IndexW])==0)))
            {
                hv_CharBoxIndices = hvec_WordToCharVec[hv_IndexW].T();
                if (0 != (int((hv_CharBoxIndices.TupleLength())==0)))
                {
                    continue;
                }
                else if (0 != (int((hv_CharBoxIndices.TupleLength())==1)))
                {
                    //Generate a dot in the char center.
                    GenCircle(&ho_Lines, HTuple(hv_CRow[hv_CharBoxIndices]), HTuple(hv_CCol[hv_CharBoxIndices]),
                              (((0.5*hv_Alpha)*HTuple(hv_DiameterC[hv_CharBoxIndices])).TupleRound())+0.5);
                }
                else
                {
                    //Generate link lines between chars.
                    hv_CharCRows = HTuple(hv_CRow[hv_CharBoxIndices]);
                    hv_CharCCols = HTuple(hv_CCol[hv_CharBoxIndices]);
                    //Sort the char boxes within the word.
                    hv_CharDistToWordCenter = (hv_CharCRows-HTuple(hv_CRow[hv_IndexW])).TupleHypot(hv_CharCCols-HTuple(hv_CCol[hv_IndexW]));
                    hv_ExtremeCharIndex = ((const HTuple&)HTuple(hv_CharDistToWordCenter.TupleSortIndex()))[(hv_CharDistToWordCenter.TupleLength())-1];
                    hv_DistToExtreme = (hv_CharCRows-HTuple(hv_CharCRows[hv_ExtremeCharIndex])).TupleHypot(hv_CharCCols-HTuple(hv_CharCCols[hv_ExtremeCharIndex]));
                    hv_CharIndexSorted = hv_DistToExtreme.TupleSortIndex();
                    //Get the indices of adjacent characters.
                    hv_Box1Idx = hv_CharIndexSorted.TupleSelectRange(0,(hv_CharIndexSorted.TupleLength())-2);
                    hv_Box2Idx = hv_CharIndexSorted.TupleSelectRange(1,(hv_CharIndexSorted.TupleLength())-1);
                    //Generate link lines between each pair of adjacent characters.
                    GenRegionLine(&ho_Lines, HTuple(hv_CharCRows[hv_Box1Idx]), HTuple(hv_CharCCols[hv_Box1Idx]),
                                  HTuple(hv_CharCRows[hv_Box2Idx]), HTuple(hv_CharCCols[hv_Box2Idx]));
                    //Dilate the lines by 0.5/1.5/2.5/... pixels, such that the line thickness is approximately Alpha*mean(D1, D2)
                    hv_Diameter1 = HTuple(hv_DiameterC[HTuple(hv_CharBoxIndices[hv_Box1Idx])]);
                    hv_Diameter2 = HTuple(hv_DiameterC[HTuple(hv_CharBoxIndices[hv_Box2Idx])]);
                    hv_DilationRadius = (((0.25*hv_Alpha)*(hv_Diameter1+hv_Diameter2)).TupleRound())+0.5;
                    //dilation_circle only accepts a single radius, so we need to loop over the lines.
                    CountObj(ho_Lines, &hv_NumLines);
                    {
                        HTuple end_val39 = hv_NumLines;
                        HTuple step_val39 = 1;
                        for (hv_Index=1; hv_Index.Continue(end_val39, step_val39); hv_Index += step_val39)
                        {
                            SelectObj(ho_Lines, &ho_Line, hv_Index);
                            DilationCircle(ho_Line, &ho_LineDilated, HTuple(hv_DilationRadius[hv_Index-1]));
                            ReplaceObj(ho_Lines, ho_LineDilated, &ho_Lines, hv_Index);
                        }
                    }
                }
                OverpaintRegion((*ho_GtLinkMap), ho_Lines, 1.0, "fill");
            }
        }
    }
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate target orientation score maps for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_gt_orientation_map (HObject *ho_GtOrientationMaps, HTuple hv_ImageWidth,
                                                       HTuple hv_ImageHeight, HTuple hv_DLSample)
{

    // Local iconic variables
    HObject  ho_GtOrientationSin, ho_GtOrientationCos;
    HObject  ho_Region;

    // Local control variables
    HTuple  hv_InitImage, hv_Indices, hv_Phi;

    GenImageConst(&ho_GtOrientationSin, "real", hv_ImageWidth, hv_ImageHeight);
    GenImageConst(&ho_GtOrientationCos, "real", hv_ImageWidth, hv_ImageHeight);
    GetSystem("init_new_image", &hv_InitImage);
    if (0 != (int(hv_InitImage==HTuple("false"))))
    {
        OverpaintRegion(ho_GtOrientationSin, ho_GtOrientationSin, 0.0, "fill");
        OverpaintRegion(ho_GtOrientationCos, ho_GtOrientationCos, 0.0, "fill");
    }
    if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
    {
        //Process char boxes
        TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_Indices);
        if (0 != (int(hv_Indices!=-1)))
        {
            hv_Phi = hv_DLSample.TupleGetDictTuple("bbox_phi");
            GenRectangle2(&ho_Region, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Indices]),
                          HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Indices]),
                          HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Indices]));
            OverpaintRegion(ho_GtOrientationSin, ho_Region, HTuple(hv_Phi[hv_Indices]).TupleSin(),
                            "fill");
            OverpaintRegion(ho_GtOrientationCos, ho_Region, HTuple(hv_Phi[hv_Indices]).TupleCos(),
                            "fill");
        }
    }
    Compose2(ho_GtOrientationSin, ho_GtOrientationCos, &(*ho_GtOrientationMaps));
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate target text score map for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_gt_score_map (HObject *ho_TargetText, HTuple hv_DLSample,
                                                 HTuple hv_BoxCutoff, HTuple hv_RenderCutoff, HTuple hv_ImageWidth, HTuple hv_ImageHeight)
{

    // Local iconic variables
    HObject  ho_ExtendedRectangle;

    // Local control variables
    HTuple  hv_InitImage, hv_Index, hv_Sigma1, hv_Sigma2;
    HTuple  hv_ExtendedLength1, hv_ExtendedLength2, hv_Rows;
    HTuple  hv_Columns, hv_Area, hv_Row, hv_Column, hv_HomMat2D;
    HTuple  hv_DistRow, hv_DistCol, hv_ScaledGaussian, hv_Grayval;

    GenImageConst(&(*ho_TargetText), "real", hv_ImageWidth, hv_ImageHeight);
    GetSystem("init_new_image", &hv_InitImage);
    if (0 != (int(hv_InitImage==HTuple("false"))))
    {
        OverpaintRegion((*ho_TargetText), (*ho_TargetText), 0.0, "fill");
    }
    {
        HTuple end_val5 = ((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
        HTuple step_val5 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val5, step_val5); hv_Index += step_val5)
        {
            //For each char box
            if (0 != (HTuple(int(HTuple((hv_DLSample.TupleGetDictTuple("bbox_label_id"))[hv_Index])==1)).TupleAnd(int(hv_BoxCutoff!=0))))
            {
                //Compute the sigma of an unnormalized normal distribution, such that
                //a certain threshold value is reached at the interval of a certain size.
                hv_Sigma1 = HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Index])*((-0.5/(hv_BoxCutoff.TupleLog())).TupleSqrt());
                hv_Sigma2 = HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Index])*((-0.5/(hv_BoxCutoff.TupleLog())).TupleSqrt());
                if (0 != (HTuple(HTuple(int(hv_Sigma1!=0)).TupleAnd(int(hv_Sigma2!=0))).TupleAnd(int(hv_RenderCutoff!=0))))
                {
                    //Compute the radius of an unnormalized normal distribution,
                    //where a certain threshold value is reached at the end.
                    hv_ExtendedLength1 = hv_Sigma1*((-2*(hv_RenderCutoff.TupleLog())).TupleSqrt());
                    hv_ExtendedLength2 = hv_Sigma2*((-2*(hv_RenderCutoff.TupleLog())).TupleSqrt());
                    GenRectangle2(&ho_ExtendedRectangle, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Index]),
                                  HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Index]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Index]),
                                  hv_ExtendedLength1, hv_ExtendedLength2);
                    ClipRegion(ho_ExtendedRectangle, &ho_ExtendedRectangle, 0, 0, hv_ImageHeight-1,
                               hv_ImageWidth-1);
                    GetRegionPoints(ho_ExtendedRectangle, &hv_Rows, &hv_Columns);
                    //Verify that the bounding box has an area to plot a gaussian
                    AreaCenter(ho_ExtendedRectangle, &hv_Area, &hv_Row, &hv_Column);
                    if (0 != (int(hv_Area>1)))
                    {
                        HomMat2dIdentity(&hv_HomMat2D);
                        HomMat2dTranslate(hv_HomMat2D, -HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Index]),
                                          -HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Index]), &hv_HomMat2D);
                        HomMat2dRotate(hv_HomMat2D, -HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Index]),
                                       0, 0, &hv_HomMat2D);
                        AffineTransPoint2d(hv_HomMat2D, hv_Rows, hv_Columns, &hv_DistRow, &hv_DistCol);
                        hv_ScaledGaussian = (-0.5*(((hv_DistCol*hv_DistCol)/(hv_Sigma1*hv_Sigma1))+((hv_DistRow*hv_DistRow)/(hv_Sigma2*hv_Sigma2)))).TupleExp();
                        GetGrayval((*ho_TargetText), hv_Rows, hv_Columns, &hv_Grayval);
                        SetGrayval((*ho_TargetText), hv_Rows, hv_Columns, hv_ScaledGaussian.TupleMax2(hv_Grayval));
                    }
                }
            }
        }
    }
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Preprocess dl samples and generate targets and weights for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_targets (HTuple hv_DLSampleOriginal, HTuple hv_DLPreprocessParam)
{

    // Local iconic variables
    HObject  ho_TargetText, ho_TargetLink, ho_TargetOrientation;
    HObject  ho_TargetWeightText, ho_TargetWeightLink, ho_WeightedCharScore;
    HObject  ho_TargetWeightOrientation, ho_OriginalDomain, ho_Image;
    HObject  ho_DomainWeight, ho_Domain, ho_TargetOrientationOut;
    HObject  ho_TargetWeightOrientationOut, ho_TargetOrientationChannel;
    HObject  ho_TargetWeightOrientationChannel;

    // Local control variables
    HTuple  hv_ImageWidth, hv_ImageHeight, hv_Stride;
    HTuple  hv_ScaleHeight, hv_ScaleWidth, hv_BoxCutoff, hv_RenderCutoff;
    HTuple  hv_Alpha, hv_WSWeightRenderThreshold, hv_LinkZeroWeightRadius;
    HTuple  hv_Confidence, hv_ScoreMapsWidth, hv_ScoreMapsHeight;
    HTuple  hv_DLSample, hv_HomMat2DIdentity, hv_HomMat2DScale;
    HTuple  hv_DLSampleTargets, hv_OriginalDomainArea, hv__;
    HTuple  hv_OriginalWidth, hv_OriginalHeight, hv_IsOriginalDomainFull;
    HTuple  hv_ChannelIdx, hv___Tmp_Ctrl_0, hv___Tmp_Ctrl_1;
    HTupleVector  hvec_WordsCharsMapping(1);

    check_dl_preprocess_param(hv_DLPreprocessParam);
    GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
    GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
    hv_Stride = 2;
    //Parameters used in the fallback weak supervision case.
    //They make the the uniformly sized char boxes a bit smaller, as we can expect a spacing between the characters.
    hv_ScaleHeight = 0.9;
    hv_ScaleWidth = 0.8;
    //Parameters relevant to plot the gaussian blobs in the score map.
    hv_BoxCutoff = 0.3;
    hv_RenderCutoff = 0.01;
    //Parameter used to determine the dilation of lines in link map.
    hv_Alpha = 0.1;
    //Parameter used to determine the dilation radius of word boxes in the weight score map.
    hv_WSWeightRenderThreshold = 0.05;
    //Parameter represents the dilation radius of word lines in the weight link map.
    hv_LinkZeroWeightRadius = 2.5;
    //Confidence is here only a place holder for the fallback weak supervision case.
    hv_Confidence = 1.0;
    if (0 != (int(hv_Stride==0)))
    {
        throw HException("Stride must be greater than 0.");
    }
    //Calculate the size of score maps.
    hv_ScoreMapsWidth = hv_ImageWidth/hv_Stride;
    hv_ScoreMapsHeight = hv_ImageHeight/hv_Stride;
    //Copy DLSample to maintain the original bounding boxes dimensions.
    CopyDict(hv_DLSampleOriginal, HTuple(), HTuple(), &hv_DLSample);
    //Preprocess bounding boxes to match targets dimensions.
    HomMat2dIdentity(&hv_HomMat2DIdentity);
    HomMat2dScale(hv_HomMat2DIdentity, 1.0/hv_Stride, 1.0/hv_Stride, 0, 0, &hv_HomMat2DScale);
    AffineTransPoint2d(hv_HomMat2DScale, hv_DLSample.TupleGetDictTuple("bbox_col"),
                       hv_DLSample.TupleGetDictTuple("bbox_row"), &hv___Tmp_Ctrl_0, &hv___Tmp_Ctrl_1);
    SetDictTuple(hv_DLSample, "bbox_row", hv___Tmp_Ctrl_1);
    SetDictTuple(hv_DLSample, "bbox_col", hv___Tmp_Ctrl_0);
    SetDictTuple(hv_DLSample, "bbox_length1", (hv_DLSample.TupleGetDictTuple("bbox_length1"))/hv_Stride);
    SetDictTuple(hv_DLSample, "bbox_length2", (hv_DLSample.TupleGetDictTuple("bbox_length2"))/hv_Stride);
    CopyDict(hv_DLSample, HTuple(), HTuple(), &hv_DLSampleTargets);
    gen_dl_ocr_detection_gt_chars(hv_DLSampleTargets, hv_DLSample, hv_ScaleWidth, hv_ScaleHeight,
                                  &hvec_WordsCharsMapping);
    //Generate target maps from WordRegions and CharBoxes.
    gen_dl_ocr_detection_gt_score_map(&ho_TargetText, hv_DLSampleTargets, hv_BoxCutoff,
                                      hv_RenderCutoff, hv_ScoreMapsWidth, hv_ScoreMapsHeight);
    gen_dl_ocr_detection_gt_link_map(&ho_TargetLink, hv_ScoreMapsWidth, hv_ScoreMapsHeight,
                                     hv_DLSampleTargets, hvec_WordsCharsMapping, hv_Alpha);
    gen_dl_ocr_detection_gt_orientation_map(&ho_TargetOrientation, hv_ScoreMapsWidth,
                                            hv_ScoreMapsHeight, hv_DLSampleTargets);
    //Generate weight maps from WordRegions and CharBoxes.
    gen_dl_ocr_detection_weight_score_map(&ho_TargetWeightText, hv_ScoreMapsWidth,
                                          hv_ScoreMapsHeight, hv_DLSampleTargets, hv_BoxCutoff, hv_WSWeightRenderThreshold,
                                          hv_Confidence);
    gen_dl_ocr_detection_weight_link_map(ho_TargetLink, ho_TargetWeightText, &ho_TargetWeightLink,
                                         hv_LinkZeroWeightRadius);
    MultImage(ho_TargetText, ho_TargetWeightText, &ho_WeightedCharScore, 1, 0);
    gen_dl_ocr_detection_weight_orientation_map(ho_WeightedCharScore, &ho_TargetWeightOrientation,
                                                hv_DLSampleTargets);
    //Take account of the image domain in DLSampleOriginal.
    GetDomain(hv_DLSampleOriginal.TupleGetDictObject("image"), &ho_OriginalDomain);
    AreaCenter(ho_OriginalDomain, &hv_OriginalDomainArea, &hv__, &hv__);
    GetImageSize(hv_DLSampleOriginal.TupleGetDictObject("image"), &hv_OriginalWidth,
                 &hv_OriginalHeight);
    hv_IsOriginalDomainFull = int(hv_OriginalDomainArea==(hv_OriginalWidth*hv_OriginalHeight));
    if (0 != (hv_IsOriginalDomainFull.TupleNot()))
    {
        //Calculate the domain weight.
        GenImageConst(&ho_Image, "real", hv_OriginalWidth, hv_OriginalHeight);
        ChangeDomain(ho_Image, ho_OriginalDomain, &ho_Image);
        ZoomImageSize(ho_Image, &ho_DomainWeight, hv_ScoreMapsWidth, hv_ScoreMapsHeight,
                      "constant");
        GetDomain(ho_DomainWeight, &ho_Domain);
        FullDomain(ho_DomainWeight, &ho_DomainWeight);
        OverpaintRegion(ho_DomainWeight, ho_DomainWeight, 0.0, "fill");
        OverpaintRegion(ho_DomainWeight, ho_Domain, 1.0, "fill");
        //Apply the domain weight.
        MultImage(ho_DomainWeight, ho_TargetText, &ho_TargetText, 1, 0);
        MultImage(ho_DomainWeight, ho_TargetLink, &ho_TargetLink, 1, 0);
        MultImage(ho_DomainWeight, ho_TargetWeightText, &ho_TargetWeightText, 1, 0);
        MultImage(ho_DomainWeight, ho_TargetWeightLink, &ho_TargetWeightLink, 1, 0);
        GenEmptyObj(&ho_TargetOrientationOut);
        GenEmptyObj(&ho_TargetWeightOrientationOut);
        for (hv_ChannelIdx=1; hv_ChannelIdx<=2; hv_ChannelIdx+=1)
        {
            AccessChannel(ho_TargetOrientation, &ho_TargetOrientationChannel, hv_ChannelIdx);
            AccessChannel(ho_TargetWeightOrientation, &ho_TargetWeightOrientationChannel,
                          hv_ChannelIdx);
            MultImage(ho_DomainWeight, ho_TargetOrientationChannel, &ho_TargetOrientationChannel,
                      1, 0);
            MultImage(ho_DomainWeight, ho_TargetWeightOrientationChannel, &ho_TargetWeightOrientationChannel,
                      1, 0);
            AppendChannel(ho_TargetOrientationOut, ho_TargetOrientationChannel, &ho_TargetOrientationOut
                          );
            AppendChannel(ho_TargetWeightOrientationOut, ho_TargetWeightOrientationChannel,
                          &ho_TargetWeightOrientationOut);
        }
        ho_TargetOrientation = ho_TargetOrientationOut;
        ho_TargetWeightOrientation = ho_TargetWeightOrientationOut;
    }
    //Set targets in output sample.
    SetDictObject(ho_TargetText, hv_DLSampleOriginal, "target_text");
    SetDictObject(ho_TargetLink, hv_DLSampleOriginal, "target_link");
    SetDictObject(ho_TargetOrientation, hv_DLSampleOriginal, "target_orientation");
    SetDictObject(ho_TargetWeightText, hv_DLSampleOriginal, "target_weight_text");
    SetDictObject(ho_TargetWeightLink, hv_DLSampleOriginal, "target_weight_link");
    SetDictObject(ho_TargetWeightOrientation, hv_DLSampleOriginal, "target_weight_orientation");
}

// Chapter: OCR / Deep OCR
// Short Description: Generate link score map weight for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_weight_link_map (HObject ho_LinkMap, HObject ho_TargetWeight,
                                                    HObject *ho_TargetWeightLink, HTuple hv_LinkZeroWeightRadius)
{

    // Local iconic variables
    HObject  ho_LinkRegion, ho_RegionDilation, ho_RegionComplement;
    HObject  ho_RegionUnion, ho_RegionBorder;

    // Local control variables
    HTuple  hv_Width, hv_Height;

    if (0 != (int(hv_LinkZeroWeightRadius>0)))
    {
        //Set zero weight around the link regions.
        Threshold(ho_LinkMap, &ho_LinkRegion, 0.01, "max");
        DilationCircle(ho_LinkRegion, &ho_RegionDilation, hv_LinkZeroWeightRadius);
        Complement(ho_RegionDilation, &ho_RegionComplement);
        GetImageSize(ho_TargetWeight, &hv_Width, &hv_Height);
        ClipRegion(ho_RegionComplement, &ho_RegionComplement, 0, 0, hv_Height-1, hv_Width-1);
        Union2(ho_LinkRegion, ho_RegionComplement, &ho_RegionUnion);
        Complement(ho_RegionUnion, &ho_RegionBorder);
        PaintRegion(ho_RegionBorder, ho_TargetWeight, &(*ho_TargetWeightLink), 0, "fill");
    }
    else
    {
        //Just copy the original weight map.
        CopyObj(ho_TargetWeight, &(*ho_TargetWeightLink), 1, 1);
    }
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate orientation score map weight for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_weight_orientation_map (HObject ho_InitialWeight, HObject *ho_OrientationTargetWeight,
                                                           HTuple hv_DLSample)
{

    // Local iconic variables
    HObject  ho_CharRegions, ho_CharRegion, ho_BackgroundRegion;

    // Local control variables
    HTuple  hv_Indices;

    //Inside the valid regions, the inital weight is set to the initial weight.
    CopyImage(ho_InitialWeight, &(*ho_OrientationTargetWeight));
    FullDomain((*ho_OrientationTargetWeight), &(*ho_OrientationTargetWeight));
    //Set orientation weight to 0 outside the valid regions.
    if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
    {
        //Process char boxes
        TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_Indices);
        if (0 != (int(hv_Indices!=-1)))
        {
            GenRectangle2(&ho_CharRegions, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Indices]),
                          HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Indices]),
                          HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Indices]));
            Union1(ho_CharRegions, &ho_CharRegion);
            Complement(ho_CharRegion, &ho_BackgroundRegion);
            OverpaintRegion((*ho_OrientationTargetWeight), ho_BackgroundRegion, 0, "fill");
        }
    }
    //We need two channels: for Sin and Cos
    Compose2((*ho_OrientationTargetWeight), (*ho_OrientationTargetWeight), &(*ho_OrientationTargetWeight)
             );
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate text score map weight for ocr detection training.
void HalxAI:: gen_dl_ocr_detection_weight_score_map (HObject *ho_TargetWeightText, HTuple hv_ImageWidth,
                                                     HTuple hv_ImageHeight, HTuple hv_DLSample, HTuple hv_BoxCutoff, HTuple hv_WSWeightRenderThreshold,
                                                     HTuple hv_Confidence)
{

    // Local iconic variables
    HObject  ho_IgnoreRegion, ho_WordRegion, ho_WordRegionDilated;

    // Local control variables
    HTuple  hv_Indices, hv_WordIndex, hv_SigmaL2;
    HTuple  hv_WordLength2Ext, hv_DilationRadius;

    GenImageConst(&(*ho_TargetWeightText), "real", hv_ImageWidth, hv_ImageHeight);
    OverpaintRegion((*ho_TargetWeightText), (*ho_TargetWeightText), 1.0, "fill");
    if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
    {
        //Process ignore boxes
        TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 2, &hv_Indices);
        if (0 != (int(hv_Indices!=-1)))
        {
            GenRectangle2(&ho_IgnoreRegion, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_Indices]),
                          HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_Indices]),
                          HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_Indices]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_Indices]));
            OverpaintRegion((*ho_TargetWeightText), ho_IgnoreRegion, 0.0, "fill");
        }
        {
            HTuple end_val9 = ((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1;
            HTuple step_val9 = 1;
            for (hv_WordIndex=0; hv_WordIndex.Continue(end_val9, step_val9); hv_WordIndex += step_val9)
            {
                //For each word box
                if (0 != (int(HTuple((hv_DLSample.TupleGetDictTuple("bbox_label_id"))[hv_WordIndex])==0)))
                {
                    if (0 != (HTuple(HTuple(int(hv_BoxCutoff==0)).TupleOr(int(hv_WSWeightRenderThreshold==0))).TupleNot()))
                    {
                        hv_SigmaL2 = HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordIndex])*((-0.5/(hv_BoxCutoff.TupleLog())).TupleSqrt());
                        hv_WordLength2Ext = hv_SigmaL2*((-2*(hv_WSWeightRenderThreshold.TupleLog())).TupleSqrt());
                        hv_DilationRadius = hv_WordLength2Ext-HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordIndex]);
                    }
                    else
                    {
                        hv_DilationRadius = 0;
                    }
                    GenRectangle2(&ho_WordRegion, HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_WordIndex]),
                                  HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_WordIndex]), HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_WordIndex]),
                                  HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_WordIndex]),
                                  HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordIndex]));
                    //Slightly enlarge the weight region to suppress halos at the box borders.
                    if (0 != (int(hv_DilationRadius>=0.5)))
                    {
                        DilationCircle(ho_WordRegion, &ho_WordRegionDilated, hv_DilationRadius);
                    }
                    else
                    {
                        ho_WordRegionDilated = ho_WordRegion;
                    }
                    //Set the confidence as weight for the word region.
                    OverpaintRegion((*ho_TargetWeightText), ho_WordRegionDilated, hv_Confidence,
                                    "fill");
                }
            }
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Store the given images in a tuple of dictionaries DLSamples.
void HalxAI:: gen_dl_samples_from_images (HObject ho_Images, HTuple *hv_DLSampleBatch)
{

    // Local iconic variables
    HObject  ho_Image;

    // Local control variables
    HTuple  hv_NumImages, hv_ImageIndex, hv_DLSample;

    //
    //This procedure creates DLSampleBatch, a tuple
    //containing a dictionary DLSample
    //for every image given in Images.
    //
    //Initialize output tuple.
    CountObj(ho_Images, &hv_NumImages);
    (*hv_DLSampleBatch) = HTuple(hv_NumImages,-1);
    //
    //Loop through all given images.
    {
        HTuple end_val10 = hv_NumImages-1;
        HTuple step_val10 = 1;
        for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val10, step_val10); hv_ImageIndex += step_val10)
        {
            SelectObj(ho_Images, &ho_Image, hv_ImageIndex+1);
            //Create DLSample from image.
            CreateDict(&hv_DLSample);
            SetDictObject(ho_Image, hv_DLSample, "image");
            //
            //Collect the DLSamples.
            (*hv_DLSampleBatch)[hv_ImageIndex] = hv_DLSample;
        }
    }
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Generate a tiled image for the classified DLSamples and add indications whether the predictions are true or not.
void HalxAI:: gen_tiled_classification_image_result (HObject *ho_TiledImageRow, HTuple hv_DLSamples,
                                                     HTuple hv_SpacingCol, HTuple hv_PredictionsCorrect, HTuple hv_ResClasses, HTuple *hv_TextImageRows,
                                                     HTuple *hv_TextImageColumns, HTuple *hv_TextImageWidth, HTuple *hv_TextImageHeight)
{

    // Local iconic variables
    HObject  ho_GTImagesRaw, ho_GTImage, ho_Channel;
    HObject  ho_RegionContourCheck, ho_Rectangle1, ho_Rectangle2;
    HObject  ho_RegionContourCross, ho_TopContour, ho_LeftContour;
    HObject  ho_RightContour, ho_BottomContour, ho_Frame, ho_TextImageOneChannel;
    HObject  ho_TextImageOneChannels, ho_TextImage, ho_SeparateImageOneChannel;
    HObject  ho_SeparateImageOneChannels, ho_SeparateImage, ho_GTImages;
    HObject  ho_GTImageChannelsScaled, ho_GTImageChannel, ho_GTImageChannelScaled;
    HObject  ho_GTImageR, ho_GTImageG, ho_GTImageB, ho_RegionContour;

    // Local control variables
    HTuple  hv_NumSamples, hv_NumRows, hv_NumColumns;
    HTuple  hv_Index, hv_NumChannels, hv_GrayMin, hv_GrayMax;
    HTuple  hv_IndexChannel, hv_GrayMinTmp, hv_GrayMaxTmp, hv__;
    HTuple  hv_ImageWidth, hv_ImageHeight, hv_Length1, hv_Length2;
    HTuple  hv_HomMat2DIdentity, hv_HomMat2DRotate, hv_HomMat2DCompose;
    HTuple  hv_FrameSize, hv_SeparateImageHeight, hv_SeparateImageWidth;
    HTuple  hv_ScaleMax, hv_ScaleMin, hv_Color, hv_Number, hv_TiledRows;
    HTuple  hv_TiledColumns, hv_TiledHeights, hv_TiledWidths;
    HTuple  hv_MinusOnes;
    HTupleVector  hvec_GrayMins(1), hvec_GrayMaxs(1);

    //
    //This procedure generates a tiled image for the classified DLSamples.
    //In the process it adds indications if the prediction was
    //correct (green frame and checkmark) or wrong (red frame and cross).
    //
    hv_NumSamples = hv_DLSamples.TupleLength();
    //
    //Get number of rows/columns of tiled image.
    if (0 != (int(hv_NumSamples>9)))
    {
        throw HException("More than 9 images cannot be shown in the training progress.");
    }
    if (0 != (HTuple(HTuple(int(hv_NumSamples==1)).TupleOr(int(hv_NumSamples==4))).TupleOr(int(hv_NumSamples==9))))
    {
        hv_NumRows = (hv_NumSamples.TupleSqrt()).TupleInt();
        hv_NumColumns = hv_NumRows;
    }
    else
    {
        hv_NumRows = hv_NumSamples.TupleMin2(3);
        hv_NumColumns = ((hv_NumSamples-1)/hv_NumRows)+1;
    }
    //
    //Get images and minimal/maximal gray values.
    GenEmptyObj(&ho_GTImagesRaw);
    {
        HTuple end_val21 = hv_NumSamples-1;
        HTuple step_val21 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
        {
            GetDictObject(&ho_GTImage, HTuple(hv_DLSamples[hv_Index]), "image");
            ConcatObj(ho_GTImagesRaw, ho_GTImage, &ho_GTImagesRaw);
            CountChannels(ho_GTImage, &hv_NumChannels);
            hv_GrayMin = HTuple();
            hv_GrayMax = HTuple();
            {
                HTuple end_val27 = hv_NumChannels-1;
                HTuple step_val27 = 1;
                for (hv_IndexChannel=0; hv_IndexChannel.Continue(end_val27, step_val27); hv_IndexChannel += step_val27)
                {
                    AccessChannel(ho_GTImage, &ho_Channel, hv_IndexChannel+1);
                    MinMaxGray(ho_Channel, ho_Channel, 0, &hv_GrayMinTmp, &hv_GrayMaxTmp, &hv__);
                    hv_GrayMin = hv_GrayMin.TupleConcat(hv_GrayMinTmp);
                    hv_GrayMax = hv_GrayMax.TupleConcat(hv_GrayMaxTmp);
                }
            }
            hvec_GrayMins[hv_Index] = HTupleVector(hv_GrayMin);
            hvec_GrayMaxs[hv_Index] = HTupleVector(hv_GrayMax);
        }
    }
    //
    //Create a checkmark, a cross, and a frame.
    //Note: It is assumed that all images have the same size.
    //Set parameters for displaying crosses/hooks at the bottom-right corner.
    GetImageSize(ho_GTImage, &hv_ImageWidth, &hv_ImageHeight);
    hv_Length1 = (hv_ImageWidth.TupleMin2(hv_ImageHeight))/5;
    hv_Length2 = (hv_ImageWidth.TupleMin2(hv_ImageHeight))/25;
    HomMat2dIdentity(&hv_HomMat2DIdentity);
    HomMat2dRotate(hv_HomMat2DIdentity, HTuple(45).TupleRad(), 0, 0, &hv_HomMat2DRotate);
    HomMat2dTranslate(hv_HomMat2DRotate, hv_ImageHeight-(0.75*hv_Length1), hv_ImageWidth-(0.75*hv_Length1),
                      &hv_HomMat2DCompose);
    //Generate checkmark.
    GenContourPolygonXld(&ho_RegionContourCheck, (((((-hv_Length2).TupleConcat(hv_Length2)).TupleConcat(hv_Length2)).TupleConcat((HTuple(0).Append(0)))).TupleConcat(-hv_Length2)).TupleConcat(-hv_Length2),
                         ((((((HTuple(0).Append(0)).TupleConcat(hv_Length1)).TupleConcat(hv_Length1)).TupleConcat(hv_Length2)).TupleConcat(hv_Length2)).TupleConcat(0))-(hv_Length1/2));
    AffineTransContourXld(ho_RegionContourCheck, &ho_RegionContourCheck, hv_HomMat2DCompose);
    //Generate cross.
    GenRectangle2ContourXld(&ho_Rectangle1, 0, 0, 0, hv_Length1/2, hv_Length2/2);
    GenRectangle2ContourXld(&ho_Rectangle2, 0, 0, 0, hv_Length2/2, hv_Length1/2);
    ConcatObj(ho_Rectangle1, ho_Rectangle2, &ho_RegionContourCross);
    AffineTransContourXld(ho_RegionContourCross, &ho_RegionContourCross, hv_HomMat2DCompose);
    //Generate the color frame.
    hv_FrameSize = 7;
    GenContourPolygonXld(&ho_TopContour, ((((HTuple(0).Append(0)).TupleConcat(hv_FrameSize)).TupleConcat(hv_FrameSize)).TupleConcat(0))-0.5,
                         (((HTuple(0).TupleConcat(hv_ImageWidth)).TupleConcat(hv_ImageWidth)).TupleConcat((HTuple(0).Append(0))))-0.5);
    GenContourPolygonXld(&ho_LeftContour, ((((HTuple(0).Append(0)).TupleConcat(hv_ImageHeight)).TupleConcat(hv_ImageHeight)).TupleConcat(0))-0.5,
                         (((HTuple(0).TupleConcat(hv_FrameSize)).TupleConcat(hv_FrameSize)).TupleConcat((HTuple(0).Append(0))))-0.5);
    GenContourPolygonXld(&ho_RightContour, (((HTuple(0).TupleConcat(hv_ImageHeight)).TupleConcat(hv_ImageHeight)).TupleConcat((HTuple(0).Append(0))))-0.5,
                         ((((hv_ImageWidth.TupleConcat(hv_ImageWidth)).TupleConcat(hv_ImageWidth-hv_FrameSize)).TupleConcat(hv_ImageWidth-hv_FrameSize)).TupleConcat(hv_ImageWidth))-0.5);
    GenContourPolygonXld(&ho_BottomContour, ((((hv_ImageHeight.TupleConcat(hv_ImageHeight-hv_FrameSize)).TupleConcat(hv_ImageHeight-hv_FrameSize)).TupleConcat(hv_ImageHeight)).TupleConcat(hv_ImageHeight))-0.5,
                         ((((HTuple(0).Append(0)).TupleConcat(hv_ImageWidth)).TupleConcat(hv_ImageWidth)).TupleConcat(0))-0.5);
    ConcatObj(ho_TopContour, ho_RightContour, &ho_Frame);
    ConcatObj(ho_Frame, ho_BottomContour, &ho_Frame);
    ConcatObj(ho_Frame, ho_LeftContour, &ho_Frame);
    //
    //Create black image to print in text later.
    (*hv_TextImageHeight) = 40;
    (*hv_TextImageWidth) = hv_ImageWidth;
    GenImageConst(&ho_TextImageOneChannel, "real", (*hv_TextImageWidth), (*hv_TextImageHeight));
    ConcatObj(ho_TextImageOneChannel, ho_TextImageOneChannel, &ho_TextImageOneChannels
              );
    ConcatObj(ho_TextImageOneChannels, ho_TextImageOneChannel, &ho_TextImageOneChannels
              );
    ChannelsToImage(ho_TextImageOneChannels, &ho_TextImage);
    //
    //Create black image to separate columns.
    hv_SeparateImageHeight = hv_NumRows*(hv_ImageHeight+(*hv_TextImageHeight));
    hv_SeparateImageWidth = 4;
    GenImageConst(&ho_SeparateImageOneChannel, "real", hv_SeparateImageWidth, hv_SeparateImageHeight);
    ConcatObj(ho_SeparateImageOneChannel, ho_SeparateImageOneChannel, &ho_SeparateImageOneChannels
              );
    ConcatObj(ho_SeparateImageOneChannels, ho_SeparateImageOneChannel, &ho_SeparateImageOneChannels
              );
    ChannelsToImage(ho_SeparateImageOneChannels, &ho_SeparateImage);
    //
    //Adapt images with frame and checkmark/cross.
    GenEmptyObj(&ho_GTImages);
    {
        HTuple end_val82 = hv_NumSamples-1;
        HTuple step_val82 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val82, step_val82); hv_Index += step_val82)
        {
            //Scale images to [0,1] to have identical color ranges.
            SelectObj(ho_GTImagesRaw, &ho_GTImage, hv_Index+1);
            CountChannels(ho_GTImage, &hv_NumChannels);
            GenEmptyObj(&ho_GTImageChannelsScaled);
            {
                HTuple end_val87 = hv_NumChannels-1;
                HTuple step_val87 = 1;
                for (hv_IndexChannel=0; hv_IndexChannel.Continue(end_val87, step_val87); hv_IndexChannel += step_val87)
                {
                    AccessChannel(ho_GTImage, &ho_GTImageChannel, hv_IndexChannel+1);
                    hv_ScaleMax = HTuple(hvec_GrayMaxs[hv_Index].T()[hv_IndexChannel]);
                    hv_ScaleMin = HTuple(hvec_GrayMins[hv_Index].T()[hv_IndexChannel]);
                    if (0 != (int((hv_ScaleMax-hv_ScaleMin)>1e-5)))
                    {
                        ScaleImage(ho_GTImageChannel, &ho_GTImageChannelScaled, 1.0/(hv_ScaleMax-hv_ScaleMin),
                                   (-hv_ScaleMin)/(hv_ScaleMax-hv_ScaleMin));
                    }
                    else
                    {
                        ScaleImage(ho_GTImageChannel, &ho_GTImageChannelScaled, 0, 0);
                    }
                    ConcatObj(ho_GTImageChannelsScaled, ho_GTImageChannelScaled, &ho_GTImageChannelsScaled
                              );
                }
            }
            ChannelsToImage(ho_GTImageChannelsScaled, &ho_GTImage);
            //The frame has 3 channels, hence ensure that GTImage
            //has equal number of channels for display.
            if (0 != (int(hv_NumChannels!=3)))
            {
                //Just take the first channel and use this to generate
                //an image with 3 channels for visualization.
                AccessChannel(ho_GTImage, &ho_GTImageR, 1);
                CopyImage(ho_GTImageR, &ho_GTImageG);
                CopyImage(ho_GTImageR, &ho_GTImageB);
                Compose3(ho_GTImageR, ho_GTImageG, ho_GTImageB, &ho_GTImage);
            }
            //
            if (0 != (int(HTuple(hv_PredictionsCorrect[hv_Index])==1)))
            {
                //If the actual image is predicted correctly, plot a green frame and
                //a green checkmark.
                ho_RegionContour = ho_RegionContourCheck;
                hv_Color.Clear();
                hv_Color[0] = 0;
                hv_Color[1] = 1;
                hv_Color[2] = 0;
            }
            else
            {
                //Same as for the correct predictions, plot red frame and
                //a red cross for incorrect predictions.
                ho_RegionContour = ho_RegionContourCross;
                hv_Color.Clear();
                hv_Color[0] = 1;
                hv_Color[1] = 0;
                hv_Color[2] = 0;
            }
            if (HDevWindowStack::IsOpen())
                SetDraw(HDevWindowStack::GetActive(),"margin");
            PaintXld(ho_Frame, ho_GTImage, &ho_GTImage, hv_Color);
            PaintXld(ho_RegionContour, ho_GTImage, &ho_GTImage, hv_Color);
            ConcatObj(ho_GTImages, ho_GTImage, &ho_GTImages);
            //Add TextImage.
            ConcatObj(ho_GTImages, ho_TextImage, &ho_GTImages);
        }
    }
    //
    //Tile the images. The maximum is 3x3=9 samples.
    //Set row/column positions of upper-left corners of images and text images.
    CountObj(ho_GTImages, &hv_Number);
    TupleGenConst(hv_Number, 0, &hv_TiledRows);
    TupleGenConst(hv_Number, 0, &hv_TiledColumns);
    TupleGenConst(hv_Number/2, 0, &(*hv_TextImageRows));
    TupleGenConst(hv_Number/2, 0, &(*hv_TextImageColumns));
    {
        HTuple end_val136 = (hv_Number/2)-1;
        HTuple step_val136 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val136, step_val136); hv_Index += step_val136)
        {
            hv_TiledRows[2*hv_Index] = ((*hv_TextImageHeight)+hv_ImageHeight)*(hv_Index%hv_NumRows);
            (*hv_TextImageRows)[hv_Index] = (((*hv_TextImageHeight)+hv_ImageHeight)*(hv_Index%hv_NumRows))+hv_ImageHeight;
            hv_TiledRows[(2*hv_Index)+1] = HTuple((*hv_TextImageRows)[hv_Index]);
            hv_TiledColumns[2*hv_Index] = (hv_ImageWidth+hv_SeparateImageWidth)*(hv_Index/hv_NumRows);
            (*hv_TextImageColumns)[hv_Index] = HTuple(hv_TiledColumns[2*hv_Index]);
            hv_TiledColumns[(2*hv_Index)+1] = HTuple((*hv_TextImageColumns)[hv_Index]);
        }
    }
    //Add images and row/column positions of upper-left corners of SeparateImages.
    {
        HTuple end_val145 = hv_NumColumns-2;
        HTuple step_val145 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val145, step_val145); hv_Index += step_val145)
        {
            ConcatObj(ho_GTImages, ho_SeparateImage, &ho_GTImages);
            hv_TiledRows[hv_TiledRows.TupleLength()] = 0;
            hv_TiledColumns[hv_TiledColumns.TupleLength()] = (hv_Index+1)*hv_ImageWidth;
        }
    }
    //
    hv_TiledHeights = hv_NumRows*((*hv_TextImageHeight)+hv_ImageHeight);
    hv_TiledWidths = (hv_NumColumns*hv_ImageWidth)+((hv_NumColumns-1)*hv_SeparateImageWidth);
    TupleGenConst(hv_TiledRows.TupleLength(), -1, &hv_MinusOnes);
    TileImagesOffset(ho_GTImages, &(*ho_TiledImageRow), hv_TiledRows, hv_TiledColumns,
                     hv_MinusOnes, hv_MinusOnes, hv_MinusOnes, hv_MinusOnes, hv_TiledWidths, hv_TiledHeights);
    //
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Generate a tiled image for the Deep OCR DLSamples and add indications whether the predictions are true or not.
void HalxAI:: gen_tiled_ocr_recognition_image_result (HObject *ho_TiledImage, HTuple hv_DLSamples,
                                                      HTuple hv_PredictionsCorrect, HTuple *hv_TextImageRows, HTuple *hv_TextImageColumns,
                                                      HTuple *hv_TextImageWidth, HTuple *hv_TextImageHeight)
{

    // Local iconic variables
    HObject  ho_SampleImagesRaw, ho_Image, ho_ChannelR;
    HObject  ho_ChannelG, ho_ChannelB, ho_TextImageRaw, ho_SeparateImage;
    HObject  ho_Checkmark, ho_Cross, ho_ImagesToTile, ho_SampleImage;
    HObject  ho_ImageChannelsScaled, ho_ImageChannel, ho_ImageChannelScaled;
    HObject  ho_ImageR, ho_ImageG, ho_ImageB, ho_PredictionSymbol;
    HObject  ho_TextImage;

    // Local control variables
    HTuple  hv_NumSamples, hv_NumColumnsTiled, hv_NumRowsTiled;
    HTuple  hv_MaxNumSamplesSupported, hv_NumRows, hv_NumColumns;
    HTuple  hv_Index, hv_ImageWidth, hv_ImageHeight, hv_SeparateImageWidth;
    HTuple  hv_SeparateImageHeight, hv_SymbolLineWidth, hv_SymbolSize;
    HTuple  hv_SymbolRow, hv_SymbolColumn, hv_HomMat2DIdentity;
    HTuple  hv_HomMat2DRotate, hv_HomMat2DCompose, hv_S, hv_W;
    HTuple  hv_NumChannels, hv_IndexChannel, hv_ScaleMax, hv_ScaleMin;
    HTuple  hv_PredictionForegroundColor, hv_PredictionBackgroundColor;
    HTuple  hv_TiledRows, hv_TiledColumns, hv_TiledHeights;
    HTuple  hv_TiledWidths, hv_MinusOnes;

    //
    //This procedure generates a tiled image for the Deep OCR Recognition samples.
    //It adds indications if the prediction was correct (green bar with checkmark)
    //or wrong (red bar with cross).
    //
    hv_NumSamples = hv_DLSamples.TupleLength();
    //
    //Maximum number of samples supported: 16 (grid 4 x 4).
    hv_NumColumnsTiled.Clear();
    hv_NumColumnsTiled[0] = 1;
    hv_NumColumnsTiled[1] = 1;
    hv_NumColumnsTiled[2] = 1;
    hv_NumColumnsTiled[3] = 1;
    hv_NumColumnsTiled[4] = 2;
    hv_NumColumnsTiled[5] = 2;
    hv_NumColumnsTiled[6] = 2;
    hv_NumColumnsTiled[7] = 2;
    hv_NumColumnsTiled[8] = 3;
    hv_NumColumnsTiled[9] = 3;
    hv_NumColumnsTiled[10] = 3;
    hv_NumColumnsTiled[11] = 3;
    hv_NumColumnsTiled[12] = 4;
    hv_NumColumnsTiled[13] = 4;
    hv_NumColumnsTiled[14] = 4;
    hv_NumColumnsTiled[15] = 4;
    hv_NumRowsTiled.Clear();
    hv_NumRowsTiled[0] = 1;
    hv_NumRowsTiled[1] = 2;
    hv_NumRowsTiled[2] = 3;
    hv_NumRowsTiled[3] = 4;
    hv_NumRowsTiled[4] = 4;
    hv_NumRowsTiled[5] = 4;
    hv_NumRowsTiled[6] = 4;
    hv_NumRowsTiled[7] = 4;
    hv_NumRowsTiled[8] = 4;
    hv_NumRowsTiled[9] = 4;
    hv_NumRowsTiled[10] = 4;
    hv_NumRowsTiled[11] = 4;
    hv_NumRowsTiled[12] = 4;
    hv_NumRowsTiled[13] = 4;
    hv_NumRowsTiled[14] = 4;
    hv_NumRowsTiled[15] = 4;
    hv_MaxNumSamplesSupported = hv_NumRowsTiled.TupleLength();
    //
    //Get number of rows/columns of tiled image.
    if (0 != (int(hv_NumSamples>hv_MaxNumSamplesSupported)))
    {
        throw HException(("More than "+hv_MaxNumSamplesSupported)+" images cannot be shown in the training progress.");
    }
    hv_NumRows = HTuple(hv_NumRowsTiled[hv_NumSamples-1]);
    hv_NumColumns = HTuple(hv_NumColumnsTiled[hv_NumSamples-1]);
    //
    //Get images and minimal/maximal gray values.
    GenEmptyObj(&ho_SampleImagesRaw);
    {
        HTuple end_val21 = hv_NumSamples-1;
        HTuple step_val21 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val21, step_val21); hv_Index += step_val21)
        {
            GetDictObject(&ho_Image, HTuple(hv_DLSamples[hv_Index]), "image");
            ConcatObj(ho_SampleImagesRaw, ho_Image, &ho_SampleImagesRaw);
        }
    }
    GetImageSize(ho_Image, &hv_ImageWidth, &hv_ImageHeight);
    //
    //Create text image to print in text later.
    (*hv_TextImageHeight) = 24;
    (*hv_TextImageWidth) = hv_ImageWidth;
    GenImageConst(&ho_ChannelR, "real", (*hv_TextImageWidth), (*hv_TextImageHeight));
    GenImageConst(&ho_ChannelG, "real", (*hv_TextImageWidth), (*hv_TextImageHeight));
    GenImageConst(&ho_ChannelB, "real", (*hv_TextImageWidth), (*hv_TextImageHeight));
    Compose3(ho_ChannelR, ho_ChannelG, ho_ChannelB, &ho_TextImageRaw);
    //
    //Create black image to separate columns.
    hv_SeparateImageWidth = 4;
    hv_SeparateImageHeight = hv_NumRows*(hv_ImageHeight+(*hv_TextImageHeight));
    GenImageConst(&ho_ChannelR, "real", hv_SeparateImageWidth, hv_SeparateImageHeight);
    GenImageConst(&ho_ChannelG, "real", hv_SeparateImageWidth, hv_SeparateImageHeight);
    GenImageConst(&ho_ChannelB, "real", hv_SeparateImageWidth, hv_SeparateImageHeight);
    Compose3(ho_ChannelR, ho_ChannelG, ho_ChannelB, &ho_SeparateImage);
    //
    //Create prediction symbols: checkmark/cross for correct/incorrect.
    hv_SymbolLineWidth = 3.6;
    hv_SymbolSize = 0.5*(*hv_TextImageHeight);
    hv_SymbolRow = 0.5*(*hv_TextImageHeight);
    hv_SymbolColumn = hv_ImageWidth-hv_SymbolSize;
    HomMat2dIdentity(&hv_HomMat2DIdentity);
    HomMat2dRotate(hv_HomMat2DIdentity, HTuple(45).TupleRad(), 0, 0, &hv_HomMat2DRotate);
    HomMat2dTranslate(hv_HomMat2DRotate, hv_SymbolRow, hv_SymbolColumn, &hv_HomMat2DCompose);
    hv_S = 0.5*hv_SymbolSize;
    hv_W = 0.5*hv_SymbolLineWidth;
    GenContourPolygonXld(&ho_Checkmark, (((((hv_W.TupleConcat(-0.75*hv_S)).TupleConcat(-0.75*hv_S)).TupleConcat(-hv_W)).TupleConcat(-hv_W)).TupleConcat(hv_W)).TupleConcat(hv_W),
                         (((((((-hv_S)-hv_W).TupleConcat((-hv_S)-hv_W)).TupleConcat((-hv_S)+hv_W)).TupleConcat((-hv_S)+hv_W)).TupleConcat(hv_S)).TupleConcat(hv_S)).TupleConcat((-hv_S)-hv_W));
    GenContourPolygonXld(&ho_Cross, ((((((((((((-hv_W).TupleConcat(-hv_W)).TupleConcat(-hv_S)).TupleConcat(-hv_S)).TupleConcat(-hv_W)).TupleConcat(-hv_W)).TupleConcat(hv_W)).TupleConcat(hv_W)).TupleConcat(hv_S)).TupleConcat(hv_S)).TupleConcat(hv_W)).TupleConcat(hv_W)).TupleConcat(-hv_W),
                         ((((((((((((-hv_S).TupleConcat(-hv_W)).TupleConcat(-hv_W)).TupleConcat(hv_W)).TupleConcat(hv_W)).TupleConcat(hv_S)).TupleConcat(hv_S)).TupleConcat(hv_W)).TupleConcat(hv_W)).TupleConcat(-hv_W)).TupleConcat(-hv_W)).TupleConcat(-hv_S)).TupleConcat(-hv_S));
    AffineTransContourXld(ho_Checkmark, &ho_Checkmark, hv_HomMat2DCompose);
    AffineTransContourXld(ho_Cross, &ho_Cross, hv_HomMat2DCompose);
    //
    //Adapt images with prediction results.
    GenEmptyObj(&ho_ImagesToTile);
    {
        HTuple end_val60 = hv_NumSamples-1;
        HTuple step_val60 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val60, step_val60); hv_Index += step_val60)
        {
            //Scale images to [0,1] to have identical color ranges.
            SelectObj(ho_SampleImagesRaw, &ho_SampleImage, hv_Index+1);
            FullDomain(ho_SampleImage, &ho_SampleImage);
            CountChannels(ho_SampleImage, &hv_NumChannels);
            GenEmptyObj(&ho_ImageChannelsScaled);
            {
                HTuple end_val66 = hv_NumChannels-1;
                HTuple step_val66 = 1;
                for (hv_IndexChannel=0; hv_IndexChannel.Continue(end_val66, step_val66); hv_IndexChannel += step_val66)
                {
                    //ocr_recognition image range is [-1,1]
                    hv_ScaleMax = 1.0;
                    hv_ScaleMin = -1.0;
                    AccessChannel(ho_SampleImage, &ho_ImageChannel, hv_IndexChannel+1);
                    ScaleImage(ho_ImageChannel, &ho_ImageChannelScaled, 1.0/(hv_ScaleMax-hv_ScaleMin),
                               (-(hv_ScaleMin.TupleReal()))/(hv_ScaleMax-hv_ScaleMin));
                    ConcatObj(ho_ImageChannelsScaled, ho_ImageChannelScaled, &ho_ImageChannelsScaled
                              );
                }
            }
            ChannelsToImage(ho_ImageChannelsScaled, &ho_SampleImage);
            //Ensure that all images in Image has equal number of channels for display.
            if (0 != (int(hv_NumChannels!=3)))
            {
                AccessChannel(ho_SampleImage, &ho_ImageR, 1);
                CopyImage(ho_ImageR, &ho_ImageG);
                CopyImage(ho_ImageR, &ho_ImageB);
                Compose3(ho_ImageR, ho_ImageG, ho_ImageB, &ho_SampleImage);
            }
            //Set prediction parameters.
            if (0 != (HTuple(hv_PredictionsCorrect[hv_Index])))
            {
                hv_PredictionForegroundColor.Clear();
                hv_PredictionForegroundColor[0] = 0;
                hv_PredictionForegroundColor[1] = 1;
                hv_PredictionForegroundColor[2] = 0;
                hv_PredictionBackgroundColor.Clear();
                hv_PredictionBackgroundColor[0] = 0;
                hv_PredictionBackgroundColor[1] = 0.5;
                hv_PredictionBackgroundColor[2] = 0;
                ho_PredictionSymbol = ho_Checkmark;
            }
            else
            {
                hv_PredictionForegroundColor.Clear();
                hv_PredictionForegroundColor[0] = 1;
                hv_PredictionForegroundColor[1] = 0;
                hv_PredictionForegroundColor[2] = 0;
                hv_PredictionBackgroundColor.Clear();
                hv_PredictionBackgroundColor[0] = 0.5;
                hv_PredictionBackgroundColor[1] = 0;
                hv_PredictionBackgroundColor[2] = 0;
                ho_PredictionSymbol = ho_Cross;
            }
            //Add sample image.
            ConcatObj(ho_ImagesToTile, ho_SampleImage, &ho_ImagesToTile);
            //Add text image.
            CopyImage(ho_TextImageRaw, &ho_TextImage);
            OverpaintRegion(ho_TextImage, ho_TextImage, hv_PredictionBackgroundColor, "fill");
            PaintXld(ho_PredictionSymbol, ho_TextImage, &ho_TextImage, hv_PredictionForegroundColor);
            ConcatObj(ho_ImagesToTile, ho_TextImage, &ho_ImagesToTile);
        }
    }
    //
    //Set row/column positions of upper-left corners for the images to tile,
    //and for the text images.
    hv_TiledRows = HTuple(2*hv_NumSamples,0);
    hv_TiledColumns = HTuple(2*hv_NumSamples,0);
    (*hv_TextImageRows) = HTuple(hv_NumSamples,0);
    (*hv_TextImageColumns) = HTuple(hv_NumSamples,0);
    {
        HTuple end_val107 = hv_NumSamples-1;
        HTuple step_val107 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val107, step_val107); hv_Index += step_val107)
        {
            hv_TiledRows[2*hv_Index] = (hv_Index%hv_NumRows)*((*hv_TextImageHeight)+hv_ImageHeight);
            hv_TiledRows[(2*hv_Index)+1] = HTuple(hv_TiledRows[2*hv_Index])+hv_ImageHeight;
            hv_TiledColumns[2*hv_Index] = (hv_Index/hv_NumRows)*(hv_ImageWidth+hv_SeparateImageWidth);
            hv_TiledColumns[(2*hv_Index)+1] = HTuple(hv_TiledColumns[2*hv_Index]);
            (*hv_TextImageRows)[hv_Index] = HTuple(hv_TiledRows[(2*hv_Index)+1]);
            (*hv_TextImageColumns)[hv_Index] = HTuple(hv_TiledColumns[(2*hv_Index)+1]);
        }
    }
    //
    //Add vertical separator images to the images to tile, and
    //set the row/column positions of their upper-left corners.
    {
        HTuple end_val118 = hv_NumColumns-1;
        HTuple step_val118 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val118, step_val118); hv_Index += step_val118)
        {
            ConcatObj(ho_ImagesToTile, ho_SeparateImage, &ho_ImagesToTile);
            hv_TiledRows[hv_TiledRows.TupleLength()] = 0;
            hv_TiledColumns[hv_TiledColumns.TupleLength()] = (hv_Index*(hv_ImageWidth+hv_SeparateImageWidth))+hv_ImageWidth;
        }
    }
    //
    hv_TiledHeights = hv_NumRows*((*hv_TextImageHeight)+hv_ImageHeight);
    hv_TiledWidths = (hv_NumColumns*hv_ImageWidth)+((hv_NumColumns-1)*hv_SeparateImageWidth);
    TupleGenConst(hv_TiledRows.TupleLength(), -1, &hv_MinusOnes);
    TileImagesOffset(ho_ImagesToTile, &(*ho_TiledImage), hv_TiledRows, hv_TiledColumns,
                     hv_MinusOnes, hv_MinusOnes, hv_MinusOnes, hv_MinusOnes, hv_TiledWidths, hv_TiledHeights);
    //
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Generate a tiled image for segmentation and 3D Gripping Point Detection DLSamples.
void HalxAI:: gen_tiled_segmentation_image (HObject *ho_TiledImageRow, HTuple hv_DLSamples,
                                            HTuple hv_SpacingCol, HTuple hv_Width, HTuple hv_Height)
{

    // Local iconic variables
    HObject  ho_GTImages, ho_GTImage;

    // Local control variables
    HTuple  hv_SegmentationImageExist, hv_GrippingMapExist;
    HTuple  hv_ImageNameKey, hv_Crop, hv_OffsetRow, hv_NumSamples;
    HTuple  hv_Index;

    //
    //This procedure tiles the existing segmentation or gripping map images in given samples in a row.
    //
    //Check the required image for tiling.
    GetDictParam(HTuple(hv_DLSamples[0]), "key_exists", "segmentation_image", &hv_SegmentationImageExist);
    GetDictParam(HTuple(hv_DLSamples[0]), "key_exists", "gripping_map", &hv_GrippingMapExist);
    if (0 != hv_SegmentationImageExist)
    {
        hv_ImageNameKey = "segmentation_image";
    }
    else if (0 != hv_GrippingMapExist)
    {
        hv_ImageNameKey = "gripping_map";
    }
    //
    TupleGenConst(hv_Width.TupleLength(), -1, &hv_Crop);
    TupleGenConst(hv_Width.TupleLength(), 0, &hv_OffsetRow);
    hv_NumSamples = hv_DLSamples.TupleLength();
    GenEmptyObj(&ho_GTImages);
    {
        HTuple end_val16 = hv_NumSamples-1;
        HTuple step_val16 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val16, step_val16); hv_Index += step_val16)
        {
            GetDictObject(&ho_GTImage, HTuple(hv_DLSamples[hv_Index]), hv_ImageNameKey);
            ConcatObj(ho_GTImages, ho_GTImage, &ho_GTImages);
        }
    }
    //
    TileImagesOffset(ho_GTImages, &(*ho_TiledImageRow), hv_OffsetRow, (HTuple(0).TupleConcat((hv_Width+hv_SpacingCol).TupleCumul())).TupleSelectRange(0,(hv_Width.TupleLength())-1),
                     hv_Crop, hv_Crop, hv_Crop, hv_Crop, HTuple(((hv_Width+hv_SpacingCol).TupleCumul())[(hv_Width.TupleLength())-1])-hv_SpacingCol,
            hv_Height.TupleMax());
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Generate a word to characters mapping.
void HalxAI:: gen_words_chars_mapping (HTuple hv_DLSample, HTupleVector/*{eTupleVector,Dim=1}*/ *hvec_WordsCharsMapping)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WordsIndices, hv_CharsIndices, hv_WordLengths;
    HTuple  hv_WordArea, hv_CharArea, hv_CharAreaThreshold;
    HTuple  hv_WordIndex, hv_AreaIntersection, hv_CIsInsideW;
    HTuple  hv_CIndex;

    //Procedure to generate the mapping: gen_words_chars_mapping
    if (0 != (int(((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())>0)))
    {
        TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 0, &hv_WordsIndices);
        TupleFind(hv_DLSample.TupleGetDictTuple("bbox_label_id"), 1, &hv_CharsIndices);
        if (0 != (HTuple(int(hv_CharsIndices!=-1)).TupleAnd(int(hv_WordsIndices!=-1))))
        {
            hv_WordLengths = HTuple((hv_DLSample.TupleGetDictTuple("word"))[hv_WordsIndices]).TupleStrlen();
            //Init vector.
            (*hvec_WordsCharsMapping)[((hv_DLSample.TupleGetDictTuple("bbox_label_id")).TupleLength())-1] = HTupleVector(HTuple());
            hv_WordArea = (4*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_WordsIndices]))*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_WordsIndices]);
            hv_CharArea = (4*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_CharsIndices]))*HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_CharsIndices]);
            //TODO: This threshold is quite arbitrary and not stable.
            hv_CharAreaThreshold = hv_CharArea*0.8;
            {
                HTuple end_val12 = (hv_WordsIndices.TupleLength())-1;
                HTuple step_val12 = 1;
                for (hv_WordIndex=0; hv_WordIndex.Continue(end_val12, step_val12); hv_WordIndex += step_val12)
                {
                    if (0 != (int(HTuple(hv_WordLengths[hv_WordIndex])!=0)))
                    {
                        AreaIntersectionRectangle2(HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[HTuple(hv_WordsIndices[hv_WordIndex])]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[HTuple(hv_WordsIndices[hv_WordIndex])]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[HTuple(hv_WordsIndices[hv_WordIndex])]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[HTuple(hv_WordsIndices[hv_WordIndex])]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[HTuple(hv_WordsIndices[hv_WordIndex])]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_row"))[hv_CharsIndices]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_col"))[hv_CharsIndices]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_phi"))[hv_CharsIndices]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_length1"))[hv_CharsIndices]),
                                HTuple((hv_DLSample.TupleGetDictTuple("bbox_length2"))[hv_CharsIndices]),
                                &hv_AreaIntersection);
                        hv_CIsInsideW = hv_AreaIntersection.TupleGreaterElem(hv_CharAreaThreshold);
                        hv_CIndex = hv_CIsInsideW.TupleFind(1);
                        if (0 != (int(hv_CIndex!=-1)))
                        {
                            (*hvec_WordsCharsMapping)[HTuple(hv_WordsIndices[hv_WordIndex])] = HTupleVector(HTuple(hv_CharsIndices[hv_CIndex]));
                        }
                    }
                    else
                    {
                        throw HException(((("Sample with image id "+(hv_DLSample.TupleGetDictTuple("image_id")))+" is not valid. The word bounding box at index ")+hv_WordIndex)+" has an empty string as the ground truth. This is not allowed. Please assign a word label to every word bounding box.");
                    }
                }
            }
        }
    }
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Get the ground truth anomaly label and label ID.
void HalxAI:: get_anomaly_ground_truth_label (HTuple hv_SampleKeys, HTuple hv_DLSample, HTuple *hv_AnomalyLabelGroundTruth,
                                              HTuple *hv_AnomalyLabelIDGroundTruth)
{

    //
    //This procedure returns the anomaly ground truth label.
    //
    if (0 != (int((hv_SampleKeys.TupleFind("anomaly_label"))!=-1)))
    {
        GetDictTuple(hv_DLSample, "anomaly_label", &(*hv_AnomalyLabelGroundTruth));
    }
    else
    {
        throw HException("Ground truth class label cannot be found in DLSample.");
    }
    if (0 != (int((hv_SampleKeys.TupleFind("anomaly_label_id"))!=-1)))
    {
        GetDictTuple(hv_DLSample, "anomaly_label_id", &(*hv_AnomalyLabelIDGroundTruth));
    }
    else
    {
        throw HException("Ground truth class label id cannot be found in DLSample.");
    }
    //
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Get the anomaly results out of DLResult and apply thresholds (if specified).
void HalxAI:: get_anomaly_result (HObject *ho_AnomalyImage, HObject *ho_AnomalyRegion, HTuple hv_DLResult,
                                  HTuple hv_AnomalyClassThreshold, HTuple hv_AnomalyRegionThreshold, HTuple hv_AnomalyResultPostfix,
                                  HTuple *hv_AnomalyScore, HTuple *hv_AnomalyClassID, HTuple *hv_AnomalyClassThresholdDisplay,
                                  HTuple *hv_AnomalyRegionThresholdDisplay)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_AnomalyImageKey, hv_AnomalyScoreKey;
    HTuple  hv_AnomalyRegionKey, hv_AnomalyClassIdKey, hv_ErrorMsgPostfix;
    HTuple  hv_ResultKeys;

    //
    //This procedure returns the inference results in DLResult which are
    //the anomaly image and the anomaly score. It also returns the
    //classification of the anomaly score and segmentation of anomalous
    //pixels in the anomaly image by applying the specified thresholds if
    //given. Otherwise the results from DLResult are used.
    //
    //
    hv_AnomalyImageKey = "anomaly_image"+hv_AnomalyResultPostfix;
    hv_AnomalyScoreKey = "anomaly_score"+hv_AnomalyResultPostfix;
    hv_AnomalyRegionKey = "anomaly_region"+hv_AnomalyResultPostfix;
    hv_AnomalyClassIdKey = "anomaly_class_id"+hv_AnomalyResultPostfix;
    //
    TupleRegexpReplace(hv_AnomalyResultPostfix, "_", " ", &hv_ErrorMsgPostfix);
    //
    GetDictParam(hv_DLResult, "keys", HTuple(), &hv_ResultKeys);
    if (0 != (int(hv_ResultKeys==HTuple())))
    {
        throw HException(("Result anomaly image"+hv_ErrorMsgPostfix)+" could not be found in DLResult.");
    }
    //
    if (0 != (int((hv_ResultKeys.TupleFindFirst(hv_AnomalyImageKey))!=-1)))
    {
        GetDictObject(&(*ho_AnomalyImage), hv_DLResult, hv_AnomalyImageKey);
    }
    else
    {
        throw HException(("Result anomaly image"+hv_ErrorMsgPostfix)+" could not be found in DLResult.");
    }
    //
    if (0 != (int((hv_ResultKeys.TupleFindFirst(hv_AnomalyScoreKey))!=-1)))
    {
        GetDictTuple(hv_DLResult, hv_AnomalyScoreKey, &(*hv_AnomalyScore));
    }
    else
    {
        throw HException(("Result anomaly score"+hv_ErrorMsgPostfix)+" could not be found in DLResult.");
    }
    //
    (*hv_AnomalyRegionThresholdDisplay) = -1;
    if (0 != (int(hv_AnomalyRegionThreshold!=-1)))
    {
        //Apply threshold for segmentation result.
        if (0 != (int((hv_AnomalyRegionThreshold.TupleLength())!=1)))
        {
            throw HException("Selected 'anomaly_region_threshold' must be specified by exactly one value.");
        }
        Threshold((*ho_AnomalyImage), &(*ho_AnomalyRegion), hv_AnomalyRegionThreshold,
                  "max");
        (*hv_AnomalyRegionThresholdDisplay) = hv_AnomalyRegionThreshold;
    }
    else
    {
        //If no threshold is given, use the threshold and resulting anomaly region out of DLResult.
        if (0 != (int((hv_ResultKeys.TupleFindFirst(hv_AnomalyRegionKey))!=-1)))
        {
            GetDictObject(&(*ho_AnomalyRegion), hv_DLResult, hv_AnomalyRegionKey);
        }
        else
        {
            GenEmptyObj(&(*ho_AnomalyRegion));
        }
        if (0 != (int((hv_ResultKeys.TupleFind("anomaly_segmentation_threshold"))!=-1)))
        {
            GetDictTuple(hv_DLResult, "anomaly_segmentation_threshold", &(*hv_AnomalyRegionThresholdDisplay));
        }
    }
    //
    (*hv_AnomalyClassThresholdDisplay) = -1;
    (*hv_AnomalyClassID) = -1;
    if (0 != (int(hv_AnomalyClassThreshold!=-1)))
    {
        //Apply threshold for classification result.
        if (0 != (int((hv_AnomalyClassThreshold.TupleLength())!=1)))
        {
            throw HException("Selected 'anomaly_classification_threshold' must be specified by exactly one value.");
        }
        if (0 != (int((*hv_AnomalyScore)<hv_AnomalyClassThreshold)))
        {
            (*hv_AnomalyClassID) = 0;
        }
        else
        {
            (*hv_AnomalyClassID) = 1;
        }
        (*hv_AnomalyClassThresholdDisplay) = hv_AnomalyClassThreshold;
    }
    else
    {
        //If no threshold is given, use the threshold and resulting class id out of DLResult.
        if (0 != (int((hv_ResultKeys.TupleFindFirst(hv_AnomalyClassIdKey))!=-1)))
        {
            GetDictTuple(hv_DLResult, hv_AnomalyClassIdKey, &(*hv_AnomalyClassID));
        }
        else
        {
            (*hv_AnomalyClassID) = -1;
        }
        if (0 != (int((hv_ResultKeys.TupleFind("anomaly_classification_threshold"))!=-1)))
        {
            GetDictTuple(hv_DLResult, "anomaly_classification_threshold", &(*hv_AnomalyClassThresholdDisplay));
        }
    }
    //
    return;
}

// Chapter: Graphics / Window
// Short Description: Get the next child window that can be used for visualization.
void HalxAI:: get_child_window (HTuple hv_HeightImage, HTuple hv_Font, HTuple hv_FontSize,
                                HTuple hv_Text, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict,
                                HTuple hv_WindowHandleKey, HTuple *hv_WindowImageRatio, HTuple *hv_PrevWindowCoordinatesOut)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_OpenNewWindow, hv_WindowHandles, hv_ParentWindowHandle;
    HTuple  hv_ChildWindowHandle, hv_Exception, hv_MetaInfo;
    HTuple  hv_WindowRow, hv_WindowColumn, hv_WindowWidth, hv_WindowHeight;

    //
    //This procedure returns the next child window that
    //is used for visualization. If ReuseWindows is true
    //and WindowHandleList is suitable, the window handles
    //that are passed over are used. Else, this procedure
    //opens a new window, either next to the last ones, or
    //in a new row.
    //
    //First, check if the requested window is already available.
    hv_OpenNewWindow = 0;
    try
    {
        GetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, &hv_WindowHandles);
        hv_ParentWindowHandle = ((const HTuple&)hv_WindowHandles)[0];
        hv_ChildWindowHandle = ((const HTuple&)hv_WindowHandles)[1];
        //Check if window handle is valid.
        try
        {
            FlushBuffer(hv_ChildWindowHandle);
        }
        // catch (Exception)
        catch (HException &HDevExpDefaultException)
        {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            //Since there is something wrong with the current window, create a new one.
            hv_OpenNewWindow = 1;
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_OpenNewWindow = 1;
    }
    //
    //Get next child window.
    if (0 != (hv_OpenNewWindow.TupleNot()))
    {
        //
        //If possible, reuse existing window handles.
        HDevWindowStack::SetActive(hv_ChildWindowHandle);
        if (HDevWindowStack::IsOpen())
            ClearWindow(HDevWindowStack::GetActive());
        set_display_font(hv_ChildWindowHandle, hv_FontSize, hv_Font, "true", "false");
        //
        GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
        //
        //Get previous window coordinates.
        GetWindowExtents(hv_ParentWindowHandle, &hv_WindowRow, &hv_WindowColumn, &hv_WindowWidth,
                         &hv_WindowHeight);
        (*hv_WindowImageRatio) = hv_WindowHeight/(hv_HeightImage*1.0);
        //
        try
        {
            //
            //Get WindowImageRatio from parent window.
            GetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_height",
                         &(*hv_WindowImageRatio));
            //
            //Get previous window coordinates.
            GetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_child_window_coordinates", &(*hv_PrevWindowCoordinatesOut));
        }
        // catch (Exception)
        catch (HException &HDevExpDefaultException)
        {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            //
            //Set WindowImageRatio from parent window.
            GetWindowExtents(hv_ParentWindowHandle, &hv_WindowRow, &hv_WindowColumn, &hv_WindowWidth,
                             &hv_WindowHeight);
            (*hv_WindowImageRatio) = hv_WindowHeight/(hv_HeightImage*1.0);
            //
            //Set previous window coordinates.
            (*hv_PrevWindowCoordinatesOut)[0] = hv_WindowRow;
            (*hv_PrevWindowCoordinatesOut)[1] = hv_WindowColumn;
            (*hv_PrevWindowCoordinatesOut)[2] = hv_WindowWidth;
            (*hv_PrevWindowCoordinatesOut)[3] = hv_WindowHeight;
        }
    }
    else
    {
        //
        //Open a new child window.
        open_child_window(hv_ParentWindowHandle, hv_Font, hv_FontSize, hv_Text, hv_PrevWindowCoordinates,
                          hv_WindowHandleDict, hv_WindowHandleKey, &hv_ChildWindowHandle, &(*hv_PrevWindowCoordinatesOut));
        SetWindowParam(hv_ChildWindowHandle, "flush", "false");
        SetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, hv_ParentWindowHandle.TupleConcat(hv_ChildWindowHandle));
    }
    //
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Get the ground truth classification label id.
void HalxAI:: get_classification_ground_truth (HTuple hv_SampleKeys, HTuple hv_DLSample, HTuple *hv_ClassificationLabelIDGroundTruth)
{

    //
    //This procedure returns the classification ground truth label ID.
    //
    if (0 != (int((hv_SampleKeys.TupleFind("image_label_id"))!=-1)))
    {
        GetDictTuple(hv_DLSample, "image_label_id", &(*hv_ClassificationLabelIDGroundTruth));
    }
    else
    {
        throw HException("Ground truth class label cannot be found in DLSample.");
    }
    //
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Get the predicted classification class ID.
void HalxAI:: get_classification_result (HTuple hv_ResultKeys, HTuple hv_DLResult, HTuple *hv_ClassificationClassID)
{

    // Local iconic variables

    //
    //This procedure returns the predicted classification class ID.
    //
    if (0 != (int((hv_ResultKeys.TupleFind("classification_class_ids"))!=-1)))
    {
        GetDictTuple(hv_DLResult, "classification_class_ids", &(*hv_ClassificationClassID));
        if (0 != (int(((*hv_ClassificationClassID).TupleLength())>0)))
        {
            (*hv_ClassificationClassID) = ((const HTuple&)(*hv_ClassificationClassID))[0];
        }
    }
    else
    {
        throw HException("Key entry 'classification_class_ids' could not be found in DLResult.");
    }
    //
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Get the confidences of the segmentation result.
void HalxAI:: get_confidence_image (HObject *ho_ImageConfidence, HTuple hv_ResultKeys, HTuple hv_DLResult)
{

    //
    //This procedure returns confidences of the segmentation result.
    //
    if (0 != (int((hv_ResultKeys.TupleFind("segmentation_confidence"))!=-1)))
    {
        GetDictObject(&(*ho_ImageConfidence), hv_DLResult, "segmentation_confidence");
    }
    else if (0 != (int((hv_ResultKeys.TupleFind("segmentation_confidences"))!=-1)))
    {
        GetDictObject(&(*ho_ImageConfidence), hv_DLResult, "segmentation_confidences");
    }
    else
    {
        throw HException("Confidence image could not be found in DLSample.");
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Generate NumColors distinct colors
void HalxAI:: get_distinct_colors (HTuple hv_NumColors, HTuple hv_Random, HTuple hv_StartColor,
                                   HTuple hv_EndColor, HTuple *hv_Colors)
{

    // Local iconic variables
    HObject  ho_HLSImageH, ho_HLSImageL, ho_HLSImageS;
    HObject  ho_ImageR, ho_ImageG, ho_ImageB;

    // Local control variables
    HTuple  hv_IsString, hv_Hue, hv_Lightness, hv_Saturation;
    HTuple  hv_Rows, hv_Columns, hv_Red, hv_Green, hv_Blue;

    //
    //We get distinct color-values first in HLS color-space.
    //Assumes hue [0, EndColor), lightness [0, 1), saturation [0, 1).
    //
    //Parameter checks.
    //NumColors.
    if (0 != (int(hv_NumColors<1)))
    {
        throw HException("NumColors should be at least 1");
    }
    if (0 != ((hv_NumColors.TupleIsInt()).TupleNot()))
    {
        throw HException("NumColors should be of type int");
    }
    if (0 != (int((hv_NumColors.TupleLength())!=1)))
    {
        throw HException("NumColors should have length 1");
    }
    //Random.
    if (0 != (HTuple(int(hv_Random!=0)).TupleAnd(int(hv_Random!=1))))
    {
        TupleIsString(hv_Random, &hv_IsString);
        if (0 != hv_IsString)
        {
            hv_Random = HTuple(int(hv_Random==HTuple("true"))).TupleOr("false");
        }
        else
        {
            throw HException("Random should be either true or false");
        }
    }
    //StartColor.
    if (0 != (int((hv_StartColor.TupleLength())!=1)))
    {
        throw HException("StartColor should have length 1");
    }
    if (0 != (HTuple(int(hv_StartColor<0)).TupleOr(int(hv_StartColor>255))))
    {
        throw HException(HTuple("StartColor should be in the range [0, 255]"));
    }
    if (0 != ((hv_StartColor.TupleIsInt()).TupleNot()))
    {
        throw HException("StartColor should be of type int");
    }
    //EndColor.
    if (0 != (int((hv_EndColor.TupleLength())!=1)))
    {
        throw HException("EndColor should have length 1");
    }
    if (0 != (HTuple(int(hv_EndColor<0)).TupleOr(int(hv_EndColor>255))))
    {
        throw HException(HTuple("EndColor should be in the range [0, 255]"));
    }
    if (0 != ((hv_EndColor.TupleIsInt()).TupleNot()))
    {
        throw HException("EndColor should be of type int");
    }
    //
    //Color generation.
    if (0 != (int(hv_StartColor>hv_EndColor)))
    {
        hv_EndColor += 255;
    }
    if (0 != (int(hv_NumColors!=1)))
    {
        hv_Hue = (hv_StartColor+((((hv_EndColor-hv_StartColor)*(HTuple::TupleGenSequence(0,hv_NumColors-1,1).TupleReal()))/((hv_NumColors-1).TupleReal())).TupleInt()))%255;
    }
    else
    {
        hv_Hue = (hv_StartColor.TupleConcat(hv_EndColor)).TupleMean();
    }
    if (0 != hv_Random)
    {
        hv_Hue = ((const HTuple&)hv_Hue)[HTuple::TupleRand(hv_NumColors).TupleSortIndex()];
        hv_Lightness = (((5.0+HTuple::TupleRand(hv_NumColors))*255.0)/10.0).TupleInt();
        hv_Saturation = (((9.0+HTuple::TupleRand(hv_NumColors))*255.0)/10.0).TupleInt();
    }
    else
    {
        hv_Lightness = (HTuple(hv_NumColors,0.55)*255.0).TupleInt();
        hv_Saturation = (HTuple(hv_NumColors,0.95)*255.0).TupleInt();
    }
    //
    //Write colors to a 3-channel image in order to transform easier.
    GenImageConst(&ho_HLSImageH, "byte", 1, hv_NumColors);
    GenImageConst(&ho_HLSImageL, "byte", 1, hv_NumColors);
    GenImageConst(&ho_HLSImageS, "byte", 1, hv_NumColors);
    GetRegionPoints(ho_HLSImageH, &hv_Rows, &hv_Columns);
    SetGrayval(ho_HLSImageH, hv_Rows, hv_Columns, hv_Hue);
    SetGrayval(ho_HLSImageL, hv_Rows, hv_Columns, hv_Lightness);
    SetGrayval(ho_HLSImageS, hv_Rows, hv_Columns, hv_Saturation);
    //
    //Convert from HLS to RGB.
    TransToRgb(ho_HLSImageH, ho_HLSImageL, ho_HLSImageS, &ho_ImageR, &ho_ImageG, &ho_ImageB,
               "hls");
    //
    //Get RGB-values and transform to Hex.
    GetGrayval(ho_ImageR, hv_Rows, hv_Columns, &hv_Red);
    GetGrayval(ho_ImageG, hv_Rows, hv_Columns, &hv_Green);
    GetGrayval(ho_ImageB, hv_Rows, hv_Columns, &hv_Blue);
    (*hv_Colors) = (("#"+(hv_Red.TupleString("02x")))+(hv_Green.TupleString("02x")))+(hv_Blue.TupleString("02x"));
    return;
    //
}

// Chapter: Deep Learning / Model
// Short Description: Generate certain colors for different ClassNames
void HalxAI:: get_dl_class_colors (HTuple hv_ClassNames, HTuple hv_AdditionalGreenClassNames,
                                   HTuple *hv_Colors)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_NumColors, hv_ColorsRainbow, hv_ClassNamesGood;
    HTuple  hv_IndexFind, hv_GoodIdx, hv_CurrentColor, hv_GreenIdx;

    //
    //This procedure returns for each class a certain color.
    //
    //Define distinct colors for the classes.
    hv_NumColors = hv_ClassNames.TupleLength();
    //Get distinct colors without randomness makes neighboring colors look very similar.
    //We use a workaround to get deterministic colors where subsequent colors are distinguishable.
    get_distinct_colors(hv_NumColors, 0, 0, 200, &hv_ColorsRainbow);
    TupleInverse(hv_ColorsRainbow, &hv_ColorsRainbow);
    make_neighboring_colors_distinguishable(hv_ColorsRainbow, &(*hv_Colors));
    //If a class 'OK','ok', 'good' or 'GOOD' or a class specified in AdditionalGreenClassNames is present set this class to green.
    //Only the first occurrence found is set to a green shade.
    TupleUnion((((HTuple("good").Append("GOOD")).Append("ok")).Append("OK")), hv_AdditionalGreenClassNames,
               &hv_ClassNamesGood);
    {
        HTuple end_val13 = (hv_ClassNamesGood.TupleLength())-1;
        HTuple step_val13 = 1;
        for (hv_IndexFind=0; hv_IndexFind.Continue(end_val13, step_val13); hv_IndexFind += step_val13)
        {
            hv_GoodIdx = hv_ClassNames.TupleFindFirst(HTuple(hv_ClassNamesGood[hv_IndexFind]));
            if (0 != (HTuple(int(hv_GoodIdx!=-1)).TupleAnd(int((hv_ClassNames.TupleLength())<=8))))
            {
                //If number of classes is <= 8, swap color with a green color.
                hv_CurrentColor = HTuple((*hv_Colors)[hv_GoodIdx]);
                hv_GreenIdx = HTuple((hv_ClassNames.TupleLength())/2.0).TupleFloor();
                //Set to pure green.
                (*hv_Colors)[hv_GoodIdx] = "#00ff00";
                //Write original color to a green entry.
                (*hv_Colors)[hv_GreenIdx] = hv_CurrentColor;
                break;
            }
            else if (0 != (HTuple(int(hv_GoodIdx!=-1)).TupleAnd(int((hv_ClassNames.TupleLength())>8))))
            {
                //If number of classes is larger than 8, set the respective color to green.
                (*hv_Colors)[hv_GoodIdx] = "#00ff00";
                break;
            }
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Return the intended optimization method based on given evaluation key(s).
void HalxAI:: get_dl_evaluation_optimization_method (HTuple hv_EvaluationKeys, HTuple *hv_OptimizationMethod)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Matches, hv_Length, hv_ErrorKeys, hv_Sum;

    //Only evaluation keys which contain the name 'error' are minimization problems.
    TupleRegexpMatch(hv_EvaluationKeys, "error", &hv_Matches);
    TupleStrlen(hv_Matches, &hv_Length);
    TupleGreaterElem(hv_Length, 0, &hv_ErrorKeys);
    TupleSum(hv_ErrorKeys, &hv_Sum);
    if (0 != (int(hv_Sum==(hv_ErrorKeys.TupleLength()))))
    {
        (*hv_OptimizationMethod) = "min";
    }
    else if (0 != (int(hv_Sum==0)))
    {
        (*hv_OptimizationMethod) = "max";
    }
    else
    {
        (*hv_OptimizationMethod) = "mixed";
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Get an image of a sample with a certain key.
void HalxAI:: get_dl_sample_image (HObject *ho_Image, HTuple hv_SampleKeys, HTuple hv_DLSample,
                                   HTuple hv_Key)
{

    //This procedure returns an image with key Key of a sample.
    //
    if (0 != (int((hv_SampleKeys.TupleFind(hv_Key))!=-1)))
    {
        GetDictObject(&(*ho_Image), hv_DLSample, hv_Key);
    }
    else
    {
        throw HException(("Image with key '"+hv_Key)+"' could not be found in DLSample.");
    }
    return;
}

// Chapter: Deep Learning / OCR
// Short Description: Determine the ocr type of the sample based on the sample structure.
void HalxAI:: get_dl_sample_ocr_type (HTuple hv_DLSample, HTuple *hv_OCRType)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WordExists, hv_BoundingBoxExists;

    (*hv_OCRType) = "non_ocr";
    GetDictParam(hv_DLSample, "key_exists", "word", &hv_WordExists);
    if (0 != hv_WordExists)
    {
        GetDictParam(hv_DLSample, "key_exists", "bbox_label_id", &hv_BoundingBoxExists);
        if (0 != hv_BoundingBoxExists)
        {
            (*hv_OCRType) = "ocr_detection";
        }
        else
        {
            (*hv_OCRType) = "ocr_recognition";
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Get a parameter value from GenParamValue with the name RequestedGenParamName.
void HalxAI:: get_genparam_single_value (HTuple hv_GenParamName, HTuple hv_GenParamValue,
                                         HTuple hv_RequestedGenParamName, HTuple *hv_FoundGenParamValue)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Indices;

    //
    //Get a parameter value from GenParamValue with the name RequestedGenParamName,
    //which is allowed to appear only once in GenParamName.
    //
    //Set a default in case no value is provided.
    (*hv_FoundGenParamValue) = HTuple();
    //Set user provided values, if provided.
    hv_Indices = hv_GenParamName.TupleFind(hv_RequestedGenParamName);
    if (0 != (HTuple(int((hv_Indices.TupleLength())==1)).TupleAnd(int(hv_Indices!=-1))))
    {
        (*hv_FoundGenParamValue) = HTuple(hv_GenParamValue[hv_Indices]);
    }
    else if (0 != (int((hv_Indices.TupleLength())>1)))
    {
        //Throw an error if more than one value was provided for RequestedGenParamName.
        throw HException(("Only a single parameter dictionary or none is allowed for '"+hv_RequestedGenParamName)+"'.");
    }
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Extract gripping points from a dictionary.
void HalxAI:: get_gripping_points_from_dict (HTuple hv_DLResult, HTuple *hv_Rows, HTuple *hv_Columns)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_KeyExists, hv_GrippingPoints, hv_NumberOfResults;
    HTuple  hv_IndexGrippingPointsPoint, hv_GrippingPointCoordDict;

    if (0 != (int(hv_DLResult==HTuple())))
    {
        throw HException("DLResult dict is empty.");
    }
    GetDictParam(hv_DLResult, "key_exists", "gripping_points", &hv_KeyExists);
    if (0 != hv_KeyExists)
    {
        GetDictTuple(hv_DLResult, "gripping_points", &hv_GrippingPoints);
    }
    else
    {
        throw HException("Result data could not be found in DLResult.");
    }
    hv_NumberOfResults = hv_GrippingPoints.TupleLength();
    TupleGenConst(hv_NumberOfResults, 0, &(*hv_Rows));
    TupleGenConst(hv_NumberOfResults, 0, &(*hv_Columns));
    {
        HTuple end_val12 = (hv_GrippingPoints.TupleLength())-1;
        HTuple step_val12 = 1;
        for (hv_IndexGrippingPointsPoint=0; hv_IndexGrippingPointsPoint.Continue(end_val12, step_val12); hv_IndexGrippingPointsPoint += step_val12)
        {
            hv_GrippingPointCoordDict = HTuple(hv_GrippingPoints[hv_IndexGrippingPointsPoint]);
            (*hv_Rows)[hv_IndexGrippingPointsPoint] = hv_GrippingPointCoordDict.TupleGetDictTuple("row");
            (*hv_Columns)[hv_IndexGrippingPointsPoint] = hv_GrippingPointCoordDict.TupleGetDictTuple("column");
        }
    }
    return;
}

// Chapter: Graphics / Window
// Short Description: Get the next window that can be used for visualization.
void HalxAI:: get_next_window (HTuple hv_Font, HTuple hv_FontSize, HTuple hv_ShowBottomDesc,
                               HTuple hv_WidthImage, HTuple hv_HeightImage, HTuple hv_MapColorBarWidth, HTuple hv_ScaleWindows,
                               HTuple hv_ThresholdWidth, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict,
                               HTuple hv_WindowHandleKey, HTuple *hv_CurrentWindowHandle, HTuple *hv_WindowImageRatioHeight,
                               HTuple *hv_PrevWindowCoordinatesOut)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_OpenNewWindow, hv_WindowHandles, hv_Value;
    HTuple  hv_Exception, hv_Ascent, hv_Descent, hv__, hv_NumLines;
    HTuple  hv_MarginBottom, hv_WindowImageRatioWidth, hv_SetPartRow2;
    HTuple  hv_SetPartColumn2, hv_MetaInfo;

    //
    //This procedure returns the next window that
    //is used for visualization. If ReuseWindows is true
    //and WindowHandleList is suitable, the window handles
    //that are passed over are used. Else, this procedure
    //opens a new window, either next to the last ones, or
    //in a new row.
    //
    //First, check if the requested window is already available.
    hv_OpenNewWindow = 0;
    try
    {
        GetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, &hv_WindowHandles);
        (*hv_CurrentWindowHandle) = ((const HTuple&)hv_WindowHandles)[0];
        //Check if window handle is valid.
        try
        {
            GetWindowParam((*hv_CurrentWindowHandle), "flush", &hv_Value);
        }
        // catch (Exception)
        catch (HException &HDevExpDefaultException)
        {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            //If there is something wrong with the current window, create a new one.
            hv_OpenNewWindow = 1;
            RemoveDictKey(hv_WindowHandleDict, hv_WindowHandleKey);
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_OpenNewWindow = 1;
    }
    //
    //Get next window.
    if (0 != (hv_OpenNewWindow.TupleNot()))
    {
        //
        //If possible, reuse existing window handles.
        HDevWindowStack::SetActive((*hv_CurrentWindowHandle));
        if (HDevWindowStack::IsOpen())
            ClearWindow(HDevWindowStack::GetActive());
        set_display_font((*hv_CurrentWindowHandle), hv_FontSize, hv_Font, "true", "false");
        //
        //Calculate MarginBottom.
        if (0 != hv_ShowBottomDesc)
        {
            GetStringExtents((*hv_CurrentWindowHandle), "test_string", &hv_Ascent, &hv_Descent,
                             &hv__, &hv__);
            hv_NumLines = hv_ShowBottomDesc;
            hv_MarginBottom = (hv_NumLines*(hv_Ascent+hv_Descent))+(2*12);
        }
        else
        {
            hv_MarginBottom = 0;
        }
        //
        //Get and set meta information for current window.
        update_window_meta_information((*hv_CurrentWindowHandle), hv_WidthImage, hv_HeightImage,
                                       0, 0, hv_MapColorBarWidth, hv_MarginBottom, &(*hv_WindowImageRatioHeight),
                                       &hv_WindowImageRatioWidth, &hv_SetPartRow2, &hv_SetPartColumn2, &(*hv_PrevWindowCoordinatesOut));
        //
        //Update meta information.
        GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_height", (*hv_WindowImageRatioHeight));
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_width", hv_WindowImageRatioWidth);
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_row2", hv_SetPartRow2);
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_column2", hv_SetPartColumn2);
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_margin_bottom", hv_MarginBottom);
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_map_color_bar_with", hv_MapColorBarWidth);
        SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_coordinates", (*hv_PrevWindowCoordinatesOut));
    }
    else
    {
        //
        //Open a new window.
        open_next_window(hv_Font, hv_FontSize, hv_ShowBottomDesc, hv_WidthImage, hv_HeightImage,
                         hv_MapColorBarWidth, hv_ScaleWindows, hv_ThresholdWidth, hv_PrevWindowCoordinates,
                         hv_WindowHandleDict, hv_WindowHandleKey, &(*hv_CurrentWindowHandle), &(*hv_WindowImageRatioHeight),
                         &(*hv_PrevWindowCoordinatesOut));
        SetWindowParam((*hv_CurrentWindowHandle), "flush", "false");
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Return all pixel measures from a specified list of measures.
void HalxAI:: get_requested_pixel_measures (HTuple hv_Measures, HTuple hv_EvaluationType,
                                            HTuple *hv_PixelMeasures)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ValidMeasures, hv_M;

    //
    //This helper procedure returns for a given list of
    //requested measures all pixel measures for the specified
    //evaluation type.
    //
    (*hv_PixelMeasures) = HTuple();
    get_valid_pixel_measures(hv_EvaluationType, &hv_ValidMeasures);
    //
    {
        HTuple end_val8 = (hv_Measures.TupleLength())-1;
        HTuple step_val8 = 1;
        for (hv_M=0; hv_M.Continue(end_val8, step_val8); hv_M += step_val8)
        {
            if (0 != (int(HTuple(hv_Measures[hv_M])==HTuple("all"))))
            {
                (*hv_PixelMeasures) = (*hv_PixelMeasures).TupleConcat(hv_ValidMeasures);
            }
            else if (0 != (int((hv_ValidMeasures.TupleFind(HTuple(hv_Measures[hv_M])))!=-1)))
            {
                (*hv_PixelMeasures) = (*hv_PixelMeasures).TupleConcat(HTuple(hv_Measures[hv_M]));
            }
        }
    }
    //
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Get the ground truth segmentation image.
void HalxAI:: get_segmentation_image_ground_truth (HObject *ho_SegmentationImagGroundTruth,
                                                   HTuple hv_SampleKeys, HTuple hv_DLSample)
{

    //
    //This procedure returns the ground truth segmentation image.
    //
    if (0 != (int((hv_SampleKeys.TupleFind("segmentation_image"))!=-1)))
    {
        GetDictObject(&(*ho_SegmentationImagGroundTruth), hv_DLSample, "segmentation_image");
    }
    else
    {
        throw HException("Ground truth segmentation image could not be found in DLSample.");
    }
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Get the predicted segmentation result image.
void HalxAI:: get_segmentation_image_result (HObject *ho_SegmentationImageResult, HTuple hv_ResultKeys,
                                             HTuple hv_DLResult)
{

    //
    //This procedure returns the predicted segmentation result image.
    //
    if (0 != (int((hv_ResultKeys.TupleFind("segmentation_image"))!=-1)))
    {
        GetDictObject(&(*ho_SegmentationImageResult), hv_DLResult, "segmentation_image");
    }
    else
    {
        throw HException("Result segmentation data could not be found in DLSample.");
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Returns the list of available pixel evaluation measures for the specified type.
void HalxAI:: get_valid_pixel_measures (HTuple hv_EvaluationType, HTuple *hv_EvaluationMeasures)
{

    // Local iconic variables

    //
    //This helper procedure returns for the given evaluation type
    //all pixel measures available for this type.
    //
    (*hv_EvaluationMeasures) = HTuple();
    if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
    {
        (*hv_EvaluationMeasures).Clear();
        (*hv_EvaluationMeasures)[0] = "pixel_accuracy";
        (*hv_EvaluationMeasures)[1] = "mean_accuracy";
        (*hv_EvaluationMeasures)[2] = "mean_iou";
        (*hv_EvaluationMeasures)[3] = "class_iou";
        (*hv_EvaluationMeasures)[4] = "class_pixel_accuracy";
        (*hv_EvaluationMeasures)[5] = "pixel_confusion_matrix";
        (*hv_EvaluationMeasures)[6] = "frequency_weighted_iou";
    }
    else if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
    {
        (*hv_EvaluationMeasures).Clear();
        (*hv_EvaluationMeasures)[0] = "mean_precision";
        (*hv_EvaluationMeasures)[1] = "mean_iou";
    }
    //
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Get the weight image of a sample.
void HalxAI:: get_weight_image (HObject *ho_ImageWeight, HTuple hv_SampleKeys, HTuple hv_DLSample)
{

    //
    //This procedure returns the segmentation weight image of a sample.
    //
    if (0 != (int((hv_SampleKeys.TupleFind("weight_image"))!=-1)))
    {
        GetDictObject(&(*ho_ImageWeight), hv_DLSample, "weight_image");
    }
    else
    {
        throw HException("Weight image could not be found in DLSample.");
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize the dictionary RunningMeasures for the evaluation.
void HalxAI:: init_running_evaluation_measures (HTuple hv_EvalParams, HTuple *hv_RunningMeasures)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Valid, hv_Exception, hv_NumClasses;
    HTuple  hv_EvaluationType, hv_Measures, hv_ClassIDs, hv_PixelMeasures;
    HTuple  hv_CalcRegionMeasures, hv_CalcGrippingPointMeasures;
    HTuple  hv_InstanceType, hv_EvalOrientation, hv_AllocationBlockLength;
    HTuple  hv_IoUThreshs, hv_MaxNumDetections, hv_AreaRanges;
    HTuple  hv_AreaNames, hv_MinAreas, hv_MaxAreas, hv_DetailedEvaluation;
    HTuple  hv_MaxNumIdx, hv_MaxNum, hv_CurrentRunningMeasure;
    HTuple  hv_AreaIdx, hv_AreaRunningMeasure, hv_I, hv_IoURunningMeasure;
    HTuple  hv_ClsIdx, hv_ClassRunningMeasures, hv_Confidence;
    HTuple  hv_IgnoreClassIDs, hv_CalcConfMatrix, hv_MatrixSize;
    HTuple  hv_PixelConfusionMatrix, hv_MaxId, hv_ClsIDToClsIdx;
    HTuple  hv_TP, hv_FP, hv_FN;

    //
    //This procedure initializes the dictionary RunningMeasures for evaluation.
    //It uses the evaluation parameters to initialize the running measures accordingly.
    //
    //The structure of RunningMeasures depends on the entry 'evaluate_instances' in the dictionary EvalParams.
    //
    //The dictionary RunningMeasures can be updated based on the per-batch/per-image evaluation results.
    //
    CreateDict(&(*hv_RunningMeasures));
    //Check that the necessary evaluation parameters exist.
    validate_evaluation_param(hv_EvalParams, &hv_Valid, &hv_Exception);
    if (0 != (hv_Valid.TupleNot()))
    {
        throw HException(HTuple("Invalid EvalParams, ")+hv_Exception);
    }
    //
    //Get general evaluation parameters.
    GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    //
    if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
    {
        //RunningMeasures contains:
        //if pixel measures:
        //- tp/fp/fn (pixel numbers for the gripping_map class)
        //if region measures:
        //- gt_overlap (accumulated overlap of groundtruth regions with the prediction)
        //- num_gt_regions (overall number of groundtruth regions)
        //if gripping point measures:
        //- gp_tp/gp_fp/gp_fn (gripping point true positives, false positives, and
        //  false negatives w.r.t. ground truth gripping point region).
        get_requested_pixel_measures(hv_Measures, hv_EvaluationType, &hv_PixelMeasures);
        if (0 != (int((hv_PixelMeasures.TupleLength())>0)))
        {
            SetDictTuple((*hv_RunningMeasures), "tp", 0);
            SetDictTuple((*hv_RunningMeasures), "fp", 0);
            SetDictTuple((*hv_RunningMeasures), "fn", 0);
        }
        hv_CalcRegionMeasures = HTuple(int((hv_Measures.TupleFind("mean_pro"))>-1)).TupleOr(int((hv_Measures.TupleFind("all"))>-1));
        if (0 != hv_CalcRegionMeasures)
        {
            SetDictTuple((*hv_RunningMeasures), "gt_overlap", 0);
            SetDictTuple((*hv_RunningMeasures), "num_gt_regions", 0);
        }
        hv_CalcGrippingPointMeasures = int((HTuple(hv_Measures.TupleRegexpSelect("gripping_point_.*|all")).TupleLength())>0);
        if (0 != hv_CalcGrippingPointMeasures)
        {
            SetDictTuple((*hv_RunningMeasures), "gp_tp", 0);
            SetDictTuple((*hv_RunningMeasures), "gp_fp", 0);
            SetDictTuple((*hv_RunningMeasures), "gp_fn", 0);
        }
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
    {
        //RunningMeasures contains:
        //- image_ids:          IDs of the images.
        //- anomaly_label_ids:  Class IDs of ground truth labels.
        //- anomaly_scores:     Predicted image level anomaly scores.
        SetDictTuple((*hv_RunningMeasures), "image_ids", HTuple());
        SetDictTuple((*hv_RunningMeasures), "anomaly_label_ids", HTuple());
        SetDictTuple((*hv_RunningMeasures), "anomaly_scores", HTuple());
    }
    else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
    {
        //RunningMeasures contains:
        //- image_ids:          IDs of the images.
        //- image_label_ids:    Class IDs of ground truth labels.
        //- top1_predictions:   Class IDs of the top predicted class.
        //- topk_predictions:   Class IDs of top-K predicted classes.
        SetDictTuple((*hv_RunningMeasures), "image_ids", HTuple());
        SetDictTuple((*hv_RunningMeasures), "image_label_ids", HTuple());
        SetDictTuple((*hv_RunningMeasures), "top1_predictions", HTuple());
        SetDictTuple((*hv_RunningMeasures), "topk_predictions", HTuple());
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("detection"))).TupleOr(int(hv_EvaluationType==HTuple("ocr_detection")))))
    {
        //RunningMeasures contains:
        //For each maximal number of regions (MaxNumDetections):
        // - For each area range (AreaRanges):
        //   -- confidence:     Confidence (score) of each result.
        //   -- num_gt:         Total number of ground truth instances per class.
        //   -- num_pred:       Total number of predictions per class.
        //   -- num_gt_ignore:  Number of ignored ground truth instances per class.
        //   -- for each IoU-threshold:
        //      --- For each class:
        //          ---- is_tp:                  TP/FP assignment of result.
        //          ---- ignore:                 Ignore/Not-Ignore assignment of result.
        //          ---- abs_orientation_diff (for instance_type 'rectangle2' with measure SoAP):
        //                                       Absolute orientation difference of the result.
        //
        //Check if the orientation difference is to be evaluated.
        GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
        hv_EvalOrientation = 0;
        if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(HTuple(int((hv_Measures.TupleFind("soap"))!=-1)).TupleOr(int((hv_Measures.TupleFind("all"))!=-1)))))
        {
            hv_EvalOrientation = 1;
        }
        //
        //Calculating the measures confidence, is_tp, ignore, and abs_orientation_diff,
        //arrays are allocated with -1 in blocks of AllocationBlockLength
        //(thus, if a block is filled, the next block is allocated).
        //Otherwise the arrays have to be concatenated which is rather slow.
        //The actual length of the array is garnered in num_pred.
        GetDictTuple(hv_EvalParams, "allocation_block_length", &hv_AllocationBlockLength);
        GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IoUThreshs);
        GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
        GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
        //AreaRanges is a dictionary containing 'name', 'min_area', 'max_area'.
        GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
        GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
        GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
        //Check if a detailed evaluation will be performed.
        GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
        //Set a result dictionary for each maximal number of detections and IoU-threshold.
        {
            HTuple end_val104 = (hv_MaxNumDetections.TupleLength())-1;
            HTuple step_val104 = 1;
            for (hv_MaxNumIdx=0; hv_MaxNumIdx.Continue(end_val104, step_val104); hv_MaxNumIdx += step_val104)
            {
                hv_MaxNum = HTuple(hv_MaxNumDetections[hv_MaxNumIdx]);
                CreateDict(&hv_CurrentRunningMeasure);
                {
                    HTuple end_val107 = (hv_AreaNames.TupleLength())-1;
                    HTuple step_val107 = 1;
                    for (hv_AreaIdx=0; hv_AreaIdx.Continue(end_val107, step_val107); hv_AreaIdx += step_val107)
                    {
                        CreateDict(&hv_AreaRunningMeasure);
                        {
                            HTuple end_val109 = (hv_IoUThreshs.TupleLength())-1;
                            HTuple step_val109 = 1;
                            for (hv_I=0; hv_I.Continue(end_val109, step_val109); hv_I += step_val109)
                            {
                                CreateDict(&hv_IoURunningMeasure);
                                {
                                    HTuple end_val111 = hv_NumClasses-1;
                                    HTuple step_val111 = 1;
                                    for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val111, step_val111); hv_ClsIdx += step_val111)
                                    {
                                        CreateDict(&hv_ClassRunningMeasures);
                                        SetDictTuple(hv_ClassRunningMeasures, "is_tp", HTuple(hv_AllocationBlockLength,-1));
                                        SetDictTuple(hv_ClassRunningMeasures, "ignore", HTuple(hv_AllocationBlockLength,-1));
                                        if (0 != hv_EvalOrientation)
                                        {
                                            SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff", HTuple(hv_AllocationBlockLength,-1));
                                        }
                                        if (0 != hv_DetailedEvaluation)
                                        {
                                            SetDictTuple(hv_ClassRunningMeasures, "is_fp_class", HTuple(hv_AllocationBlockLength,-1));
                                            SetDictTuple(hv_ClassRunningMeasures, "is_fp_background", HTuple(hv_AllocationBlockLength,-1));
                                            SetDictTuple(hv_ClassRunningMeasures, "is_fp_localization", HTuple(hv_AllocationBlockLength,-1));
                                            SetDictTuple(hv_ClassRunningMeasures, "is_fp_duplicate", HTuple(hv_AllocationBlockLength,-1));
                                            SetDictTuple(hv_ClassRunningMeasures, "is_fp_multiple", HTuple(hv_AllocationBlockLength,-1));
                                            if (0 != hv_EvalOrientation)
                                            {
                                                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_class",
                                                             HTuple(hv_AllocationBlockLength,-1));
                                                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_localization",
                                                             HTuple(hv_AllocationBlockLength,-1));
                                                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_duplicate",
                                                             HTuple(hv_AllocationBlockLength,-1));
                                                SetDictTuple(hv_ClassRunningMeasures, "abs_orientation_diff_multiple",
                                                             HTuple(hv_AllocationBlockLength,-1));
                                            }
                                            SetDictTuple(hv_IoURunningMeasure, "image_ids_with_false_negatives",
                                                         HTuple(hv_AllocationBlockLength,-1));
                                            SetDictTuple(hv_IoURunningMeasure, "image_ids_with_false_positives",
                                                         HTuple(hv_AllocationBlockLength,-1));
                                            SetDictTuple(hv_IoURunningMeasure, "num_image_ids_with_false_negatives",
                                                         0);
                                            SetDictTuple(hv_IoURunningMeasure, "num_image_ids_with_false_positives",
                                                         0);
                                        }
                                        SetDictTuple(hv_IoURunningMeasure, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                     hv_ClassRunningMeasures);
                                    }
                                }
                                SetDictTuple(hv_AreaRunningMeasure, "iou_"+((""+HTuple(hv_IoUThreshs[hv_I])).TupleRegexpReplace("\\.","")),
                                             hv_IoURunningMeasure);
                            }
                        }
                        CreateDict(&hv_Confidence);
                        {
                            HTuple end_val140 = hv_NumClasses-1;
                            HTuple step_val140 = 1;
                            for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val140, step_val140); hv_ClsIdx += step_val140)
                            {
                                SetDictTuple(hv_Confidence, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]), HTuple(hv_AllocationBlockLength,-1.0));
                            }
                        }
                        SetDictTuple(hv_AreaRunningMeasure, "confidence", hv_Confidence);
                        SetDictTuple(hv_AreaRunningMeasure, "num_gt", HTuple(hv_NumClasses,0));
                        SetDictTuple(hv_AreaRunningMeasure, "num_pred", HTuple(hv_NumClasses,0));
                        SetDictTuple(hv_AreaRunningMeasure, "num_gt_ignore", HTuple(hv_NumClasses,0));
                        SetDictTuple(hv_CurrentRunningMeasure, "area_"+HTuple(hv_AreaNames[hv_AreaIdx]),
                                     hv_AreaRunningMeasure);
                    }
                }
                if (0 != (int(hv_MaxNum==-1)))
                {
                    hv_MaxNum = "all";
                }
                SetDictTuple((*hv_RunningMeasures), "max_num_detections_"+hv_MaxNum, hv_CurrentRunningMeasure);
            }
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
    {
        //RunningMeasures contains:
        //if confusion matrix in Measures (slower but more information).
        // - confusion matrix per pixel.
        //else:
        // - TP/FP/FN (pixel numbers per class).
        //
        //Incorporate ignore class IDs.
        GetDictTuple(hv_EvalParams, "ignore_class_ids", &hv_IgnoreClassIDs);
        //
        //Check if we need to compute/update the confusion matrix.
        hv_CalcConfMatrix = HTuple(int((hv_Measures.TupleFind("pixel_confusion_matrix"))>-1)).TupleOr(int((hv_Measures.TupleFind("all"))>-1));
        if (0 != hv_CalcConfMatrix)
        {
            //Define the size of the confusion matrix.
            hv_MatrixSize = hv_NumClasses+(int((hv_IgnoreClassIDs.TupleLength())>0));
            CreateMatrix(hv_MatrixSize, hv_MatrixSize, 0, &hv_PixelConfusionMatrix);
            SetDictTuple((*hv_RunningMeasures), "pixel_confusion_matrix", hv_PixelConfusionMatrix);
            //
            //If the class IDs are not running indices from 0 to NumClasses we
            //define a mapping from class IDs to class indices.
            if (0 != (HTuple(int(hv_ClassIDs!=HTuple::TupleGenSequence(0,(hv_ClassIDs.TupleLength())-1,1))).TupleOr(int((hv_IgnoreClassIDs.TupleLength())>0))))
            {
                //Get the max ID that can occur.
                hv_MaxId = (hv_ClassIDs.TupleMax())+(int((hv_IgnoreClassIDs.TupleLength())>0));
                //Define the basic mapping.
                TupleGenConst(hv_MaxId+1, -1, &hv_ClsIDToClsIdx);
                hv_ClsIDToClsIdx[hv_ClassIDs] = HTuple::TupleGenSequence(0,(hv_ClassIDs.TupleLength())-1,1);
                //Map ignore IDs to the next higher one.
                hv_ClsIDToClsIdx[hv_IgnoreClassIDs] = (hv_ClsIDToClsIdx.TupleMax())+1;
                //Set the mapping to the evaluation parameters.
                SetDictTuple(hv_EvalParams, "class_id_mapping", hv_ClsIDToClsIdx);
            }
        }
        else
        {
            hv_TP = HTuple(hv_NumClasses,0);
            hv_FP = HTuple(hv_NumClasses,0);
            hv_FN = HTuple(hv_NumClasses,0);
            SetDictTuple((*hv_RunningMeasures), "tp", hv_TP);
            SetDictTuple((*hv_RunningMeasures), "fp", hv_FP);
            SetDictTuple((*hv_RunningMeasures), "fn", hv_FN);
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
    {
        //RunningMeasures for OCR recognition models.
        SetDictTuple((*hv_RunningMeasures), "image_ids", HTuple());
        SetDictTuple((*hv_RunningMeasures), "words_ground_truth", HTuple());
        SetDictTuple((*hv_RunningMeasures), "words_prediction", HTuple());
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize change strategies data.
void HalxAI:: init_train_dl_model_change_strategies (HTuple hv_TrainParam, HTuple *hv_ChangeStrategyData)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ChangeStrategies, hv_Enabled, hv_Index;
    HTuple  hv_ChangeStrategy, hv_ModelParam, hv_Epochs, hv_Values;
    HTuple  hv_Initial, hv_Indices, hv_ScaleThresholdExists;

    //
    //Initialize a dictionary with the change strategies data.
    CreateDict(&(*hv_ChangeStrategyData));
    GetDictTuple(hv_TrainParam, "change_strategies", &hv_ChangeStrategies);
    hv_Enabled = int((hv_ChangeStrategies.TupleLength())>0);
    SetDictTuple((*hv_ChangeStrategyData), "enabled", hv_Enabled);
    if (0 != (hv_Enabled.TupleNot()))
    {
        return;
    }
    //
    //Sort all epochs in all change strategies.
    {
        HTuple end_val11 = (hv_ChangeStrategies.TupleLength())-1;
        HTuple step_val11 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val11, step_val11); hv_Index += step_val11)
        {
            hv_ChangeStrategy = HTuple(hv_ChangeStrategies[hv_Index]);
            GetDictTuple(hv_ChangeStrategy, "model_param", &hv_ModelParam);
            GetDictTuple(hv_ChangeStrategy, "epochs", &hv_Epochs);
            GetDictTuple(hv_ChangeStrategy, "values", &hv_Values);
            GetDictTuple(hv_ChangeStrategy, "initial_value", &hv_Initial);
            //Check that the length are equal.
            if (0 != (int((hv_Epochs.TupleLength())!=(hv_Values.TupleLength()))))
            {
                throw HException("ChangeStrategy parameter error: 'epochs' and 'values' need to have same length.");
            }
            //We need sorted arrays for faster access.
            TupleSortIndex(hv_Epochs, &hv_Indices);
            SetDictTuple(hv_ChangeStrategy, "epochs", HTuple(hv_Epochs[hv_Indices]));
            SetDictTuple(hv_ChangeStrategy, "values", HTuple(hv_Values[hv_Indices]));
            //
            //For the learning rate, there can be an additional parameter
            //indicating if the momentum should be scaled as well.
            if (0 != (int(hv_ModelParam==HTuple("learning_rate"))))
            {
                GetDictParam(hv_ChangeStrategy, "key_exists", "scale_momentum_threshold", &hv_ScaleThresholdExists);
                if (0 != (hv_ScaleThresholdExists.TupleNot()))
                {
                    //If not given, the threshold is set to an empty tuple such that no scaling is performed.
                    SetDictTuple(hv_ChangeStrategy, "scale_momentum_threshold", HTuple());
                }
            }
        }
    }
    SetDictTuple((*hv_ChangeStrategyData), "strategies", hv_ChangeStrategies);
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Initialize the dictionary setting for serialization strategies.
void HalxAI:: init_train_dl_model_serialization_strategies (HTuple hv_TrainParam, HTuple *hv_SerializationData)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_SerializationStrategies, hv_RawData;
    HTuple  hv_Types, hv_SerializeFinal, hv_Index, hv_Strategy;
    HTuple  hv_Type, hv_Data, hv_Epochs, hv_NumEpochs;

    //
    //This procedure initializes the dictionary setting the serialization strategies.
    //
    //Initialize each serialization strategy.
    GetDictTuple(hv_TrainParam, "serialization_strategies", &hv_SerializationStrategies);
    CreateDict(&(*hv_SerializationData));
    SetDictTuple((*hv_SerializationData), "strategies", hv_SerializationStrategies);
    hv_RawData = HTuple();
    hv_Types = HTuple();
    hv_SerializeFinal = 0;
    {
        HTuple end_val10 = (hv_SerializationStrategies.TupleLength())-1;
        HTuple step_val10 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val10, step_val10); hv_Index += step_val10)
        {
            hv_Strategy = HTuple(hv_SerializationStrategies[hv_Index]);
            GetDictTuple(hv_Strategy, "type", &hv_Type);
            CreateDict(&hv_Data);
            if (0 != (int(hv_Type==HTuple("best"))))
            {
                SetDictTuple(hv_Data, "best_value", -1);
            }
            else if (0 != (int(hv_Type==HTuple("epochs"))))
            {
                GetDictTuple(hv_Strategy, "epochs", &hv_Epochs);
                //Store sorted values in order to search faster during updates.
                TupleSort(hv_Epochs, &hv_Epochs);
                SetDictTuple(hv_Data, "epochs", hv_Epochs);
                SetDictTuple(hv_Data, "last_epoch_index", -1);
            }
            else if (0 != (int(hv_Type==HTuple("current"))))
            {
                GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
                SetDictTuple(hv_Data, "epochs", HTuple::TupleGenSequence(1,hv_NumEpochs,1));
                SetDictTuple(hv_Data, "last_epoch_index", -1);
            }
            else if (0 != (int(hv_Type==HTuple("final"))))
            {
                SetDictTuple(hv_Data, "serialize_final", 1);
            }
            else
            {
                throw HException(("Unknown serialization strategy type: '"+hv_Type)+"'");
            }
            hv_Types = hv_Types.TupleConcat(hv_Type);
            hv_RawData = hv_RawData.TupleConcat(hv_Data);
        }
    }
    SetDictTuple((*hv_SerializationData), "raw_data", hv_RawData);
    SetDictTuple((*hv_SerializationData), "types", hv_Types);
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Shuffle the input colors in a deterministic way
void HalxAI:: make_neighboring_colors_distinguishable (HTuple hv_ColorsRainbow, HTuple *hv_Colors)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_NumColors, hv_NumChunks, hv_NumLeftOver;
    HTuple  hv_ColorsPerChunk, hv_StartIdx, hv_S, hv_EndIdx;
    HTuple  hv_IdxsLeft, hv_IdxsRight;

    //
    //Shuffle the input colors in a deterministic way
    //to make adjacent colors more distinguishable.
    //Neighboring colors from the input are distributed to every NumChunks
    //position in the output.
    //Depending on the number of colors, increase NumChunks.
    hv_NumColors = hv_ColorsRainbow.TupleLength();
    if (0 != (int(hv_NumColors>=8)))
    {
        hv_NumChunks = 3;
        if (0 != (int(hv_NumColors>=40)))
        {
            hv_NumChunks = 6;
        }
        else if (0 != (int(hv_NumColors>=20)))
        {
            hv_NumChunks = 4;
        }
        (*hv_Colors) = HTuple(hv_NumColors,-1);
        //Check if the Number of Colors is dividable by NumChunks.
        hv_NumLeftOver = hv_NumColors%hv_NumChunks;
        hv_ColorsPerChunk = (hv_NumColors/hv_NumChunks).TupleInt();
        hv_StartIdx = 0;
        {
            HTuple end_val19 = hv_NumChunks-1;
            HTuple step_val19 = 1;
            for (hv_S=0; hv_S.Continue(end_val19, step_val19); hv_S += step_val19)
            {
                hv_EndIdx = (hv_StartIdx+hv_ColorsPerChunk)-1;
                if (0 != (int(hv_S<hv_NumLeftOver)))
                {
                    hv_EndIdx += 1;
                }
                hv_IdxsLeft = HTuple::TupleGenSequence(hv_S,hv_NumColors-1,hv_NumChunks);
                hv_IdxsRight = HTuple::TupleGenSequence(hv_StartIdx,hv_EndIdx,1);
                (*hv_Colors)[HTuple::TupleGenSequence(hv_S,hv_NumColors-1,hv_NumChunks)] = hv_ColorsRainbow.TupleSelectRange(hv_StartIdx,hv_EndIdx);
                hv_StartIdx = hv_EndIdx+1;
            }
        }
    }
    else
    {
        (*hv_Colors) = hv_ColorsRainbow;
    }
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Normalize the output features of the Global Context Anomaly Detection model before training.
void HalxAI:: normalize_dl_gc_anomaly_features (HTuple hv_DLDataset, HTuple hv_DLModelHandle,
                                                HTuple hv_GenParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_DLSamples, hv_TrainSampleIndices, hv_OriginalSeed;
    HTuple  hv_ShuffledIndices, hv_NumNormalizationIndices;
    HTuple  hv_NormalizationIndices, hv_DLSamplesNormalization;
    HTuple  hv_NormalizationLayerNames, hv_ModelLayerNames;
    HTuple  hv_Index, hv_LayerName, hv_Mean, hv_StdDev, hv_Normalizer;

    //To normalize the output of the feature extractor E_loc its
    //output channels are normalized to have zero mean and a
    //standard deviation of 1.0 on the training samples.
    //
    //Make sure GenParam is an empty tuple.
    if (0 != (int(hv_GenParam!=HTuple())))
    {
        throw HException("The parameter GenParam must be an empty tuple.");
    }
    //
    GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
    find_dl_samples(hv_DLSamples, "split", "train", "match", &hv_TrainSampleIndices);
    //Make sure we use the same samples given the same dataset,
    //so that repeatedly calling this procedure with the same dataset does not
    //update the normalization of E_loc.
    GetSystem("seed_rand", &hv_OriginalSeed);
    SetSystem("seed_rand", 0);
    tuple_shuffle(hv_TrainSampleIndices, &hv_ShuffledIndices);
    SetSystem("seed_rand", hv_OriginalSeed);
    hv_NumNormalizationIndices = HTuple(100).TupleMin2(hv_ShuffledIndices.TupleLength());
    hv_NormalizationIndices = hv_ShuffledIndices.TupleSelectRange(0,hv_NumNormalizationIndices-1);
    read_dl_samples(hv_DLDataset, hv_NormalizationIndices, &hv_DLSamplesNormalization);

    hv_NormalizationLayerNames.Clear();
    hv_NormalizationLayerNames[0] = "eloc_output";
    hv_NormalizationLayerNames[1] = "tglo_output";
    GetDlModelParam(hv_DLModelHandle, "layer_names", &hv_ModelLayerNames);
    {
        HTuple end_val24 = (hv_NormalizationLayerNames.TupleLength())-1;
        HTuple step_val24 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val24, step_val24); hv_Index += step_val24)
        {
            hv_LayerName = HTuple(hv_NormalizationLayerNames[hv_Index]);
            if (0 != (int((hv_ModelLayerNames.TupleFindFirst(hv_LayerName))!=-1)))
            {
                calculate_dl_model_layer_mean_stddev(hv_DLModelHandle, hv_LayerName, hv_DLSamplesNormalization,
                                                     &hv_Mean, &hv_StdDev);
                //Clip the standard deviation to avoid HalxAI:: numerical issues.
                hv_Normalizer = hv_StdDev.TupleMax2(0.001);
                scale_and_shift_dl_model_layer(hv_DLModelHandle, hv_LayerName, 1.0/(hv_Normalizer.TupleReal()),
                                               (-hv_Mean)/(hv_Normalizer.TupleReal()));
            }
        }
    }
    return;
}

// Chapter: Graphics / Window
// Short Description: Open a window next to the given WindowHandleFather.
void HalxAI:: open_child_window (HTuple hv_WindowHandleFather, HTuple hv_Font, HTuple hv_FontSize,
                                 HTuple hv_Text, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict,
                                 HTuple hv_WindowHandleKey, HTuple *hv_WindowHandleChild, HTuple *hv_PrevWindowCoordinatesOut)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_StringWidth, hv_IndexText, hv__, hv_TextWidth;
    HTuple  hv_WindowRow, hv_WindowColumn, hv_WindowWidth, hv_WindowHeight;
    HTuple  hv_MetaInfo;

    //
    //This procedure opens a window next to the given WindowHandleFather.
    //
    //Get the maximum width of the text to be displayed.
    //The width should be at least 200.
    hv_StringWidth = 150;
    {
        HTuple end_val6 = (hv_Text.TupleLength())-1;
        HTuple step_val6 = 1;
        for (hv_IndexText=0; hv_IndexText.Continue(end_val6, step_val6); hv_IndexText += step_val6)
        {
            GetStringExtents(hv_WindowHandleFather, HTuple(hv_Text[hv_IndexText]), &hv__,
                             &hv__, &hv_TextWidth, &hv__);
            hv_StringWidth = hv_StringWidth.TupleMax2(hv_TextWidth);
        }
    }
    //
    //Define window coordinates.
    hv_WindowRow = ((const HTuple&)hv_PrevWindowCoordinates)[0];
    hv_WindowColumn = (HTuple(hv_PrevWindowCoordinates[1])+HTuple(hv_PrevWindowCoordinates[2]))+5;
    hv_WindowWidth = hv_StringWidth+(2*12.0);
    hv_WindowHeight = ((const HTuple&)hv_PrevWindowCoordinates)[3];
    //
    SetWindowAttr("background_color","black");
    OpenWindow(hv_WindowRow,hv_WindowColumn,hv_WindowWidth,hv_WindowHeight,0,"visible","",&(*hv_WindowHandleChild));
    HDevWindowStack::Push((*hv_WindowHandleChild));
    set_display_font((*hv_WindowHandleChild), hv_FontSize, hv_Font, "true", "false");
    //
    //Return the coordinates of the new window.
    (*hv_PrevWindowCoordinatesOut).Clear();
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowRow);
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowColumn);
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowWidth);
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowHeight);
    //
    //Set some meta information about the new child window handle.
    GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_child_window_coordinates", (*hv_PrevWindowCoordinatesOut));
    SetDictTuple(hv_WindowHandleDict, "meta_information", hv_MetaInfo);
    //
    return;
}

// Chapter: Graphics / Window
// Short Description: Open a new window, either next to the last ones, or in a new row.
void HalxAI:: open_next_window (HTuple hv_Font, HTuple hv_FontSize, HTuple hv_ShowBottomDesc,
                                HTuple hv_WidthImage, HTuple hv_HeightImage, HTuple hv_MapColorBarWidth, HTuple hv_ScaleWindows,
                                HTuple hv_ThresholdWidth, HTuple hv_PrevWindowCoordinates, HTuple hv_WindowHandleDict,
                                HTuple hv_WindowHandleKey, HTuple *hv_WindowHandleNew, HTuple *hv_WindowImageRatioHeight,
                                HTuple *hv_PrevWindowCoordinatesOut)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_PrevWindowRow, hv_PrevWindowColumn;
    HTuple  hv_PrevWindowWidth, hv_PrevWindowHeight, hv_WindowRow;
    HTuple  hv_WindowColumn, hv_Ascent, hv_Descent, hv__, hv_NumLines;
    HTuple  hv_MarginBottom, hv_WindowWidth, hv_WindowHeight;
    HTuple  hv_WindowImageRatioWidth, hv_SetPartRow2, hv_SetPartColumn2;
    HTuple  hv_MetaInfo;

    //
    //This procedure opens a new window, either next to
    //the last ones, or in a new row.
    //
    //Get coordinates of previous window.
    hv_PrevWindowRow = ((const HTuple&)hv_PrevWindowCoordinates)[0];
    hv_PrevWindowColumn = ((const HTuple&)hv_PrevWindowCoordinates)[1];
    hv_PrevWindowWidth = ((const HTuple&)hv_PrevWindowCoordinates)[2];
    hv_PrevWindowHeight = ((const HTuple&)hv_PrevWindowCoordinates)[3];
    //
    if (0 != (int((hv_PrevWindowColumn+hv_PrevWindowWidth)>hv_ThresholdWidth)))
    {
        //Open window in new row.
        hv_WindowRow = (hv_PrevWindowRow+hv_PrevWindowHeight)+55;
        hv_WindowColumn = 0;
    }
    else
    {
        //Open window in same row.
        hv_WindowRow = hv_PrevWindowRow;
        hv_WindowColumn = hv_PrevWindowColumn+hv_PrevWindowWidth;
        if (0 != (int(hv_WindowColumn!=0)))
        {
            hv_WindowColumn += 5;
        }
    }
    //
    dev_open_window_fit_size(hv_WindowRow, hv_WindowColumn, hv_WidthImage, hv_HeightImage,
                             (HTuple(500).Append(800))*hv_ScaleWindows, (HTuple(400).Append(600))*hv_ScaleWindows,
                             &(*hv_WindowHandleNew));
    set_display_font((*hv_WindowHandleNew), hv_FontSize, hv_Font, "true", "false");
    //
    //Add MarginBottom and MapColorBarWidth to window.
    if (0 != hv_ShowBottomDesc)
    {
        GetStringExtents((*hv_WindowHandleNew), "Test_string", &hv_Ascent, &hv_Descent,
                         &hv__, &hv__);
        hv_NumLines = hv_ShowBottomDesc;
        hv_MarginBottom = (hv_NumLines*(hv_Ascent+hv_Descent))+(2*12);
    }
    else
    {
        hv_MarginBottom = 0;
    }
    GetWindowExtents((*hv_WindowHandleNew), &hv__, &hv__, &hv_WindowWidth, &hv_WindowHeight);
    if (HDevWindowStack::IsOpen())
        SetWindowExtents(HDevWindowStack::GetActive(),hv_WindowRow, hv_WindowColumn,
                         hv_WindowWidth+hv_MapColorBarWidth, hv_WindowHeight+hv_MarginBottom);
    //
    //Get and set meta information of new window handle.
    update_window_meta_information((*hv_WindowHandleNew), hv_WidthImage, hv_HeightImage,
                                   hv_WindowRow, hv_WindowColumn, hv_MapColorBarWidth, hv_MarginBottom, &(*hv_WindowImageRatioHeight),
                                   &hv_WindowImageRatioWidth, &hv_SetPartRow2, &hv_SetPartColumn2, &(*hv_PrevWindowCoordinatesOut));
    //
    //Set window handle and some meta information about the new window handle.
    SetDictTuple(hv_WindowHandleDict, hv_WindowHandleKey, (*hv_WindowHandleNew));
    GetDictTuple(hv_WindowHandleDict, "meta_information", &hv_MetaInfo);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_height", (*hv_WindowImageRatioHeight));
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_image_ratio_width", hv_WindowImageRatioWidth);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_row2", hv_SetPartRow2);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_set_part_column2", hv_SetPartColumn2);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_margin_bottom", hv_MarginBottom);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_map_color_bar_with", hv_MapColorBarWidth);
    SetDictTuple(hv_MetaInfo, hv_WindowHandleKey+"_window_coordinates", (*hv_PrevWindowCoordinatesOut));
    SetDictTuple(hv_WindowHandleDict, "meta_information", hv_MetaInfo);
    //
    return;
}

// Chapter: Graphics / Output
// Short Description: Plot tuples representing functions or curves in a coordinate system.
void HalxAI:: plot_tuple_no_window_handling (HTuple hv_WindowHandle, HTuple hv_XValues, HTuple hv_YValues,
                                             HTuple hv_XLabel, HTuple hv_YLabel, HTuple hv_Color, HTuple hv_GenParamName,
                                             HTuple hv_GenParamValue)
{

    // Local iconic variables
    HObject  ho_ContourXGrid, ho_ContourYGrid, ho_XArrow;
    HObject  ho_YArrow, ho_ContourXTick, ho_ContourYTick, ho_Contour;
    HObject  ho_Cross, ho_Circle, ho_Filled, ho_Stair, ho_StairTmp;

    // Local control variables
    HTuple  hv_ClipRegion, hv_Row, hv_Column, hv_Width;
    HTuple  hv_Height, hv_PartRow1, hv_PartColumn1, hv_PartRow2;
    HTuple  hv_PartColumn2, hv_Red, hv_Green, hv_Blue, hv_DrawMode;
    HTuple  hv_OriginStyle, hv_PartDiffers, hv_PlotYLog, hv_YLogIndices;
    HTuple  hv_PlotYLogUser, hv_IsString, hv_YInd, hv_Indices1;
    HTuple  hv_XAxisEndValue, hv_YAxisEndValue, hv_XAxisStartValue;
    HTuple  hv_YAxisStartValue, hv_XValuesAreStrings, hv_XTickValues;
    HTuple  hv_XTicks, hv_YAxisPosition, hv_XAxisPosition, hv_LeftBorder;
    HTuple  hv_RightBorder, hv_UpperBorder, hv_LowerBorder;
    HTuple  hv_AxesColor, hv_Style, hv_Clip, hv_YTicks, hv_XGrid;
    HTuple  hv_YGrid, hv_GridColor, hv_YPosition, hv_FormatX;
    HTuple  hv_FormatY, hv_LineWidth, hv_NumGenParamNames, hv_NumGenParamValues;
    HTuple  hv_GenParamIndex, hv_XGridTicks, hv_YTickDirection;
    HTuple  hv_XTickDirection, hv_XAxisWidthPx, hv_XAxisWidth;
    HTuple  hv_XScaleFactor, hv_YAxisHeightPx, hv_YAxisHeight;
    HTuple  hv_YScaleFactor, hv_YAxisOffsetPx, hv_XAxisOffsetPx;
    HTuple  hv_DotStyle, hv_XGridValues, hv_XGridStart, hv_XCoord;
    HTuple  hv_IndexGrid, hv_YGridValues, hv_YGridStart, hv_YCoord;
    HTuple  hv_Ascent, hv_Descent, hv_TextWidthXLabel, hv_TextHeightXLabel;
    HTuple  hv_TextWidthYLabel, hv_TextHeightYLabel, hv_XTickStart;
    HTuple  hv_Indices, hv_TypeTicks, hv_IndexTicks, hv_Ascent1;
    HTuple  hv_Descent1, hv_TextWidthXTicks, hv_TextHeightXTicks;
    HTuple  hv_YTickValues, hv_YTickStart, hv_TextWidthYTicks;
    HTuple  hv_TextHeightYTicks, hv_Num, hv_I, hv_YSelected;
    HTuple  hv_StyleOriginal, hv_OldLineWidth, hv_Radii, hv_OldContourStyle;
    HTuple  hv_Y1Selected, hv_X1Selected, hv_Index, hv_Row1;
    HTuple  hv_Row2, hv_Col1, hv_Col2;

    //
    //This procedure plots tuples representing functions
    //or curves in a coordinate system.

    //In the following, the possible values are listed for the parameters:
    //
    //- XValues: X values of the function to be plotted. Thereby you have the following options:
    //  -- []: XValues are internally set to 0,1,2,...,|YValues|-1.
    //  -- a tuple of strings: These values are taken as categories.
    //
    //- YValues: Y values of the function(s) to be plotted. Thereby you have the following options:
    //  -- []: YValues are internally set to 0,1,2,...,|XValues|-1.
    //  -- a tuple of values: The number of y values must be equal to the number of x values or an integral multiple.
    //     In the latter case, multiple functions are plotted, that share the same x values.
    //
    //- XLabel: X-axis label.
    //
    //- YLabel: Y-axis label.
    //
    //- Color: Color of the plotted function. Thereby you have the following options:
    //  -- []: The currently set display color is used.
    //  -- 'none': The function is not plotted, but only the coordinate axes as specified.
    //  -- string: Defining the color of the plotted function.
    //  -- tuple of strings: -multiple functions can be displayed in different colors.
    //
    //- GenParamName: Generic parameter names to control the presentation.
    // The corresponding values are taken from GenParamValue. Possible Values string/value pairs:
    //  -- 'axes_color': Color of the coordinate axes. The default value is 'white'.
    //     If 'none' is given, no coordinate axes are shown.
    //  -- 'style': Graph style. Possible values:
    //     --- 'line' (default)
    //     --- 'cross'
    //     --- 'circle'
    //     --- 'step'
    //     --- 'filled'
    //  -- 'clip': Clip graph to coordinate system area. Possible values:
    //     --- 'no' (default)
    //     --- 'yes''
    //  -- 'ticks': Control display of ticks on the axes. Thereby you have the following options:
    //     --- 'min_max_origin' (default): Ticks are shown at the minimum and maximum values
    //         of the axes and at the intercept point of x- and y-axis.
    //     --- 'none': No ticks are shown.
    //     --- any number != 0: This number specifies the distance between the ticks.
    //  -- 'ticks_x': Control display of ticks on x-axis only. You have the same options as for 'ticks'.
    //  -- 'ticks_y': Control display of ticks on y-axis only. You have the same options as for 'ticks'.
    //  -- 'format_x': Format of the values next to the ticks of the x-axis (see tuple_string for more details).
    //  -- 'format_y': Format of the values next to the ticks of the y-axis (see tuple_string for more details).
    //  -- 'grid': Control display of grid lines within the coordinate system.
    //     Thereby you have the following options:
    //    --- 'min_max_origin' (default): Grid lines are shown at the minimum and maximum values of the axes.
    //    --- 'none': No grid lines are shown.
    //    --- If any number != 0: This number specifies the distance between the grid lines.
    //  -- 'grid_x': Control display of grid lines for the x-axis only.
    //  -- 'grid_y': Control display of grid lines for the y-axis only.
    //  -- 'grid_color': Color of the grid (default: 'dim gray').
    //  -- 'margin': The distance in pixels of the plot area to all four window borders.
    //  -- 'margin_left': The distance in pixels of the plot area to the left window border.
    //  -- 'margin_right': The distance in pixels of the plot area to the right window border.
    //  -- 'margin_top': The distance in pixels of the plot area to the upper window border.
    //  -- 'margin_bottom'': The distance in pixels of the plot area to the lower window border.
    //  -- 'start_x': Lowest x value of the x-axis. The default value is min(XValues).
    //  -- 'end_x': Highest x value of the x-axis. The default value is max(XValues).
    //  -- 'start_y': Lowest y value of the y-axis. The default value is min(YValues).
    //  -- 'end_y': Highest y value of the y-axis. The default value is max(YValues).
    //  -- 'axis_location_x': Position of the x-axis (Used to be called 'origin_y').
    //     Thereby you have the following options:
    //     --- 'bottom' (default)
    //     --- 'origin'
    //     --- 'top'
    //     --- Y coordinate of the intercept point of x- and y-axis.
    //  -- 'axis_location_y': Position of the y-axis (Used to be called 'origin_x').
    //     Thereby you have the following options:
    //     --- 'left' (default)
    //     --- 'right'
    //     --- 'origin'
    //     --- X coordinate of the intercept point of x- and y-axis.
    //  -- 'line_width': Line width of the plot.
    //  -- 'log_y': If 'true', plot the YValue in logarithmic scale. Default is 'false'.
    //
    //
    GetSystem("clip_region", &hv_ClipRegion);
    GetWindowExtents(hv_WindowHandle, &hv_Row, &hv_Column, &hv_Width, &hv_Height);
    GetPart(hv_WindowHandle, &hv_PartRow1, &hv_PartColumn1, &hv_PartRow2, &hv_PartColumn2);
    hv_Width = (hv_PartColumn2-hv_PartColumn1)+1;
    hv_Height = (hv_PartRow2-hv_PartRow1)+1;
    GetRgb(hv_WindowHandle, &hv_Red, &hv_Green, &hv_Blue);
    GetDraw(hv_WindowHandle, &hv_DrawMode);
    GetLineStyle(hv_WindowHandle, &hv_OriginStyle);
    //
    //Set the display parameters.
    SetLineStyle(hv_WindowHandle, HTuple());
    SetSystem("clip_region", "false");

    hv_PartDiffers = HTuple(HTuple(HTuple(int(0!=hv_PartRow1)).TupleOr(int(0!=hv_Column))).TupleOr(int((hv_Width-1)!=hv_PartColumn2))).TupleOr(int((hv_Height-1)!=hv_PartRow2));
    //Only use set part if it differs.
    if (0 != hv_PartDiffers)
    {
        if (HDevWindowStack::IsOpen())
            SetPart(HDevWindowStack::GetActive(),0, 0, hv_Height-1, hv_Width-1);
    }
    //
    //Check if we need to plot y-values logarithmically.
    //It is checked here because we want to convert the YValues tuple
    //immediately so that derived values will be correct.
    hv_PlotYLog = 0;
    if (0 != (HTuple(int((hv_GenParamName.TupleLength())>0)).TupleAnd(int((hv_GenParamName.TupleLength())==(hv_GenParamValue.TupleLength())))))
    {
        TupleFind(hv_GenParamName, "log_y", &hv_YLogIndices);
        if (0 != (int(hv_YLogIndices>=0)))
        {
            hv_PlotYLogUser = HTuple(hv_GenParamValue[HTuple(hv_YLogIndices[0])]);
            TupleIsString(hv_PlotYLogUser, &hv_IsString);
            if (0 != hv_IsString)
            {
                if (0 != (int(hv_PlotYLogUser==HTuple("true"))))
                {
                    hv_PlotYLog = 1;
                }
                else if (0 != (int(hv_PlotYLogUser==HTuple("false"))))
                {
                    hv_PlotYLog = 0;
                }
                else
                {
                    throw HException(("Unknown generic parameter value: '"+hv_PlotYLogUser)+"' for value: 'log_y'");
                }
                hv_PlotYLog = int(hv_PlotYLogUser==HTuple("true"));
            }
            else
            {
                hv_PlotYLog = int(hv_PlotYLogUser==1);
            }
        }
    }
    if (0 != hv_PlotYLog)
    {
        //Clamp values to be >= 0.00001.
        hv_YInd = hv_YValues.TupleLessEqualElem(0);
        TupleFind(hv_YInd, 1, &hv_Indices1);
        if (0 != (int(hv_Indices1>=0)))
        {
            hv_YValues[hv_Indices1] = 0.00001;
        }
        hv_YValues = hv_YValues.TupleLog10();
    }
    //
    //Check input coordinate values.
    //
    if (0 != (HTuple(int(hv_XValues==HTuple())).TupleAnd(int(hv_YValues==HTuple()))))
    {
        //Neither XValues nor YValues are given:
        //Set axes to interval [0,1]
        hv_XAxisEndValue = 1;
        hv_YAxisEndValue = 1;
        hv_XAxisStartValue = 0;
        hv_YAxisStartValue = 0;
        hv_XValuesAreStrings = 0;
    }
    else
    {
        if (0 != (int(hv_XValues==HTuple())))
        {
            //XValues are omitted: Set equidistant XValues.
            hv_XValues = HTuple::TupleGenSequence(0,(hv_YValues.TupleLength())-1,1);
            hv_XValuesAreStrings = 0;
        }
        else if (0 != (int(hv_YValues==HTuple())))
        {
            //YValues are omitted: Set equidistant YValues.
            hv_YValues = HTuple::TupleGenSequence(0,(hv_XValues.TupleLength())-1,1);
        }
        if (0 != (int(((hv_YValues.TupleLength())%(hv_XValues.TupleLength()))!=0)))
        {
            //Number of YValues does not match number of XValues.
            throw HException("Number of YValues is no multiple of the number of XValues.");
            return;
        }

        hv_XValuesAreStrings = hv_XValues.TupleIsStringElem();
        hv_XValuesAreStrings = int((hv_XValuesAreStrings.TupleSum())==(hv_XValuesAreStrings.TupleLength()));
        if (0 != hv_XValuesAreStrings)
        {
            //XValues are given as strings: Show XValues as ticks.
            hv_XTickValues = hv_XValues;
            hv_XTicks = 1;
            //Set x-axis dimensions.
            hv_XValues = HTuple::TupleGenSequence(1,hv_XValues.TupleLength(),1);
        }
        //Set default x-axis dimensions.
        if (0 != (int((hv_XValues.TupleLength())>1)))
        {
            hv_XAxisStartValue = hv_XValues.TupleMin();
            hv_XAxisEndValue = hv_XValues.TupleMax();
        }
        else
        {
            hv_XAxisEndValue = HTuple(hv_XValues[0])+0.5;
            hv_XAxisStartValue = HTuple(hv_XValues[0])-0.5;
        }
    }
    //Set default y-axis dimensions.
    if (0 != (int((hv_YValues.TupleLength())>1)))
    {
        hv_YAxisStartValue = hv_YValues.TupleMin();
        hv_YAxisEndValue = hv_YValues.TupleMax();
    }
    else if (0 != (int((hv_YValues.TupleLength())==1)))
    {
        hv_YAxisStartValue = HTuple(hv_YValues[0])-0.5;
        hv_YAxisEndValue = HTuple(hv_YValues[0])+0.5;
    }
    else
    {
        hv_YAxisStartValue = 0;
        hv_YAxisEndValue = 1;
    }
    //Set default interception point of x- and y- axis.
    hv_YAxisPosition = "default";
    hv_XAxisPosition = "default";
    //
    //Set further default values:
    hv_LeftBorder = hv_Width*0.1;
    hv_RightBorder = hv_Width*0.1;
    hv_UpperBorder = hv_Height*0.1;
    hv_LowerBorder = hv_Height*0.1;
    hv_AxesColor = "white";
    hv_Style = "line";
    hv_Clip = "no";
    hv_XTicks = "min_max_origin";
    hv_YTicks = "min_max_origin";
    hv_XGrid = "none";
    hv_YGrid = "none";
    hv_GridColor = "dim gray";
    hv_YPosition = "left";
    hv_FormatX = "default";
    hv_FormatY = "default";
    hv_LineWidth = 1;
    //
    //Parse generic parameters.
    //
    hv_NumGenParamNames = hv_GenParamName.TupleLength();
    hv_NumGenParamValues = hv_GenParamValue.TupleLength();
    if (0 != (int(hv_NumGenParamNames!=hv_NumGenParamValues)))
    {
        throw HException("Number of generic parameter names does not match generic parameter values.");
        return;
    }
    //
    {
        HTuple end_val217 = (hv_GenParamName.TupleLength())-1;
        HTuple step_val217 = 1;
        for (hv_GenParamIndex=0; hv_GenParamIndex.Continue(end_val217, step_val217); hv_GenParamIndex += step_val217)
        {
            //
            //Set 'axes_color'.
            if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axes_color"))))
            {
                hv_AxesColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'style'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("style"))))
            {
                hv_Style = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'clip'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("clip"))))
            {
                hv_Clip = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                if (0 != (HTuple(int(hv_Clip!=HTuple("yes"))).TupleAnd(int(hv_Clip!=HTuple("no")))))
                {
                    throw HException(("Unsupported clipping option: '"+hv_Clip)+"'");
                }
                //
                //Set 'ticks'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks"))))
            {
                hv_XTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                hv_YTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'ticks_x'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks_x"))))
            {
                hv_XTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'ticks_y'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("ticks_y"))))
            {
                hv_YTicks = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'grid'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid"))))
            {
                hv_XGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                hv_YGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                hv_XGridTicks = hv_XTicks;
                //
                //Set 'grid_x'
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_x"))))
            {
                hv_XGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'grid_y'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_y"))))
            {
                hv_YGrid = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'grid_color'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("grid_color"))))
            {
                hv_GridColor = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'start_x'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("start_x"))))
            {
                hv_XAxisStartValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'end_x'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("end_x"))))
            {
                hv_XAxisEndValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'start_y'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("start_y"))))
            {
                hv_YAxisStartValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                if (0 != hv_PlotYLog)
                {
                    hv_YAxisStartValue = (HTuple(0.00000001).TupleMax2(hv_YAxisStartValue)).TupleLog10();
                }
                //
                //Set 'end_y'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("end_y"))))
            {
                hv_YAxisEndValue = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                if (0 != hv_PlotYLog)
                {
                    hv_YAxisEndValue = (HTuple(0.00000001).TupleMax2(hv_YAxisEndValue)).TupleLog10();
                }
                //
                //Set 'axis_location_y' (old name 'origin_x').
            }
            else if (0 != (HTuple(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axis_location_y"))).TupleOr(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("origin_x")))))
            {
                hv_YAxisPosition = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'axis_location_x' (old name: 'origin_y').
            }
            else if (0 != (HTuple(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("axis_location_x"))).TupleOr(int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("origin_y")))))
            {
                hv_XAxisPosition = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'margin'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin"))))
            {
                hv_LeftBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                hv_RightBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                hv_UpperBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                hv_LowerBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'margin_left'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_left"))))
            {
                hv_LeftBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'margin_right'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_right"))))
            {
                hv_RightBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'margin_top'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_top"))))
            {
                hv_UpperBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
                //
                //Set 'margin_bottom'.
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("margin_bottom"))))
            {
                hv_LowerBorder = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("format_x"))))
            {
                hv_FormatX = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("format_y"))))
            {
                hv_FormatY = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("line_width"))))
            {
                hv_LineWidth = HTuple(hv_GenParamValue[hv_GenParamIndex]);
            }
            else if (0 != (int(HTuple(hv_GenParamName[hv_GenParamIndex])==HTuple("log_y"))))
            {
                //log_y already checked before because some other values depend on it.
            }
            else
            {
                throw HException(("Unknown generic parameter: '"+HTuple(hv_GenParamName[hv_GenParamIndex]))+"'");
            }
        }
    }
    //
    //Check consistency of start and end values of the axes.
    if (0 != (int(hv_XAxisStartValue>hv_XAxisEndValue)))
    {
        throw HException("Value for 'start_x' is greater than value for 'end_x'");
    }
    if (0 != (int(hv_YAxisStartValue>hv_YAxisEndValue)))
    {
        throw HException("Value for 'start_y' is greater than value for 'end_y'");
    }
    //
    //Set the position of the y-axis.
    if (0 != (int(hv_YAxisPosition==HTuple("default"))))
    {
        hv_YAxisPosition = hv_XAxisStartValue;
    }
    if (0 != (int((hv_YAxisPosition.TupleIsString())==1)))
    {
        if (0 != (int(hv_YAxisPosition==HTuple("left"))))
        {
            hv_YAxisPosition = hv_XAxisStartValue;
        }
        else if (0 != (int(hv_YAxisPosition==HTuple("right"))))
        {
            hv_YAxisPosition = hv_XAxisEndValue;
        }
        else if (0 != (int(hv_YAxisPosition==HTuple("origin"))))
        {
            hv_YAxisPosition = 0;
        }
        else
        {
            throw HException(("Unsupported axis_location_y: '"+hv_YAxisPosition)+"'");
        }
    }
    //Set the position of the ticks on the y-axis
    //depending of the location of the y-axis.
    if (0 != (int(((hv_XAxisStartValue.TupleConcat(hv_XAxisEndValue)).TupleMean())>hv_YAxisPosition)))
    {
        hv_YTickDirection = "right";
    }
    else
    {
        hv_YTickDirection = "left";
    }
    //
    //Set the position of the x-axis.
    if (0 != (int(hv_XAxisPosition==HTuple("default"))))
    {
        hv_XAxisPosition = hv_YAxisStartValue;
    }
    if (0 != (int((hv_XAxisPosition.TupleIsString())==1)))
    {
        if (0 != (int(hv_XAxisPosition==HTuple("bottom"))))
        {
            hv_XAxisPosition = hv_YAxisStartValue;
        }
        else if (0 != (int(hv_XAxisPosition==HTuple("top"))))
        {
            hv_XAxisPosition = hv_YAxisEndValue;
        }
        else if (0 != (int(hv_XAxisPosition==HTuple("origin"))))
        {
            hv_XAxisPosition = 0;
        }
        else
        {
            throw HException(("Unsupported axis_location_x: '"+hv_XAxisPosition)+"'");
        }
    }
    //Set the position of the ticks on the y-axis
    //depending of the location of the y-axis.
    if (0 != (int(((hv_YAxisStartValue.TupleConcat(hv_YAxisEndValue)).TupleMean())>hv_XAxisPosition)))
    {
        hv_XTickDirection = "up";
    }
    else
    {
        hv_XTickDirection = "down";
    }
    //
    //Calculate basic pixel coordinates and scale factors.
    //
    hv_XAxisWidthPx = (hv_Width-hv_LeftBorder)-hv_RightBorder;
    hv_XAxisWidth = hv_XAxisEndValue-hv_XAxisStartValue;
    if (0 != (int(hv_XAxisWidth==0)))
    {
        hv_XAxisStartValue = hv_XAxisStartValue-0.5;
        hv_XAxisEndValue += 0.5;
        hv_XAxisWidth = 1;
    }
    hv_XScaleFactor = hv_XAxisWidthPx/(hv_XAxisWidth.TupleReal());
    hv_YAxisHeightPx = (hv_Height-hv_LowerBorder)-hv_UpperBorder;
    hv_YAxisHeight = hv_YAxisEndValue-hv_YAxisStartValue;
    if (0 != (int(hv_YAxisHeight==0)))
    {
        hv_YAxisStartValue = hv_YAxisStartValue-0.5;
        hv_YAxisEndValue += 0.5;
        hv_YAxisHeight = 1;
    }
    hv_YScaleFactor = hv_YAxisHeightPx/(hv_YAxisHeight.TupleReal());
    hv_YAxisOffsetPx = (hv_YAxisPosition-hv_XAxisStartValue)*hv_XScaleFactor;
    hv_XAxisOffsetPx = (hv_XAxisPosition-hv_YAxisStartValue)*hv_YScaleFactor;
    //
    //Display grid lines.
    //
    if (0 != (int(hv_GridColor!=HTuple("none"))))
    {
        hv_DotStyle.Clear();
        hv_DotStyle[0] = 5;
        hv_DotStyle[1] = 7;
        SetLineStyle(hv_WindowHandle, hv_DotStyle);
        if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),hv_GridColor);
        //
        //Display x grid lines.
        if (0 != (int(hv_XGrid!=HTuple("none"))))
        {
            if (0 != (int(hv_XGrid==HTuple("min_max_origin"))))
            {
                //Calculate 'min_max_origin' grid line coordinates.
                if (0 != (int(hv_YAxisPosition==hv_XAxisStartValue)))
                {
                    hv_XGridValues.Clear();
                    hv_XGridValues.Append(hv_XAxisStartValue);
                    hv_XGridValues.Append(hv_XAxisEndValue);
                }
                else
                {
                    hv_XGridValues.Clear();
                    hv_XGridValues.Append(hv_XAxisStartValue);
                    hv_XGridValues.Append(hv_YAxisPosition);
                    hv_XGridValues.Append(hv_XAxisEndValue);
                }
            }
            else
            {
                //Calculate equidistant grid line coordinates.
                hv_XGridStart = ((hv_XAxisStartValue/hv_XGrid).TupleCeil())*hv_XGrid;
                hv_XGridValues = HTuple::TupleGenSequence(hv_XGridStart,hv_XAxisEndValue,hv_XGrid);
            }
            hv_XCoord = (hv_XGridValues-hv_XAxisStartValue)*hv_XScaleFactor;
            //Generate and display grid lines.
            {
                HTuple end_val428 = (hv_XGridValues.TupleLength())-1;
                HTuple step_val428 = 1;
                for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val428, step_val428); hv_IndexGrid += step_val428)
                {
                    GenContourPolygonXld(&ho_ContourXGrid, (hv_Height-hv_LowerBorder).TupleConcat(hv_UpperBorder),
                                         (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexGrid])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexGrid])));
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_ContourXGrid, HDevWindowStack::GetActive());
                }
            }
        }
        //
        //Display y grid lines.
        if (0 != (int(hv_YGrid!=HTuple("none"))))
        {
            if (0 != (int(hv_YGrid==HTuple("min_max_origin"))))
            {
                //Calculate 'min_max_origin' grid line coordinates.
                if (0 != (int(hv_XAxisPosition==hv_YAxisStartValue)))
                {
                    hv_YGridValues.Clear();
                    hv_YGridValues.Append(hv_YAxisStartValue);
                    hv_YGridValues.Append(hv_YAxisEndValue);
                }
                else
                {
                    hv_YGridValues.Clear();
                    hv_YGridValues.Append(hv_YAxisStartValue);
                    hv_YGridValues.Append(hv_XAxisPosition);
                    hv_YGridValues.Append(hv_YAxisEndValue);
                }
            }
            else
            {
                //Calculate equidistant grid line coordinates.
                hv_YGridStart = ((hv_YAxisStartValue/hv_YGrid).TupleCeil())*hv_YGrid;
                hv_YGridValues = HTuple::TupleGenSequence(hv_YGridStart,hv_YAxisEndValue,hv_YGrid);
            }
            hv_YCoord = (hv_YGridValues-hv_YAxisStartValue)*hv_YScaleFactor;
            //Generate and display grid lines.
            {
                HTuple end_val450 = (hv_YGridValues.TupleLength())-1;
                HTuple step_val450 = 1;
                for (hv_IndexGrid=0; hv_IndexGrid.Continue(end_val450, step_val450); hv_IndexGrid += step_val450)
                {
                    GenContourPolygonXld(&ho_ContourYGrid, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexGrid])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexGrid])),
                                         hv_LeftBorder.TupleConcat(hv_Width-hv_RightBorder));
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_ContourYGrid, HDevWindowStack::GetActive());
                }
            }
        }
    }
    SetLineStyle(hv_WindowHandle, HTuple());
    //
    //
    //Display the coordinate system axes.
    if (0 != (int(hv_AxesColor!=HTuple("none"))))
    {
        //Display axes.
        if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
        gen_arrow_contour_xld(&ho_XArrow, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx,
                              hv_LeftBorder, (hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx, hv_Width-hv_RightBorder,
                              0, 0);
        if (HDevWindowStack::IsOpen())
            DispObj(ho_XArrow, HDevWindowStack::GetActive());
        gen_arrow_contour_xld(&ho_YArrow, hv_Height-hv_LowerBorder, hv_LeftBorder+hv_YAxisOffsetPx,
                              hv_UpperBorder, hv_LeftBorder+hv_YAxisOffsetPx, 0, 0);
        if (HDevWindowStack::IsOpen())
            DispObj(ho_YArrow, HDevWindowStack::GetActive());
        //Display labels.
        GetStringExtents(hv_WindowHandle, hv_XLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthXLabel,
                         &hv_TextHeightXLabel);
        GetStringExtents(hv_WindowHandle, hv_YLabel, &hv_Ascent, &hv_Descent, &hv_TextWidthYLabel,
                         &hv_TextHeightYLabel);
        if (0 != (int(hv_YTickDirection==HTuple("right"))))
        {
            if (0 != (int(hv_XTickDirection==HTuple("up"))))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3,
                             ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box",
                             "false");
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder,
                             (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
            }
            else
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)+3)-hv_XAxisOffsetPx,
                             ((hv_Width-hv_RightBorder)-hv_TextWidthXLabel)-3, hv_AxesColor, "box",
                             "false");
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3,
                             (hv_LeftBorder+3)+hv_YAxisOffsetPx, hv_AxesColor, "box", "false");
            }
        }
        else
        {
            if (0 != (int(hv_XTickDirection==HTuple("up"))))
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)-(2*hv_TextHeightXLabel))+3,
                             hv_LeftBorder-3, hv_AxesColor, "box", "false");
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", hv_UpperBorder,
                             ((hv_Width-hv_RightBorder)-hv_TextWidthYLabel)-13, hv_AxesColor, "box",
                             "false");
            }
            else
            {
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_XLabel, "image", ((hv_Height-hv_LowerBorder)+3)-hv_XAxisOffsetPx,
                             hv_LeftBorder-3, hv_AxesColor, "box", "false");
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive()," "+hv_YLabel, "image", ((hv_Height-hv_LowerBorder)-hv_TextHeightXLabel)-3,
                             ((hv_Width-hv_RightBorder)-(2*hv_TextWidthYLabel))-3, hv_AxesColor,
                             "box", "false");
            }
        }
    }
    //
    //Display ticks.
    //
    if (0 != (int(hv_AxesColor!=HTuple("none"))))
    {
        if (HDevWindowStack::IsOpen())
            SetColor(HDevWindowStack::GetActive(),hv_AxesColor);
        if (0 != (int(hv_XTicks!=HTuple("none"))))
        {
            //
            //Display x ticks.
            if (0 != hv_XValuesAreStrings)
            {
                //Display string XValues as categories.
                hv_XTicks = (hv_XValues.TupleLength())/(hv_XTickValues.TupleLength());
                hv_XCoord = (hv_XValues-hv_XAxisStartValue)*hv_XScaleFactor;
            }
            else
            {
                //Display tick values.
                if (0 != (int(hv_XTicks==HTuple("min_max_origin"))))
                {
                    //Calculate 'min_max_origin' tick coordinates.
                    if (0 != (int(hv_YAxisPosition==hv_XAxisStartValue)))
                    {
                        hv_XTickValues.Clear();
                        hv_XTickValues.Append(hv_XAxisStartValue);
                        hv_XTickValues.Append(hv_XAxisEndValue);
                    }
                    else
                    {
                        hv_XTickValues.Clear();
                        hv_XTickValues.Append(hv_XAxisStartValue);
                        hv_XTickValues.Append(hv_YAxisPosition);
                        hv_XTickValues.Append(hv_XAxisEndValue);
                    }
                }
                else
                {
                    //Calculate equidistant tick coordinates.
                    hv_XTickStart = ((hv_XAxisStartValue/hv_XTicks).TupleCeil())*hv_XTicks;
                    hv_XTickValues = HTuple::TupleGenSequence(hv_XTickStart,hv_XAxisEndValue,hv_XTicks);
                }
                //Remove ticks that are smaller than the x-axis start.
                hv_Indices = (hv_XTickValues.TupleLessElem(hv_XAxisStartValue)).TupleFind(1);
                hv_XCoord = (hv_XTickValues-hv_XAxisStartValue)*hv_XScaleFactor;
                hv_XCoord = hv_XCoord.TupleRemove(hv_Indices);
                hv_XTickValues = hv_XTickValues.TupleRemove(hv_Indices);
                //
                if (0 != (int(hv_FormatX==HTuple("default"))))
                {
                    hv_TypeTicks = hv_XTicks.TupleType();
                    if (0 != (int(hv_TypeTicks==4)))
                    {
                        //String ('min_max_origin').
                        //Format depends on actual values.
                        hv_TypeTicks = hv_XTickValues.TupleType();
                    }
                    if (0 != (int(hv_TypeTicks==1)))
                    {
                        //Round to integer.
                        hv_XTickValues = hv_XTickValues.TupleInt();
                    }
                    else
                    {
                        //Use floating point numbers.
                        hv_XTickValues = hv_XTickValues.TupleString(".2f");
                    }
                }
                else
                {
                    hv_XTickValues = hv_XTickValues.TupleString(hv_FormatX);
                }
            }
            //Generate and display ticks.
            {
                HTuple end_val539 = (hv_XTickValues.TupleLength())-1;
                HTuple step_val539 = 1;
                for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val539, step_val539); hv_IndexTicks += step_val539)
                {
                    GetStringExtents(hv_WindowHandle, HTuple(hv_XTickValues[hv_IndexTicks]),
                                     &hv_Ascent1, &hv_Descent1, &hv_TextWidthXTicks, &hv_TextHeightXTicks);
                    if (0 != (int(hv_XTickDirection==HTuple("up"))))
                    {
                        GenContourPolygonXld(&ho_ContourXTick, ((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx).TupleConcat(((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)-5),
                                             (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])));
                        if (HDevWindowStack::IsOpen())
                            DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]),
                                     "image", ((hv_Height-hv_LowerBorder)+2)-hv_XAxisOffsetPx, (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks]))-(0.5*hv_TextWidthXTicks),
                                     hv_AxesColor, "box", "false");
                    }
                    else
                    {
                        GenContourPolygonXld(&ho_ContourXTick, (((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx)+5).TupleConcat((hv_Height-hv_LowerBorder)-hv_XAxisOffsetPx),
                                             (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])).TupleConcat(hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks])));
                        if (HDevWindowStack::IsOpen())
                            DispText(HDevWindowStack::GetActive(),HTuple(hv_XTickValues[hv_IndexTicks]),
                                     "image", ((hv_Height-hv_LowerBorder)-(2*hv_TextHeightXTicks))-hv_XAxisOffsetPx,
                                     (hv_LeftBorder+HTuple(hv_XCoord[hv_IndexTicks]))-(0.5*hv_TextWidthXTicks),
                                     hv_AxesColor, "box", "false");
                    }
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_ContourXTick, HDevWindowStack::GetActive());
                }
            }
        }
        //
        if (0 != (int(hv_YTicks!=HTuple("none"))))
        {
            //
            //Display y ticks.

            if (0 != (int(hv_YTicks==HTuple("min_max_origin"))))
            {
                //Calculate 'min_max_origin' tick coordinates.
                if (0 != (int(hv_XAxisPosition==hv_YAxisStartValue)))
                {
                    hv_YTickValues.Clear();
                    hv_YTickValues.Append(hv_YAxisStartValue);
                    hv_YTickValues.Append(hv_YAxisEndValue);
                }
                else
                {
                    hv_YTickValues.Clear();
                    hv_YTickValues.Append(hv_YAxisStartValue);
                    hv_YTickValues.Append(hv_XAxisPosition);
                    hv_YTickValues.Append(hv_YAxisEndValue);
                }
            }
            else
            {
                //Calculate equidistant tick coordinates.
                hv_YTickStart = ((hv_YAxisStartValue/hv_YTicks).TupleCeil())*hv_YTicks;
                hv_YTickValues = HTuple::TupleGenSequence(hv_YTickStart,hv_YAxisEndValue,hv_YTicks);
            }

            //Remove ticks that are smaller than the y-axis start.
            hv_Indices = (hv_YTickValues.TupleLessElem(hv_YAxisStartValue)).TupleFind(1);
            hv_YCoord = (hv_YTickValues-hv_YAxisStartValue)*hv_YScaleFactor;
            hv_YCoord = hv_YCoord.TupleRemove(hv_Indices);
            hv_YTickValues = hv_YTickValues.TupleRemove(hv_Indices);
            //
            if (0 != hv_PlotYLog)
            {
                hv_YTickValues = HTuple(10).TuplePow(hv_YTickValues);
            }
            if (0 != (int(hv_FormatY==HTuple("default"))))
            {
                hv_TypeTicks = hv_YTicks.TupleType();
                if (0 != (int(hv_TypeTicks==4)))
                {
                    //String ('min_max_origin').
                    //Format depends on actual values.
                    hv_TypeTicks = hv_YTickValues.TupleType();
                }
                if (0 != (int(hv_TypeTicks==1)))
                {
                    //Round to integer.
                    hv_YTickValues = hv_YTickValues.TupleInt();
                }
                else
                {
                    //Use floating point numbers.
                    hv_YTickValues = hv_YTickValues.TupleString(".2f");
                }
            }
            else
            {
                hv_YTickValues = hv_YTickValues.TupleString(hv_FormatY);
            }
            //Generate and display ticks.
            {
                HTuple end_val596 = (hv_YTickValues.TupleLength())-1;
                HTuple step_val596 = 1;
                for (hv_IndexTicks=0; hv_IndexTicks.Continue(end_val596, step_val596); hv_IndexTicks += step_val596)
                {
                    GetStringExtents(hv_WindowHandle, HTuple(hv_YTickValues[hv_IndexTicks]),
                                     &hv_Ascent1, &hv_Descent1, &hv_TextWidthYTicks, &hv_TextHeightYTicks);
                    //Since we only deal with numbers, use the Ascent as text height.
                    hv_TextHeightYTicks = hv_Ascent;
                    if (0 != (int(hv_YTickDirection==HTuple("right"))))
                    {
                        GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])),
                                             (hv_LeftBorder+hv_YAxisOffsetPx).TupleConcat((hv_LeftBorder+hv_YAxisOffsetPx)+5));
                        if (HDevWindowStack::IsOpen())
                            DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]),
                                     "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YCoord[hv_IndexTicks]),
                                     ((hv_LeftBorder-hv_TextWidthYTicks)-4)+hv_YAxisOffsetPx, hv_Color,
                                     "box", "false");
                    }
                    else
                    {
                        GenContourPolygonXld(&ho_ContourYTick, ((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])).TupleConcat((hv_Height-hv_LowerBorder)-HTuple(hv_YCoord[hv_IndexTicks])),
                                             ((hv_LeftBorder+hv_YAxisOffsetPx)-5).TupleConcat(hv_LeftBorder+hv_YAxisOffsetPx));
                        if (HDevWindowStack::IsOpen())
                            DispText(HDevWindowStack::GetActive(),HTuple(hv_YTickValues[hv_IndexTicks]),
                                     "image", (((hv_Height-hv_LowerBorder)-hv_TextHeightYTicks)+3)-HTuple(hv_YCoord[hv_IndexTicks]),
                                     (hv_LeftBorder+4)+hv_YAxisOffsetPx, hv_Color, "box", "false");
                    }
                    if (HDevWindowStack::IsOpen())
                        DispObj(ho_ContourYTick, HDevWindowStack::GetActive());
                }
            }
        }
    }
    //
    //Display function plot.
    //
    if (0 != (int(hv_Color!=HTuple("none"))))
    {
        if (0 != (HTuple(int(hv_XValues!=HTuple())).TupleAnd(int(hv_YValues!=HTuple()))))
        {
            hv_Num = (hv_YValues.TupleLength())/(hv_XValues.TupleLength());
            //
            //Iterate over all functions to be displayed.
            {
                HTuple end_val619 = hv_Num-1;
                HTuple step_val619 = 1;
                for (hv_I=0; hv_I.Continue(end_val619, step_val619); hv_I += step_val619)
                {
                    //Select y values for current function.
                    hv_YSelected = hv_YValues.TupleSelectRange(hv_I*(hv_XValues.TupleLength()),((hv_I+1)*(hv_XValues.TupleLength()))-1);
                    //Set color
                    if (0 != (int(hv_Color==HTuple())))
                    {
                        SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
                    }
                    else
                    {
                        if (HDevWindowStack::IsOpen())
                            SetColor(HDevWindowStack::GetActive(),HTuple(hv_Color[hv_I%(hv_Color.TupleLength())]));
                    }
                    //
                    //Display in different styles.
                    //
                    if (0 != (HTuple(HTuple(HTuple(int(hv_Style==HTuple("line"))).TupleOr(int(hv_Style==HTuple()))).TupleOr(hv_Style.TupleIsReal())).TupleOr(hv_Style.TupleIsInt())))
                    {
                        //Style = Line. For real value, the line is plotted dashed.
                        if (0 != ((hv_Style.TupleIsReal()).TupleOr(hv_Style.TupleIsInt())))
                        {
                            GetLineStyle(hv_WindowHandle, &hv_StyleOriginal);
                            SetLineStyle(hv_WindowHandle, hv_Style.TupleConcat(hv_Style/2.0));
                        }
                        GenContourPolygonXld(&ho_Contour, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor),
                                             ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
                        //Clip, if necessary.
                        if (0 != (int(hv_Clip==HTuple("yes"))))
                        {
                            ClipContoursXld(ho_Contour, &ho_Contour, hv_UpperBorder, hv_LeftBorder,
                                            hv_Height-hv_LowerBorder, hv_Width-hv_RightBorder);
                        }
                        GetLineWidth(hv_WindowHandle, &hv_OldLineWidth);
                        if (HDevWindowStack::IsOpen())
                            SetLineWidth(HDevWindowStack::GetActive(),hv_LineWidth.TupleInt());
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_Contour, HDevWindowStack::GetActive());
                        if (HDevWindowStack::IsOpen())
                            SetLineWidth(HDevWindowStack::GetActive(),hv_OldLineWidth.TupleInt());
                        if (0 != ((hv_Style.TupleIsReal()).TupleOr(hv_Style.TupleIsInt())))
                        {
                            SetLineStyle(hv_WindowHandle, hv_StyleOriginal);
                        }
                    }
                    else if (0 != (int(hv_Style==HTuple("cross"))))
                    {
                        //Style = Cross.
                        GetLineWidth(hv_WindowHandle, &hv_LineWidth);
                        GenCrossContourXld(&ho_Cross, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor),
                                           ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor),
                                           6, 0.785398);
                        //Clip, if necessary.
                        if (0 != (int(hv_Clip==HTuple("yes"))))
                        {
                            ClipContoursXld(ho_Cross, &ho_Cross, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder,
                                            hv_Width-hv_RightBorder);
                        }
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_Cross, HDevWindowStack::GetActive());
                    }
                    else if (0 != (int(hv_Style==HTuple("circle"))))
                    {
                        //Style = Circle.
                        GetLineWidth(hv_WindowHandle, &hv_LineWidth);
                        TupleGenConst(hv_YSelected.TupleLength(), 3*hv_LineWidth, &hv_Radii);
                        GenCircleContourXld(&ho_Circle, ((hv_Height-hv_LowerBorder)-(hv_YSelected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor),
                                            ((hv_XValues*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor),
                                            hv_Radii, 0, 6.28318, "positive", 1);
                        //Clip, if necessary.
                        if (0 != (int(hv_Clip==HTuple("yes"))))
                        {
                            ClipContoursXld(ho_Circle, &ho_Circle, hv_UpperBorder, hv_LeftBorder,
                                            hv_Height-hv_LowerBorder, hv_Width-hv_RightBorder);
                        }
                        GetContourStyle(hv_WindowHandle, &hv_OldContourStyle);
                        SetContourStyle(hv_WindowHandle, "stroke_and_fill");
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_Circle, HDevWindowStack::GetActive());
                        SetContourStyle(hv_WindowHandle, hv_OldContourStyle);
                    }
                    else if (0 != (int(hv_Style==HTuple("filled"))))
                    {
                        //Style = Filled.
                        hv_Y1Selected.Clear();
                        hv_Y1Selected.Append(0+hv_XAxisPosition);
                        hv_Y1Selected.Append(hv_YSelected);
                        hv_Y1Selected.Append(0+hv_XAxisPosition);
                        hv_X1Selected.Clear();
                        hv_X1Selected.Append(hv_XValues.TupleMin());
                        hv_X1Selected.Append(hv_XValues);
                        hv_X1Selected.Append(hv_XValues.TupleMax());
                        if (HDevWindowStack::IsOpen())
                            SetDraw(HDevWindowStack::GetActive(),"fill");
                        GenRegionPolygonFilled(&ho_Filled, ((hv_Height-hv_LowerBorder)-(hv_Y1Selected*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor),
                                               ((hv_X1Selected*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor));
                        //Clip, if necessary.
                        if (0 != (int(hv_Clip==HTuple("yes"))))
                        {
                            ClipRegion(ho_Filled, &ho_Filled, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder,
                                       hv_Width-hv_RightBorder);
                        }
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_Filled, HDevWindowStack::GetActive());
                    }
                    else if (0 != (int(hv_Style==HTuple("step"))))
                    {
                        GenEmptyObj(&ho_Stair);
                        {
                            HTuple end_val684 = (hv_XValues.TupleLength())-2;
                            HTuple step_val684 = 1;
                            for (hv_Index=0; hv_Index.Continue(end_val684, step_val684); hv_Index += step_val684)
                            {
                                hv_Row1 = ((hv_Height-hv_LowerBorder)-(HTuple(hv_YSelected[hv_Index])*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor);
                                hv_Row2 = ((hv_Height-hv_LowerBorder)-(HTuple(hv_YSelected[hv_Index+1])*hv_YScaleFactor))+(hv_YAxisStartValue*hv_YScaleFactor);
                                hv_Col1 = ((HTuple(hv_XValues[hv_Index])*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor);
                                hv_Col2 = ((HTuple(hv_XValues[hv_Index+1])*hv_XScaleFactor)+hv_LeftBorder)-(hv_XAxisStartValue*hv_XScaleFactor);
                                GenContourPolygonXld(&ho_StairTmp, (hv_Row1.TupleConcat(hv_Row1)).TupleConcat(hv_Row2),
                                                     (hv_Col1.TupleConcat(hv_Col2)).TupleConcat(hv_Col2));
                                ConcatObj(ho_Stair, ho_StairTmp, &ho_Stair);
                            }
                        }
                        UnionAdjacentContoursXld(ho_Stair, &ho_Stair, 0.1, 0.1, "attr_keep");
                        if (0 != (int(hv_Clip==HTuple("yes"))))
                        {
                            ClipRegion(ho_Stair, &ho_Stair, hv_UpperBorder, hv_LeftBorder, hv_Height-hv_LowerBorder,
                                       hv_Width-hv_RightBorder);
                        }
                        if (HDevWindowStack::IsOpen())
                            DispObj(ho_Stair, HDevWindowStack::GetActive());
                    }
                    else
                    {
                        throw HException("Unsupported style: "+hv_Style);
                    }
                }
            }
        }
    }
    //
    //
    SetRgb(hv_WindowHandle, hv_Red, hv_Green, hv_Blue);
    if (HDevWindowStack::IsOpen())
        SetDraw(HDevWindowStack::GetActive(),hv_DrawMode);
    SetLineStyle(hv_WindowHandle, hv_OriginStyle);
    SetSystem("clip_region", hv_ClipRegion);
    return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Preprocess the bounding boxes of type 'rectangle2' for a given sample.
void HalxAI:: preprocess_dl_model_bbox_rect2 (HObject ho_ImageRaw, HTuple hv_DLSample, HTuple hv_DLPreprocessParam)
{

    // Local iconic variables
    HObject  ho_DomainRaw, ho_Rectangle2XLD, ho_Rectangle2XLDSheared;

    // Local control variables
    HTuple  hv_ImageWidth, hv_ImageHeight, hv_DomainHandling;
    HTuple  hv_IgnoreDirection, hv_ClassIDsNoOrientation, hv_KeyExists;
    HTuple  hv_BBoxRow, hv_BBoxCol, hv_BBoxLength1, hv_BBoxLength2;
    HTuple  hv_BBoxPhi, hv_BBoxLabel, hv_Exception, hv_ImageId;
    HTuple  hv_ExceptionMessage, hv_BoxesInvalid, hv_DomainRow1;
    HTuple  hv_DomainColumn1, hv_DomainRow2, hv_DomainColumn2;
    HTuple  hv_WidthRaw, hv_HeightRaw, hv_MaskDelete, hv_MaskNewBbox;
    HTuple  hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxLength1New;
    HTuple  hv_BBoxLength2New, hv_BBoxPhiNew, hv_BBoxLabelNew;
    HTuple  hv_ClassIDsNoOrientationIndices, hv_Index, hv_ClassIDsNoOrientationIndicesTmp;
    HTuple  hv_DirectionLength1Row, hv_DirectionLength1Col;
    HTuple  hv_DirectionLength2Row, hv_DirectionLength2Col;
    HTuple  hv_Corner1Row, hv_Corner1Col, hv_Corner2Row, hv_Corner2Col;
    HTuple  hv_FactorResampleWidth, hv_FactorResampleHeight;
    HTuple  hv_BBoxRow1, hv_BBoxCol1, hv_BBoxRow2, hv_BBoxCol2;
    HTuple  hv_BBoxRow3, hv_BBoxCol3, hv_BBoxRow4, hv_BBoxCol4;
    HTuple  hv_BBoxCol1New, hv_BBoxCol2New, hv_BBoxCol3New;
    HTuple  hv_BBoxCol4New, hv_BBoxRow1New, hv_BBoxRow2New;
    HTuple  hv_BBoxRow3New, hv_BBoxRow4New, hv_HomMat2DIdentity;
    HTuple  hv_HomMat2DScale, hv__, hv_BBoxPhiTmp, hv_PhiDelta;
    HTuple  hv_PhiDeltaNegativeIndices, hv_IndicesRot90, hv_IndicesRot180;
    HTuple  hv_IndicesRot270, hv_SwapIndices, hv_Tmp, hv_BBoxPhiNewIndices;
    HTuple  hv_PhiThreshold, hv_PhiToCorrect, hv_NumCorrections;

    //This procedure preprocesses the bounding boxes of type 'rectangle2' for a given sample.
    //
    check_dl_preprocess_param(hv_DLPreprocessParam);
    //
    //Get preprocess parameters.
    GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
    GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
    GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
    //The keys 'ignore_direction' and 'class_ids_no_orientation' are optional.
    hv_IgnoreDirection = 0;
    hv_ClassIDsNoOrientation = HTuple();
    GetDictParam(hv_DLPreprocessParam, "key_exists", (HTuple("ignore_direction").Append("class_ids_no_orientation")),
                 &hv_KeyExists);
    if (0 != (HTuple(hv_KeyExists[0])))
    {
        GetDictTuple(hv_DLPreprocessParam, "ignore_direction", &hv_IgnoreDirection);
        if (0 != (int(hv_IgnoreDirection==HTuple("true"))))
        {
            hv_IgnoreDirection = 1;
        }
        else if (0 != (int(hv_IgnoreDirection==HTuple("false"))))
        {
            hv_IgnoreDirection = 0;
        }
    }
    if (0 != (HTuple(hv_KeyExists[1])))
    {
        GetDictTuple(hv_DLPreprocessParam, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
    }
    //
    //Get bounding box coordinates and labels.
    try
    {
        GetDictTuple(hv_DLSample, "bbox_row", &hv_BBoxRow);
        GetDictTuple(hv_DLSample, "bbox_col", &hv_BBoxCol);
        GetDictTuple(hv_DLSample, "bbox_length1", &hv_BBoxLength1);
        GetDictTuple(hv_DLSample, "bbox_length2", &hv_BBoxLength2);
        GetDictTuple(hv_DLSample, "bbox_phi", &hv_BBoxPhi);
        GetDictTuple(hv_DLSample, "bbox_label_id", &hv_BBoxLabel);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
        if (0 != (int(HTuple(hv_Exception[0])==1302)))
        {
            hv_ExceptionMessage = "A bounding box coordinate key is missing.";
        }
        else
        {
            hv_ExceptionMessage = ((const HTuple&)hv_Exception)[2];
        }
        throw HException((("An error has occurred during preprocessing image_id "+hv_ImageId)+" when getting bounding box coordinates : ")+hv_ExceptionMessage);
    }
    //
    //Check that there are no invalid boxes.
    if (0 != (int((hv_BBoxRow.TupleLength())>0)))
    {
        hv_BoxesInvalid = ((hv_BBoxLength1.TupleEqualElem(0)).TupleSum())+((hv_BBoxLength2.TupleEqualElem(0)).TupleSum());
        if (0 != (int(hv_BoxesInvalid>0)))
        {
            GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
            throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one bounding box with zero-area, i.e. bbox_length1 == 0 or bbox_length2 == 0!"));
        }
    }
    else
    {
        //There are no bounding boxes, hence nothing to do.
        return;
    }
    //
    //If the domain is cropped, crop bounding boxes.
    if (0 != (int(hv_DomainHandling==HTuple("crop_domain"))))
    {
        //
        //Get domain.
        GetDomain(ho_ImageRaw, &ho_DomainRaw);
        //
        //Set the size of the raw image to the domain extensions.
        SmallestRectangle1(ho_DomainRaw, &hv_DomainRow1, &hv_DomainColumn1, &hv_DomainRow2,
                           &hv_DomainColumn2);
        hv_WidthRaw = (hv_DomainColumn2-hv_DomainColumn1)+1;
        hv_HeightRaw = (hv_DomainRow2-hv_DomainRow1)+1;
        //
        //Crop the bounding boxes.
        //Remove the boxes with center outside of the domain.
        hv_MaskDelete = HTuple(HTuple((hv_BBoxRow.TupleLessElem(hv_DomainRow1)).TupleOr(hv_BBoxCol.TupleLessElem(hv_DomainColumn1))).TupleOr(hv_BBoxRow.TupleGreaterElem(hv_DomainRow2))).TupleOr(hv_BBoxCol.TupleGreaterElem(hv_DomainColumn2));
        hv_MaskNewBbox = 1-hv_MaskDelete;
        //Store the preprocessed bounding box entries.
        hv_BBoxRowNew = (hv_BBoxRow.TupleSelectMask(hv_MaskNewBbox))-hv_DomainRow1;
        hv_BBoxColNew = (hv_BBoxCol.TupleSelectMask(hv_MaskNewBbox))-hv_DomainColumn1;
        hv_BBoxLength1New = hv_BBoxLength1.TupleSelectMask(hv_MaskNewBbox);
        hv_BBoxLength2New = hv_BBoxLength2.TupleSelectMask(hv_MaskNewBbox);
        hv_BBoxPhiNew = hv_BBoxPhi.TupleSelectMask(hv_MaskNewBbox);
        hv_BBoxLabelNew = hv_BBoxLabel.TupleSelectMask(hv_MaskNewBbox);
        //
        //If we remove/select bounding boxes we also need to filter the corresponding
        //instance segmentation masks if they exist.
        filter_dl_sample_instance_segmentation_masks(hv_DLSample, hv_MaskNewBbox);
        //
    }
    else if (0 != (int(hv_DomainHandling==HTuple("full_domain"))))
    {
        //If the entire image is used, set the variables accordingly.
        //Get the original size.
        GetImageSize(ho_ImageRaw, &hv_WidthRaw, &hv_HeightRaw);
        //Set new coordinates to input coordinates.
        hv_BBoxRowNew = hv_BBoxRow;
        hv_BBoxColNew = hv_BBoxCol;
        hv_BBoxLength1New = hv_BBoxLength1;
        hv_BBoxLength2New = hv_BBoxLength2;
        hv_BBoxPhiNew = hv_BBoxPhi;
        hv_BBoxLabelNew = hv_BBoxLabel;
    }
    else
    {
        throw HException("Unsupported parameter value for 'domain_handling'");
    }
    //
    //Generate smallest enclosing axis-aligned bounding box for classes in ClassIDsNoOrientation.
    hv_ClassIDsNoOrientationIndices = HTuple();
    {
        HTuple end_val98 = (hv_ClassIDsNoOrientation.TupleLength())-1;
        HTuple step_val98 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val98, step_val98); hv_Index += step_val98)
        {
            hv_ClassIDsNoOrientationIndicesTmp = (hv_BBoxLabelNew.TupleEqualElem(HTuple(hv_ClassIDsNoOrientation[hv_Index]))).TupleFind(1);
            if (0 != (int(hv_ClassIDsNoOrientationIndicesTmp!=-1)))
            {
                hv_ClassIDsNoOrientationIndices = hv_ClassIDsNoOrientationIndices.TupleConcat(hv_ClassIDsNoOrientationIndicesTmp);
            }
        }
    }
    if (0 != (int((hv_ClassIDsNoOrientationIndices.TupleLength())>0)))
    {
        //Calculate length1 and length2 using position of corners.
        hv_DirectionLength1Row = -(HTuple(hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices]).TupleSin());
        hv_DirectionLength1Col = HTuple(hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices]).TupleCos();
        hv_DirectionLength2Row = -hv_DirectionLength1Col;
        hv_DirectionLength2Col = hv_DirectionLength1Row;
        hv_Corner1Row = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Row)+(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Row);
        hv_Corner1Col = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Col)+(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Col);
        hv_Corner2Row = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Row)-(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Row);
        hv_Corner2Col = (HTuple(hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength1Col)-(HTuple(hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices])*hv_DirectionLength2Col);
        //
        hv_BBoxPhiNew[hv_ClassIDsNoOrientationIndices] = 0.0;
        hv_BBoxLength1New[hv_ClassIDsNoOrientationIndices] = (hv_Corner1Col.TupleAbs()).TupleMax2(hv_Corner2Col.TupleAbs());
        hv_BBoxLength2New[hv_ClassIDsNoOrientationIndices] = (hv_Corner1Row.TupleAbs()).TupleMax2(hv_Corner2Row.TupleAbs());
    }
    //
    //Rescale bounding boxes.
    //
    //Get required images width and height.
    //
    //Only rescale bounding boxes if the required image dimensions are not the raw dimensions.
    if (0 != (HTuple(int(hv_ImageHeight!=hv_HeightRaw)).TupleOr(int(hv_ImageWidth!=hv_WidthRaw))))
    {
        //
        //Calculate rescaling factor.
        calculate_dl_image_zoom_factors(hv_WidthRaw, hv_HeightRaw, hv_ImageWidth, hv_ImageHeight,
                                        hv_DLPreprocessParam, &hv_FactorResampleWidth, &hv_FactorResampleHeight);
        //
        if (0 != (HTuple(int(hv_FactorResampleHeight!=hv_FactorResampleWidth)).TupleAnd(int((hv_BBoxRowNew.TupleLength())>0))))
        {
            //In order to preserve the correct orientation we have to transform the points individually.
            //Get the coordinates of the four corner points.
            convert_rect2_5to8param(hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxLength1New, hv_BBoxLength2New,
                                    hv_BBoxPhiNew, &hv_BBoxRow1, &hv_BBoxCol1, &hv_BBoxRow2, &hv_BBoxCol2,
                                    &hv_BBoxRow3, &hv_BBoxCol3, &hv_BBoxRow4, &hv_BBoxCol4);
            //
            //Rescale the coordinates.
            hv_BBoxCol1New = hv_BBoxCol1*hv_FactorResampleWidth;
            hv_BBoxCol2New = hv_BBoxCol2*hv_FactorResampleWidth;
            hv_BBoxCol3New = hv_BBoxCol3*hv_FactorResampleWidth;
            hv_BBoxCol4New = hv_BBoxCol4*hv_FactorResampleWidth;
            hv_BBoxRow1New = hv_BBoxRow1*hv_FactorResampleHeight;
            hv_BBoxRow2New = hv_BBoxRow2*hv_FactorResampleHeight;
            hv_BBoxRow3New = hv_BBoxRow3*hv_FactorResampleHeight;
            hv_BBoxRow4New = hv_BBoxRow4*hv_FactorResampleHeight;
            //
            //The rectangles will get sheared, that is why new rectangles have to be found.
            //Generate homography to scale rectangles.
            HomMat2dIdentity(&hv_HomMat2DIdentity);
            HomMat2dScale(hv_HomMat2DIdentity, hv_FactorResampleHeight, hv_FactorResampleWidth,
                          0, 0, &hv_HomMat2DScale);
            //Generate XLD contours for the rectangles.
            GenRectangle2ContourXld(&ho_Rectangle2XLD, hv_BBoxRowNew, hv_BBoxColNew, hv_BBoxPhiNew,
                                    hv_BBoxLength1New, hv_BBoxLength2New);
            //Scale the XLD contours --> results in sheared regions.
            AffineTransContourXld(ho_Rectangle2XLD, &ho_Rectangle2XLDSheared, hv_HomMat2DScale);
            SmallestRectangle2Xld(ho_Rectangle2XLDSheared, &hv_BBoxRowNew, &hv_BBoxColNew,
                                  &hv_BBoxPhiNew, &hv_BBoxLength1New, &hv_BBoxLength2New);
            //
            //smallest_rectangle2_xld might change the orientation of the bounding box.
            //Hence, take the orientation that is closest to the one obtained out of the 4 corner points.
            convert_rect2_8to5param(hv_BBoxRow1New, hv_BBoxCol1New, hv_BBoxRow2New, hv_BBoxCol2New,
                                    hv_BBoxRow3New, hv_BBoxCol3New, hv_BBoxRow4New, hv_BBoxCol4New, hv_IgnoreDirection,
                                    &hv__, &hv__, &hv__, &hv__, &hv_BBoxPhiTmp);
            hv_PhiDelta = (hv_BBoxPhiTmp-hv_BBoxPhiNew).TupleFmod(HTuple(360).TupleRad());
            //Guarantee that angles are positive.
            hv_PhiDeltaNegativeIndices = (hv_PhiDelta.TupleLessElem(0.0)).TupleFind(1);
            if (0 != (int(hv_PhiDeltaNegativeIndices!=-1)))
            {
                hv_PhiDelta[hv_PhiDeltaNegativeIndices] = HTuple(hv_PhiDelta[hv_PhiDeltaNegativeIndices])+(HTuple(360).TupleRad());
            }
            hv_IndicesRot90 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(45).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(135).TupleRad()))).TupleFind(1);
            hv_IndicesRot180 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(135).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(225).TupleRad()))).TupleFind(1);
            hv_IndicesRot270 = HTuple((hv_PhiDelta.TupleGreaterElem(HTuple(225).TupleRad())).TupleAnd(hv_PhiDelta.TupleLessEqualElem(HTuple(315).TupleRad()))).TupleFind(1);
            hv_SwapIndices = HTuple();
            if (0 != (int(hv_IndicesRot90!=-1)))
            {
                hv_BBoxPhiNew[hv_IndicesRot90] = HTuple(hv_BBoxPhiNew[hv_IndicesRot90])+(HTuple(90).TupleRad());
                hv_SwapIndices = hv_SwapIndices.TupleConcat(hv_IndicesRot90);
            }
            if (0 != (int(hv_IndicesRot180!=-1)))
            {
                hv_BBoxPhiNew[hv_IndicesRot180] = HTuple(hv_BBoxPhiNew[hv_IndicesRot180])+(HTuple(180).TupleRad());
            }
            if (0 != (int(hv_IndicesRot270!=-1)))
            {
                hv_BBoxPhiNew[hv_IndicesRot270] = HTuple(hv_BBoxPhiNew[hv_IndicesRot270])+(HTuple(270).TupleRad());
                hv_SwapIndices = hv_SwapIndices.TupleConcat(hv_IndicesRot270);
            }
            if (0 != (int(hv_SwapIndices!=HTuple())))
            {
                hv_Tmp = HTuple(hv_BBoxLength1New[hv_SwapIndices]);
                hv_BBoxLength1New[hv_SwapIndices] = HTuple(hv_BBoxLength2New[hv_SwapIndices]);
                hv_BBoxLength2New[hv_SwapIndices] = hv_Tmp;
            }
            //Change angles such that they lie in the range (-180бу, 180бу].
            hv_BBoxPhiNewIndices = (hv_BBoxPhiNew.TupleGreaterElem(HTuple(180).TupleRad())).TupleFind(1);
            if (0 != (int(hv_BBoxPhiNewIndices!=-1)))
            {
                hv_BBoxPhiNew[hv_BBoxPhiNewIndices] = HTuple(hv_BBoxPhiNew[hv_BBoxPhiNewIndices])-(HTuple(360).TupleRad());
            }
            //
        }
        else
        {
            hv_BBoxColNew = hv_BBoxColNew*hv_FactorResampleWidth;
            hv_BBoxRowNew = hv_BBoxRowNew*hv_FactorResampleWidth;
            hv_BBoxLength1New = hv_BBoxLength1New*hv_FactorResampleWidth;
            hv_BBoxLength2New = hv_BBoxLength2New*hv_FactorResampleWidth;
            //Phi stays the same.
        }
        //
    }
    //
    //Adapt the bounding box angles such that they are within the correct range,
    //which is (-180бу,180бу] for 'ignore_direction'==false and (-90бу,90бу] else.
    hv_PhiThreshold = (HTuple(180).TupleRad())-(hv_IgnoreDirection*(HTuple(90).TupleRad()));
    hv_PhiDelta = 2*hv_PhiThreshold;
    //Correct angles that are too large.
    hv_PhiToCorrect = (hv_BBoxPhiNew.TupleGreaterElem(hv_PhiThreshold)).TupleFind(1);
    if (0 != (HTuple(int(hv_PhiToCorrect!=-1)).TupleAnd(int(hv_PhiToCorrect!=HTuple()))))
    {
        hv_NumCorrections = (((HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])-hv_PhiThreshold)/hv_PhiDelta).TupleInt())+1;
        hv_BBoxPhiNew[hv_PhiToCorrect] = HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])-(hv_NumCorrections*hv_PhiDelta);
    }
    //Correct angles that are too small.
    hv_PhiToCorrect = (hv_BBoxPhiNew.TupleLessEqualElem(-hv_PhiThreshold)).TupleFind(1);
    if (0 != (HTuple(int(hv_PhiToCorrect!=-1)).TupleAnd(int(hv_PhiToCorrect!=HTuple()))))
    {
        hv_NumCorrections = ((((HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])+hv_PhiThreshold).TupleAbs())/hv_PhiDelta).TupleInt())+1;
        hv_BBoxPhiNew[hv_PhiToCorrect] = HTuple(hv_BBoxPhiNew[hv_PhiToCorrect])+(hv_NumCorrections*hv_PhiDelta);
    }
    //
    //Check that there are no invalid boxes.
    if (0 != (int((hv_BBoxRowNew.TupleLength())>0)))
    {
        hv_BoxesInvalid = ((hv_BBoxLength1New.TupleEqualElem(0)).TupleSum())+((hv_BBoxLength2New.TupleEqualElem(0)).TupleSum());
        if (0 != (int(hv_BoxesInvalid>0)))
        {
            GetDictTuple(hv_DLSample, "image_id", &hv_ImageId);
            throw HException(("An error has occurred during preprocessing image_id "+hv_ImageId)+HTuple(": Sample contains at least one box with zero-area, i.e. bbox_length1 == 0 or bbox_length2 == 0!"));
        }
    }
    SetDictTuple(hv_DLSample, "bbox_row", hv_BBoxRowNew);
    SetDictTuple(hv_DLSample, "bbox_col", hv_BBoxColNew);
    SetDictTuple(hv_DLSample, "bbox_length1", hv_BBoxLength1New);
    SetDictTuple(hv_DLSample, "bbox_length2", hv_BBoxLength2New);
    SetDictTuple(hv_DLSample, "bbox_phi", hv_BBoxPhiNew);
    SetDictTuple(hv_DLSample, "bbox_label_id", hv_BBoxLabelNew);
    //
    return;

}

// Chapter: OCR / Deep OCR
// Short Description: Preprocess images for deep-learning-based training and inference of Deep OCR detection models.
void HalxAI:: preprocess_dl_model_images_ocr_detection (HObject ho_Images, HObject *ho_ImagesPreprocessed,
                                                        HTuple hv_DLPreprocessParam)
{

    // Local iconic variables
    HObject  ho_Image, ho_ImageScaled, ho_Channel;
    HObject  ho_ChannelScaled, ho_ImageG, ho_ImageB;

    // Local control variables
    HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
    HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
    HTuple  hv_NormalizationType, hv_ModelType, hv_NumImages;
    HTuple  hv_NumChannels, hv_ImageTypes, hv_InputImageWidths;
    HTuple  hv_InputImageHeights, hv_ImageRange, hv_I, hv_InputImageWidth;
    HTuple  hv_InputImageHeight, hv_ZoomFactorWidth, hv_ZoomFactorHeight;
    HTuple  hv_ZoomHeight, hv_ZoomWidth, hv_ChannelIndex, hv_Min;
    HTuple  hv_Max, hv_Range, hv_Scale, hv_Shift;

    //This procedure preprocesses the provided images according to the parameters
    //in the dictionary DLPreprocessParam for an ocr_detection model.
    //
    //Check the validity of the preprocessing parameters.
    check_dl_preprocess_param(hv_DLPreprocessParam);
    //
    //Get the preprocessing parameters.
    GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
    GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
    GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
    GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
    GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
    GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
    GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
    GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
    //
    //Check the preprocessing parameters.
    if (0 != (int(hv_ModelType!=HTuple("ocr_detection"))))
    {
        throw HException("The only 'model_type' value supported is'ocr_detection'.");
    }
    if (0 != (int(hv_ImageNumChannels!=3)))
    {
        throw HException("The only 'image_num_channels' value supported for ocr_detection models is 3.");
    }
    if (0 != (int(hv_DomainHandling!=HTuple("full_domain"))))
    {
        throw HException("The only 'domain_handling' value supported for ocr_detection models is 'full_domain'.");
    }
    if (0 != (HTuple(int(hv_NormalizationType!=HTuple("none"))).TupleAnd(int(hv_NormalizationType!=HTuple("all_channels")))))
    {
        throw HException("The 'normalization_type' values supported for ocr_detection models are 'all_channels' and 'none'.");
    }
    //
    //Get the image properties.
    CountObj(ho_Images, &hv_NumImages);
    CountChannels(ho_Images, &hv_NumChannels);
    GetImageType(ho_Images, &hv_ImageTypes);
    GetImageSize(ho_Images, &hv_InputImageWidths, &hv_InputImageHeights);
    //
    //Check the image properties.
    if (0 != (int(hv_NumImages==0)))
    {
        throw HException("Please provide some images to preprocess.");
    }
    if (0 != (int(hv_NumImages!=(hv_ImageTypes.TupleRegexpTest("byte")))))
    {
        throw HException("Please provide only images of type 'byte'.");
    }
    if (0 != (int(hv_NumImages!=(HTuple((hv_NumChannels.TupleEqualElem(1)).TupleOr(hv_NumChannels.TupleEqualElem(3))).TupleSum()))))
    {
        throw HException("Please provide only 1- or 3-channels images for ocr_detection models.");
    }
    //
    //Preprocess the images.
    hv_ImageRange = (hv_ImageRangeMax-hv_ImageRangeMin).TupleReal();
    {
        HTuple end_val49 = hv_NumImages-1;
        HTuple step_val49 = 1;
        for (hv_I=0; hv_I.Continue(end_val49, step_val49); hv_I += step_val49)
        {
            hv_InputImageWidth = HTuple(hv_InputImageWidths[hv_I]);
            hv_InputImageHeight = HTuple(hv_InputImageHeights[hv_I]);
            //
            SelectObj(ho_Images, &ho_Image, hv_I+1);
            //
            //Calculate aspect-ratio preserving zoom factors
            calculate_dl_image_zoom_factors(hv_InputImageWidth, hv_InputImageHeight, hv_ImageWidth,
                                            hv_ImageHeight, hv_DLPreprocessParam, &hv_ZoomFactorWidth, &hv_ZoomFactorHeight);
            //
            //Zoom image
            hv_ZoomHeight = (hv_ZoomFactorHeight*hv_InputImageHeight).TupleRound();
            hv_ZoomWidth = (hv_ZoomFactorWidth*hv_InputImageWidth).TupleRound();
            ZoomImageSize(ho_Image, &ho_Image, hv_ZoomWidth, hv_ZoomHeight, "constant");
            //
            //Convert to real and normalize
            ConvertImageType(ho_Image, &ho_Image, "real");
            if (0 != (int(hv_NormalizationType==HTuple("all_channels"))))
            {
                GenEmptyObj(&ho_ImageScaled);
                {
                    HTuple end_val67 = HTuple(hv_NumChannels[hv_I]);
                    HTuple step_val67 = 1;
                    for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val67, step_val67); hv_ChannelIndex += step_val67)
                    {
                        AccessChannel(ho_Image, &ho_Channel, hv_ChannelIndex);
                        MinMaxGray(ho_Channel, ho_Channel, 0, &hv_Min, &hv_Max, &hv_Range);
                        if (0 != (int((hv_Max-hv_Min)==0)))
                        {
                            hv_Scale = 1;
                        }
                        else
                        {
                            hv_Scale = (hv_ImageRangeMax-hv_ImageRangeMin)/(hv_Max-hv_Min);
                        }
                        hv_Shift = ((-hv_Scale)*hv_Min)+hv_ImageRangeMin;
                        ScaleImage(ho_Channel, &ho_ChannelScaled, hv_Scale, hv_Shift);
                        AppendChannel(ho_ImageScaled, ho_ChannelScaled, &ho_ImageScaled);
                    }
                }
                ho_Image = ho_ImageScaled;
            }
            else if (0 != (int(hv_NormalizationType==HTuple("none"))))
            {
                ScaleImage(ho_Image, &ho_Image, hv_ImageRange/255.0, hv_ImageRangeMin);
            }
            //
            //Obtain an RGB image.
            if (0 != (int(HTuple(hv_NumChannels[hv_I])==1)))
            {
                CopyImage(ho_Image, &ho_ImageG);
                CopyImage(ho_Image, &ho_ImageB);
                Compose3(ho_Image, ho_ImageG, ho_ImageB, &ho_Image);
            }
            //
            //Apply padding to fit the desired image size.
            //The padding value is zero, corresponding to the
            //border handling of the convolution layers.
            ChangeFormat(ho_Image, &ho_Image, hv_ImageWidth, hv_ImageHeight);
            ReplaceObj(ho_Images, ho_Image, &ho_Images, hv_I+1);
        }
    }
    //
    //Return the preprocessed images.
    (*ho_ImagesPreprocessed) = ho_Images;
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Preprocess images for deep-learning-based training and inference of Deep OCR recognition models.
void HalxAI:: preprocess_dl_model_images_ocr_recognition (HObject ho_Images, HObject *ho_ImagesPreprocessed,
                                                          HTuple hv_DLPreprocessParam)
{

    // Local iconic variables
    HObject  ho_TargetImage, ho_Image;

    // Local control variables
    HTuple  hv_ImageWidth, hv_ImageHeight, hv_ImageNumChannels;
    HTuple  hv_ImageRangeMin, hv_ImageRangeMax, hv_DomainHandling;
    HTuple  hv_NormalizationType, hv_ModelType, hv_NumImages;
    HTuple  hv_NumChannels, hv_ImageTypes, hv_InputImageWidths;
    HTuple  hv_InputImageHeights, hv_PaddingGrayval, hv_ImageRange;
    HTuple  hv_I, hv_InputImageWidth, hv_InputImageHeight, hv_InputImageWidthHeightRatio;
    HTuple  hv_ZoomHeight, hv_ZoomWidth, hv_GrayvalMin, hv_GrayvalMax;
    HTuple  hv_Range, hv_GrayvalRange, hv_Scale, hv_Shift;

    //This procedure preprocesses the provided Images according to the parameters
    //in the dictionary DLPreprocessParam for an ocr_recognition model.
    //
    //Check the validity of the preprocessing parameters.
    check_dl_preprocess_param(hv_DLPreprocessParam);
    //
    //Get the preprocessing parameters.
    GetDictTuple(hv_DLPreprocessParam, "image_width", &hv_ImageWidth);
    GetDictTuple(hv_DLPreprocessParam, "image_height", &hv_ImageHeight);
    GetDictTuple(hv_DLPreprocessParam, "image_num_channels", &hv_ImageNumChannels);
    GetDictTuple(hv_DLPreprocessParam, "image_range_min", &hv_ImageRangeMin);
    GetDictTuple(hv_DLPreprocessParam, "image_range_max", &hv_ImageRangeMax);
    GetDictTuple(hv_DLPreprocessParam, "domain_handling", &hv_DomainHandling);
    GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
    GetDictTuple(hv_DLPreprocessParam, "model_type", &hv_ModelType);
    //
    //Check the preprocessing parameters.
    if (0 != (int(hv_ModelType!=HTuple("ocr_recognition"))))
    {
        throw HException("The only 'model_type' value supported is'ocr_recognition'.");
    }
    if (0 != (int(hv_ImageNumChannels!=1)))
    {
        throw HException("The only 'image_num_channels' value supported for ocr_recognition models is 1.");
    }
    if (0 != (int(hv_DomainHandling!=HTuple("full_domain"))))
    {
        throw HException("The only 'domain_handling' value supported for ocr_recognition models is 'full_domain'.");
    }
    if (0 != (HTuple(HTuple(int(hv_NormalizationType!=HTuple("none"))).TupleAnd(int(hv_NormalizationType!=HTuple("first_channel")))).TupleAnd(int(hv_NormalizationType!=HTuple("all_channels")))))
    {
        throw HException(HTuple("The 'normalization_type' values supported for ocr_recognition models are 'first_channel', 'all_channels' and 'none'."));
    }
    //
    //Get the image properties.
    CountObj(ho_Images, &hv_NumImages);
    CountChannels(ho_Images, &hv_NumChannels);
    GetImageType(ho_Images, &hv_ImageTypes);
    GetImageSize(ho_Images, &hv_InputImageWidths, &hv_InputImageHeights);
    //
    //Check the image properties.
    if (0 != (int(hv_NumImages==0)))
    {
        throw HException("Please provide some images to preprocess.");
    }
    if (0 != (int(hv_NumImages!=(hv_ImageTypes.TupleRegexpTest("byte|real")))))
    {
        throw HException("Please provide only images of type 'byte' or 'real'.");
    }
    if (0 != (int(hv_NumImages!=(HTuple((hv_NumChannels.TupleEqualElem(1)).TupleOr(hv_NumChannels.TupleEqualElem(3))).TupleSum()))))
    {
        throw HException("Please provide only 1- or 3-channels images for ocr_recognition models.");
    }
    //
    //Preprocess the images.
    hv_PaddingGrayval = 0.0;
    hv_ImageRange = (hv_ImageRangeMax-hv_ImageRangeMin).TupleReal();
    GenImageConst(&ho_TargetImage, "real", hv_ImageWidth, hv_ImageHeight);
    OverpaintRegion(ho_TargetImage, ho_TargetImage, hv_PaddingGrayval, "fill");
    {
        HTuple end_val52 = hv_NumImages-1;
        HTuple step_val52 = 1;
        for (hv_I=0; hv_I.Continue(end_val52, step_val52); hv_I += step_val52)
        {
            hv_InputImageWidth = HTuple(hv_InputImageWidths[hv_I]);
            hv_InputImageHeight = HTuple(hv_InputImageHeights[hv_I]);
            hv_InputImageWidthHeightRatio = hv_InputImageWidth/(hv_InputImageHeight.TupleReal());
            //
            SelectObj(ho_Images, &ho_Image, hv_I+1);
            FullDomain(ho_Image, &ho_Image);
            if (0 != (int(HTuple(hv_NumChannels[hv_I])==3)))
            {
                Rgb1ToGray(ho_Image, &ho_Image);
            }
            //
            hv_ZoomHeight = hv_ImageHeight;
            hv_ZoomWidth = hv_ImageWidth.TupleMin2((hv_ImageHeight*hv_InputImageWidthHeightRatio).TupleInt());
            ZoomImageSize(ho_Image, &ho_Image, hv_ZoomWidth, hv_ZoomHeight, "constant");
            if (0 != (int(HTuple(hv_ImageTypes[hv_I])==HTuple("byte"))))
            {
                ConvertImageType(ho_Image, &ho_Image, "real");
            }
            if (0 != (HTuple(int(hv_NormalizationType==HTuple("first_channel"))).TupleOr(int(hv_NormalizationType==HTuple("all_channels")))))
            {
                MinMaxGray(ho_Image, ho_Image, 0, &hv_GrayvalMin, &hv_GrayvalMax, &hv_Range);
                hv_GrayvalRange = (hv_GrayvalMax-hv_GrayvalMin).TupleReal();
                if (0 != (int(hv_GrayvalRange==0.0)))
                {
                    hv_Scale = 1.0;
                }
                else
                {
                    hv_Scale = hv_ImageRange/hv_GrayvalRange;
                }
                hv_Shift = ((-hv_Scale)*hv_GrayvalMin)+hv_ImageRangeMin;
                ScaleImage(ho_Image, &ho_Image, hv_Scale, hv_Shift);
            }
            else if (0 != (int(hv_NormalizationType==HTuple("none"))))
            {
                if (0 != (int(HTuple(hv_ImageTypes[hv_I])==HTuple("byte"))))
                {
                    ScaleImage(ho_Image, &ho_Image, hv_ImageRange/255.0, hv_ImageRangeMin);
                }
            }
            //
            OverpaintGray(ho_TargetImage, ho_Image);
            ReduceDomain(ho_TargetImage, ho_Image, &ho_TargetImage);
            ReplaceObj(ho_Images, ho_TargetImage, &ho_Images, hv_I+1);
        }
    }
    //
    //Return the preprocessed images.
    (*ho_ImagesPreprocessed) = ho_Images;
    return;
}

// Chapter: Tuple / Conversion
// Short Description: Print a tuple of values to a string.
void HalxAI:: pretty_print_tuple (HTuple hv_Tuple, HTuple *hv_TupleStr)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_J;

    //
    //This procedure prints a tuple of values to a string.
    //
    if (0 != (int((hv_Tuple.TupleLength())>1)))
    {
        (*hv_TupleStr) = "[";
        {
            HTuple end_val5 = (hv_Tuple.TupleLength())-1;
            HTuple step_val5 = 1;
            for (hv_J=0; hv_J.Continue(end_val5, step_val5); hv_J += step_val5)
            {
                if (0 != (int(hv_J>0)))
                {
                    (*hv_TupleStr) += HTuple(HTuple(","));
                }
                (*hv_TupleStr) += HTuple(hv_Tuple[hv_J]);
            }
        }
        (*hv_TupleStr) += HTuple("]");
    }
    else
    {
        (*hv_TupleStr) = hv_Tuple;
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Read the dictionaries DLSamples from files.
void HalxAI:: read_dl_samples (HTuple hv_DLDataset, HTuple hv_SampleIndices, HTuple *hv_DLSampleBatch)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_DatasetSamples, hv_MinIndex, hv_MaxIndex;
    HTuple  hv_KeyDirExists, hv_DictDir, hv_DLSamplesProc, hv_ImageIndex;
    HTuple  hv_KeyFileExists, hv_ImageID, hv_FileNameRelative;
    HTuple  hv_FileNameSample, hv_FileExists, hv_DictPath, hv_DLSample;
    HTuple  hv_Exception;


    //custom define ╫╘╢и╥х
    HTuple hv_CompleteDictDir;

    //
    //This procedure reads a batch of DLSample dictionaries from disk.
    //The wanted samples are selected from a DLDataset by their indices.
    //The indices of the wanted samples are handed over in SampleIndices.
    //It returns the tuple of read-in dictionaries in DLSampleBatch.
    //
    //Sanity checks of inputs.
    //
    if (0 != (int((hv_SampleIndices.TupleLength())<=0)))
    {
        //Check the length of selected indices.
        throw HException(HTuple("Invalid length of SelectedIndices: ")+(hv_SampleIndices.TupleLength()));
    }
    else
    {
        //Get the samples from the DLDataset.
        GetDictTuple(hv_DLDataset, "samples", &hv_DatasetSamples);
        //Get min and max value of given indices.
        TupleMin(hv_SampleIndices, &hv_MinIndex);
        TupleMax(hv_SampleIndices, &hv_MaxIndex);
        if (0 != (HTuple(int(hv_MinIndex<0)).TupleOr(int(hv_MaxIndex>((hv_DatasetSamples.TupleLength())-1)))))
        {
            //Check the value range of the provided indices.
            throw HException("The given SampleIndices are not within the range of available samples in DLDataset.");
        }
    }
    //
    //Check if the key dlsample_dir is given.
    GetDictParam(hv_DLDataset, "key_exists", "dlsample_dir", &hv_KeyDirExists);
    //
    if (0 != hv_KeyDirExists)
    {
        //
        //Get the dlsample_dir.
        GetDictTuple(hv_DLDataset, "dlsample_dir", &hv_DictDir);
        hv_CompleteDictDir = "F:/QtProject/BIN/HalxAIDet/"+(hv_DictDir+"/");
        //Get the samples to be processed.
        hv_DLSamplesProc = HTuple(hv_DatasetSamples[hv_SampleIndices]);
        //
        //Initialize DLSampleBatch tuple.
        (*hv_DLSampleBatch) = HTuple();
        //
        //Read in all DLSamples into the batch.
        {
            HTuple end_val37 = (hv_SampleIndices.TupleLength())-1;
            HTuple step_val37 = 1;
            for (hv_ImageIndex=0; hv_ImageIndex.Continue(end_val37, step_val37); hv_ImageIndex += step_val37)
            {
                //Check if dlsample key exist.
                GetDictParam(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "key_exists", "dlsample_file_name",
                             &hv_KeyFileExists);
                //
                if (0 != (hv_KeyFileExists.TupleNot()))
                {
                    //
                    //If the key does not exist, check if a corresponding file exists.
                    GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "image_id", &hv_ImageID);
                    hv_FileNameRelative = hv_ImageID+"_dlsample.hdict";
                    //hv_FileNameSample = (hv_DictDir+"/")+hv_FileNameRelative;
                    hv_FileNameSample = (hv_CompleteDictDir+"/")+hv_FileNameRelative;
                    //
                    FileExists(hv_FileNameSample, &hv_FileExists);
                    if (0 != hv_FileExists)
                    {
                        //If it exists, create corresponding key.
                        SetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "dlsample_file_name",
                                     hv_FileNameRelative);
                    }
                    else
                    {
                        //If not, throw an error.
                        throw HException("No 'dlsample_file_name' and hdict file available for image ID "+hv_ImageID);
                    }
                    //
                }
                //
                //If dlsample dictionary is available for reading, read it.
                GetDictTuple(HTuple(hv_DLSamplesProc[hv_ImageIndex]), "dlsample_file_name",
                             &hv_DictPath);
                try
                {
                    //ReadDict((hv_DictDir+"/")+hv_DictPath, HTuple(), HTuple(), &hv_DLSample);
                    ReadDict((hv_CompleteDictDir+"/")+hv_DictPath, HTuple(), HTuple(), &hv_DLSample);
                }
                // catch (Exception)
                catch (HException &HDevExpDefaultException)
                {
                    HDevExpDefaultException.ToHTuple(&hv_Exception);
                    //throw HException((((("An error has occurred while reading "+hv_DictDir)+"/")+hv_DictPath)+HTuple(" , HALCON error # "))+HTuple(hv_Exception[0]));
                    throw HException((((("An error has occurred while reading "+hv_CompleteDictDir)+"/")+hv_DictPath)+HTuple(" , HALCON error # "))+HTuple(hv_Exception[0]));

                }
                //Add it to the DLSampleBatch.
                (*hv_DLSampleBatch) = (*hv_DLSampleBatch).TupleConcat(hv_DLSample);
                //
            }
        }
    }
    else
    {
        throw HException("The dataset needs to include the key 'dlsample_dir' for reading a DLSample from file.");
    }

    return;
}

// Chapter: Deep Learning / Model
// Short Description: Reduce the evaluation result to a single value.
void HalxAI:: reduce_dl_evaluation_result (HTuple hv_EvaluationResult, HTuple hv_EvaluationComparisonKeys,
                                           HTuple *hv_Value, HTuple *hv_ValidEvaluationKeys)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_TopLevelResult, hv_KeysEvalResult;
    HTuple  hv_NumMatches, hv_FirstMaxNumDetections, hv_KeysFirstMaxNumDetections;
    HTuple  hv_DetectionResult, hv_Index, hv_ClassificationResult;
    HTuple  hv_KeysExist, hv_Indices, hv_Values, hv_K, hv_Key;
    HTuple  hv_Tuple;

    //
    //In order to compare a model we need to reduce the evaluation parameter/result
    //to a single float Value which is comparable via >.
    //
    if (0 != (HTuple(int((hv_EvaluationComparisonKeys.TupleLength())>0)).TupleAnd(int((hv_EvaluationResult.TupleLength())>0))))
    {
        hv_TopLevelResult = hv_EvaluationResult;
        //We need to check for a special case: detection results.
        //They have a complex structure.
        GetDictParam(hv_EvaluationResult, "keys", HTuple(), &hv_KeysEvalResult);
        TupleRegexpTest(hv_KeysEvalResult, "max_num_detections_.*", &hv_NumMatches);
        if (0 != (int(hv_NumMatches>0)))
        {
            //We use only the first results of every level.
            GetDictTuple(hv_EvaluationResult, HTuple(hv_KeysEvalResult[0]), &hv_FirstMaxNumDetections);
            GetDictParam(hv_FirstMaxNumDetections, "keys", HTuple(), &hv_KeysFirstMaxNumDetections);
            GetDictTuple(hv_FirstMaxNumDetections, HTuple(hv_KeysFirstMaxNumDetections[0]),
                    &hv_DetectionResult);
            //We use this result here as the top level to retrieve values.
            hv_EvaluationResult = hv_DetectionResult;
        }
        //We need to check for a special case: classification results.
        //They have a complex structure.
        TupleFind(hv_KeysEvalResult.TupleEqualElem("global"), 1, &hv_Index);
        if (0 != (int(hv_Index!=-1)))
        {
            //We use the results for key 'global'.
            GetDictTuple(hv_EvaluationResult, HTuple(hv_KeysEvalResult[hv_Index]), &hv_ClassificationResult);
            hv_EvaluationResult = hv_ClassificationResult;
        }
        TupleFind(hv_KeysEvalResult.TupleEqualElem("ocr_detection"), 1, &hv_Index);
        if (0 != (int(hv_Index!=-1)))
        {
            //We use the results for key 'ocr_detection'.
            GetDictTuple(hv_TopLevelResult, HTuple(hv_KeysEvalResult[hv_Index]), &hv_EvaluationResult);
        }
        //Reduce comparison to keys that exist.
        GetDictParam(hv_EvaluationResult, "key_exists", hv_EvaluationComparisonKeys,
                     &hv_KeysExist);
        //
        TupleFind(hv_KeysExist, 1, &hv_Indices);
        if (0 != (int(hv_Indices==-1)))
        {
            hv_EvaluationComparisonKeys = HTuple();
        }
        else
        {
            hv_EvaluationComparisonKeys = HTuple(hv_EvaluationComparisonKeys[hv_Indices]);
        }
    }
    //
    (*hv_ValidEvaluationKeys) = hv_EvaluationComparisonKeys;
    //
    (*hv_Value) = 0.0;
    hv_Values = HTuple();
    if (0 != (int((hv_EvaluationResult.TupleLength())>0)))
    {
        {
            HTuple end_val47 = (hv_EvaluationComparisonKeys.TupleLength())-1;
            HTuple step_val47 = 1;
            for (hv_K=0; hv_K.Continue(end_val47, step_val47); hv_K += step_val47)
            {
                hv_Key = HTuple(hv_EvaluationComparisonKeys[hv_K]);
                //
                GetDictTuple(hv_EvaluationResult, hv_Key, &hv_Tuple);
                //Use the mean in order to reduce tuples with length > 1.
                hv_Values = hv_Values.TupleConcat(hv_Tuple.TupleMean());
            }
        }
    }
    else
    {
        (*hv_Value) = -1;
    }
    if (0 != (int((hv_Values.TupleLength())>0)))
    {
        (*hv_Value) = hv_Values.TupleMean();
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Replace legacy preprocessing parameters or values.
void HalxAI:: replace_legacy_preprocessing_parameters (HTuple hv_DLPreprocessParam)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Exception, hv_NormalizationTypeExists;
    HTuple  hv_NormalizationType, hv_LegacyNormalizationKeyExists;
    HTuple  hv_ContrastNormalization;

    //
    //This procedure adapts the dictionary DLPreprocessParam
    //if a legacy preprocessing parameter is set.
    //
    //Map legacy value set to new parameter.
    hv_Exception = 0;
    try
    {
        GetDictParam(hv_DLPreprocessParam, "key_exists", "normalization_type", &hv_NormalizationTypeExists);
        //
        if (0 != hv_NormalizationTypeExists)
        {
            GetDictTuple(hv_DLPreprocessParam, "normalization_type", &hv_NormalizationType);
            if (0 != (int(hv_NormalizationType==HTuple("true"))))
            {
                hv_NormalizationType = "first_channel";
            }
            else if (0 != (int(hv_NormalizationType==HTuple("false"))))
            {
                hv_NormalizationType = "none";
            }
            SetDictTuple(hv_DLPreprocessParam, "normalization_type", hv_NormalizationType);
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    //Map legacy parameter to new parameter and corresponding value.
    hv_Exception = 0;
    try
    {
        GetDictParam(hv_DLPreprocessParam, "key_exists", "contrast_normalization", &hv_LegacyNormalizationKeyExists);
        if (0 != hv_LegacyNormalizationKeyExists)
        {
            GetDictTuple(hv_DLPreprocessParam, "contrast_normalization", &hv_ContrastNormalization);
            //Replace 'contrast_normalization' by 'normalization_type'.
            if (0 != (int(hv_ContrastNormalization==HTuple("false"))))
            {
                SetDictTuple(hv_DLPreprocessParam, "normalization_type", "none");
            }
            else if (0 != (int(hv_ContrastNormalization==HTuple("true"))))
            {
                SetDictTuple(hv_DLPreprocessParam, "normalization_type", "first_channel");
            }
            RemoveDictKey(hv_DLPreprocessParam, "contrast_normalization");
        }
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Restore serialized DL train information to resume the training.
void HalxAI:: restore_dl_train_info_for_resuming (HTuple hv_StartEpoch, HTuple hv_SerializationData,
                                                  HTuple hv_TrainParam, HTuple hv_DisplayData, HTuple *hv_EvaluationInfos, HTuple *hv_TrainInfos,
                                                  HTuple *hv_DisplayEvaluationEpochs, HTuple *hv_DisplayValidationEvaluationValues,
                                                  HTuple *hv_DisplayTrainEvaluationValues, HTuple *hv_DisplayLossEpochs, HTuple *hv_DisplayLoss,
                                                  HTuple *hv_DisplayLearningRates, HTuple *hv_TrainResultsRestored, HTuple *hv_StartEpochNumber)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_TrainResults, hv_SerializationStrategies;
    HTuple  hv_RawData, hv_FoundEpochs, hv_FoundDicts, hv_Index;
    HTuple  hv_Strategy, hv_Type, hv_Basename, hv_Substrings;
    HTuple  hv_BaseFolder, hv_Files, hv_DictFiles, hv_EpochStrings;
    HTuple  hv_EpochStringsNumbers, hv_DictFileNames, hv_IndexDict;
    HTuple  hv_DictFileName, hv_InfoDicts, hv_Epochs, hv_ReadSuccess;
    HTuple  hv_InfoDict, hv_Epoch, hv_Exception, hv_EvaluationComparisonKeys;
    HTuple  hv_DisplayEnabled, hv_IndexEval, hv_EvaluationResult;
    HTuple  hv_Value, hv_ValidEvaluationKeys, hv_IndexTrain;
    HTuple  hv_EpochsStatus, hv_MeanLoss, hv_ModelParams, hv_DisplayLearningRate;
    HTuple  hv_LossParam, hv_CountSamples, hv_LossValues, hv_NumMeanLossSamples;
    HTuple  hv_SamplesPerEpoch, hv_MeanLossCur, hv_NumSamplesInterval;
    HTuple  hv_LossValueIdxsPrev, hv_MeanLossCurInterval, hv_LossValuesCurInterval;
    HTuple  hv_IndexSample, hv_TrainResult, hv_NumEpochs;

    //
    //┤╦╣¤│╠│ї╩╝╗п╤╡┴╖╞┌╝ф┤ц┤в╡─╤╡┴╖╧р╣╪▓╬╩¤бг
    //╚ч╣√ StartEpoch ┤є╙┌┴у╗Є╡╚╙┌б░resumeб▒гм╘Є╕├╣¤│╠╗╓╕┤┤╦╨┼╧вбг
    //╒т╘╩╨э╒¤╚╖╗╓╕┤╥╤╘▌═г╗Є╥Є╞ф╦√╘н╥Є╙ж╝╠╨°╡─╤╡┴╖бг
         //
    //│ї╩╝╗п▒ф┴┐╥╘│╨╘╪╤╡┴╖╣¤│╠╓╨╡─╦∙╙╨╤╡┴╖╜с╣√бг
    hv_TrainResults = HTuple();
    //
    //evaluation information during training.
    (*hv_EvaluationInfos) = HTuple();
    (*hv_TrainResultsRestored) = HTuple();
    //
    //train status information during training.
    (*hv_TrainInfos) = HTuple();
    //
    // Initialize visualization parameters.
    (*hv_DisplayLossEpochs) = HTuple();
    (*hv_DisplayLoss) = HTuple();
    (*hv_DisplayEvaluationEpochs) = HTuple();
    (*hv_DisplayValidationEvaluationValues) = HTuple();
    (*hv_DisplayTrainEvaluationValues) = HTuple();
    (*hv_DisplayLearningRates) = HTuple();
    //
    //Initialize the start epoch number.
    (*hv_StartEpochNumber) = 0;
    //
    //Training parameters are initialized for new training,
    //hence return if StartEpoch is zero.
    if (0 != (int(hv_StartEpoch==0.0)))
    {
        return;
    }
    //
    //This procedure reads the latest training and evaluation information from disk to resume training.
    //
    //Initialize each serialization strategy.
    GetDictTuple(hv_SerializationData, "strategies", &hv_SerializationStrategies);
    GetDictTuple(hv_SerializationData, "raw_data", &hv_RawData);
    //
    //Loop over all serialization strategies. If more than one is available and StartEpoch='resume',
    //choose the most up-to-date training information that can be found.
    hv_FoundEpochs = HTuple();
    hv_FoundDicts = HTuple();
    {
        HTuple end_val43 = (hv_SerializationStrategies.TupleLength())-1;
        HTuple step_val43 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val43, step_val43); hv_Index += step_val43)
        {
            //
            //Get current strategy and data.
            hv_Strategy = HTuple(hv_SerializationStrategies[hv_Index]);
            GetDictTuple(hv_Strategy, "type", &hv_Type);
            GetDictTuple(hv_Strategy, "basename", &hv_Basename);
            //
            if (0 != (HTuple(HTuple(int(hv_Type==HTuple("best"))).TupleOr(int(hv_Type==HTuple("current")))).TupleOr(int(hv_Type==HTuple("epochs")))))
            {
                //
                if (0 != (int(hv_Type==HTuple("epochs"))))
                {
                    //Find the last written training information
                    TupleRegexpReplace(hv_Basename, (HTuple("\\\\+").Append("replace_all")),
                                       "/", &hv_Basename);
                    TupleSplit(hv_Basename, "/", &hv_Substrings);
                    hv_BaseFolder = ".";
                    if (0 != (int((hv_Substrings.TupleLength())>1)))
                    {
                        hv_BaseFolder = (hv_Substrings.TupleSelectRange(0,(hv_Substrings.TupleLength())-2))+"/";
                    }
                    ListFiles(hv_BaseFolder, "files", &hv_Files);
                    TupleRegexpSelect(hv_Files, "[0-9]\\.[0-9]*_info\\.hdict", &hv_DictFiles);
                    TupleRegexpMatch(hv_DictFiles, "[0-9]\\.[0-9]*", &hv_EpochStrings);
                    hv_EpochStringsNumbers = hv_EpochStrings.TupleNumber();
                    TupleGenConst(hv_EpochStrings.TupleLength(), "", &hv_DictFileNames);
                    {
                        HTuple end_val65 = (hv_EpochStrings.TupleLength())-1;
                        HTuple step_val65 = 1;
                        for (hv_IndexDict=0; hv_IndexDict.Continue(end_val65, step_val65); hv_IndexDict += step_val65)
                        {
                            TupleRegexpSelect(hv_DictFiles, (HTuple(hv_EpochStringsNumbers[hv_IndexDict]).TupleString(".2f"))+"_info.hdict",
                                              &hv_DictFileName);
                            if (0 != (int((hv_DictFileName.TupleLength())!=0)))
                            {
                                hv_DictFileNames[hv_IndexDict] = hv_DictFileName;
                            }
                        }
                    }
                }
                else
                {
                    hv_DictFileNames = hv_Basename+"_info.hdict";
                }
                //
                //Try to read in the training information dictionaries.
                TupleGenConst(hv_DictFileNames.TupleLength(), -1, &hv_InfoDicts);
                TupleGenConst(hv_DictFileNames.TupleLength(), -1, &hv_Epochs);
                hv_ReadSuccess = 0;
                {
                    HTuple end_val79 = (hv_DictFileNames.TupleLength())-1;
                    HTuple step_val79 = 1;
                    for (hv_IndexDict=0; hv_IndexDict.Continue(end_val79, step_val79); hv_IndexDict += step_val79)
                    {
                        try
                        {
                            ReadDict(HTuple(hv_DictFileNames[hv_IndexDict]), HTuple(), HTuple(), &hv_InfoDict);
                            GetDictTuple(hv_InfoDict, "epoch", &hv_Epoch);
                            hv_InfoDicts[hv_IndexDict] = hv_InfoDict;
                            hv_Epochs[hv_IndexDict] = hv_Epoch;
                            hv_ReadSuccess = 1;
                        }
                        // catch (Exception)
                        catch (HException &HDevExpDefaultException)
                        {
                            HDevExpDefaultException.ToHTuple(&hv_Exception);
                        }
                    }
                }
                if (0 != (hv_ReadSuccess.TupleNot()))
                {
                    //Not even a single file has been found.
                    continue;
                }
                //
                hv_FoundEpochs = hv_FoundEpochs.TupleConcat(hv_Epochs);
                hv_FoundDicts = hv_FoundDicts.TupleConcat(hv_InfoDicts);
                //
            }
            else if (0 != (int(hv_Type==HTuple("final"))))
            {
                //Nothing to restore.
                continue;
            }
            else
            {
                throw HException(("Unknown serialization strategy type: '"+hv_Type)+"'");
            }
        }
    }
    //
    //Check if training can or needs to be resumed.
    if (0 != (int(hv_StartEpoch==HTuple("resume"))))
    {
        //Resume at highest epoch available.
        hv_Epoch = hv_FoundEpochs.TupleMax();
        if (0 != (int(hv_Epoch<0.0)))
        {
            throw HException("No training information found. Training cannot be resumed.");
        }
        hv_Index = (hv_FoundEpochs.TupleEqualElem(hv_Epoch)).TupleFindFirst(1);
        hv_InfoDict = HTuple(hv_FoundDicts[hv_Index]);
        hv_StartEpoch = hv_Epoch;
    }
    else
    {
        //Check if requested StartEpoch was found.
        hv_Index = (hv_FoundEpochs.TupleEqualElem(hv_StartEpoch)).TupleFindFirst(1);
        if (0 != (HTuple(int(hv_Index!=HTuple())).TupleAnd(int(hv_Index!=-1))))
        {
            hv_InfoDict = HTuple(hv_FoundDicts[hv_Index]);
        }
        else
        {
            //Try to find the rounded value as it is serialized.
            hv_Index = ((hv_FoundEpochs.TupleString(".2f")).TupleEqualElem(hv_StartEpoch.TupleString(".2f"))).TupleFindFirst(1);
            if (0 != (HTuple(int(hv_Index!=HTuple())).TupleAnd(int(hv_Index!=-1))))
            {
                hv_InfoDict = HTuple(hv_FoundDicts[hv_Index]);
            }
            else
            {
                throw HException("No training information matches requested StartEpoch "+hv_StartEpoch);
            }
        }
    }
    //
    //Get evaluation and training information.
    GetDictTuple(hv_InfoDict, "evaluation_infos", &(*hv_EvaluationInfos));
    GetDictTuple(hv_InfoDict, "train_infos", &(*hv_TrainInfos));
    GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
    //
    //Restore history of display values.
    GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
    if (0 != hv_DisplayEnabled)
    {
        {
            HTuple end_val139 = ((*hv_EvaluationInfos).TupleLength())-1;
            HTuple step_val139 = 1;
            for (hv_IndexEval=0; hv_IndexEval.Continue(end_val139, step_val139); hv_IndexEval += step_val139)
            {
                GetDictTuple(HTuple((*hv_EvaluationInfos)[hv_IndexEval]), "result", &hv_EvaluationResult);
                reduce_dl_evaluation_result(hv_EvaluationResult, hv_EvaluationComparisonKeys,
                                            &hv_Value, &hv_ValidEvaluationKeys);
                (*hv_DisplayValidationEvaluationValues) = (*hv_DisplayValidationEvaluationValues).TupleConcat(hv_Value);
                hv_Value = -1;
                try
                {
                    GetDictTuple(HTuple((*hv_EvaluationInfos)[hv_IndexEval]), "train_result",
                                 &hv_EvaluationResult);
                    reduce_dl_evaluation_result(hv_EvaluationResult, hv_EvaluationComparisonKeys,
                                                &hv_Value, &hv_ValidEvaluationKeys);
                }
                // catch (Exception)
                catch (HException &HDevExpDefaultException)
                {
                    HDevExpDefaultException.ToHTuple(&hv_Exception);
                }
                (*hv_DisplayTrainEvaluationValues) = (*hv_DisplayTrainEvaluationValues).TupleConcat(hv_Value);
                GetDictTuple(HTuple((*hv_EvaluationInfos)[hv_IndexEval]), "epoch", &hv_Epoch);
                (*hv_DisplayEvaluationEpochs) = (*hv_DisplayEvaluationEpochs).TupleConcat(hv_Epoch);
            }
        }
        {
            HTuple end_val153 = ((*hv_TrainInfos).TupleLength())-1;
            HTuple step_val153 = 1;
            for (hv_IndexTrain=0; hv_IndexTrain.Continue(end_val153, step_val153); hv_IndexTrain += step_val153)
            {
                GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "epoch", &hv_EpochsStatus);
                (*hv_DisplayLossEpochs) = (*hv_DisplayLossEpochs).TupleConcat(hv_EpochsStatus);
                GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "mean_loss", &hv_MeanLoss);
                (*hv_DisplayLoss) = (*hv_DisplayLoss).TupleConcat(hv_MeanLoss);
                GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "model_params", &hv_ModelParams);
                GetDictTuple(hv_ModelParams, "learning_rate", &hv_DisplayLearningRate);
                (*hv_DisplayLearningRates) = (*hv_DisplayLearningRates).TupleConcat(hv_DisplayLearningRate);
            }
        }
    }
    //
    //Restore dictionaries that contain the approximate loss-values for each iteration.
    //We cannot reconstruct the exact loss values, therefore, we use the serialized mean values.
    hv_LossParam = "total_loss";
    hv_CountSamples = 0;
    hv_LossValues = HTuple();
    GetDictTuple(HTuple((*hv_TrainInfos)[0]), "epoch", &hv_Epoch);
    GetDictTuple(HTuple((*hv_TrainInfos)[0]), "mean_loss_samples", &hv_NumMeanLossSamples);
    hv_SamplesPerEpoch = (hv_NumMeanLossSamples.TupleReal())/hv_Epoch;
    //
    {
        HTuple end_val173 = ((*hv_TrainInfos).TupleLength())-1;
        HTuple step_val173 = 1;
        for (hv_IndexTrain=0; hv_IndexTrain.Continue(end_val173, step_val173); hv_IndexTrain += step_val173)
        {
            GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "mean_loss", &hv_MeanLossCur);
            GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "mean_loss_samples", &hv_NumMeanLossSamples);
            //The iterations within one interval are not fixed.
            //Calculate the current iteration and the number of iterations within the interval based on the epoch.
            GetDictTuple(HTuple((*hv_TrainInfos)[hv_IndexTrain]), "epoch", &hv_Epoch);
            hv_NumSamplesInterval = ((hv_Epoch*hv_SamplesPerEpoch).TupleRound())-hv_CountSamples;
            //For multiple resuming it can happen that more than one train-info for the same time-point exists.
            if (0 != (int(hv_NumSamplesInterval==0)))
            {
                continue;
            }
            //Calculate the mean loss within the interval between the previous and the current serialization time-point.
            hv_LossValueIdxsPrev = HTuple::TupleGenSequence((hv_LossValues.TupleLength())-(hv_NumMeanLossSamples-hv_NumSamplesInterval),(hv_LossValues.TupleLength())-1,1).TupleInt();
            if (0 != (hv_LossValueIdxsPrev.TupleLength()))
            {
                //The total mean loss (MeanLossCur) consists of the mean loss within this interval (MeanLossCurInterval) and
                //the fraction of previous samples.
                hv_MeanLossCurInterval = ((hv_MeanLossCur*hv_NumMeanLossSamples)-(HTuple(hv_LossValues[hv_LossValueIdxsPrev]).TupleSum()))/hv_NumSamplesInterval;
            }
            else
            {
                //In this case the total mean loss is just the loss of this interval.
                hv_MeanLossCurInterval = hv_MeanLossCur;
            }
            //
            hv_LossValuesCurInterval = HTuple(hv_NumSamplesInterval,hv_MeanLossCurInterval);
            hv_LossValues = hv_LossValues.TupleConcat(hv_LossValuesCurInterval);
            //
            //Pack the loss values into dictionaries.
            (*hv_TrainResultsRestored) = (*hv_TrainResultsRestored).TupleConcat(HTuple(hv_NumSamplesInterval,-1));
            {
                HTuple end_val200 = hv_NumSamplesInterval-1;
                HTuple step_val200 = 1;
                for (hv_IndexSample=0; hv_IndexSample.Continue(end_val200, step_val200); hv_IndexSample += step_val200)
                {
                    CreateDict(&hv_TrainResult);
                    SetDictTuple(hv_TrainResult, hv_LossParam, HTuple(hv_LossValuesCurInterval[hv_IndexSample]));
                    (*hv_TrainResultsRestored)[hv_CountSamples] = hv_TrainResult;
                    hv_CountSamples += 1;
                }
            }
        }
    }
    //
    //Plot the current training status.
    if (0 != hv_DisplayEnabled)
    {
        GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
        SetDictTuple(HTuple((*hv_TrainInfos)[((*hv_TrainInfos).TupleLength())-1]), "num_epochs",
                hv_NumEpochs);
        dev_display_update_train_dl_model(hv_TrainParam, hv_DisplayData, HTuple((*hv_TrainInfos)[((*hv_TrainInfos).TupleLength())-1]),
                (*hv_DisplayLossEpochs), (*hv_DisplayLoss), (*hv_DisplayLearningRates), (*hv_DisplayEvaluationEpochs),
                (*hv_DisplayValidationEvaluationValues), (*hv_DisplayTrainEvaluationValues));
    }
    //
    //Return StartEpoch as number.
    (*hv_StartEpochNumber) = hv_StartEpoch;
    //
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Scale and shift a DL model layer.
void HalxAI:: scale_and_shift_dl_model_layer (HTuple hv_DLModelHandle, HTuple hv_LayerName,
                                              HTuple hv_Scale, HTuple hv_Shift)
{

    // Local iconic variables
    HObject  ho_Weights, ho_Bias, ho_WeightsScaled;
    HObject  ho_ChannelWeights, ho_ChannelWeightsScaled, ho_BiasScaled;

    // Local control variables
    HTuple  hv_BiasTuple, hv_NumOutputChannels, hv_BiasScaledTuple;
    HTuple  hv_OutputChannelIndex, hv_ChannelMult, hv_ChannelAdd;
    HTuple  hv_ChannelBias, hv_ChannelBiasScaled;

    //Get the original weights.
    GetDlModelLayerWeights(&ho_Weights, hv_DLModelHandle, hv_LayerName, "weights");
    GetDlModelLayerWeights(&ho_Bias, hv_DLModelHandle, hv_LayerName, "bias");
    GetGrayval(ho_Bias, 0, 0, &hv_BiasTuple);
    CountObj(ho_Weights, &hv_NumOutputChannels);
    //Create collections for the new weights and biases.
    GenEmptyObj(&ho_WeightsScaled);
    hv_BiasScaledTuple = HTuple(hv_NumOutputChannels,0);
    //Iterate over the output channels.
    {
        HTuple end_val9 = hv_NumOutputChannels-1;
        HTuple step_val9 = 1;
        for (hv_OutputChannelIndex=0; hv_OutputChannelIndex.Continue(end_val9, step_val9); hv_OutputChannelIndex += step_val9)
        {
            hv_ChannelMult = HTuple(hv_Scale[hv_OutputChannelIndex]);
            hv_ChannelAdd = HTuple(hv_Shift[hv_OutputChannelIndex]);
            //Get the weights and bias of this channel.
            SelectObj(ho_Weights, &ho_ChannelWeights, hv_OutputChannelIndex+1);
            hv_ChannelBias = HTuple(hv_BiasTuple[hv_OutputChannelIndex]);
            //Each weight scalar needs to be multiplied with ChannelMult.
            ScaleImage(ho_ChannelWeights, &ho_ChannelWeightsScaled, hv_ChannelMult, 0);
            //The bias needs to be multiplied with ChannelMult and
            //added to ChannelAdd.
            hv_ChannelBiasScaled = (hv_ChannelBias*hv_ChannelMult)+hv_ChannelAdd;
            //Store the scaled weights and bias.
            ConcatObj(ho_WeightsScaled, ho_ChannelWeightsScaled, &ho_WeightsScaled);
            hv_BiasScaledTuple[hv_OutputChannelIndex] = hv_ChannelBiasScaled;
        }
    }
    //Create the new bias image.
    CopyImage(ho_Bias, &ho_BiasScaled);
    SetGrayval(ho_BiasScaled, 0, 0, hv_BiasScaledTuple);
    //Set the weights in the model.
    SetDlModelLayerWeights(ho_WeightsScaled, hv_DLModelHandle, hv_LayerName, "weights");
    SetDlModelLayerWeights(ho_BiasScaled, hv_DLModelHandle, hv_LayerName, "bias");
    return;
}

// Chapter: Filters / Arithmetic
// Short Description: Scale the gray values of an image from the interval [Min,Max] to [0,255]
void HalxAI:: scale_image_range (HObject ho_Image, HObject *ho_ImageScaled, HTuple hv_Min,
                                 HTuple hv_Max)
{

    // Local iconic variables
    HObject  ho_ImageSelected, ho_SelectedChannel;
    HObject  ho_LowerRegion, ho_UpperRegion, ho_ImageSelectedScaled;

    // Local control variables
    HTuple  hv_LowerLimit, hv_UpperLimit, hv_Mult;
    HTuple  hv_Add, hv_NumImages, hv_ImageIndex, hv_Channels;
    HTuple  hv_ChannelIndex, hv_MinGray, hv_MaxGray, hv_Range;

    //Convenience procedure to scale the gray values of the
    //input image Image from the interval [Min,Max]
    //to the interval [0,255] (default).
    //Gray values < 0 or > 255 (after scaling) are clipped.
    //
    //If the image shall be scaled to an interval different from [0,255],
    //this can be achieved by passing tuples with 2 values [From, To]
    //as Min and Max.
    //Example:
    //scale_image_range(Image:ImageScaled:[100,50],[200,250])
    //maps the gray values of Image from the interval [100,200] to [50,250].
    //All other gray values will be clipped.
    //
    //input parameters:
    //Image: the input image
    //Min: the minimum gray value which will be mapped to 0
    //     If a tuple with two values is given, the first value will
    //     be mapped to the second value.
    //Max: The maximum gray value which will be mapped to 255
    //     If a tuple with two values is given, the first value will
    //     be mapped to the second value.
    //
    //Output parameter:
    //ImageScale: the resulting scaled image.
    //
    if (0 != (int((hv_Min.TupleLength())==2)))
    {
        hv_LowerLimit = ((const HTuple&)hv_Min)[1];
        hv_Min = ((const HTuple&)hv_Min)[0];
    }
    else
    {
        hv_LowerLimit = 0.0;
    }
    if (0 != (int((hv_Max.TupleLength())==2)))
    {
        hv_UpperLimit = ((const HTuple&)hv_Max)[1];
        hv_Max = ((const HTuple&)hv_Max)[0];
    }
    else
    {
        hv_UpperLimit = 255.0;
    }
    //
    //Calculate scaling parameters.
    //Only scale if the scaling range is not zero.
    if (0 != (HTuple(int(((hv_Max-hv_Min).TupleAbs())<1.0E-6)).TupleNot()))
    {
        hv_Mult = ((hv_UpperLimit-hv_LowerLimit).TupleReal())/(hv_Max-hv_Min);
        hv_Add = ((-hv_Mult)*hv_Min)+hv_LowerLimit;
        //Scale image.
        ScaleImage(ho_Image, &ho_Image, hv_Mult, hv_Add);
    }
    //
    //Clip gray values if necessary.
    //This must be done for each image and channel separately.
    GenEmptyObj(&(*ho_ImageScaled));
    CountObj(ho_Image, &hv_NumImages);
    {
        HTuple end_val51 = hv_NumImages;
        HTuple step_val51 = 1;
        for (hv_ImageIndex=1; hv_ImageIndex.Continue(end_val51, step_val51); hv_ImageIndex += step_val51)
        {
            SelectObj(ho_Image, &ho_ImageSelected, hv_ImageIndex);
            CountChannels(ho_ImageSelected, &hv_Channels);
            {
                HTuple end_val54 = hv_Channels;
                HTuple step_val54 = 1;
                for (hv_ChannelIndex=1; hv_ChannelIndex.Continue(end_val54, step_val54); hv_ChannelIndex += step_val54)
                {
                    AccessChannel(ho_ImageSelected, &ho_SelectedChannel, hv_ChannelIndex);
                    MinMaxGray(ho_SelectedChannel, ho_SelectedChannel, 0, &hv_MinGray, &hv_MaxGray,
                               &hv_Range);
                    Threshold(ho_SelectedChannel, &ho_LowerRegion, (hv_MinGray.TupleConcat(hv_LowerLimit)).TupleMin(),
                              hv_LowerLimit);
                    Threshold(ho_SelectedChannel, &ho_UpperRegion, hv_UpperLimit, (hv_UpperLimit.TupleConcat(hv_MaxGray)).TupleMax());
                    PaintRegion(ho_LowerRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_LowerLimit,
                                "fill");
                    PaintRegion(ho_UpperRegion, ho_SelectedChannel, &ho_SelectedChannel, hv_UpperLimit,
                                "fill");
                    if (0 != (int(hv_ChannelIndex==1)))
                    {
                        CopyObj(ho_SelectedChannel, &ho_ImageSelectedScaled, 1, 1);
                    }
                    else
                    {
                        AppendChannel(ho_ImageSelectedScaled, ho_SelectedChannel, &ho_ImageSelectedScaled
                                      );
                    }
                }
            }
            ConcatObj((*ho_ImageScaled), ho_ImageSelectedScaled, &(*ho_ImageScaled));
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Serialize a DLModelHandle with current meta information.
void HalxAI:: serialize_train_dl_model_intermediate (HTuple hv_DLModelHandle, HTuple hv_Epoch,
                                                     HTuple hv_EvaluationValueReduced, HTuple hv_Strategy, HTuple hv_TrainInfos, HTuple hv_EvaluationInfos,
                                                     HTuple *hv_FilenameModel, HTuple *hv_FilenameMetaData)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Type, hv_Basename, hv_Exception, hv_Epochs;
    HTuple  hv_Index, hv_MetaData;

    //
    //Serialize the model DLModelHandle with current meta information.
    //
    //We need the type of strategy used.
    GetDictTuple(hv_Strategy, "type", &hv_Type);

    //Get basename/default.
    try
    {
        GetDictTuple(hv_Strategy, "basename", &hv_Basename);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        if (0 != (int(hv_Type==HTuple("epochs"))))
        {
            hv_Basename = "model_at_epoch";
        }
        else
        {
            hv_Basename = hv_Type;
        }
    }
    //
    //If we serialize epochs and only one basename is given,
    //we need to add the current epoch to it.
    //If a basename has been specified for each epoch,
    //appending the current epoch is not necessary.
    if (0 != (int(hv_Type==HTuple("epochs"))))
    {
        GetDictTuple(hv_Strategy, "epochs", &hv_Epochs);
        if (0 != (int((hv_Basename.TupleLength())==(hv_Epochs.TupleLength()))))
        {
            TupleFindLast(hv_Epoch.TupleLessElem(hv_Epochs), 0, &hv_Index);
            hv_Basename = HTuple(hv_Basename[hv_Index]);
        }
        else
        {
            hv_Basename = (hv_Basename+"_")+(hv_Epoch.TupleString(".2f"));
        }
    }
    //
    //Filenames.
    (*hv_FilenameModel) = hv_Basename+".hdl";
    (*hv_FilenameMetaData) = hv_Basename+"_info.hdict";
    //
    //Metadata.
    CreateDict(&hv_MetaData);
    SetDictTuple(hv_MetaData, "train_infos", hv_TrainInfos);
    SetDictTuple(hv_MetaData, "evaluation_infos", hv_EvaluationInfos);
    SetDictTuple(hv_MetaData, "epoch", hv_Epoch);
    if (0 != (int((hv_EvaluationValueReduced.TupleLength())>=1)))
    {
        SetDictTuple(hv_MetaData, "best_value", hv_EvaluationValueReduced);
    }
    //
    //Write files.
    WriteDlModel(hv_DLModelHandle, (*hv_FilenameModel));
    WriteDict(hv_MetaData, (*hv_FilenameMetaData), HTuple(), HTuple());
    return;
}

// Chapter: Graphics / Text
// Short Description: Set font independent of OS
void HalxAI:: set_display_font (HTuple hv_WindowHandle, HTuple hv_Size, HTuple hv_Font, HTuple hv_Bold,
                                HTuple hv_Slant)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_OS, hv_Fonts, hv_Style, hv_Exception;
    HTuple  hv_AvailableFonts, hv_Fdx, hv_Indices;

    //This procedure sets the text font of the current window with
    //the specified attributes.
    //
    //Input parameters:
    //WindowHandle: The graphics window for which the font will be set
    //Size: The font size. If Size=-1, the default of 16 is used.
    //Bold: If set to 'true', a bold font is used
    //Slant: If set to 'true', a slanted font is used
    //
    GetSystem("operating_system", &hv_OS);
    if (0 != (HTuple(int(hv_Size==HTuple())).TupleOr(int(hv_Size==-1))))
    {
        hv_Size = 16;
    }
    if (0 != (int((hv_OS.TupleSubstr(0,2))==HTuple("Win"))))
    {
        //Restore previous behavior
        hv_Size = (1.13677*hv_Size).TupleInt();
    }
    else
    {
        hv_Size = hv_Size.TupleInt();
    }
    if (0 != (int(hv_Font==HTuple("Courier"))))
    {
        hv_Fonts.Clear();
        hv_Fonts[0] = "Courier";
        hv_Fonts[1] = "Courier 10 Pitch";
        hv_Fonts[2] = "Courier New";
        hv_Fonts[3] = "CourierNew";
        hv_Fonts[4] = "Liberation Mono";
    }
    else if (0 != (int(hv_Font==HTuple("mono"))))
    {
        hv_Fonts.Clear();
        hv_Fonts[0] = "Consolas";
        hv_Fonts[1] = "Menlo";
        hv_Fonts[2] = "Courier";
        hv_Fonts[3] = "Courier 10 Pitch";
        hv_Fonts[4] = "FreeMono";
        hv_Fonts[5] = "Liberation Mono";
    }
    else if (0 != (int(hv_Font==HTuple("sans"))))
    {
        hv_Fonts.Clear();
        hv_Fonts[0] = "Luxi Sans";
        hv_Fonts[1] = "DejaVu Sans";
        hv_Fonts[2] = "FreeSans";
        hv_Fonts[3] = "Arial";
        hv_Fonts[4] = "Liberation Sans";
    }
    else if (0 != (int(hv_Font==HTuple("serif"))))
    {
        hv_Fonts.Clear();
        hv_Fonts[0] = "Times New Roman";
        hv_Fonts[1] = "Luxi Serif";
        hv_Fonts[2] = "DejaVu Serif";
        hv_Fonts[3] = "FreeSerif";
        hv_Fonts[4] = "Utopia";
        hv_Fonts[5] = "Liberation Serif";
    }
    else
    {
        hv_Fonts = hv_Font;
    }
    hv_Style = "";
    if (0 != (int(hv_Bold==HTuple("true"))))
    {
        hv_Style += HTuple("Bold");
    }
    else if (0 != (int(hv_Bold!=HTuple("false"))))
    {
        hv_Exception = "Wrong value of control parameter Bold";
        throw HException(hv_Exception);
    }
    if (0 != (int(hv_Slant==HTuple("true"))))
    {
        hv_Style += HTuple("Italic");
    }
    else if (0 != (int(hv_Slant!=HTuple("false"))))
    {
        hv_Exception = "Wrong value of control parameter Slant";
        throw HException(hv_Exception);
    }
    if (0 != (int(hv_Style==HTuple(""))))
    {
        hv_Style = "Normal";
    }
    QueryFont(hv_WindowHandle, &hv_AvailableFonts);
    hv_Font = "";
    {
        HTuple end_val48 = (hv_Fonts.TupleLength())-1;
        HTuple step_val48 = 1;
        for (hv_Fdx=0; hv_Fdx.Continue(end_val48, step_val48); hv_Fdx += step_val48)
        {
            hv_Indices = hv_AvailableFonts.TupleFind(HTuple(hv_Fonts[hv_Fdx]));
            if (0 != (int((hv_Indices.TupleLength())>0)))
            {
                if (0 != (int(HTuple(hv_Indices[0])>=0)))
                {
                    hv_Font = HTuple(hv_Fonts[hv_Fdx]);
                    break;
                }
            }
        }
    }
    if (0 != (int(hv_Font==HTuple(""))))
    {
        throw HException("Wrong value of control parameter Font");
    }
    hv_Font = (((hv_Font+"-")+hv_Style)+"-")+hv_Size;
    SetFont(hv_WindowHandle, hv_Font);
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Split rectangle2 into a number of rectangles.
void HalxAI:: split_rectangle2 (HTuple hv_Row, HTuple hv_Column, HTuple hv_Phi, HTuple hv_Length1,
                                HTuple hv_Length2, HTuple hv_NumSplits, HTuple *hv_SplitRow, HTuple *hv_SplitColumn,
                                HTuple *hv_SplitPhi, HTuple *hv_SplitLength1Out, HTuple *hv_SplitLength2Out)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_SplitLength, hv_TRow, hv_TCol, hv_HomMat2D;

    if (0 != (int(hv_NumSplits>0)))
    {
        hv_SplitLength = hv_Length1/(hv_NumSplits.TupleReal());
        //Assume center (0,0), transform afterwards.
        hv_TRow = HTuple(hv_NumSplits,0.0);
        hv_TCol = ((-hv_Length1)+hv_SplitLength)+((HTuple::TupleGenSequence(0,hv_NumSplits-1,1)*2)*hv_SplitLength);
        HomMat2dIdentity(&hv_HomMat2D);
        HomMat2dRotate(hv_HomMat2D, hv_Phi, 0, 0, &hv_HomMat2D);
        HomMat2dTranslate(hv_HomMat2D, hv_Row, hv_Column, &hv_HomMat2D);
        (*hv_SplitLength1Out) = HTuple(hv_NumSplits,hv_SplitLength);
        (*hv_SplitLength2Out) = HTuple(hv_NumSplits,hv_Length2);
        (*hv_SplitPhi) = HTuple(hv_NumSplits,hv_Phi);
        AffineTransPoint2d(hv_HomMat2D, hv_TRow, hv_TCol, &(*hv_SplitRow), &(*hv_SplitColumn));
    }
    else
    {
        throw HException("Number of splits must be greater than 0.");
    }
    return;
}

// Chapter: System / Operating System
// Short Description: Create a formatted string of a time span.
void HalxAI:: timespan_string (HTuple hv_TotalSeconds, HTuple hv_Format, HTuple *hv_TimeString)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Seconds, hv_TotalMinutes, hv_Minutes;
    HTuple  hv_TotalHours, hv_Hours, hv_Days;

    //
    //This procedure creates a readable representation of a time span
    //given the elapsed time in seconds.
    //
    //Ensure that the input is an integer.
    hv_TotalSeconds = hv_TotalSeconds.TupleInt();
    //
    hv_Seconds = hv_TotalSeconds%60;
    //
    hv_TotalMinutes = hv_TotalSeconds/60;
    hv_Minutes = hv_TotalMinutes%60;
    //
    hv_TotalHours = hv_TotalSeconds/3600;
    hv_Hours = hv_TotalHours%24;
    //
    hv_Days = hv_TotalSeconds/86400;
    //
    if (0 != (int(hv_Format==HTuple("auto"))))
    {
        //Print the highest non-zero unit and all remaining sub-units.
        if (0 != (int(hv_Days>0)))
        {
            (*hv_TimeString) = (((((((hv_Days.TupleString("d"))+"d ")+(hv_Hours.TupleString("d")))+"h ")+(hv_Minutes.TupleString("d")))+"m ")+(hv_Seconds.TupleString("d")))+"s";
        }
        else if (0 != (int(hv_Hours>0)))
        {
            (*hv_TimeString) = (((((hv_Hours.TupleString("d"))+"h ")+(hv_Minutes.TupleString("d")))+"m ")+(hv_Seconds.TupleString("d")))+"s";
        }
        else if (0 != (int(hv_Minutes>0)))
        {
            (*hv_TimeString) = (((hv_Minutes.TupleString("d"))+"m ")+(hv_Seconds.TupleString("d")))+"s";
        }
        else
        {
            (*hv_TimeString) = (hv_Seconds.TupleString("d"))+"s";
        }
    }
    else if (0 != (int(hv_Format==HTuple("top1"))))
    {
        //Print the highest non-zero unit.
        if (0 != (int(hv_Days>0)))
        {
            (*hv_TimeString) = (hv_Days.TupleString("d"))+"d";
        }
        else if (0 != (int(hv_Hours>0)))
        {
            (*hv_TimeString) = (hv_Hours.TupleString("d"))+"h";
        }
        else if (0 != (int(hv_Minutes>0)))
        {
            (*hv_TimeString) = (hv_Minutes.TupleString("d"))+"m";
        }
        else
        {
            (*hv_TimeString) = (hv_Seconds.TupleString("d"))+"s";
        }
    }
    else if (0 != (int(hv_Format==HTuple("top2"))))
    {
        //Print the highest non-zero unit and the following sub-unit.
        if (0 != (int(hv_Days>0)))
        {
            (*hv_TimeString) = (((hv_Days.TupleString("d"))+"d ")+(hv_Hours.TupleString("d")))+"h";
        }
        else if (0 != (int(hv_Hours>0)))
        {
            (*hv_TimeString) = (((hv_Hours.TupleString("d"))+"h ")+(hv_Minutes.TupleString("d")))+"m";
        }
        else if (0 != (int(hv_Minutes>0)))
        {
            (*hv_TimeString) = (((hv_Minutes.TupleString("d"))+"m ")+(hv_Seconds.TupleString("d")))+"s";
        }
        else
        {
            (*hv_TimeString) = (hv_Seconds.TupleString("d"))+"s";
        }
    }
    else if (0 != (int(hv_Format==HTuple("dhms"))))
    {
        //Print a Days-Hours-Minutes-Seconds string.
        (*hv_TimeString) = (((((((hv_Days.TupleString("d"))+"d ")+(hv_Hours.TupleString("d")))+"h ")+(hv_Minutes.TupleString("d")))+"m ")+(hv_Seconds.TupleString("d")))+"s";
    }
    else if (0 != (int(hv_Format==HTuple("hms"))))
    {
        //Print a Hours-Minutes-Seconds string, where hours can be >= 24.
        (*hv_TimeString) = (((((hv_TotalHours.TupleString("d"))+"h ")+(hv_Minutes.TupleString("d")))+"m ")+(hv_Seconds.TupleString("d")))+"s";
    }
    else
    {
        throw HException("Unknown format string.");
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Train a deep-learning-based model on a dataset.
void HalxAI:: train_dl_model (HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_TrainParam,
                              HTuple hv_StartEpoch, HTuple *hv_TrainResults, HTuple *hv_TrainInfos, HTuple *hv_EvaluationInfos)
{
    // Local control variables
    HTuple  hv_ModelType, hv_DLSamples, hv_TrainSampleIndices;
    HTuple  hv_NumTrainSamples, hv_EvaluationComparisonKeyExist;
    HTuple  hv_EvaluationComparisonKeys, hv_EvaluationOptimizationMethod;
    HTuple  hv_NumEpochs, hv_SeedRand, hv_SampleIndicesTrainRaw;
    HTuple  hv_Index, hv_Shuffled, hv_SampleSeedsTrainRaw, hv_BatchSize;
    HTuple  hv_EvaluateBeforeTraining, hv_ChangeStrategyData;
    HTuple  hv_SerializationData, hv_DisplayData, hv_DisplayEnabled;
    HTuple  hv_DisplayPreviewInitialized, hv_DisplayEvaluationEpochs;
    HTuple  hv_DisplayValidationEvaluationValues, hv_DisplayTrainEvaluationValues;
    HTuple  hv_DisplayLossEpochs, hv_DisplayLoss, hv_DisplayLearningRates;
    HTuple  hv_TrainResultsRestored, hv_StartTime, hv_ThresholdInformation;
    HTuple  hv_FirstIteration, hv_Epoch, hv_Iteration, hv_NumIterationsPerEpoch;
    HTuple  hv_BatchSizeDevice, hv_BatchSizeMultiplier, hv_BatchSizeModel;
    HTuple  hv_NumIterations, hv_SampleIndicesTrain, hv_IterationEvaluateOnly;
    HTuple  hv_BatchStart, hv_BatchEnd, hv_BatchIndices, hv_DLSampleBatch;
    HTuple  hv_AugmentationParam, hv_TrainResult, hv_EvaluationIntervalEpochs;
    HTuple  hv_EvaluationInterval, hv_ValidationEvaluationResult;
    HTuple  hv_TrainEvaluationResult, hv_DisplayParam, hv_SelectPercentageTrainSamples;
    HTuple  hv_EvaluationParam, hv__, hv_TrainEvaluationRatio;
    HTuple  hv_NumTrainEvaluationSampleIndices, hv_TrainEvaluationSampleIndices;
    HTuple  hv_Exception, hv_EvaluationInfo, hv_Valuevalidation;
    HTuple  hv_ValueTrain, hv_TrainInfoUpdateIntervalSeconds;
    HTuple  hv_LastUpdate, hv_Seconds, hv_NumSamplesMeanLoss;
    HTuple  hv_TrainInfo, hv_UpdateTime, hv_EpochsStatus, hv_MeanLoss;
    HTuple  hv_DisplayLearningRate, hv_NumImages, hv_UpdateImagesIntervalEpochs;
    HTuple  hv_UpdateImagesInterval, hv_WindowImages, hv_FirstCall;
    HTuple  hv_GenParamTiled, hv_TrainParamAnomaly, hv_WindowHandleInfo;
    HTuple  hv___Tmp_Ctrl_Dict_Init_0, hv___Tmp_Ctrl_0;

    //StartEpoch is always 0.
    //
    //╖╡╗╪╚¤╕Ў╫╓╡фг║
    //╕├╣¤│╠╖╡╗╪╚¤╕Ў╫╓╡фг║
    //- TrainResultsг║├┐┤╬╡№┤·╡─train_dl_model_batch╖╡╗╪╡─╩╒╝п╜с╣√,╢╘╙┌б░anomaly_detectionб▒└р╨═╡──г╨═г║╫ю╓╒error║═╫ю╓╒epochбг
    //- TrainInfoг║╩╒╝п╡─╤╡┴╖╜°╢╚╨┼╧вбг ╢╘╙┌б░anomaly_detectionб▒└р╨═╡──г╨═гм╕├╫╓╡ф╬к┐╒бг
    //-EvaluationInfosг║╤╡┴╖╞┌╝ф╩╒╝п╡─╞└╣└╜с╣√бг ╢╘╙┌б░anomaly_detectionб▒└р╨═╡──г╨═гм╕├╫╓╡ф╬к┐╒бг

    //Get the model type.
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
    {
        throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
    }
    //
    //Get the samples for training.
    GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
    find_dl_samples(hv_DLSamples, "split", "train", "match", &hv_TrainSampleIndices);
    hv_NumTrainSamples = hv_TrainSampleIndices.TupleLength();
    //
    //Check inconsistent training parameters.
    check_train_dl_model_params(hv_DLDataset, hv_DLModelHandle, hv_NumTrainSamples,
                                hv_StartEpoch, hv_TrainParam);
    //
    //Determine evaluation optimization method.
    GetDictParam(hv_TrainParam, "key_exists", "evaluation_comparison_keys", &hv_EvaluationComparisonKeyExist);
    if (0 != hv_EvaluationComparisonKeyExist)
    {
        GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
        get_dl_evaluation_optimization_method(hv_EvaluationComparisonKeys, &hv_EvaluationOptimizationMethod);
    }
    //
    if (0 != (int(hv_ModelType!=HTuple("anomaly_detection"))))
    {
        //
        //Check if training is required.
        GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
        if (0 != (hv_StartEpoch.TupleIsNumber()))
        {
            if (0 != (int(hv_StartEpoch>=hv_NumEpochs)))
            {
                //Nothing to do.
                return;
            }
        }
        //

        GetDictTuple(hv_TrainParam, "seed_rand", &hv_SeedRand);
        if (0 != (int((hv_SeedRand.TupleLength())>0)))
        {
            //╬к▒г╓д╕┤╧╓╙ыbenchmark═ъ╚л╥╗╓┬гм╨ш╥к╔ш╓├cudnn_deterministic=true
            //SetSystem('cudnn_deterministic', 'true')
            SetSystem("seed_rand", hv_SeedRand);
        }
        //
        //shuffle
        hv_SampleIndicesTrainRaw = HTuple();
        {
            HTuple end_val63 = (hv_NumEpochs.TupleCeil())-1;
            HTuple step_val63 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val63, step_val63); hv_Index += step_val63)
            {
                tuple_shuffle(hv_TrainSampleIndices, &hv_Shuffled);
                hv_SampleIndicesTrainRaw = hv_SampleIndicesTrainRaw.TupleConcat(hv_Shuffled);
            }
        }
        //
        //Generate a random seed pool for the whole training independent of batch size.
        hv_SampleSeedsTrainRaw = HTuple(((HTuple(2).TuplePow(31))-1)*HTuple::TupleRand(hv_SampleIndicesTrainRaw.TupleLength())).TupleInt();
        //
        //│ї╩╝╗пtrain│м▓╬╩¤/Initialize the variables for the training.
        //
        //╩╣╙├╬▐╨з╓╡│ї╩╝╗п┼·┴┐┤є╨бгм╥╘▒у while ╤н╗╖╓▒╜╙│ї╩╝╗п╦∙╙╨╓╡бг
        hv_BatchSize = -1;
        //Initialize iteration overhead parameter to 0 or 1.
        //0: if no evaluation before training is performed
        //1: if evaluation before training is performed
        CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
        SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "true");
        hv_EvaluateBeforeTraining = (hv_TrainParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("evaluate_before_train","comp");
        hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
        //
        //│ї╩╝╗п lr╦е╝ї▓▀┬╘ ╧р╣╪▓╬╩¤/Initialize change strategies.
        init_train_dl_model_change_strategies(hv_TrainParam, &hv_ChangeStrategyData);
        init_train_dl_model_serialization_strategies(hv_TrainParam, &hv_SerializationData);

        //
        //┐╔╩╙╗п╥╗┬╔╫в╩═╡Ї//Initialize visualizations if enabled.
        dev_display_init_train_dl_model(hv_DLModelHandle, hv_TrainParam, &hv_DisplayData);
        GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
        hv_DisplayPreviewInitialized = 0;


        //
        //╓╪╨┬╤╡┴╖╗Є╝╠│╨╤╡┴╖//Initialize parameters to start new or resume previous training.
        restore_dl_train_info_for_resuming(hv_StartEpoch, hv_SerializationData, hv_TrainParam,
                                           hv_DisplayData, &(*hv_EvaluationInfos), &(*hv_TrainInfos), &hv_DisplayEvaluationEpochs,
                                           &hv_DisplayValidationEvaluationValues, &hv_DisplayTrainEvaluationValues,
                                           &hv_DisplayLossEpochs, &hv_DisplayLoss, &hv_DisplayLearningRates, &hv_TrainResultsRestored,
                                           &hv_StartEpoch);
        //
        //Start time for measurement of elapsed training time.
        CountSeconds(&hv_StartTime);
        //
        //In case of a 'gc_anomaly_detection' model it is necessary to normalize
        //the model outputs before training.
        if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            if (0 != hv_DisplayEnabled)
            {
                hv_ThresholdInformation.Clear();
                hv_ThresholdInformation[0] = "Preparing the model for training";
                hv_ThresholdInformation[1] = "by analyzing image statistics...";
                if (HDevWindowStack::IsOpen())
                    ClearWindow(HDevWindowStack::GetActive());
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ThresholdInformation, "window",
                             "top", "left", "black", "box", "false");
                CountSeconds(&hv___Tmp_Ctrl_0);
                SetDictTuple(hv_DisplayData, "last_update", hv___Tmp_Ctrl_0);
            }
            normalize_dl_gc_anomaly_features(hv_DLDataset, hv_DLModelHandle, HTuple());
        }
        //
        //The while loop needs to know if it is the very first iteration.
        hv_FirstIteration = 1;
        while (true)
        {
            //Do some initializations only for the very first iteration.
            if (0 != hv_FirstIteration)
            {
                //Jump to StartEpoch (Default: 0 but it could be used to resume training at given StartIteration).
                hv_Epoch = hv_StartEpoch;
            }
            else
            {
                hv_Epoch = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
            }
            //
            //Update any parameters based on strategies.
            update_train_dl_model_change_strategies(hv_DLModelHandle, hv_ChangeStrategyData,
                                                    hv_Epoch);
            //
            //Check if the current batch size and total model batch size differ.
            GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
            GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
            hv_BatchSizeModel = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
            //
            if (0 != (HTuple(int(hv_BatchSize!=hv_BatchSizeModel)).TupleOr(hv_FirstIteration)))
            {
                //Set the current value.
                hv_BatchSize = hv_BatchSizeModel;
                //Now, we compute all values which are related to the batch size of the model.
                //That way, the batch_size can be changed during the training without issues.
                //All inputs/outputs/visualizations are based on epochs.
                //
                //Calculate total number of iterations.
                hv_NumIterationsPerEpoch = ((hv_NumTrainSamples/(hv_BatchSize.TupleReal())).TupleFloor()).TupleInt();
                hv_NumIterations = (hv_NumIterationsPerEpoch*hv_NumEpochs).TupleInt();
                //Select those indices that fit into the batch size.
                hv_SampleIndicesTrain = hv_SampleIndicesTrainRaw.TupleSelectRange(0,(hv_NumIterations*hv_BatchSize)-1);
                //The TrainResults tuple will be updated every iteration.
                //Hence, we initialize it as a constant tuple for speedup.
                //It is based on the iterations and hence cannot be reused if the batch size changes.
                TupleGenConst(hv_NumIterations, -1, &(*hv_TrainResults));
                if (0 != (hv_FirstIteration.TupleNot()))
                {
                    hv_Iteration = (((hv_Epoch.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
                    hv_Epoch = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
                }
            }
            //
            //In the first iteration do some initializations.
            if (0 != hv_FirstIteration)
            {
                //Jump to StartEpoch (Default: 0 but it could be used to resume training at given StartIteration).
                hv_Iteration = (((hv_StartEpoch.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
                hv_FirstIteration = 0;
                if (0 != (int(((hv_Iteration*hv_BatchSize)+hv_BatchSize)>(hv_SampleIndicesTrain.TupleLength()))))
                {
                    hv_Iteration = hv_NumIterations-1;
                    break;
                }
                if (0 != (HTuple(int(hv_StartEpoch>0.0)).TupleAnd(int((hv_TrainResultsRestored.TupleLength())>0))))
                {
                    //Overwrite the first train results.
                    if (0 != (int((hv_TrainResultsRestored.TupleLength())>hv_Iteration)))
                    {
                        hv_TrainResultsRestored = hv_TrainResultsRestored.TupleSelectRange((hv_TrainResultsRestored.TupleLength())-hv_Iteration,(hv_TrainResultsRestored.TupleLength())-1);
                    }
                    (*hv_TrainResults)[HTuple::TupleGenSequence(hv_Iteration-(hv_TrainResultsRestored.TupleLength()),hv_Iteration-1,1)] = hv_TrainResultsRestored;
                }
                //
                //Add an iteration before starting the training for the evaluation if specified.
                hv_IterationEvaluateOnly = hv_Iteration-1;
                hv_Iteration = hv_Iteration-hv_EvaluateBeforeTraining;
            }
            if (0 != (int(hv_Iteration>hv_IterationEvaluateOnly)))
            {
                //
                //Generate the sample batch indices.
                hv_BatchStart = hv_Iteration*hv_BatchSize;
                hv_BatchEnd = (hv_BatchStart+hv_BatchSize)-1;
                hv_BatchIndices = hv_SampleIndicesTrain.TupleSelectRange(hv_BatchStart,hv_BatchEnd);
                //
                //Set a random seed for the sample batch.
                SetSystem("seed_rand", HTuple(hv_SampleSeedsTrainRaw[hv_BatchEnd]));
                //
                //Read preprocessed samples.
                read_dl_samples(hv_DLDataset, hv_BatchIndices, &hv_DLSampleBatch);
                //
                //Augment samples based on train parameter.
                GetDictTuple(hv_TrainParam, "augmentation_param", &hv_AugmentationParam);
                augment_dl_samples(hv_DLSampleBatch, hv_AugmentationParam);
                //
                //Train the model on current batch.
                TrainDlModelBatch(hv_DLModelHandle, hv_DLSampleBatch, &hv_TrainResult);
                //
                //We store each train result.
                (*hv_TrainResults)[hv_Iteration] = hv_TrainResult;
            }
            //
            //Evaluation handling.
            GetDictTuple(hv_TrainParam, "evaluation_interval_epochs", &hv_EvaluationIntervalEpochs);
            hv_EvaluationInterval = ((hv_EvaluationIntervalEpochs*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
            hv_ValidationEvaluationResult = HTuple();
            hv_TrainEvaluationResult = HTuple();
            GetDictTuple(hv_DisplayData, "display_param", &hv_DisplayParam);
            //Get percentage of evaluated training samples from display parameters.
            GetDictTuple(hv_DisplayParam, "selected_percentage_train_samples", &hv_SelectPercentageTrainSamples);
            //
            //Evaluate the current model.
            if (0 != (int(hv_EvaluationInterval>0)))
            {
                //Evaluate the model at given intervals.
                if (0 != (HTuple(HTuple(HTuple(int(hv_EvaluationInterval==1)).TupleOr(HTuple(int((hv_Iteration%hv_EvaluationInterval)==0)).TupleAnd(int(hv_Iteration!=0)))).TupleOr(int(hv_Iteration==(hv_NumIterations-1)))).TupleOr(int(hv_Iteration==hv_IterationEvaluateOnly))))
                {
                    GetDictTuple(hv_TrainParam, "evaluation_param", &hv_EvaluationParam);
                    //Evaluate on validation split.
                    evaluate_dl_model(hv_DLDataset, hv_DLModelHandle, "split", "validation",
                                      hv_EvaluationParam, &hv_ValidationEvaluationResult, &hv__);
                    //Evaluate a subset of the train split.
                    hv_TrainEvaluationRatio = hv_SelectPercentageTrainSamples/100.0;
                    hv_NumTrainEvaluationSampleIndices = (hv_TrainEvaluationRatio*(hv_TrainSampleIndices.TupleLength())).TupleInt();
                    if (0 != (int(hv_NumTrainEvaluationSampleIndices>0)))
                    {
                        tuple_shuffle(hv_TrainSampleIndices, &hv_TrainEvaluationSampleIndices);
                        //It might happen that the subset is too small for evaluation.
                        try
                        {
                            evaluate_dl_model(hv_DLDataset, hv_DLModelHandle, "sample_indices",
                                              hv_TrainEvaluationSampleIndices.TupleSelectRange(0,hv_NumTrainEvaluationSampleIndices-1),
                                              hv_EvaluationParam, &hv_TrainEvaluationResult, &hv__);
                        }
                        // catch (Exception)
                        catch (HException &HDevExpDefaultException)
                        {
                            HDevExpDefaultException.ToHTuple(&hv_Exception);
                        }
                    }
                    CreateDict(&hv_EvaluationInfo);
                    SetDictTuple(hv_EvaluationInfo, "epoch", hv_Epoch);
                    SetDictTuple(hv_EvaluationInfo, "iteration", hv_Iteration+hv_EvaluateBeforeTraining);
                    SetDictTuple(hv_EvaluationInfo, "result", hv_ValidationEvaluationResult);
                    SetDictTuple(hv_EvaluationInfo, "result_train", hv_TrainEvaluationResult);
                    (*hv_EvaluationInfos) = (*hv_EvaluationInfos).TupleConcat(hv_EvaluationInfo);
                    if (0 != hv_DisplayEnabled)
                    {
                        GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
                        reduce_dl_evaluation_result(hv_ValidationEvaluationResult, hv_EvaluationComparisonKeys,
                                                    &hv_Valuevalidation, &hv__);
                        reduce_dl_evaluation_result(hv_TrainEvaluationResult, hv_EvaluationComparisonKeys,
                                                    &hv_ValueTrain, &hv__);
                        hv_DisplayValidationEvaluationValues = hv_DisplayValidationEvaluationValues.TupleConcat(hv_Valuevalidation);
                        hv_DisplayTrainEvaluationValues = hv_DisplayTrainEvaluationValues.TupleConcat(hv_ValueTrain);
                        hv_DisplayEvaluationEpochs = hv_DisplayEvaluationEpochs.TupleConcat(hv_Epoch);
                    }
                }
            }
            if (0 != (int(hv_Iteration>hv_IterationEvaluateOnly)))
            {
                //
                //Check if an update is needed.
                GetDictTuple(hv_TrainParam, "update_interval_seconds", &hv_TrainInfoUpdateIntervalSeconds);
                GetDictTuple(hv_DisplayData, "last_update", &hv_LastUpdate);
                CountSeconds(&hv_Seconds);
                //Check for next update (enough time has elapsed or last iteration).
                if (0 != (HTuple(HTuple(int(((hv_LastUpdate-hv_Seconds).TupleAbs())>hv_TrainInfoUpdateIntervalSeconds)).TupleOr(int(hv_Iteration==(hv_NumIterations-1)))).TupleOr(int((hv_ValidationEvaluationResult.TupleLength())>0))))
                {
                    SetDictTuple(hv_DisplayData, "last_update", hv_Seconds);
                    GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
                    GetDictTuple(hv_TrainParam, "num_samples_mean_loss", &hv_NumSamplesMeanLoss);
                    collect_train_dl_model_info(hv_DLModelHandle, (*hv_TrainResults), (*hv_EvaluationInfos),
                                                hv_EvaluationComparisonKeys, hv_EvaluationOptimizationMethod, hv_Iteration,
                                                hv_NumIterations, hv_NumIterationsPerEpoch, hv_NumSamplesMeanLoss,
                                                &hv_TrainInfo);

                    SetDictTuple(hv_TrainInfo, "start_epoch", hv_StartEpoch);
                    SetDictTuple(hv_TrainInfo, "start_time", hv_StartTime);
                    CountSeconds(&hv_UpdateTime);
                    SetDictTuple(hv_TrainInfo, "time_elapsed", hv_UpdateTime-hv_StartTime);
                    (*hv_TrainInfos) = (*hv_TrainInfos).TupleConcat(hv_TrainInfo);
                    //
                    //Display handling.
                    if (0 != hv_DisplayEnabled)
                    {
                        GetDictTuple(hv_TrainInfo, "epoch", &hv_EpochsStatus);
                        hv_DisplayLossEpochs = hv_DisplayLossEpochs.TupleConcat(hv_EpochsStatus);
                        GetDictTuple(hv_TrainInfo, "mean_loss", &hv_MeanLoss);
                        hv_DisplayLoss = hv_DisplayLoss.TupleConcat(hv_MeanLoss);
                        GetDlModelParam(hv_DLModelHandle, "learning_rate", &hv_DisplayLearningRate);
                        hv_DisplayLearningRates = hv_DisplayLearningRates.TupleConcat(hv_DisplayLearningRate);
                        dev_display_update_train_dl_model(hv_TrainParam, hv_DisplayData, hv_TrainInfo,
                                                          hv_DisplayLossEpochs, hv_DisplayLoss, hv_DisplayLearningRates, hv_DisplayEvaluationEpochs,
                                                          hv_DisplayValidationEvaluationValues, hv_DisplayTrainEvaluationValues);
                    }
                }
                //
                //Image result preview handling.
                if (0 != hv_DisplayEnabled)
                {
                    //Show interim results for test images.
                    //For models of type 'gc_anomaly_detection' this is not possible.
                    GetDictTuple(hv_DisplayParam, "num_images", &hv_NumImages);
                    if (0 != (int(hv_NumImages>0)))
                    {
                        //Check if the image preview has to be updated.
                        GetDictTuple(hv_DisplayParam, "update_images_interval_epochs", &hv_UpdateImagesIntervalEpochs);
                        hv_UpdateImagesInterval = (((hv_UpdateImagesIntervalEpochs.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
                        if (0 != (int(hv_UpdateImagesInterval==0)))
                        {
                            hv_UpdateImagesInterval = 1;
                        }
                        if (0 != (HTuple(int((hv_Iteration%hv_UpdateImagesInterval)==0)).TupleOr(hv_DisplayPreviewInitialized.TupleNot())))
                        {
                            GetDictTuple(hv_DisplayData, "window_images", &hv_WindowImages);
                            hv_FirstCall = int((hv_WindowImages.TupleLength())==0);
                            GetDictTuple(hv_DisplayParam, "tiled_param", &hv_GenParamTiled);
                            //
                            dev_display_dl_data_tiled(hv_DLDataset, hv_DLModelHandle, hv_NumImages,
                                                      "validation", hv_GenParamTiled, hv_WindowImages, &hv_WindowImages);
                            //
                            if (0 != hv_FirstCall)
                            {
                                SetDictTuple(hv_DisplayData, "window_images", hv_WindowImages);
                                set_display_font(hv_WindowImages, 12, "mono", "true", "false");
                            }
                            dev_display_tiled_legend(hv_WindowImages, hv_GenParamTiled);
                            hv_DisplayPreviewInitialized = 1;
                        }
                    }
                }
                //
                //Serialization handling.
                update_train_dl_model_serialization(hv_TrainParam, hv_SerializationData,
                                                    hv_Iteration, hv_NumIterations, hv_Epoch, hv_ValidationEvaluationResult,
                                                    hv_EvaluationOptimizationMethod, hv_DLModelHandle, (*hv_TrainInfos),
                                                    (*hv_EvaluationInfos));
            }
            //
            //Check for end of training.
            if (0 != (int(hv_Iteration>=(hv_NumIterations-1))))
            {
                break;
            }
            if (0 != (int(hv_Iteration==hv_IterationEvaluateOnly)))
            {
                hv_EvaluateBeforeTraining = 0;
            }
            //
            //Continue with next iteration.
            hv_Iteration += 1;
        }
        //
    }
    else
    {
        //Case for models of type 'anomaly_detection'.
        //
        //Read the training samples.
        read_dl_samples(hv_DLDataset, hv_TrainSampleIndices, &hv_DLSamples);
        //
        //Get training parameters for anomaly detection.
        GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
        //
        //Display information about training.
        GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
        GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
        if (0 != hv_DisplayEnabled)
        {
            dev_display_train_info_anomaly_detection(hv_TrainParam, &hv_WindowHandleInfo);
        }
        //
        //Train the model.
        TrainDlModelAnomalyDataset(hv_DLModelHandle, hv_DLSamples, hv_TrainParamAnomaly,
                                   &(*hv_TrainResults));
        //
        //Initialize TrainInfos and EvaluationInfos
        (*hv_TrainInfos) = HTuple();
        (*hv_EvaluationInfos) = HTuple();
        //
        //Close window with information about the training.
        if (0 != hv_DisplayEnabled)
        {
            HDevWindowStack::SetActive(hv_WindowHandleInfo);
        }
    }
    //
    return;
}

// Chapter: Tuple / Element Order
// Short Description: Sort the elements of a tuple randomly.
void HalxAI:: tuple_shuffle (HTuple hv_Tuple, HTuple *hv_Shuffled)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShuffleIndices;

    //This procedure sorts the input tuple randomly.
    //
    if (0 != (int((hv_Tuple.TupleLength())>0)))
    {
        //Create a tuple of random numbers,
        //sort this tuple, and return the indices
        //of this sorted tuple.
        hv_ShuffleIndices = HTuple::TupleRand(hv_Tuple.TupleLength()).TupleSortIndex();
        //Assign the elements of Tuple
        //to these random positions.
        (*hv_Shuffled) = HTuple(hv_Tuple[hv_ShuffleIndices]);
    }
    else
    {
        //If the input tuple is empty,
        //an empty tuple should be returned.
        (*hv_Shuffled) = HTuple();
    }
    return;
}

// Chapter: Tuple / Arithmetic
// Short Description: Calculate the cross product of two vectors of length 3.
void HalxAI:: tuple_vector_cross_product (HTuple hv_V1, HTuple hv_V2, HTuple *hv_VC)
{

    // Local iconic variables

    //The caller must ensure that the length of both input vectors is 3
    (*hv_VC) = (HTuple(hv_V1[1])*HTuple(hv_V2[2]))-(HTuple(hv_V1[2])*HTuple(hv_V2[1]));
    (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[2])*HTuple(hv_V2[0]))-(HTuple(hv_V1[0])*HTuple(hv_V2[2])));
    (*hv_VC) = (*hv_VC).TupleConcat((HTuple(hv_V1[0])*HTuple(hv_V2[1]))-(HTuple(hv_V1[1])*HTuple(hv_V2[0])));
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Update RunningMeasures by evaluating Samples and corresponding Results.
void HalxAI:: update_running_evaluation_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams,
                                                  HTuple hv_RunningMeasures)
{

    // Local control variables
    HTuple  hv_EvaluationType;

    //
    //This procedure updates the running measures depending on the evaluation type.
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
    {
        update_running_image_anomaly_measures(hv_Samples, hv_Results, hv_EvalParams,
                                              hv_RunningMeasures);
    }
    else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
    {
        update_running_image_classification_measures(hv_Samples, hv_Results, hv_EvalParams,
                                                     hv_RunningMeasures);
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("detection"))).TupleOr(int(hv_EvaluationType==HTuple("ocr_detection")))))
    {
        update_running_instance_measures(hv_Samples, hv_Results, hv_EvalParams, hv_RunningMeasures);
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("segmentation"))).TupleOr(int(hv_EvaluationType==HTuple("3d_gripping_point_detection")))))
    {
        update_running_pixel_measures(hv_Samples, hv_Results, hv_EvalParams, hv_RunningMeasures);
        if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
        {
            update_running_region_measures(hv_Samples, hv_Results, hv_EvalParams, hv_RunningMeasures);
            update_running_gripping_point_measures(hv_Samples, hv_Results, hv_EvalParams,
                                                   hv_RunningMeasures);
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
    {
        update_running_ocr_recognition_measures(hv_Samples, hv_Results, hv_EvalParams,
                                                hv_RunningMeasures);
    }
    //
    return;
}

// Chapter: 3D Matching / 3D Gripping Point Detection
// Short Description: Update running measures for 3D gripping points.
void HalxAI:: update_running_gripping_point_measures (HTuple hv_Samples, HTuple hv_Results,
                                                      HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

    // Local iconic variables
    HObject  ho_AnnotationRegion, ho_GTRegions, ho_GTRegion;

    // Local control variables
    HTuple  hv_Index, hv_Sample, hv_Result, hv_NumGTRegions;
    HTuple  hv_GrippingPointFound, hv_IndexGTRegions, hv_TP;
    HTuple  hv_FP, hv_IndexGrippingPoint, hv_GrippingPoint;
    HTuple  hv_GPFound, hv_NumGrippingPointFound;

    if (0 != (int((HTuple((hv_EvalParams.TupleGetDictTuple("measures")).TupleRegexpSelect("gripping_point_.*|all")).TupleLength())>0)))
    {
        {
            HTuple end_val1 = (hv_Samples.TupleLength())-1;
            HTuple step_val1 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val1, step_val1); hv_Index += step_val1)
            {
                hv_Sample = HTuple(hv_Samples[hv_Index]);
                hv_Result = HTuple(hv_Results[hv_Index]);
                gen_dl_3d_gripping_points_and_poses(hv_Sample, hv_EvalParams.TupleGetDictTuple("gripping_point_params"),
                                                    hv_Result);
                Threshold(hv_Sample.TupleGetDictObject("segmentation_image"), &ho_AnnotationRegion,
                          HTuple((hv_EvalParams.TupleGetDictTuple("class_ids"))[0]), HTuple((hv_EvalParams.TupleGetDictTuple("class_ids"))[0]));
                Connection(ho_AnnotationRegion, &ho_GTRegions);
                CountObj(ho_GTRegions, &hv_NumGTRegions);
                //True positives: Only one gripping point
                //within a ground truth region is counted
                //as true positive. All additional points
                //witin the same ground truth region are
                //considered a false positive.
                //False negative: All ground truth regions
                //that do not contain at least one
                //gripping point are a false negative.
                hv_GrippingPointFound = HTuple((hv_Result.TupleGetDictTuple("gripping_points")).TupleLength(),0);
                {
                    HTuple end_val17 = hv_NumGTRegions;
                    HTuple step_val17 = 1;
                    for (hv_IndexGTRegions=1; hv_IndexGTRegions.Continue(end_val17, step_val17); hv_IndexGTRegions += step_val17)
                    {
                        SelectObj(ho_GTRegions, &ho_GTRegion, hv_IndexGTRegions);
                        hv_TP = 0.0;
                        hv_FP = 0.0;
                        {
                            HTuple end_val21 = ((hv_Result.TupleGetDictTuple("gripping_points")).TupleLength())-1;
                            HTuple step_val21 = 1;
                            for (hv_IndexGrippingPoint=0; hv_IndexGrippingPoint.Continue(end_val21, step_val21); hv_IndexGrippingPoint += step_val21)
                            {
                                hv_GrippingPoint = HTuple((hv_Result.TupleGetDictTuple("gripping_points"))[hv_IndexGrippingPoint]);
                                TestRegionPoint(ho_GTRegion, hv_GrippingPoint.TupleGetDictTuple("row"),
                                                hv_GrippingPoint.TupleGetDictTuple("column"), &hv_GPFound);
                                if (0 != hv_GPFound)
                                {
                                    if (0 != (int(hv_TP==0.0)))
                                    {
                                        hv_TP += 1.0;
                                    }
                                    else
                                    {
                                        hv_FP += 1.0;
                                    }
                                    hv_GrippingPointFound[hv_IndexGrippingPoint] = 1;
                                }
                            }
                        }
                        SetDictTuple(hv_RunningMeasures, "gp_tp", (hv_RunningMeasures.TupleGetDictTuple("gp_tp"))+hv_TP);
                        SetDictTuple(hv_RunningMeasures, "gp_fp", (hv_RunningMeasures.TupleGetDictTuple("gp_fp"))+hv_FP);
                        if (0 != (int(hv_TP==0.0)))
                        {
                            SetDictTuple(hv_RunningMeasures, "gp_fn", (hv_RunningMeasures.TupleGetDictTuple("gp_fn"))+1.0);
                        }
                    }
                }
                //All gripping points that have not been
                //found to lie within the ground truth
                //region are additional false positives.
                if (0 != (int((hv_GrippingPointFound.TupleLength())>0)))
                {
                    hv_NumGrippingPointFound = hv_GrippingPointFound.TupleSum();
                }
                else
                {
                    hv_NumGrippingPointFound = 0;
                }
                SetDictTuple(hv_RunningMeasures, "gp_fp", (hv_RunningMeasures.TupleGetDictTuple("gp_fp"))+((hv_GrippingPointFound.TupleLength())-hv_NumGrippingPointFound));
            }
        }
    }
    return;
}

// Chapter: Deep Learning / Anomaly Detection and Global Context Anomaly Detection
// Short Description: Update running measures for an anomaly detection or Global Context Anomaly Detection evaluation.
void HalxAI:: update_running_image_anomaly_measures (HTuple hv_Samples, HTuple hv_Results,
                                                     HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ImageIDs, hv_AnomalyLabelIDs, hv_AnomalyScores;
    HTuple  hv_SampleIndex, hv_Sample, hv_ImageID, hv_AnomalyLabelID;
    HTuple  hv_Result, hv_Keys, hv_AnomalyScoreKey, hv_AnomalyScore;

    //
    //This procedure updates the RunningMeasures for an evaluation for anomaly detection.
    //
    //These measures are stored in the dictionary RunningMeasures and
    //updated by incorporating the Results the model obtained for the Samples.
    //
    //
    //Get image ids.
    GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
    //Get anomaly label ids.
    GetDictTuple(hv_RunningMeasures, "anomaly_label_ids", &hv_AnomalyLabelIDs);
    //Get anomaly scores.
    GetDictTuple(hv_RunningMeasures, "anomaly_scores", &hv_AnomalyScores);
    //Loop over all samples and update running measures accordingly.
    {
        HTuple end_val14 = (hv_Samples.TupleLength())-1;
        HTuple step_val14 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val14, step_val14); hv_SampleIndex += step_val14)
        {
            hv_Sample = HTuple(hv_Samples[hv_SampleIndex]);
            GetDictTuple(hv_Sample, "image_id", &hv_ImageID);
            GetDictTuple(hv_Sample, "anomaly_label_id", &hv_AnomalyLabelID);
            hv_Result = HTuple(hv_Results[hv_SampleIndex]);
            GetDictParam(hv_Result, "keys", HTuple(), &hv_Keys);
            TupleRegexpSelect(hv_Keys, "anomaly_score.*", &hv_AnomalyScoreKey);
            //It is not expected that AnomalyScoreKey contains more than one item.
            //In case it unexpectedly does, we index it with [0].
            GetDictTuple(hv_Result, HTuple(hv_AnomalyScoreKey[0]), &hv_AnomalyScore);
            //
            hv_ImageIDs = hv_ImageIDs.TupleConcat(hv_ImageID);
            hv_AnomalyLabelIDs = hv_AnomalyLabelIDs.TupleConcat(hv_AnomalyLabelID);
            hv_AnomalyScores = hv_AnomalyScores.TupleConcat(hv_AnomalyScore);
        }
    }
    //
    //Set image ids in running measures.
    SetDictTuple(hv_RunningMeasures, "image_ids", hv_ImageIDs);
    //Set anomaly label ids in running measures.
    SetDictTuple(hv_RunningMeasures, "anomaly_label_ids", hv_AnomalyLabelIDs);
    //Set anomaly scores in running measures.
    SetDictTuple(hv_RunningMeasures, "anomaly_scores", hv_AnomalyScores);
    //
    return;
}

// Chapter: Deep Learning / Classification
// Short Description: Update running measures for an image classification evaluation.
void HalxAI:: update_running_image_classification_measures (HTuple hv_Samples, HTuple hv_Results,
                                                            HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_RegExpTopKError, hv_Measures, hv_K;
    HTuple  hv_M, hv_ComputeTopKError, hv_ImageIDs, hv_ImageLabelIDs;
    HTuple  hv_Top1Prediction, hv_TopKPredictionDicts, hv_Index;
    HTuple  hv_Sample, hv_ImageID, hv_ImageLabelID, hv_Result;
    HTuple  hv_PredictedClassIDs, hv_TopKPrediction, hv_TopKPredictionDict;

    //
    //This procedure updates the RunningMeasures for an evaluation for classification.
    //
    //To avoid HalxAI:: memory, only save first K predictions per sample.
    hv_RegExpTopKError = "top([0-9]+)_error";
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    hv_K = 1;
    {
        HTuple end_val7 = (hv_Measures.TupleLength())-1;
        HTuple step_val7 = 1;
        for (hv_M=0; hv_M.Continue(end_val7, step_val7); hv_M += step_val7)
        {
            hv_ComputeTopKError = HTuple(hv_Measures[hv_M]).TupleRegexpTest(hv_RegExpTopKError);
            if (0 != hv_ComputeTopKError)
            {
                hv_K = hv_K.TupleMax2((HTuple(hv_Measures[hv_M]).TupleRegexpMatch(hv_RegExpTopKError)).TupleNumber());
            }
        }
    }
    //
    //Extend tuples in RunningMeasures with new results.
    GetDictTuple(hv_RunningMeasures, "image_ids", &hv_ImageIDs);
    GetDictTuple(hv_RunningMeasures, "image_label_ids", &hv_ImageLabelIDs);
    GetDictTuple(hv_RunningMeasures, "top1_predictions", &hv_Top1Prediction);
    GetDictTuple(hv_RunningMeasures, "topk_predictions", &hv_TopKPredictionDicts);
    {
        HTuple end_val19 = (hv_Samples.TupleLength())-1;
        HTuple step_val19 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val19, step_val19); hv_Index += step_val19)
        {
            hv_Sample = HTuple(hv_Samples[hv_Index]);
            GetDictTuple(hv_Sample, "image_id", &hv_ImageID);
            GetDictTuple(hv_Sample, "image_label_id", &hv_ImageLabelID);
            hv_Result = HTuple(hv_Results[hv_Index]);
            GetDictTuple(hv_Result, "classification_class_ids", &hv_PredictedClassIDs);
            hv_TopKPrediction = hv_PredictedClassIDs.TupleSelectRange(0,hv_K-1);
            CreateDict(&hv_TopKPredictionDict);
            SetDictTuple(hv_TopKPredictionDict, "predictions", hv_TopKPrediction);
            //
            hv_ImageIDs = hv_ImageIDs.TupleConcat(hv_ImageID);
            hv_ImageLabelIDs = hv_ImageLabelIDs.TupleConcat(hv_ImageLabelID);
            hv_Top1Prediction = hv_Top1Prediction.TupleConcat(HTuple(hv_TopKPrediction[0]));
            hv_TopKPredictionDicts = hv_TopKPredictionDicts.TupleConcat(hv_TopKPredictionDict);
        }
    }
    //
    SetDictTuple(hv_RunningMeasures, "image_ids", hv_ImageIDs);
    SetDictTuple(hv_RunningMeasures, "image_label_ids", hv_ImageLabelIDs);
    SetDictTuple(hv_RunningMeasures, "top1_predictions", hv_Top1Prediction);
    SetDictTuple(hv_RunningMeasures, "topk_predictions", hv_TopKPredictionDicts);
    //
    return;
}

// Chapter: Deep Learning / Object Detection and Instance Segmentation
// Short Description: Update running measures for an instance-based evaluation.
void HalxAI:: update_running_instance_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams,
                                                HTuple hv_RunningMeasures)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_MaxNumDetections, hv_AreaRanges, hv_IoUThresholds;
    HTuple  hv_InstanceType, hv_ClassIDs, hv_NumClasses, hv_Measures;
    HTuple  hv_AreaNames, hv_MinAreas, hv_MaxAreas, hv_NumAreaRanges;
    HTuple  hv_AllocationBlockLength, hv_DetailedEvaluation;
    HTuple  hv_KeyExists, hv_ClassIDToClassIdx, hv_EvaluateOrientation;
    HTuple  hv_SIdx, hv_CurrentSample, hv_CurrentResult, hv_GtClassIDs;
    HTuple  hv_ResClassIDs, hv_NumGT, hv_NumRes, hv_Confidences;
    HTuple  hv_ResSortIndices, hv_GtAreas, hv_ResAreas, hv_IoUs;
    HTuple  hv_GtPhis, hv_ResPhis, hv_MDIdx, hv_MaxNum, hv_MaxNumStr;
    HTuple  hv_CurrentRunningMeasures, hv_AreaIdx, hv_MinArea;
    HTuple  hv_MaxArea, hv_AreaName, hv_AreaRunningMeasures;
    HTuple  hv_GtIgnore, hv_GtIgnoreInds, hv_PerClassNumGt;
    HTuple  hv_PerClassNumPred, hv_PerClassConfidences, hv_PerClassNumGtIgnore;
    HTuple  hv_SampleHasFP, hv_SampleHasFN, hv_ClsIdx, hv_CurrentClassID;
    HTuple  hv_CurrentGtIdxs, hv_CurrentNumGt, hv_CurrentGtIgnore;
    HTuple  hv_CurrentNumGtIgnore, hv_CurrentNumGtNoIgnore;
    HTuple  hv_CurrentResIdxs, hv_CurrentNumRes, hv_CurrentResAreas;
    HTuple  hv_OldNumPred, hv_CurrentClassConfidences, hv_GtSortIdx;
    HTuple  hv_CurrentResPhis, hv_CurrentGtPhis, hv_ITIdx, hv_GtMatched;
    HTuple  hv_ResMatched, hv_ResAbsOrientationDiff, hv_ResIgnore;
    HTuple  hv_ResIdx, hv_CurrentIoU, hv_MatchIdx, hv_GtIdx;
    HTuple  hv_AreaIgnore, hv_PerIoUMeasure, hv_PerClassMeasures;
    HTuple  hv_CurrentIsTP, hv_CurrentIgnore, hv_CurrentAbsOrientationDiff;
    HTuple  hv_GtMatchedNoIgnore, hv_ResIsFPClass, hv_ResIsFPBackground;
    HTuple  hv_ResIsFPLocalization, hv_ResIsFPDuplicate, hv_ResIsFPMultiple;
    HTuple  hv_ResAbsOrientationDiffClass, hv_ResAbsOrientationDiffLocalization;
    HTuple  hv_ResAbsOrientationDiffDuplicate, hv_ResAbsOrientationDiffMultiple;
    HTuple  hv_FPResIdxsThisClass, hv_FPResIdxsAllResults, hv_GTIdxsNotToIgnore;
    HTuple  hv_MaxIoU, hv_IoUsWithGT, hv_MaxIdx, hv_GTClassIDMaxIoU;
    HTuple  hv_AbsOrientationDiff, hv_IsFPClass, hv_IsFPBackground;
    HTuple  hv_IsFPLocalization, hv_IsFPDuplicate, hv_IsFPMultiple;
    HTuple  hv_AbsOrientationDiffMultiple, hv_AbsOrientationDiffDuplicate;
    HTuple  hv_AbsOrientationDiffLocalization, hv_AbsOrientationDiffClass;
    HTuple  hv_CurrentImageID, hv_ImageIDsWithFN, hv_NumImageIDsWithFN;
    HTuple  hv_ImageIDsWithFP, hv_NumImageIDsWithFP, hv___Tmp_Ctrl_Dict_Init_0;
    HTuple  hv___Tmp_Ctrl_Dict_Init_1;

    //
    //This procedure updates the RunningMeasures
    //for an instance-based evaluation for detection.
    //These measures are stored in the dictionary RunningMeasures and
    //updated by incorporating the Results the model obtained for the Samples.
    //
    dev_update_off();
    //Get the necessary evaluation parameters.
    GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
    GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
    GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IoUThresholds);
    GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    //
    //Get the area parameters: name, min, and max.
    GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
    GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
    GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
    hv_NumAreaRanges = (hv_AreaNames.TupleLength())-1;
    //
    //Get the allocation length for extending tuples.
    GetDictTuple(hv_EvalParams, "allocation_block_length", &hv_AllocationBlockLength);
    //
    //Check if a detailed evaluation should be done.
    hv_DetailedEvaluation = 0;
    GetDictParam(hv_EvalParams, "key_exists", "detailed_evaluation", &hv_KeyExists);
    if (0 != (HTuple(hv_KeyExists[0])))
    {
        GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
    }
    if (0 != hv_DetailedEvaluation)
    {
        //We need a mapping from class IDs to class indices
        hv_ClassIDToClassIdx = HTuple((hv_ClassIDs.TupleMax())+1,-1);
        hv_ClassIDToClassIdx[hv_ClassIDs] = HTuple::TupleGenSequence(0,hv_NumClasses-1,1);
    }
    //
    //Check if the orientation is to be evaluated.
    hv_EvaluateOrientation = 0;
    if (0 != (HTuple(int(hv_InstanceType==HTuple("rectangle2"))).TupleAnd(HTuple(int((hv_Measures.TupleFind("soap"))!=-1)).TupleOr(int((hv_Measures.TupleFind("all"))!=-1)))))
    {
        hv_EvaluateOrientation = 1;
    }
    //
    //Go through samples.
    {
        HTuple end_val44 = (hv_Samples.TupleLength())-1;
        HTuple step_val44 = 1;
        for (hv_SIdx=0; hv_SIdx.Continue(end_val44, step_val44); hv_SIdx += step_val44)
        {
            //
            hv_CurrentSample = HTuple(hv_Samples[hv_SIdx]);
            hv_CurrentResult = HTuple(hv_Results[hv_SIdx]);
            //
            //Get classes.
            GetDictTuple(hv_CurrentSample, "bbox_label_id", &hv_GtClassIDs);
            //Convert results from Deep OCR format to rectangle2 Object Detection format.
            CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
            SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "ocr_detection");
            if (0 != ((hv_EvalParams.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("evaluation_type","comp")))
            {
                convert_ocr_detection_result_to_object_detection(hv_CurrentResult, &hv_CurrentResult);
            }
            hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
            GetDictTuple(hv_CurrentResult, "bbox_class_id", &hv_ResClassIDs);
            hv_NumGT = hv_GtClassIDs.TupleLength();
            hv_NumRes = hv_ResClassIDs.TupleLength();
            //
            //Get result confidences and sort them in descending order.
            GetDictTuple(hv_CurrentResult, "bbox_confidence", &hv_Confidences);
            hv_ResSortIndices = (-hv_Confidences).TupleSortIndex();
            hv_Confidences = HTuple(hv_Confidences[hv_ResSortIndices]);
            //Sort the result class IDs.
            hv_ResClassIDs = HTuple(hv_ResClassIDs[hv_ResSortIndices]);
            //
            //Compute the IoUs of the instances.
            area_iou(hv_CurrentSample, hv_CurrentResult, hv_InstanceType, hv_ResSortIndices,
                     &hv_GtAreas, &hv_ResAreas, &hv_IoUs);
            //
            if (0 != hv_EvaluateOrientation)
            {
                GetDictTuple(hv_CurrentSample, "bbox_phi", &hv_GtPhis);
                GetDictTuple(hv_CurrentResult, "bbox_phi", &hv_ResPhis);
                hv_ResPhis = HTuple(hv_ResPhis[hv_ResSortIndices]);
            }
            //Loop over the maximal number of detections.
            {
                HTuple end_val78 = (hv_MaxNumDetections.TupleLength())-1;
                HTuple step_val78 = 1;
                for (hv_MDIdx=0; hv_MDIdx.Continue(end_val78, step_val78); hv_MDIdx += step_val78)
                {
                    hv_MaxNum = HTuple(hv_MaxNumDetections[hv_MDIdx]);
                    hv_MaxNumStr = ""+hv_MaxNum;
                    if (0 != (int(hv_MaxNum==-1)))
                    {
                        hv_MaxNumStr = "all";
                    }
                    GetDictTuple(hv_RunningMeasures, "max_num_detections_"+hv_MaxNumStr, &hv_CurrentRunningMeasures);
                    //
                    //Loop over the area ranges.
                    {
                        HTuple end_val87 = (hv_AreaNames.TupleLength())-1;
                        HTuple step_val87 = 1;
                        for (hv_AreaIdx=0; hv_AreaIdx.Continue(end_val87, step_val87); hv_AreaIdx += step_val87)
                        {
                            //
                            //Get information about the current area range.
                            hv_MinArea = HTuple(hv_MinAreas[hv_AreaIdx]);
                            hv_MaxArea = HTuple(hv_MaxAreas[hv_AreaIdx]);
                            hv_AreaName = HTuple(hv_AreaNames[hv_AreaIdx]);
                            //
                            GetDictTuple(hv_CurrentRunningMeasures, "area_"+hv_AreaName, &hv_AreaRunningMeasures);
                            //
                            //Set ignore-flag for ground truth instances.
                            //For Deep OCR detection, ignore classes other than 'word'
                            CreateDict(&hv___Tmp_Ctrl_Dict_Init_1);
                            SetDictTuple(hv___Tmp_Ctrl_Dict_Init_1, "comp", "ocr_detection");
                            if (0 != ((hv_EvalParams.TupleConcat(hv___Tmp_Ctrl_Dict_Init_1)).TupleTestEqualDictItem("evaluation_type","comp")))
                            {
                                hv_GtIgnore = hv_GtClassIDs.TupleNotEqualElem(0);
                            }
                            else
                            {
                                hv_GtIgnore = HTuple(hv_NumGT,0);
                            }
                            hv___Tmp_Ctrl_Dict_Init_1 = HTuple::TupleConstant("HNULL");
                            //
                            //Ignore ground truth instances with area outside the area range.
                            if (0 != (int(hv_NumGT>0)))
                            {
                                TupleFind((hv_GtAreas.TupleLessElem(hv_MinArea)).TupleOr(hv_GtAreas.TupleGreaterElem(hv_MaxArea)),
                                          1, &hv_GtIgnoreInds);
                                if (0 != (int(hv_GtIgnoreInds>-1)))
                                {
                                    hv_GtIgnore[hv_GtIgnoreInds] = 1;
                                }
                            }
                            //
                            GetDictTuple(hv_AreaRunningMeasures, "num_gt", &hv_PerClassNumGt);
                            GetDictTuple(hv_AreaRunningMeasures, "num_pred", &hv_PerClassNumPred);
                            GetDictTuple(hv_AreaRunningMeasures, "confidence", &hv_PerClassConfidences);
                            GetDictTuple(hv_AreaRunningMeasures, "num_gt_ignore", &hv_PerClassNumGtIgnore);
                            //
                            if (0 != hv_DetailedEvaluation)
                            {
                                //Store if a sample has at least one false positive or false negative (for each IoU threshold).
                                hv_SampleHasFP = HTuple(hv_IoUThresholds.TupleLength(),0);
                                hv_SampleHasFN = HTuple(hv_IoUThresholds.TupleLength(),0);
                            }
                            //
                            //Loop over the classes.
                            {
                                HTuple end_val127 = hv_NumClasses-1;
                                HTuple step_val127 = 1;
                                for (hv_ClsIdx=0; hv_ClsIdx.Continue(end_val127, step_val127); hv_ClsIdx += step_val127)
                                {
                                    hv_CurrentClassID = HTuple(hv_ClassIDs[hv_ClsIdx]);
                                    //
                                    //Get the ground truth for this class.
                                    hv_CurrentGtIdxs = hv_GtClassIDs.TupleFind(hv_CurrentClassID);
                                    if (0 != (int(hv_CurrentGtIdxs==-1)))
                                    {
                                        hv_CurrentGtIdxs = HTuple();
                                    }
                                    hv_CurrentNumGt = hv_CurrentGtIdxs.TupleLength();
                                    //
                                    //Get ground truth ignore for this class.
                                    hv_CurrentGtIgnore = HTuple(hv_GtIgnore[hv_CurrentGtIdxs]);
                                    if (0 != (int((hv_CurrentGtIgnore.TupleLength())==0)))
                                    {
                                        hv_CurrentNumGtIgnore = 0;
                                    }
                                    else
                                    {
                                        hv_CurrentNumGtIgnore = hv_CurrentGtIgnore.TupleSum();
                                    }
                                    //
                                    //Number of gt for this class and without ignore.
                                    hv_CurrentNumGtNoIgnore = hv_CurrentNumGt-hv_CurrentNumGtIgnore;
                                    //
                                    //Get results for this class.
                                    hv_CurrentResIdxs = hv_ResClassIDs.TupleFind(hv_CurrentClassID);
                                    if (0 != (int(hv_CurrentResIdxs==-1)))
                                    {
                                        hv_CurrentResIdxs = HTuple();
                                    }
                                    hv_CurrentNumRes = hv_MaxNum.TupleMin2(hv_CurrentResIdxs.TupleLength());
                                    //MaxNum -1 corresponds to taking all results.
                                    if (0 != (int(hv_MaxNum==-1)))
                                    {
                                        hv_CurrentNumRes = hv_CurrentResIdxs.TupleLength();
                                    }
                                    hv_CurrentResIdxs = hv_CurrentResIdxs.TupleSelectRange(0,hv_CurrentNumRes-1);
                                    //
                                    //Get areas of the current results.
                                    hv_CurrentResAreas = HTuple(hv_ResAreas[hv_CurrentResIdxs]);
                                    //
                                    //Update the confidences, num_gt and num_pred for this class.
                                    hv_OldNumPred = HTuple(hv_PerClassNumPred[hv_ClsIdx]);
                                    hv_PerClassNumGt[hv_ClsIdx] = HTuple(hv_PerClassNumGt[hv_ClsIdx])+hv_CurrentNumGt;
                                    hv_PerClassNumGtIgnore[hv_ClsIdx] = HTuple(hv_PerClassNumGtIgnore[hv_ClsIdx])+hv_CurrentNumGtIgnore;
                                    hv_PerClassNumPred[hv_ClsIdx] = HTuple(hv_PerClassNumPred[hv_ClsIdx])+hv_CurrentNumRes;
                                    GetDictTuple(hv_PerClassConfidences, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                 &hv_CurrentClassConfidences);
                                    //Confidences are allocated in blocks of AllocationBlockLength. Therefore, we have to check
                                    //if the allocated block is long enough, otherwise allocate a new block.
                                    if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentClassConfidences.TupleLength()))))
                                    {
                                        hv_CurrentClassConfidences = hv_CurrentClassConfidences.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                    }
                                    hv_CurrentClassConfidences[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = HTuple(hv_Confidences[hv_CurrentResIdxs]);
                                    SetDictTuple(hv_PerClassConfidences, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                 hv_CurrentClassConfidences);
                                    //
                                    //Sort the ground truth: Non-ignored instances first.
                                    hv_GtSortIdx = hv_CurrentGtIgnore.TupleSortIndex();
                                    hv_CurrentGtIgnore = HTuple(hv_CurrentGtIgnore[hv_GtSortIdx]);
                                    hv_CurrentGtIdxs = HTuple(hv_CurrentGtIdxs[hv_GtSortIdx]);
                                    //
                                    //Get orientations of result and ground truth instances.
                                    if (0 != hv_EvaluateOrientation)
                                    {
                                        hv_CurrentResPhis = HTuple(hv_ResPhis[hv_CurrentResIdxs]);
                                        hv_CurrentGtPhis = HTuple(hv_GtPhis[hv_CurrentGtIdxs]);
                                    }
                                    //
                                    if (0 != (int(hv_CurrentNumRes>0)))
                                    {
                                        //Loop over IoU thresholds.
                                        {
                                            HTuple end_val190 = (hv_IoUThresholds.TupleLength())-1;
                                            HTuple step_val190 = 1;
                                            for (hv_ITIdx=0; hv_ITIdx.Continue(end_val190, step_val190); hv_ITIdx += step_val190)
                                            {
                                                //We check which ground truth and
                                                //result instance can be matched.
                                                hv_GtMatched = HTuple(hv_CurrentNumGt,0);
                                                hv_ResMatched = HTuple(hv_CurrentNumRes,0);
                                                //
                                                if (0 != hv_EvaluateOrientation)
                                                {
                                                    //Initialize the absolute orientation difference to -1.
                                                    hv_ResAbsOrientationDiff = HTuple(hv_CurrentNumRes,-1);
                                                }
                                                //Store which detections should be ignored.
                                                hv_ResIgnore = HTuple(hv_CurrentNumRes,0);
                                                {
                                                    HTuple end_val202 = hv_CurrentNumRes-1;
                                                    HTuple step_val202 = 1;
                                                    for (hv_ResIdx=0; hv_ResIdx.Continue(end_val202, step_val202); hv_ResIdx += step_val202)
                                                    {
                                                        //Set the currently best achieved IoU to the IoU threshold and
                                                        //initialize the matching index.
                                                        hv_CurrentIoU = HTuple(hv_IoUThresholds[hv_ITIdx]).TupleMin2(1-1.0e-10);
                                                        hv_MatchIdx = -1;
                                                        //Loop over ground truth.
                                                        {
                                                            HTuple end_val208 = hv_CurrentNumGt-1;
                                                            HTuple step_val208 = 1;
                                                            for (hv_GtIdx=0; hv_GtIdx.Continue(end_val208, step_val208); hv_GtIdx += step_val208)
                                                            {
                                                                //Continue if this ground truth has already been matched.
                                                                if (0 != (HTuple(hv_GtMatched[hv_GtIdx])))
                                                                {
                                                                    continue;
                                                                }
                                                                //Stop if matched with non-ignored ground truth and current ground truth is on ignore.
                                                                if (0 != (int(hv_MatchIdx>-1)))
                                                                {
                                                                    if (0 != (HTuple(int(HTuple(hv_CurrentGtIgnore[hv_MatchIdx])==0)).TupleAnd(int(HTuple(hv_CurrentGtIgnore[hv_GtIdx])==1))))
                                                                    {
                                                                        break;
                                                                    }
                                                                }
                                                                //Continue if IoU is not better than a previous match.
                                                                if (0 != (int(HTuple(hv_IoUs[(HTuple(hv_CurrentGtIdxs[hv_GtIdx])*hv_NumRes)+HTuple(hv_CurrentResIdxs[hv_ResIdx])])<hv_CurrentIoU)))
                                                                {
                                                                    continue;
                                                                }
                                                                //We got a new best match, store it.
                                                                hv_CurrentIoU = HTuple(hv_IoUs[(HTuple(hv_CurrentGtIdxs[hv_GtIdx])*hv_NumRes)+HTuple(hv_CurrentResIdxs[hv_ResIdx])]);
                                                                hv_MatchIdx = hv_GtIdx;
                                                            }
                                                        }
                                                        //If a match has been made we store it for both ground truth and result.
                                                        if (0 != (int(hv_MatchIdx!=-1)))
                                                        {
                                                            //In COCO they use the IDs of GT and Res, we just use 1
                                                            //to indicate the matching, but don't store which one has been matched.
                                                            hv_ResMatched[hv_ResIdx] = 1;
                                                            hv_GtMatched[hv_MatchIdx] = 1;
                                                            hv_ResIgnore[hv_ResIdx] = HTuple(hv_CurrentGtIgnore[hv_MatchIdx]);
                                                            //
                                                            if (0 != hv_EvaluateOrientation)
                                                            {
                                                                //Set the absolute orientation difference.
                                                                hv_ResAbsOrientationDiff[hv_ResIdx] = (HTuple(hv_CurrentResPhis[hv_ResIdx])-HTuple(hv_CurrentGtPhis[hv_MatchIdx])).TupleAbs();
                                                                if (0 != (int(HTuple(hv_ResAbsOrientationDiff[hv_ResIdx])>(HTuple(180).TupleRad()))))
                                                                {
                                                                    hv_ResAbsOrientationDiff[hv_ResIdx] = (HTuple(360).TupleRad())-HTuple(hv_ResAbsOrientationDiff[hv_ResIdx]);
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                                //Ignore the unmatched results that are outside of the current area range.
                                                hv_AreaIgnore = (hv_CurrentResAreas.TupleLessElem(hv_MinArea)).TupleOr(hv_CurrentResAreas.TupleGreaterElem(hv_MaxArea));
                                                hv_ResIgnore = HTuple((hv_ResMatched.TupleEqualElem(-1)).TupleAnd(hv_AreaIgnore.TupleEqualElem(1))).TupleOr(hv_ResIgnore);
                                                //True positives are the matched results.
                                                GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                             &hv_PerIoUMeasure);
                                                GetDictTuple(hv_PerIoUMeasure, "class_"+HTuple(hv_ClassIDs[hv_ClsIdx]),
                                                             &hv_PerClassMeasures);
                                                GetDictTuple(hv_PerClassMeasures, "is_tp", &hv_CurrentIsTP);
                                                //As for confidences, check if we have to allocate a new block.
                                                if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentIsTP.TupleLength()))))
                                                {
                                                    hv_CurrentIsTP = hv_CurrentIsTP.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                }
                                                hv_CurrentIsTP[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResMatched;
                                                SetDictTuple(hv_PerClassMeasures, "is_tp", hv_CurrentIsTP);
                                                //Set the ignored results.
                                                GetDictTuple(hv_PerClassMeasures, "ignore", &hv_CurrentIgnore);
                                                if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentIgnore.TupleLength()))))
                                                {
                                                    hv_CurrentIgnore = hv_CurrentIgnore.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                }
                                                hv_CurrentIgnore[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIgnore;
                                                SetDictTuple(hv_PerClassMeasures, "ignore", hv_CurrentIgnore);
                                                //Set the absolute orientation difference.
                                                if (0 != hv_EvaluateOrientation)
                                                {
                                                    GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff", &hv_CurrentAbsOrientationDiff);
                                                    if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_CurrentAbsOrientationDiff.TupleLength()))))
                                                    {
                                                        hv_CurrentAbsOrientationDiff = hv_CurrentAbsOrientationDiff.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                    }
                                                    hv_CurrentAbsOrientationDiff[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiff;
                                                    SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff", hv_CurrentAbsOrientationDiff);
                                                }
                                                //
                                                //Beginning of detailed evaluation processing (optional).
                                                //
                                                if (0 != hv_DetailedEvaluation)
                                                {
                                                    //Check if there have been false negatives.
                                                    if (0 != (int(hv_CurrentNumGtNoIgnore>0)))
                                                    {
                                                        hv_GtMatchedNoIgnore = hv_GtMatched.TupleAnd(hv_CurrentGtIgnore.TupleNot());
                                                        if (0 != (int((hv_GtMatchedNoIgnore.TupleSum())<hv_CurrentNumGtNoIgnore)))
                                                        {
                                                            hv_SampleHasFN[hv_ITIdx] = 1;
                                                        }
                                                    }
                                                    //
                                                    //Initialize the detailed running measures.
                                                    hv_ResIsFPClass = HTuple(hv_CurrentNumRes,-1);
                                                    hv_ResIsFPBackground = HTuple(hv_CurrentNumRes,0);
                                                    hv_ResIsFPLocalization = HTuple(hv_CurrentNumRes,0);
                                                    hv_ResIsFPDuplicate = HTuple(hv_CurrentNumRes,0);
                                                    hv_ResIsFPMultiple = HTuple(hv_CurrentNumRes,0);
                                                    //
                                                    //Initialize detailed running measures for orientation difference.
                                                    if (0 != hv_EvaluateOrientation)
                                                    {
                                                        hv_ResAbsOrientationDiffClass = HTuple(hv_CurrentNumRes,-1);
                                                        hv_ResAbsOrientationDiffLocalization = HTuple(hv_CurrentNumRes,-1);
                                                        hv_ResAbsOrientationDiffDuplicate = HTuple(hv_CurrentNumRes,-1);
                                                        hv_ResAbsOrientationDiffMultiple = HTuple(hv_CurrentNumRes,-1);
                                                    }
                                                    //Check if there have been false positives.
                                                    if (0 != (int((hv_ResMatched.TupleSum())<hv_CurrentNumRes)))
                                                    {
                                                        hv_SampleHasFP[hv_ITIdx] = 1;
                                                        //
                                                        //For each false positive, find out what was the reason for being false positive:
                                                        hv_FPResIdxsThisClass = hv_ResMatched.TupleFind(0);
                                                        hv_FPResIdxsAllResults = HTuple(hv_CurrentResIdxs[hv_FPResIdxsThisClass]);
                                                        hv_GTIdxsNotToIgnore = hv_GtIgnore.TupleFind(0);
                                                        {
                                                            HTuple end_val307 = (hv_FPResIdxsThisClass.TupleLength())-1;
                                                            HTuple step_val307 = 1;
                                                            for (hv_ResIdx=0; hv_ResIdx.Continue(end_val307, step_val307); hv_ResIdx += step_val307)
                                                            {
                                                                if (0 != (HTuple(hv_ResIgnore[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])]).TupleNot()))
                                                                {
                                                                    if (0 != (HTuple(int((hv_GTIdxsNotToIgnore.TupleLength())==0)).TupleOr(int(hv_GTIdxsNotToIgnore==-1))))
                                                                    {
                                                                        //No GT instances or all GT instances are ignored.
                                                                        //Thus, any detection is a background detection
                                                                        hv_MaxIoU = 0.0;
                                                                    }
                                                                    else
                                                                    {
                                                                        //We have GT instances to consider.
                                                                        hv_IoUsWithGT = HTuple(hv_IoUs[(hv_GTIdxsNotToIgnore*hv_NumRes)+HTuple(hv_FPResIdxsAllResults[hv_ResIdx])]);
                                                                        hv_MaxIoU = hv_IoUsWithGT.TupleMax();
                                                                        //It is enough to look for the first occurrence because the IoUs to ground truth should be different.
                                                                        hv_MaxIdx = hv_IoUsWithGT.TupleFindFirst(hv_MaxIoU);
                                                                        hv_GTClassIDMaxIoU = HTuple(hv_GtClassIDs[HTuple(hv_GTIdxsNotToIgnore[hv_MaxIdx])]);
                                                                    }
                                                                    if (0 != (hv_EvaluateOrientation.TupleAnd(int(hv_MaxIoU>0.0))))
                                                                    {
                                                                        //Calculate the absolute orientation difference to the GT instance with maximal IoU.
                                                                        hv_AbsOrientationDiff = (HTuple(hv_ResPhis[HTuple(hv_FPResIdxsAllResults[hv_ResIdx])])-HTuple(hv_GtPhis[HTuple(hv_GTIdxsNotToIgnore[hv_MaxIdx])])).TupleAbs();
                                                                        if (0 != (int(hv_AbsOrientationDiff>(HTuple(180).TupleRad()))))
                                                                        {
                                                                            hv_AbsOrientationDiff = (HTuple(360).TupleRad())-hv_AbsOrientationDiff;
                                                                        }
                                                                    }
                                                                    //Determine false positive type.
                                                                    if (0 != (int(hv_MaxIoU==0.0)))
                                                                    {
                                                                        //Background detection. This detection does not overlap to any ground truth (that is not ignored).
                                                                        hv_ResIsFPBackground[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                                                                    }
                                                                    else if (0 != (HTuple(int(hv_MaxIoU>=HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID!=hv_GTClassIDMaxIoU))))
                                                                    {
                                                                        //False class.
                                                                        //Note that this does not necessarily mean that this detection
                                                                        //would be a true positive if the class was changed. It could still be a duplicate.
                                                                        hv_ResIsFPClass[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = HTuple(hv_ClassIDToClassIdx[hv_GTClassIDMaxIoU]);
                                                                        //Store the absolute orientation difference.
                                                                        if (0 != hv_EvaluateOrientation)
                                                                        {
                                                                            hv_ResAbsOrientationDiffClass[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                                                                        }
                                                                    }
                                                                    else if (0 != (HTuple(int(hv_MaxIoU>=HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID==hv_GTClassIDMaxIoU))))
                                                                    {
                                                                        //Duplicate detection. There must exist another detection with a higher confidence with the same ground truth.
                                                                        hv_ResIsFPDuplicate[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                                                                        //Store the absolute orientation difference.
                                                                        if (0 != hv_EvaluateOrientation)
                                                                        {
                                                                            hv_ResAbsOrientationDiffDuplicate[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                                                                        }
                                                                    }
                                                                    else if (0 != (HTuple(int(hv_MaxIoU<HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID==hv_GTClassIDMaxIoU))))
                                                                    {
                                                                        //Bad localization. Class is correct, but the IoU is too low.
                                                                        hv_ResIsFPLocalization[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                                                                        //Store the absolute orientation difference.
                                                                        if (0 != hv_EvaluateOrientation)
                                                                        {
                                                                            hv_ResAbsOrientationDiffLocalization[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                                                                        }
                                                                    }
                                                                    else if (0 != (HTuple(int(hv_MaxIoU<HTuple(hv_IoUThresholds[hv_ITIdx]))).TupleAnd(int(hv_CurrentClassID!=hv_GTClassIDMaxIoU))))
                                                                    {
                                                                        //Wrong class and bad localization.
                                                                        hv_ResIsFPMultiple[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = 1;
                                                                        //Store the absolute orientation difference.
                                                                        if (0 != hv_EvaluateOrientation)
                                                                        {
                                                                            hv_ResAbsOrientationDiffMultiple[HTuple(hv_FPResIdxsThisClass[hv_ResIdx])] = hv_AbsOrientationDiff;
                                                                        }
                                                                    }
                                                                    else
                                                                    {
                                                                        //This case should never occur.
                                                                        throw HException("Fatal error during detailed evaluation.");
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                    //
                                                    //Overwrite the detailed running measures.
                                                    GetDictTuple(hv_PerClassMeasures, "is_fp_class", &hv_IsFPClass);
                                                    GetDictTuple(hv_PerClassMeasures, "is_fp_background", &hv_IsFPBackground);
                                                    GetDictTuple(hv_PerClassMeasures, "is_fp_localization", &hv_IsFPLocalization);
                                                    GetDictTuple(hv_PerClassMeasures, "is_fp_duplicate", &hv_IsFPDuplicate);
                                                    GetDictTuple(hv_PerClassMeasures, "is_fp_multiple", &hv_IsFPMultiple);
                                                    if (0 != hv_EvaluateOrientation)
                                                    {
                                                        GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_multiple",
                                                                     &hv_AbsOrientationDiffMultiple);
                                                        GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_duplicate",
                                                                     &hv_AbsOrientationDiffDuplicate);
                                                        GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_localization",
                                                                     &hv_AbsOrientationDiffLocalization);
                                                        GetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_class",
                                                                     &hv_AbsOrientationDiffClass);
                                                    }
                                                    //Allocate new blocks if necessary (all have the same length).
                                                    if (0 != (int(HTuple(hv_PerClassNumPred[hv_ClsIdx])>(hv_IsFPClass.TupleLength()))))
                                                    {
                                                        hv_IsFPClass = hv_IsFPClass.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                        hv_IsFPBackground = hv_IsFPBackground.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                        hv_IsFPLocalization = hv_IsFPLocalization.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                        hv_IsFPDuplicate = hv_IsFPDuplicate.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                        hv_IsFPMultiple = hv_IsFPMultiple.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                        if (0 != hv_EvaluateOrientation)
                                                        {
                                                            hv_AbsOrientationDiffMultiple = hv_AbsOrientationDiffMultiple.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                            hv_AbsOrientationDiffDuplicate = hv_AbsOrientationDiffDuplicate.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                            hv_AbsOrientationDiffLocalization = hv_AbsOrientationDiffLocalization.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                            hv_AbsOrientationDiffClass = hv_AbsOrientationDiffClass.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                                        }
                                                    }
                                                    hv_IsFPClass[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPClass;
                                                    hv_IsFPBackground[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPBackground;
                                                    hv_IsFPLocalization[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPLocalization;
                                                    hv_IsFPDuplicate[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPDuplicate;
                                                    hv_IsFPMultiple[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResIsFPMultiple;
                                                    if (0 != hv_EvaluateOrientation)
                                                    {
                                                        hv_AbsOrientationDiffMultiple[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffMultiple;
                                                        hv_AbsOrientationDiffDuplicate[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffDuplicate;
                                                        hv_AbsOrientationDiffLocalization[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffLocalization;
                                                        hv_AbsOrientationDiffClass[HTuple::TupleGenSequence(hv_OldNumPred,HTuple(hv_PerClassNumPred[hv_ClsIdx])-1,1)] = hv_ResAbsOrientationDiffClass;
                                                    }
                                                    SetDictTuple(hv_PerClassMeasures, "is_fp_class", hv_IsFPClass);
                                                    SetDictTuple(hv_PerClassMeasures, "is_fp_background", hv_IsFPBackground);
                                                    SetDictTuple(hv_PerClassMeasures, "is_fp_localization", hv_IsFPLocalization);
                                                    SetDictTuple(hv_PerClassMeasures, "is_fp_duplicate", hv_IsFPDuplicate);
                                                    SetDictTuple(hv_PerClassMeasures, "is_fp_multiple", hv_IsFPMultiple);
                                                    if (0 != hv_EvaluateOrientation)
                                                    {
                                                        SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_multiple",
                                                                     hv_AbsOrientationDiffMultiple);
                                                        SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_duplicate",
                                                                     hv_AbsOrientationDiffDuplicate);
                                                        SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_localization",
                                                                     hv_AbsOrientationDiffLocalization);
                                                        SetDictTuple(hv_PerClassMeasures, "abs_orientation_diff_class",
                                                                     hv_AbsOrientationDiffClass);
                                                    }
                                                }
                                                //
                                                //End of detailed evaluation processing.
                                                //
                                            }
                                        }
                                    }
                                    else
                                    {
                                        if (0 != (hv_DetailedEvaluation.TupleAnd(int(hv_CurrentNumGtNoIgnore>0))))
                                        {
                                            //There are false negatives for this class.
                                            //Loop over IoU thresholds.
                                            {
                                                HTuple end_val427 = (hv_IoUThresholds.TupleLength())-1;
                                                HTuple step_val427 = 1;
                                                for (hv_ITIdx=0; hv_ITIdx.Continue(end_val427, step_val427); hv_ITIdx += step_val427)
                                                {
                                                    hv_SampleHasFN[hv_ITIdx] = 1;
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                            //Update the confidences, num_gt and num_pred.
                            SetDictTuple(hv_AreaRunningMeasures, "num_gt", hv_PerClassNumGt);
                            SetDictTuple(hv_AreaRunningMeasures, "num_pred", hv_PerClassNumPred);
                            SetDictTuple(hv_AreaRunningMeasures, "confidence", hv_PerClassConfidences);
                            SetDictTuple(hv_AreaRunningMeasures, "num_gt_ignore", hv_PerClassNumGtIgnore);
                            //
                            if (0 != hv_DetailedEvaluation)
                            {
                                //Set values that are calculated over all classes (for each IoU threshold).
                                {
                                    HTuple end_val441 = (hv_IoUThresholds.TupleLength())-1;
                                    HTuple step_val441 = 1;
                                    for (hv_ITIdx=0; hv_ITIdx.Continue(end_val441, step_val441); hv_ITIdx += step_val441)
                                    {
                                        GetDictTuple(hv_AreaRunningMeasures, "iou_"+((""+HTuple(hv_IoUThresholds[hv_ITIdx])).TupleRegexpReplace("\\.","")),
                                                     &hv_PerIoUMeasure);
                                        //Set image IDs with false negatives
                                        if (0 != (HTuple(hv_SampleHasFN[hv_ITIdx])))
                                        {
                                            GetDictTuple(hv_CurrentSample, "image_id", &hv_CurrentImageID);
                                            GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_negatives", &hv_ImageIDsWithFN);
                                            GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_negatives",
                                                         &hv_NumImageIDsWithFN);
                                            //Allocate a new block if necessary.
                                            if (0 != (int((hv_NumImageIDsWithFN+1)>(hv_ImageIDsWithFN.TupleLength()))))
                                            {
                                                hv_ImageIDsWithFN = hv_ImageIDsWithFN.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                            }
                                            hv_ImageIDsWithFN[hv_NumImageIDsWithFN] = hv_CurrentImageID;
                                            SetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_negatives", hv_ImageIDsWithFN);
                                            SetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_negatives",
                                                         hv_NumImageIDsWithFN+1);
                                        }
                                        if (0 != (HTuple(hv_SampleHasFP[hv_ITIdx])))
                                        {
                                            GetDictTuple(hv_CurrentSample, "image_id", &hv_CurrentImageID);
                                            GetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_positives", &hv_ImageIDsWithFP);
                                            GetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_positives",
                                                         &hv_NumImageIDsWithFP);
                                            //Allocate a new block if necessary.
                                            if (0 != (int((hv_NumImageIDsWithFP+1)>(hv_ImageIDsWithFP.TupleLength()))))
                                            {
                                                hv_ImageIDsWithFP = hv_ImageIDsWithFP.TupleConcat(HTuple(hv_AllocationBlockLength,-1));
                                            }
                                            hv_ImageIDsWithFP[hv_NumImageIDsWithFP] = hv_CurrentImageID;
                                            SetDictTuple(hv_PerIoUMeasure, "image_ids_with_false_positives", hv_ImageIDsWithFP);
                                            SetDictTuple(hv_PerIoUMeasure, "num_image_ids_with_false_positives",
                                                         hv_NumImageIDsWithFP+1);
                                        }
                                    }
                                }
                            }
                        }
                    }
                    SetDictTuple(hv_CurrentRunningMeasures, "area_"+hv_AreaName, hv_AreaRunningMeasures);
                }
            }
        }
    }
    //
    return;
}

// Chapter: OCR / Deep OCR
// Short Description: Update running measures for an OCR recognition evaluation.
void HalxAI:: update_running_ocr_recognition_measures (HTuple hv_Samples, HTuple hv_Results,
                                                       HTuple hv_EvalParams, HTuple hv_RunningMeasures)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_N, hv_ImageIDsBatch, hv_WordsPredictionBatch;
    HTuple  hv_WordsGroundTruthBatch, hv_SampleIndex, hv_Sample;
    HTuple  hv_Result;

    //
    //This procedure updates the RunningMeasures for an evaluation for OCR recognition.
    //
    //These measures are stored in the dictionary RunningMeasures and
    //updated by incorporating the Results the model obtained for the Samples.
    //
    //
    hv_N = hv_Samples.TupleLength();
    TupleGenConst(hv_N, 0, &hv_ImageIDsBatch);
    TupleGenConst(hv_N, 0, &hv_WordsPredictionBatch);
    TupleGenConst(hv_N, 0, &hv_WordsGroundTruthBatch);
    //Loop over all samples and update running measures accordingly.
    {
        HTuple end_val12 = hv_N-1;
        HTuple step_val12 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val12, step_val12); hv_SampleIndex += step_val12)
        {
            hv_Sample = HTuple(hv_Samples[hv_SampleIndex]);
            hv_Result = HTuple(hv_Results[hv_SampleIndex]);
            hv_ImageIDsBatch[hv_SampleIndex] = hv_Sample.TupleGetDictTuple("image_id");
            hv_WordsPredictionBatch[hv_SampleIndex] = hv_Result.TupleGetDictTuple("word");
            hv_WordsGroundTruthBatch[hv_SampleIndex] = hv_Sample.TupleGetDictTuple("word");
        }
    }
    //
    //Update running measures
    SetDictTuple(hv_RunningMeasures, "image_ids", (hv_RunningMeasures.TupleGetDictTuple("image_ids")).TupleConcat(hv_ImageIDsBatch));
    SetDictTuple(hv_RunningMeasures, "words_prediction", (hv_RunningMeasures.TupleGetDictTuple("words_prediction")).TupleConcat(hv_WordsPredictionBatch));
    SetDictTuple(hv_RunningMeasures, "words_ground_truth", (hv_RunningMeasures.TupleGetDictTuple("words_ground_truth")).TupleConcat(hv_WordsGroundTruthBatch));
    //
    return;
}

// Chapter: Deep Learning / Semantic Segmentation and Edge Extraction
// Short Description: Update running measures for a pixel-based evaluation.
void HalxAI:: update_running_pixel_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams,
                                             HTuple hv_RunningMeasures)
{

    // Local iconic variables
    HObject  ho_Annot, ho_Result, ho_ClsIgnore, ho_ClsIgnoreTmp;
    HObject  ho_ClsAnnot, ho_ClsResult, ho_TPReg, ho_FPReg, ho_FNReg;

    // Local control variables
    HTuple  hv_EvaluationType, hv_Measures, hv_PixelMeasures;
    HTuple  hv_ClassIDs, hv_NumClasses, hv_IgnoreClassIDs, hv_CalcConfMatrix;
    HTuple  hv_SegmentationImageExists, hv_GrippingMapExists;
    HTuple  hv_ResultKey, hv_ClassIDsResult, hv_ConfMatrix;
    HTuple  hv_MapClassIDs, hv_ClsIdToClsIdx, hv_TP, hv_FP;
    HTuple  hv_FN, hv_SampleIndex, hv_Rows, hv_Columns, hv_AnnotVals;
    HTuple  hv_ResultVals, hv_ConfTuple, hv_ConfHist, hv_BinSize;
    HTuple  hv_ConfMatrixTmp, hv_IgnoreIndex, hv_ClsIndex, hv_ClsId;
    HTuple  hv_ClsIdRes, hv_ClsTP, hv_ClsFP, hv_ClsFN;

    //
    //This procedure updates the RunningMeasures for a pixel-
    //based evaluation for segmentation or 3D Gripping Point
    //Detection. These measures are stored in the dictionary
    //RunningMeasures and updated by incorporating the Results
    //the model obtained for the Samples.
    //
    //Get evaluation type.
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    //Get evaluation measures.
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    //Check if any pixel measures are requested.
    get_requested_pixel_measures(hv_Measures, hv_EvaluationType, &hv_PixelMeasures);
    if (0 != (int((hv_PixelMeasures.TupleLength())==0)))
    {
        return;
    }
    //
    //Get the class IDs.
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    //Get the number of classes.
    GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
    //Get the ignore class IDs.
    GetDictTuple(hv_EvalParams, "ignore_class_ids", &hv_IgnoreClassIDs);
    //
    //Check if we need to compute/update the confusion matrix.
    hv_CalcConfMatrix = int((hv_PixelMeasures.TupleFind("pixel_confusion_matrix"))>-1);
    //
    //Check and set result type and class IDs.
    GetDictParam(HTuple(hv_Results[0]), "key_exists", "segmentation_image", &hv_SegmentationImageExists);
    GetDictParam(HTuple(hv_Results[0]), "key_exists", "gripping_map", &hv_GrippingMapExists);
    if (0 != hv_SegmentationImageExists)
    {
        hv_ResultKey = "segmentation_image";
        //Class IDs in the result are the same as in the groundtruth.
        hv_ClassIDsResult = hv_ClassIDs;
    }
    else if (0 != hv_GrippingMapExists)
    {
        hv_ResultKey = "gripping_map";
        //Since the result is a binary gripping map, the class ID
        //is always 1.
        hv_ClassIDsResult = 1;
    }
    else
    {
        throw HException("No result available for evaluation");
    }
    //
    if (0 != hv_CalcConfMatrix)
    {
        //Get the current confusion matrix.
        GetDictTuple(hv_RunningMeasures, "pixel_confusion_matrix", &hv_ConfMatrix);
        //Check if we need to map the class IDs.
        GetDictParam(hv_EvalParams, "key_exists", "class_id_mapping", &hv_MapClassIDs);
        if (0 != hv_MapClassIDs)
        {
            GetDictTuple(hv_EvalParams, "class_id_mapping", &hv_ClsIdToClsIdx);
            hv_NumClasses = (hv_ClsIdToClsIdx.TupleMax())+1;
        }
    }
    else
    {
        //Get the tuples for TP/FP/FN
        GetDictTuple(hv_RunningMeasures, "tp", &hv_TP);
        GetDictTuple(hv_RunningMeasures, "fp", &hv_FP);
        GetDictTuple(hv_RunningMeasures, "fn", &hv_FN);
    }
    //
    //Loop over images, i.e. sample dictionaries.
    {
        HTuple end_val60 = (hv_Samples.TupleLength())-1;
        HTuple step_val60 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val60, step_val60); hv_SampleIndex += step_val60)
        {
            //Get annotation.
            GetDictObject(&ho_Annot, HTuple(hv_Samples[hv_SampleIndex]), "segmentation_image");
            //Get result.
            GetDictObject(&ho_Result, HTuple(hv_Results[hv_SampleIndex]), hv_ResultKey);
            //
            //Update the measures.
            if (0 != hv_CalcConfMatrix)
            {
                //Get the ground truth and predicted class IDs of all pixels.
                GetRegionPoints(ho_Annot, &hv_Rows, &hv_Columns);
                GetGrayval(ho_Annot, hv_Rows, hv_Columns, &hv_AnnotVals);
                GetGrayval(ho_Result, hv_Rows, hv_Columns, &hv_ResultVals);
                //Map the class IDs to class indices.
                if (0 != hv_MapClassIDs)
                {
                    hv_AnnotVals = HTuple(hv_ClsIdToClsIdx[hv_AnnotVals]);
                    hv_ResultVals = HTuple(hv_ClsIdToClsIdx[hv_ResultVals]);
                }
                //The ground truth and predicted IDs are accumulated
                //such that each confusion pair (class_i <-> class_j) gets a unique value.
                hv_ConfTuple = (hv_NumClasses*hv_AnnotVals)+hv_ResultVals;
                //Compute the histogram of this confusion tuple.
                TupleHistoRange(hv_ConfTuple, 0, (hv_NumClasses*hv_NumClasses)-1, hv_NumClasses*hv_NumClasses,
                                &hv_ConfHist, &hv_BinSize);
                CreateMatrix(hv_NumClasses, hv_NumClasses, hv_ConfHist, &hv_ConfMatrixTmp);
                TransposeMatrix(hv_ConfMatrixTmp, &hv_ConfMatrixTmp);
                AddMatrix(hv_ConfMatrix, hv_ConfMatrixTmp, &hv_ConfMatrix);
            }
            else
            {
                //Get the ignore region.
                GenEmptyRegion(&ho_ClsIgnore);
                {
                    HTuple end_val88 = (hv_IgnoreClassIDs.TupleLength())-1;
                    HTuple step_val88 = 1;
                    for (hv_IgnoreIndex=0; hv_IgnoreIndex.Continue(end_val88, step_val88); hv_IgnoreIndex += step_val88)
                    {
                        Threshold(ho_Annot, &ho_ClsIgnoreTmp, HTuple(hv_IgnoreClassIDs[hv_IgnoreIndex]),
                                  HTuple(hv_IgnoreClassIDs[hv_IgnoreIndex]));
                        Union2(ho_ClsIgnore, ho_ClsIgnoreTmp, &ho_ClsIgnore);
                    }
                }
                //
                //Go through model classes.
                {
                    HTuple end_val94 = (hv_ClassIDs.TupleLength())-1;
                    HTuple step_val94 = 1;
                    for (hv_ClsIndex=0; hv_ClsIndex.Continue(end_val94, step_val94); hv_ClsIndex += step_val94)
                    {
                        hv_ClsId = HTuple(hv_ClassIDs[hv_ClsIndex]);
                        hv_ClsIdRes = HTuple(hv_ClassIDsResult[hv_ClsIndex]);
                        //Get the annotated region for this class.
                        Threshold(ho_Annot, &ho_ClsAnnot, hv_ClsId, hv_ClsId);
                        //Get the result region for this class.
                        Threshold(ho_Result, &ho_ClsResult, hv_ClsIdRes, hv_ClsIdRes);
                        //The pixels in the ignore region should not be considered.
                        Difference(ho_ClsResult, ho_ClsIgnore, &ho_ClsResult);
                        //Get TP/FP/FN.
                        Intersection(ho_ClsAnnot, ho_ClsResult, &ho_TPReg);
                        Difference(ho_ClsResult, ho_ClsAnnot, &ho_FPReg);
                        //We define false negatives as pixels that have been labeled as this class,
                        //but not been correctly predicted.
                        Difference(ho_ClsAnnot, ho_ClsResult, &ho_FNReg);
                        //Get corresponding pixel numbers and update.
                        RegionFeatures(ho_TPReg, "area", &hv_ClsTP);
                        RegionFeatures(ho_FPReg, "area", &hv_ClsFP);
                        RegionFeatures(ho_FNReg, "area", &hv_ClsFN);
                        hv_TP[hv_ClsIndex] = HTuple(hv_TP[hv_ClsIndex])+hv_ClsTP;
                        hv_FP[hv_ClsIndex] = HTuple(hv_FP[hv_ClsIndex])+hv_ClsFP;
                        hv_FN[hv_ClsIndex] = HTuple(hv_FN[hv_ClsIndex])+hv_ClsFN;
                    }
                }
            }
        }
    }
    //
    //Update running measures.
    if (0 != hv_CalcConfMatrix)
    {
        SetDictTuple(hv_RunningMeasures, "pixel_confusion_matrix", hv_ConfMatrix);
    }
    else
    {
        SetDictTuple(hv_RunningMeasures, "tp", hv_TP);
        SetDictTuple(hv_RunningMeasures, "fp", hv_FP);
        SetDictTuple(hv_RunningMeasures, "fn", hv_FN);
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Update running measures for a region-based evaluation.
void HalxAI:: update_running_region_measures (HTuple hv_Samples, HTuple hv_Results, HTuple hv_EvalParams,
                                              HTuple hv_RunningMeasures)
{

    // Local iconic variables
    HObject  ho_Annot, ho_Result, ho_ClsAnnot, ho_ClsResult;
    HObject  ho_ClsAnnotConnected, ho_ClsAnnotSelected, ho_RegionIntersection;

    // Local control variables
    HTuple  hv_Measures, hv_CalcRegionMeasures, hv_ClassIDs;
    HTuple  hv_GrippingMapExists, hv_ResultKey, hv_ClassIDsResult;
    HTuple  hv_SampleIndex, hv_ClsIndex, hv_ClsId, hv_ClsIdRes;
    HTuple  hv_NumRegions, hv_RegionIndex, hv_AreaIntersection;
    HTuple  hv_AreaGroundtruth, hv_RegionOverlap;

    //
    //This procedure updates the RunningMeasures for a region-
    //based evaluation for 3D Gripping Point Detection.
    //These measures are stored in the dictionary RunningMeasures
    //and updated by incorporating the Results the model obtained
    //for the Samples.
    //
    //Check if we need to compute any region measures.
    GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
    hv_CalcRegionMeasures = HTuple(int((hv_Measures.TupleFind("mean_pro"))>-1)).TupleOr(int((hv_Measures.TupleFind("all"))>-1));
    if (0 != (hv_CalcRegionMeasures.TupleNot()))
    {
        return;
    }
    //
    //Get the class IDs.
    GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
    //
    //Check and set result type and class IDs.
    GetDictParam(HTuple(hv_Results[0]), "key_exists", "gripping_map", &hv_GrippingMapExists);
    if (0 != hv_GrippingMapExists)
    {
        hv_ResultKey = "gripping_map";
        //Since the result is a binary gripping map, the class ID
        //is always 1.
        hv_ClassIDsResult = 1;
    }
    else
    {
        throw HException("No result available for evaluation");
    }
    //
    //Loop over images, i.e. sample dictionaries.
    {
        HTuple end_val29 = (hv_Samples.TupleLength())-1;
        HTuple step_val29 = 1;
        for (hv_SampleIndex=0; hv_SampleIndex.Continue(end_val29, step_val29); hv_SampleIndex += step_val29)
        {
            //Get annotation.
            GetDictObject(&ho_Annot, HTuple(hv_Samples[hv_SampleIndex]), "segmentation_image");
            //Get result.
            GetDictObject(&ho_Result, HTuple(hv_Results[hv_SampleIndex]), hv_ResultKey);
            //
            //Go through model classes.
            {
                HTuple end_val36 = (hv_ClassIDs.TupleLength())-1;
                HTuple step_val36 = 1;
                for (hv_ClsIndex=0; hv_ClsIndex.Continue(end_val36, step_val36); hv_ClsIndex += step_val36)
                {
                    hv_ClsId = HTuple(hv_ClassIDs[hv_ClsIndex]);
                    hv_ClsIdRes = HTuple(hv_ClassIDsResult[hv_ClsIndex]);
                    //Get the annotated region for this class.
                    Threshold(ho_Annot, &ho_ClsAnnot, hv_ClsId, hv_ClsId);
                    //Get the result region for this class.
                    Threshold(ho_Result, &ho_ClsResult, hv_ClsIdRes, hv_ClsIdRes);
                    //
                    Connection(ho_ClsAnnot, &ho_ClsAnnotConnected);
                    SelectShape(ho_ClsAnnotConnected, &ho_ClsAnnotConnected, "area", "and", 1,
                                "max");
                    CountObj(ho_ClsAnnotConnected, &hv_NumRegions);
                    {
                        HTuple end_val47 = hv_NumRegions;
                        HTuple step_val47 = 1;
                        for (hv_RegionIndex=1; hv_RegionIndex.Continue(end_val47, step_val47); hv_RegionIndex += step_val47)
                        {
                            SelectObj(ho_ClsAnnotConnected, &ho_ClsAnnotSelected, hv_RegionIndex);
                            Intersection(ho_ClsResult, ho_ClsAnnotSelected, &ho_RegionIntersection);
                            RegionFeatures(ho_RegionIntersection, "area", &hv_AreaIntersection);
                            RegionFeatures(ho_ClsAnnotSelected, "area", &hv_AreaGroundtruth);
                            hv_RegionOverlap = (hv_AreaIntersection.TupleReal())/(hv_AreaGroundtruth.TupleReal());
                            SetDictTupleAt(hv_RunningMeasures, "gt_overlap", hv_ClsIndex, HTuple((hv_RunningMeasures.TupleGetDictTuple("gt_overlap"))[hv_ClsIndex])+hv_RegionOverlap);
                            SetDictTupleAt(hv_RunningMeasures, "num_gt_regions", hv_ClsIndex, HTuple((hv_RunningMeasures.TupleGetDictTuple("num_gt_regions"))[hv_ClsIndex])+1);
                        }
                    }
                }
            }
        }
    }
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Update model parameters according to the change strategies.
void HalxAI:: update_train_dl_model_change_strategies (HTuple hv_DLModelHandle, HTuple hv_ChangeStrategyData,
                                                       HTuple hv_Epoch)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_Enabled, hv_ChangeStrategies, hv_SolverType;
    HTuple  hv_Index, hv_ChangeStrategy, hv_ModelParam, hv_Epochs;
    HTuple  hv_Values, hv_Initial, hv_Greater, hv_ValueIndex;
    HTuple  hv_Value, hv_InternalCurrentExists, hv_InternalCurrent;
    HTuple  hv_ScaleThreshold, hv_CurrentLR, hv_LRChangeRatio;
    HTuple  hv_PreviousMomentumExists, hv_CurrentMomentum, hv_AdaptedMomentum;
    HTuple  hv_AdaptedMomentumExists, hv_PreviousMomentum;

    //
    //This procedure updates all parameters according to the change strategies
    //with respect to the current iteration.
    //
    GetDictTuple(hv_ChangeStrategyData, "enabled", &hv_Enabled);
    if (0 != (hv_Enabled.TupleNot()))
    {
        return;
    }
    //
    GetDictTuple(hv_ChangeStrategyData, "strategies", &hv_ChangeStrategies);
    GetDlModelParam(hv_DLModelHandle, "solver_type", &hv_SolverType);
    //
    //Update the parameter of each strategy.
    {
        HTuple end_val13 = (hv_ChangeStrategies.TupleLength())-1;
        HTuple step_val13 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val13, step_val13); hv_Index += step_val13)
        {
            hv_ChangeStrategy = HTuple(hv_ChangeStrategies[hv_Index]);
            GetDictTuple(hv_ChangeStrategy, "model_param", &hv_ModelParam);
            GetDictTuple(hv_ChangeStrategy, "epochs", &hv_Epochs);
            GetDictTuple(hv_ChangeStrategy, "values", &hv_Values);
            GetDictTuple(hv_ChangeStrategy, "initial_value", &hv_Initial);
            //Epochs defines at which epoch the change happens. Its sorting is enforced during initialization.
            hv_Greater = hv_Epoch.TupleGreaterEqualElem(hv_Epochs);
            TupleFindLast(hv_Greater, 1, &hv_ValueIndex);
            if (0 != (int(hv_ValueIndex==-1)))
            {
                hv_Value = hv_Initial;
            }
            else
            {
                hv_Value = HTuple(hv_Values[hv_ValueIndex]);
            }
            //Check current value and only make changes if the value changed.
            GetDictParam(hv_ChangeStrategy, "key_exists", "internal_current_value", &hv_InternalCurrentExists);
            if (0 != hv_InternalCurrentExists)
            {
                GetDictTuple(hv_ChangeStrategy, "internal_current_value", &hv_InternalCurrent);
            }
            else
            {
                GetDlModelParam(hv_DLModelHandle, hv_ModelParam, &hv_InternalCurrent);
            }
            //If the current value differs from the new value we change it.
            if (0 != (int(((hv_InternalCurrent.TupleNotEqualElem(hv_Value)).TupleSum())>0)))
            {
                //If the changed model parameter is the learning rate, we also change the momentum
                //to adapt the scale of the previous update.
                if (0 != (int(hv_ModelParam==HTuple("learning_rate"))))
                {
                    //Get the threshold.
                    GetDictTuple(hv_ChangeStrategy, "scale_momentum_threshold", &hv_ScaleThreshold);
                    if (0 != (HTuple(int((hv_ScaleThreshold.TupleLength())>0)).TupleAnd(int(hv_SolverType==HTuple("sgd")))))
                    {
                        GetDlModelParam(hv_DLModelHandle, hv_ModelParam, &hv_CurrentLR);
                        //Check if the change is larger than the specified threshold.
                        hv_LRChangeRatio = ((hv_Value.TupleReal())/(hv_CurrentLR.TupleMax2(1e-10))).TupleMax2((hv_CurrentLR.TupleReal())/(hv_Value.TupleMax2(1e-10)));
                        if (0 != (HTuple(int(hv_LRChangeRatio>hv_ScaleThreshold)).TupleAnd(int(hv_CurrentLR>1e-7))))
                        {
                            GetDictParam(hv_ChangeStrategy, "key_exists", "previous_momentum", &hv_PreviousMomentumExists);
                            if (0 != hv_PreviousMomentumExists)
                            {
                                GetDictTuple(hv_ChangeStrategy, "previous_momentum", &hv_CurrentMomentum);
                            }
                            else
                            {
                                GetDlModelParam(hv_DLModelHandle, "momentum", &hv_CurrentMomentum);
                            }
                            hv_AdaptedMomentum = (hv_Value/(hv_CurrentLR.TupleReal()))*hv_CurrentMomentum;
                            SetDlModelParam(hv_DLModelHandle, "momentum", hv_AdaptedMomentum);
                            //In the next iteration the momentum has to be set back.
                            SetDictTuple(hv_ChangeStrategy, "adapted_momentum", 1);
                            SetDictTuple(hv_ChangeStrategy, "previous_momentum", hv_CurrentMomentum);
                        }
                    }
                }
                SetDlModelParam(hv_DLModelHandle, hv_ModelParam, hv_Value);
            }
            else if (0 != (HTuple(int(hv_ModelParam==HTuple("learning_rate"))).TupleAnd(int(hv_SolverType==HTuple("sgd")))))
            {
                //Get the threshold.
                GetDictTuple(hv_ChangeStrategy, "scale_momentum_threshold", &hv_ScaleThreshold);
                if (0 != (int((hv_ScaleThreshold.TupleLength())>0)))
                {
                    //Set the momentum back if it was adapted in the previous iteration.
                    GetDictParam(hv_ChangeStrategy, "key_exists", "adapted_momentum", &hv_AdaptedMomentumExists);
                    if (0 != hv_AdaptedMomentumExists)
                    {
                        GetDictTuple(hv_ChangeStrategy, "adapted_momentum", &hv_AdaptedMomentum);
                        if (0 != hv_AdaptedMomentum)
                        {
                            GetDictTuple(hv_ChangeStrategy, "previous_momentum", &hv_PreviousMomentum);
                            SetDlModelParam(hv_DLModelHandle, "momentum", hv_PreviousMomentum);
                            SetDictTuple(hv_ChangeStrategy, "adapted_momentum", 0);
                            RemoveDictKey(hv_ChangeStrategy, "previous_momentum");
                        }
                    }
                }
            }
            //Store the new internal current value.
            SetDictTuple(hv_ChangeStrategy, "internal_current_value", hv_Value);
        }
    }
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Serialize the model if a strategy applies to the current training status.
void HalxAI:: update_train_dl_model_serialization (HTuple hv_TrainParam, HTuple hv_SerializationData,
                                                   HTuple hv_Iteration, HTuple hv_NumIterations, HTuple hv_Epoch, HTuple hv_EvaluationResult,
                                                   HTuple hv_EvaluationOptimizationMethod, HTuple hv_DLModelHandle, HTuple hv_TrainInfos,
                                                   HTuple hv_EvaluationInfos)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_RawData, hv_Types, hv_Strategies, hv_Index;
    HTuple  hv_Type, hv_Data, hv_Strategy, hv_EvaluationComparisonKeys;
    HTuple  hv_Value, hv_ValidEvaluationKeys, hv_CurrentBest;
    HTuple  hv_IsNewBest, hv_FilenameModel, hv_FilenameMetaData;
    HTuple  hv_Epochs, hv_Indices, hv_LastIndex;

    //
    //Serialize the model if a strategy applies to the current training status.
    //
    GetDictTuple(hv_SerializationData, "raw_data", &hv_RawData);
    GetDictTuple(hv_SerializationData, "types", &hv_Types);
    GetDictTuple(hv_SerializationData, "strategies", &hv_Strategies);
    //
    {
        HTuple end_val7 = (hv_Types.TupleLength())-1;
        HTuple step_val7 = 1;
        for (hv_Index=0; hv_Index.Continue(end_val7, step_val7); hv_Index += step_val7)
        {
            //
            hv_Type = HTuple(hv_Types[hv_Index]);
            hv_Data = HTuple(hv_RawData[hv_Index]);
            hv_Strategy = HTuple(hv_Strategies[hv_Index]);
            //
            if (0 != (int(hv_Type==HTuple("best"))))
            {
                //If there is no new evaluation result, we will not serialize.
                if (0 != (int((hv_EvaluationResult.TupleLength())==0)))
                {
                    continue;
                }
                //Get a single value which is combined based on the given evaluation keys.
                GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
                reduce_dl_evaluation_result(hv_EvaluationResult, hv_EvaluationComparisonKeys,
                                            &hv_Value, &hv_ValidEvaluationKeys);
                GetDictTuple(hv_Data, "best_value", &hv_CurrentBest);
                if (0 != (int(hv_CurrentBest==-1)))
                {
                    hv_IsNewBest = 1;
                }
                else if (0 != (int(hv_EvaluationOptimizationMethod==HTuple("min"))))
                {
                    hv_IsNewBest = int(hv_Value<hv_CurrentBest);
                }
                else
                {
                    hv_IsNewBest = int(hv_Value>hv_CurrentBest);
                }
                if (0 != hv_IsNewBest)
                {
                    SetDictTuple(hv_Data, "best_value", hv_Value);
                    serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, hv_Value,
                                                          hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, &hv_FilenameMetaData);
                }
            }
            else if (0 != (int(hv_Type==HTuple("final"))))
            {
                if (0 != (int(hv_Iteration==(hv_NumIterations-1))))
                {
                    //Serialize final model.
                    serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, HTuple(),
                                                          hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, &hv_FilenameMetaData);
                }
            }
            else if (0 != (HTuple(int(hv_Type==HTuple("epochs"))).TupleOr(int(hv_Type==HTuple("current")))))
            {
                //Check if the specified epoch is reached.
                GetDictTuple(hv_Data, "epochs", &hv_Epochs);
                TupleFindLast(hv_Epoch.TupleLessElem(hv_Epochs), 0, &hv_Indices);
                //Also check that the last saved epoch is not the same.
                GetDictTuple(hv_Data, "last_epoch_index", &hv_LastIndex);
                if (0 != (HTuple(int(hv_Type==HTuple("current"))).TupleAnd(int((hv_EvaluationResult.TupleLength())>0))))
                {
                    //For type current we also write every EvaluationIntervalEpochs epochs.
                    serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, HTuple(),
                                                          hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel, &hv_FilenameMetaData);
                }
                else if (0 != (int((hv_Indices.TupleLength())>0)))
                {
                    //
                    if (0 != (HTuple(int(HTuple(hv_Indices[0])>-1)).TupleAnd(int(HTuple(hv_Indices[0])!=hv_LastIndex))))
                    {
                        SetDictTuple(hv_Data, "last_epoch_index", HTuple(hv_Indices[0]));
                        //Serialize final model.
                        serialize_train_dl_model_intermediate(hv_DLModelHandle, hv_Epoch, HTuple(),
                                                              hv_Strategy, hv_TrainInfos, hv_EvaluationInfos, &hv_FilenameModel,
                                                              &hv_FilenameMetaData);
                    }
                }
            }
        }
    }
    //
    return;
}

// Chapter: Graphics / Window
// Short Description: Set and return meta information to display images correctly.
void HalxAI:: update_window_meta_information (HTuple hv_WindowHandle, HTuple hv_WidthImage,
                                              HTuple hv_HeightImage, HTuple hv_WindowRow1, HTuple hv_WindowColumn1, HTuple hv_MapColorBarWidth,
                                              HTuple hv_MarginBottom, HTuple *hv_WindowImageRatioHeight, HTuple *hv_WindowImageRatioWidth,
                                              HTuple *hv_SetPartRow2, HTuple *hv_SetPartColumn2, HTuple *hv_PrevWindowCoordinatesOut)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv__, hv_WindowWidth, hv_WindowHeight;
    HTuple  hv_WindowRow2, hv_WindowColumn2, hv_WindowRatio;
    HTuple  hv_ImageRow2, hv_ImageColumn2, hv_ImageRatio, hv_ImageWindowRatioHeight;
    HTuple  hv_ImageRow2InWindow, hv_ImageCol2InWindow;

    //
    //This procedure sets and returns meta information to display images correctly.
    //
    //Set part for the image to be displayed later and adapt window size (+ MarginBottom + MapColorBarWidth).
    GetWindowExtents(hv_WindowHandle, &hv__, &hv__, &hv_WindowWidth, &hv_WindowHeight);
    (*hv_WindowImageRatioHeight) = hv_WindowHeight/(hv_HeightImage*1.0);
    (*hv_WindowImageRatioWidth) = hv_WindowWidth/(hv_WidthImage*1.0);
    //
    //Set window part such that image is displayed undistorted.
    hv_WindowRow2 = hv_WindowHeight;
    hv_WindowColumn2 = hv_WindowWidth;
    hv_WindowRatio = hv_WindowColumn2/(hv_WindowRow2*1.0);
    //
    hv_ImageRow2 = hv_HeightImage+(hv_MarginBottom/(*hv_WindowImageRatioHeight));
    hv_ImageColumn2 = hv_WidthImage+(hv_MapColorBarWidth/(*hv_WindowImageRatioWidth));
    hv_ImageRatio = hv_ImageColumn2/(hv_ImageRow2*1.0);
    if (0 != (int(hv_ImageRatio>hv_WindowRatio)))
    {
        //
        //Extend image until right window border.
        (*hv_SetPartColumn2) = hv_ImageColumn2;
        hv_ImageWindowRatioHeight = hv_ImageColumn2/(hv_WindowColumn2*1.0);
        hv_ImageRow2InWindow = hv_ImageRow2/hv_ImageWindowRatioHeight;
        (*hv_SetPartRow2) = hv_ImageRow2+((hv_WindowRow2-hv_ImageRow2InWindow)/(*hv_WindowImageRatioWidth));
    }
    else
    {
        //
        //Extend image until bottom of window.
        (*hv_SetPartRow2) = hv_ImageRow2;
        hv_ImageWindowRatioHeight = hv_ImageRow2/(hv_WindowRow2*1.0);
        hv_ImageCol2InWindow = hv_ImageColumn2/hv_ImageWindowRatioHeight;
        (*hv_SetPartColumn2) = hv_ImageColumn2+((hv_WindowColumn2-hv_ImageCol2InWindow)/(*hv_WindowImageRatioHeight));
    }
    if (HDevWindowStack::IsOpen())
        SetPart(HDevWindowStack::GetActive(),0, 0, (*hv_SetPartRow2)-1, (*hv_SetPartColumn2)-1);
    //
    //Return the coordinates of the new window.
    (*hv_PrevWindowCoordinatesOut).Clear();
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowRow1);
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowColumn1);
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowWidth);
    (*hv_PrevWindowCoordinatesOut).Append(hv_WindowHeight);
    //
    return;
}

// Chapter: Deep Learning / Model
// Short Description: Check that all given entries in EvalParams are valid.
void HalxAI:: validate_evaluation_param (HTuple hv_EvalParams, HTuple *hv_Valid, HTuple *hv_Exception)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ClassIDsExist, hv_ClassIDs, hv_NumClassesExist;
    HTuple  hv_NumClasses, hv_EvalInstancesExists, hv_EvaluationTypeExists;
    HTuple  hv_EvaluationType, hv_Indices, hv_MeasuresExists;
    HTuple  hv_Measures, hv_ValidMeasures, hv_Ks, hv_KeysExist;
    HTuple  hv_ClassNames, hv_ClassesToEvaluate, hv_ClassIDsToEvaluate;
    HTuple  hv_IouThreshExists, hv_IouThresholds, hv_MaxNumDetectionsExists;
    HTuple  hv_MaxNumDetections, hv_AreaRangesExist, hv_AreaRanges;
    HTuple  hv_AreaKeysExist, hv_AreaNames, hv_MinAreas, hv_MaxAreas;
    HTuple  hv_InstanceTypeExists, hv_InstanceType, hv_ValidInstanceTypes;
    HTuple  hv_AllocationBlockLengthExists, hv_AllocationBlockLength;
    HTuple  hv_DetailedEvaluationExists, hv_DetailedEvaluation;
    HTuple  hv_KeyExists, hv_InterpolatePRCurves, hv_IgnoreClassIDsExist;
    HTuple  hv_ValidMeasuresString, hv_Idx, hv_ValidMeasure;

    //
    //This procedure checks if the dictionary EvalParams
    //contains all necessary parameters and if they are valid (type, range, ...).
    //
    (*hv_Valid) = 0;
    (*hv_Exception) = "";
    //Check class IDs.
    GetDictParam(hv_EvalParams, "key_exists", "class_ids", &hv_ClassIDsExist);
    if (0 != (hv_ClassIDsExist.TupleNot()))
    {
        (*hv_Exception) = "The evaluation parameters need a key-value pair for 'class_ids'";
        return;
    }
    else
    {
        GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
        if (0 != (int((hv_ClassIDs.TupleLength())<1)))
        {
            (*hv_Exception) = "'class_ids' should have at least length 1";
            return;
        }
        if (0 != (int((hv_ClassIDs.TupleIsIntElem())!=HTuple(hv_ClassIDs.TupleLength(),1))))
        {
            (*hv_Exception) = "'class_ids' should be of type int";
            return;
        }
        if (0 != (int(((hv_ClassIDs.TupleLessElem(0)).TupleFind(1))>-1)))
        {
            (*hv_Exception) = "'class_ids' should be positive or zero";
            return;
        }
    }
    //Check the entry num_classes.
    GetDictParam(hv_EvalParams, "key_exists", "num_classes", &hv_NumClassesExist);
    if (0 != (hv_NumClassesExist.TupleNot()))
    {
        (*hv_Exception) = "The evaluation parameters need a key-value pair for 'num_classes'";
        return;
    }
    else
    {
        GetDictTuple(hv_EvalParams, "num_classes", &hv_NumClasses);
        if (0 != (int((hv_NumClasses.TupleLength())!=1)))
        {
            (*hv_Exception) = "'num_classes' should have length 1";
            return;
        }
        if (0 != (int((hv_NumClasses.TupleType())!=(HTuple(HTuple(1).TupleInt()).TupleType()))))
        {
            (*hv_Exception) = "'num_classes' should be of type int";
            return;
        }
        if (0 != (int(hv_NumClasses<1)))
        {
            (*hv_Exception) = "'num_classes' should be at least 1";
            return;
        }
    }
    //Check that num_classes is equal to |class_ids|.
    if (0 != (int(hv_NumClasses!=(hv_ClassIDs.TupleLength()))))
    {
        (*hv_Exception) = "'num_classes' has to be set to the number of 'class_ids'";
        return;
    }
    //Check the entry 'evaluate_instances'.
    GetDictParam(hv_EvalParams, "key_exists", "evaluate_instances", &hv_EvalInstancesExists);
    if (0 != (hv_EvalInstancesExists.TupleNot()))
    {
        (*hv_Exception) = "The evaluation parameters need a key-value pair for 'evaluate_instances'";
        return;
    }
    //Check the entry 'evaluation_type'.
    GetDictParam(hv_EvalParams, "key_exists", "evaluation_type", &hv_EvaluationTypeExists);
    if (0 != (hv_EvaluationTypeExists.TupleNot()))
    {
        (*hv_Exception) = "The evaluation parameters need a key-value pair for 'evaluation_type'";
        return;
    }
    else
    {
        GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
        TupleFind((((((((HTuple("3d_gripping_point_detection").Append("anomaly_detection")).Append("classification")).Append("detection")).Append("gc_anomaly_detection")).Append("ocr_recognition")).Append("ocr_detection")).Append("segmentation")),
                  hv_EvaluationType, &hv_Indices);
        if (0 != (HTuple(int(hv_Indices==-1)).TupleOr(int(hv_Indices==HTuple()))))
        {
            (*hv_Exception) = "Invalid entry for 'evaluation_type': "+hv_EvaluationType;
            return;
        }
    }
    //Check the entry 'measures'.
    GetDictParam(hv_EvalParams, "key_exists", "measures", &hv_MeasuresExists);
    if (0 != (hv_MeasuresExists.TupleNot()))
    {
        (*hv_Exception) = "The evaluation parameters need a key-value pair for 'measures'";
        return;
    }
    else
    {
        GetDictTuple(hv_EvalParams, "measures", &hv_Measures);
        if (0 != (int((hv_Measures.TupleLength())==0)))
        {
            (*hv_Exception) = "'measures' should contain at least one entry";
            return;
        }
    }
    //Check evaluation type specific entries of EvalParams.
    GetDictTuple(hv_EvalParams, "evaluation_type", &hv_EvaluationType);
    if (0 != (int(hv_EvaluationType==HTuple("3d_gripping_point_detection"))))
    {
        //Pixel- and region-based evaluation.
        get_valid_pixel_measures(hv_EvaluationType, &hv_ValidMeasures);
        hv_ValidMeasures = hv_ValidMeasures.TupleConcat(((((HTuple("mean_pro").Append("gripping_point_precision")).Append("gripping_point_recall")).Append("gripping_point_f_score")).Append("all")));
    }
    else if (0 != (HTuple(int(hv_EvaluationType==HTuple("anomaly_detection"))).TupleOr(int(hv_EvaluationType==HTuple("gc_anomaly_detection")))))
    {
        //
        //Check for correct number of classes.
        if (0 != (int((hv_ClassIDs.TupleLength())!=2)))
        {
            throw HException("The number of classes must be 2 for model type 'anomaly_detection' or 'gc_anomaly_detection'.");
        }
        //
        hv_ValidMeasures.Clear();
        hv_ValidMeasures[0] = "anomaly_score_histogram";
        hv_ValidMeasures[1] = "precision";
        hv_ValidMeasures[2] = "recall";
        hv_ValidMeasures[3] = "absolute_confusion_matrix";
        hv_ValidMeasures[4] = "relative_confusion_matrix";
        hv_ValidMeasures[5] = "all";
    }
    else if (0 != (int(hv_EvaluationType==HTuple("classification"))))
    {
        TupleGenSequence(1, hv_ClassIDs.TupleLength(), 1, &hv_Ks);
        hv_ValidMeasures.Clear();
        hv_ValidMeasures[0] = "all";
        hv_ValidMeasures.Append(("top"+hv_Ks)+"_error");
        hv_ValidMeasures = hv_ValidMeasures.TupleConcat(((((HTuple("precision").Append("recall")).Append("f_score")).Append("absolute_confusion_matrix")).Append("relative_confusion_matrix")));
        //
        //Check if not both of the two options to specify the evaluated classes are chosen.
        GetDictParam(hv_EvalParams, "key_exists", (HTuple("class_names_to_evaluate").Append("class_ids_to_evaluate")),
                     &hv_KeysExist);
        if (0 != (int((hv_KeysExist.TupleSum())==2)))
        {
            (*hv_Exception) = "No more than one option of 'class_names_to_evaluate' and 'class_ids_to_evaluate' is allowed";
            return;
        }
        if (0 != (HTuple(hv_KeysExist[0])))
        {
            GetDictTuple(hv_EvalParams, "class_names", &hv_ClassNames);
            GetDictTuple(hv_EvalParams, "class_names_to_evaluate", &hv_ClassesToEvaluate);
            if (0 != (int((hv_ClassesToEvaluate.TupleDifference(hv_ClassNames.TupleConcat("global")))!=HTuple())))
            {
                (*hv_Exception) = "Invalid entry in 'class_names_to_evaluate'";
                return;
            }
        }
        if (0 != (HTuple(hv_KeysExist[1])))
        {
            GetDictTuple(hv_EvalParams, "class_ids", &hv_ClassIDs);
            GetDictTuple(hv_EvalParams, "class_ids_to_evaluate", &hv_ClassIDsToEvaluate);
            if (0 != (int((hv_ClassIDsToEvaluate.TupleDifference(hv_ClassIDs.TupleConcat("global")))!=HTuple())))
            {
                (*hv_Exception) = "Invalid entry in 'class_ids_to_evaluate'";
                return;
            }
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("detection"))))
    {
        //Instance-based evaluation.
        //Add instance measures.
        hv_ValidMeasures.Clear();
        hv_ValidMeasures[0] = "all";
        hv_ValidMeasures[1] = "mean_ap";
        //
        //Check if the entry 'iou_threshold' is present.
        GetDictParam(hv_EvalParams, "key_exists", "iou_threshold", &hv_IouThreshExists);
        if (0 != (hv_IouThreshExists.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'iou_threshold'";
            return;
        }
        else
        {
            GetDictTuple(hv_EvalParams, "iou_threshold", &hv_IouThresholds);
            //Check the length of 'iou_threshold'.
            if (0 != (int((hv_IouThresholds.TupleLength())<1)))
            {
                (*hv_Exception) = "'iou_threshold' is empty";
                return;
            }
            if (0 != (int((hv_IouThresholds.TupleIsRealElem())!=HTuple(hv_IouThresholds.TupleLength(),1))))
            {
                (*hv_Exception) = "'iou_threshold' should be of type real";
                return;
            }
            //Check if the IoU thresholds are within (0.0, 1.0).
            if (0 != (HTuple(int((hv_IouThresholds.TupleMin())<=0.0)).TupleOr(int((hv_IouThresholds.TupleMax())>=1.0))))
            {
                (*hv_Exception) = HTuple("Invalid 'iou_threshold', not in range (0.0, 1.0)");
                return;
            }
        }
        //
        //Check if the entry 'max_num_detections' is present.
        GetDictParam(hv_EvalParams, "key_exists", "max_num_detections", &hv_MaxNumDetectionsExists);
        if (0 != (hv_MaxNumDetectionsExists.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'max_num_detections'";
            return;
        }
        else
        {
            GetDictTuple(hv_EvalParams, "max_num_detections", &hv_MaxNumDetections);
            //Check the length of 'max_num_detections'.
            if (0 != (int((hv_MaxNumDetections.TupleLength())<1)))
            {
                (*hv_Exception) = "'max_num_detections' is empty";
                return;
            }
            if (0 != (int((hv_MaxNumDetections.TupleIsIntElem())!=HTuple(hv_MaxNumDetections.TupleLength(),1))))
            {
                (*hv_Exception) = "'max_num_detections' should be of type int";
                return;
            }
            //Check if 'max_num_detections' is -1 (to use all detections) or positive.
            if (0 != (HTuple(int((hv_MaxNumDetections.TupleMin())<-1)).TupleOr(int((hv_MaxNumDetections.TupleFind(0))>-1))))
            {
                (*hv_Exception) = "'max_num_detections' should be -1 or positive";
                return;
            }
        }
        //
        //Check if the entry 'area_ranges' is present.
        GetDictParam(hv_EvalParams, "key_exists", "area_ranges", &hv_AreaRangesExist);
        if (0 != (hv_AreaRangesExist.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'area_ranges'";
            return;
        }
        else
        {
            //Check if the entry 'area_ranges' is a dict.
            GetDictTuple(hv_EvalParams, "area_ranges", &hv_AreaRanges);
            if (0 != (int((hv_AreaRanges.TupleSemType())!=HTuple("dict"))))
            {
                (*hv_Exception) = "'area_ranges' must be a dict";
                return;
            }
            //Check that the necessary keys exist.
            GetDictParam(hv_AreaRanges, "key_exists", ((HTuple("name").Append("min")).Append("max")),
                         &hv_AreaKeysExist);
            if (0 != (HTuple(hv_AreaKeysExist[0]).TupleNot()))
            {
                (*hv_Exception) = "'area_ranges' need a key-value pair for 'name'";
                return;
            }
            if (0 != (HTuple(hv_AreaKeysExist[1]).TupleNot()))
            {
                (*hv_Exception) = "'area_ranges' need a key-value pair for 'min'";
                return;
            }
            if (0 != (HTuple(hv_AreaKeysExist[2]).TupleNot()))
            {
                (*hv_Exception) = "'area_ranges' need a key-value pair for 'max'";
                return;
            }
            //Check the lengths of the area keys.
            GetDictTuple(hv_AreaRanges, "name", &hv_AreaNames);
            if (0 != (int((hv_AreaNames.TupleLength())<1)))
            {
                (*hv_Exception) = "'area_ranges': 'name' is empty";
                return;
            }
            GetDictTuple(hv_AreaRanges, "min", &hv_MinAreas);
            if (0 != (int((hv_MinAreas.TupleLength())<1)))
            {
                (*hv_Exception) = "'area_ranges': 'min' is empty";
                return;
            }
            GetDictTuple(hv_AreaRanges, "max", &hv_MaxAreas);
            if (0 != (int((hv_MaxAreas.TupleLength())<1)))
            {
                (*hv_Exception) = "'area_ranges': 'max' is empty";
                return;
            }
            if (0 != (HTuple(int((hv_AreaNames.TupleLength())!=(hv_MinAreas.TupleLength()))).TupleOr(int((hv_AreaNames.TupleLength())!=(hv_MaxAreas.TupleLength())))))
            {
                (*hv_Exception) = HTuple("'area_ranges': 'name', 'min' and 'max' must have the same length");
                return;
            }
            //Check values of min, max.
            if (0 != (int(((hv_MinAreas.TupleGreaterEqualElem(hv_MaxAreas)).TupleFind(1))>-1)))
            {
                (*hv_Exception) = "'area_ranges': 'min' must be elementwise smaller than 'max'";
                return;
            }
        }
        //
        //Check if instance-type is valid.
        GetDictParam(hv_EvalParams, "key_exists", "instance_type", &hv_InstanceTypeExists);
        if (0 != (hv_InstanceTypeExists.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'instance_type'";
            return;
        }
        else
        {
            GetDictTuple(hv_EvalParams, "instance_type", &hv_InstanceType);
            hv_ValidInstanceTypes.Clear();
            hv_ValidInstanceTypes[0] = "rectangle1";
            hv_ValidInstanceTypes[1] = "rectangle2";
            hv_ValidInstanceTypes[2] = "mask";
            if (0 != (int((hv_ValidInstanceTypes.TupleFind(hv_InstanceType))==-1)))
            {
                (*hv_Exception) = ("Invalid instance type '"+hv_InstanceType)+"'";
                return;
            }
        }
        //
        //Check if the entry 'allocation_block_length' is present and valid.
        GetDictParam(hv_EvalParams, "key_exists", "allocation_block_length", &hv_AllocationBlockLengthExists);
        if (0 != (hv_AllocationBlockLengthExists.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'allocation_block_length'";
            return;
        }
        else
        {
            GetDictTuple(hv_EvalParams, "allocation_block_length", &hv_AllocationBlockLength);
            //Check the length of 'allocation_block_length'.
            if (0 != (int((hv_AllocationBlockLength.TupleLength())!=1)))
            {
                (*hv_Exception) = "'allocation_block_length' should have length 1";
                return;
            }
            //Check the type of 'allocation_block_length'.
            if (0 != (int((hv_AllocationBlockLength.TupleType())!=(HTuple(HTuple(0).TupleInt()).TupleType()))))
            {
                (*hv_Exception) = "'allocation_block_length' should be of type int";
                return;
            }
            //Check if 'allocation_block_length' is larger than zero.
            if (0 != (int(hv_AllocationBlockLength<1)))
            {
                (*hv_Exception) = "'allocation_block_length' should be positive";
                return;
            }
        }
        //
        //Check if the entry 'detailed_evaluation' is valid if present.
        GetDictParam(hv_EvalParams, "key_exists", "detailed_evaluation", &hv_DetailedEvaluationExists);
        if (0 != (hv_DetailedEvaluationExists.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'detailed_evaluation'";
            return;
        }
        else
        {
            GetDictTuple(hv_EvalParams, "detailed_evaluation", &hv_DetailedEvaluation);
            //Check the length of 'detailed_evaluation'.
            if (0 != (int((hv_DetailedEvaluation.TupleLength())!=1)))
            {
                (*hv_Exception) = "'detailed_evaluation' should have length 1";
                return;
            }
            //Check the type of 'detailed_evaluation'.
            if (0 != (int((hv_DetailedEvaluation.TupleType())!=(HTuple(1).TupleType()))))
            {
                (*hv_Exception) = "'detailed_evaluation' should be of type int";
                return;
            }
            //Check if 'detailed_evaluation' is true or false.
            if (0 != (HTuple(int(hv_DetailedEvaluation!=0)).TupleAnd(int(hv_DetailedEvaluation!=1))))
            {
                (*hv_Exception) = "'detailed_evaluation' should be zero or one";
                return;
            }
        }
        //
        //Check if the entry 'interpolate_pr_curves' is valid if present.
        GetDictParam(hv_EvalParams, "key_exists", "interpolate_pr_curves", &hv_KeyExists);
        if (0 != (hv_KeyExists.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'interpolate_pr_curves'";
            return;
        }
        else
        {
            GetDictTuple(hv_EvalParams, "interpolate_pr_curves", &hv_InterpolatePRCurves);
            //Check the length of 'interpolate_pr_curves'.
            if (0 != (int((hv_InterpolatePRCurves.TupleLength())!=1)))
            {
                (*hv_Exception) = "'interpolate_pr_curves' should have length 1";
                return;
            }
            //Check the type of 'interpolate_pr_curves'.
            if (0 != (int((hv_InterpolatePRCurves.TupleType())!=(HTuple(1).TupleType()))))
            {
                (*hv_Exception) = "'interpolate_pr_curves' should be of type int";
                return;
            }
            //Check if 'interpolate_pr_curves' is true or false.
            if (0 != (HTuple(int(hv_InterpolatePRCurves!=0)).TupleAnd(int(hv_InterpolatePRCurves!=1))))
            {
                (*hv_Exception) = "'interpolate_pr_curves' should be zero or one";
                return;
            }
        }
        //
        //Add valid measure 'soap' if instance_type is 'rectangle2'.
        if (0 != (int(hv_InstanceType==HTuple("rectangle2"))))
        {
            hv_ValidMeasures = hv_ValidMeasures.TupleConcat("soap");
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("segmentation"))))
    {
        //Pixel-based evaluation.
        get_valid_pixel_measures(hv_EvaluationType, &hv_ValidMeasures);
        hv_ValidMeasures = hv_ValidMeasures.TupleConcat("all");
        //
        //Check if the entry 'ignore_class_ids' exists.
        GetDictParam(hv_EvalParams, "key_exists", "ignore_class_ids", &hv_IgnoreClassIDsExist);
        if (0 != (hv_IgnoreClassIDsExist.TupleNot()))
        {
            (*hv_Exception) = "The evaluation parameters need a key-value pair for 'ignore_class_ids'";
            return;
        }
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_recognition"))))
    {
        //OCR recognition evaluation.
        hv_ValidMeasures = "accuracy";
    }
    else if (0 != (int(hv_EvaluationType==HTuple("ocr_detection"))))
    {
        //OCR detection evaluation.
        hv_ValidMeasures.Clear();
        hv_ValidMeasures[0] = "all";
        hv_ValidMeasures[1] = "recall";
        hv_ValidMeasures[2] = "precision";
        hv_ValidMeasures[3] = "f_score";
        hv_ValidMeasures[4] = "soap";
    }
    else
    {
        (*hv_Exception) = "Unknown evaluation_type: "+hv_EvaluationType;
        return;
    }
    //Check measures.
    hv_ValidMeasuresString = HTuple(((hv_ValidMeasures.TupleLength())*2)-1,HTuple("','"));
    hv_ValidMeasuresString[HTuple::TupleGenSequence(0,(hv_ValidMeasuresString.TupleLength())-1,2)] = hv_ValidMeasures;
    hv_ValidMeasuresString = hv_ValidMeasuresString.TupleSum();
    {
        HTuple end_val342 = (hv_Measures.TupleLength())-1;
        HTuple step_val342 = 1;
        for (hv_Idx=0; hv_Idx.Continue(end_val342, step_val342); hv_Idx += step_val342)
        {
            hv_ValidMeasure = (hv_ValidMeasures.TupleFind(HTuple(hv_Measures[hv_Idx]))).TupleGreaterElem(-1);
            if (0 != (hv_ValidMeasure.TupleNot()))
            {
                (*hv_Exception) = ((("Invalid measure '"+HTuple(hv_Measures[hv_Idx]))+HTuple("', choose one of ['"))+hv_ValidMeasuresString)+"']";
                return;
            }
        }
    }
    //
    //Done with checks.
    (*hv_Valid) = 1;
    return;
}

// Local procedures
void HalxAI:: check_data_availability (HTuple hv_ExampleDataDir, HTuple hv_InitialModelFileName,
                                       HTuple hv_DLDatasetFileName)
{

    // Local control variables
    HTuple  hv_FileExists;

    //This procedure checks whether the required files are available.
    //
    FileExists(hv_ExampleDataDir, &hv_FileExists);
    if (0 != (hv_FileExists.TupleNot()))
    {
        throw HException(hv_ExampleDataDir+" does not exist. Please run part 1 of the example series.");
    }
    //
    FileExists(hv_InitialModelFileName, &hv_FileExists);
    if (0 != (hv_FileExists.TupleNot()))
    {
        throw HException(hv_InitialModelFileName+" does not exist. Please run part 1 of the example series.");
    }
    //
    FileExists(hv_DLDatasetFileName, &hv_FileExists);
    if (0 != (hv_FileExists.TupleNot()))
    {
        throw HException(hv_DLDatasetFileName+" does not exist. Please run part 1 of the example series.");
    }
    //
    return;
}

void HalxAI:: dev_close_example_image_window (HTuple hv_ExampleInternals)
{

    // Local control variables
    HTuple  hv_WindowHandleImages, hv_Exception;

    //This procedure closes the image window.
    //
    try
    {
        GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
        HDevWindowStack::SetActive(hv_WindowHandleImages);
        if (HDevWindowStack::IsOpen())
            CloseWindow(HDevWindowStack::Pop());
        //Delete key.
        RemoveDictKey(hv_ExampleInternals, "window_images");
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    return;
}

void HalxAI:: dev_close_example_legend_window (HTuple hv_ExampleInternals)
{

    // Local control variables
    HTuple  hv_WindowHandleLegend, hv_Exception;

    //This procedure closes the legend window.
    //
    try
    {
        GetDictTuple(hv_ExampleInternals, "window_legend", &hv_WindowHandleLegend);
        HDevWindowStack::SetActive(hv_WindowHandleLegend);
        if (HDevWindowStack::IsOpen())
            CloseWindow(HDevWindowStack::Pop());
        //Delete key.
        RemoveDictKey(hv_ExampleInternals, "window_legend");
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    return;
}

void HalxAI:: dev_close_example_text_window (HTuple hv_ExampleInternals)
{

    // Local control variables
    HTuple  hv_WindowHandleImages, hv_Exception;

    //This procedure closes the text window.
    //
    try
    {
        GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleImages);
        HDevWindowStack::SetActive(hv_WindowHandleImages);
        if (HDevWindowStack::IsOpen())
            CloseWindow(HDevWindowStack::Pop());
        //Delete key.
        RemoveDictKey(hv_ExampleInternals, "window_text");
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    return;
}

void HalxAI:: dev_close_example_windows (HTuple hv_ExampleInternals)
{

    // Local control variables
    HTuple  hv_ShowExampleScreens;

    //This procedure closes all example windows opened for explanations.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    dev_close_example_text_window(hv_ExampleInternals);
    dev_close_example_image_window(hv_ExampleInternals);
    dev_close_example_legend_window(hv_ExampleInternals);
    //
    return;
}

void HalxAI:: dev_display_example_reset_windows (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WindowHandlesToClose, hv_Exception;
    HTuple  hv_I, hv_WindowHandleKeys, hv_Index, hv_WindowImagesNeeded;
    HTuple  hv_WindowLegendNeeded, hv_WindowHandleImages, hv_WindowHandleLegend;
    HTuple  hv_WindowHandleText;

    //This procedure resets the graphics windows.
    //
    //Close any windows that are listed in key 'window_handles_to_close'.
    try
    {
        GetDictTuple(hv_ExampleInternals, "window_handles_to_close", &hv_WindowHandlesToClose);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
        hv_WindowHandlesToClose = HTuple();
    }
    {
        HTuple end_val8 = (hv_WindowHandlesToClose.TupleLength())-1;
        HTuple step_val8 = 1;
        for (hv_I=0; hv_I.Continue(end_val8, step_val8); hv_I += step_val8)
        {
            HDevWindowStack::SetActive(HTuple(hv_WindowHandlesToClose[hv_I]));
            if (HDevWindowStack::IsOpen())
                CloseWindow(HDevWindowStack::Pop());
        }
    }
    SetDictTuple(hv_ExampleInternals, "window_handles_to_close", HTuple());
    //
    //Open image window if needed.
    GetDictParam(hv_ExampleInternals, "keys", HTuple(), &hv_WindowHandleKeys);
    TupleFind(hv_WindowHandleKeys, "window_images", &hv_Index);
    GetDictTuple(hv_ExampleInternals, "window_images_needed", &hv_WindowImagesNeeded);
    if (0 != (hv_WindowImagesNeeded.TupleAnd(int(hv_Index==-1))))
    {
        //Open new window for images.
        dev_open_example_image_window(hv_ExampleInternals);
    }
    else if (0 != (HTuple(hv_WindowImagesNeeded.TupleNot()).TupleAnd(int(hv_Index!=-1))))
    {
        //Window for images exists but is not needed -> close it.
        dev_close_example_image_window(hv_ExampleInternals);
    }
    //
    //Open legend window if needed.
    GetDictParam(hv_ExampleInternals, "keys", HTuple(), &hv_WindowHandleKeys);
    TupleFind(hv_WindowHandleKeys, "window_legend", &hv_Index);
    GetDictTuple(hv_ExampleInternals, "window_legend_needed", &hv_WindowLegendNeeded);
    if (0 != (hv_WindowLegendNeeded.TupleAnd(int(hv_Index==-1))))
    {
        //Open new window for legend.
        dev_open_example_legend_window(hv_ExampleInternals, 290);
    }
    else if (0 != (HTuple(hv_WindowLegendNeeded.TupleNot()).TupleAnd(int(hv_Index!=-1))))
    {
        //Window for legend exists but is not needed -> close it.
        dev_close_example_legend_window(hv_ExampleInternals);
    }
    //
    //Set the correct area (part) of the image window.
    try
    {
        GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
        HDevWindowStack::SetActive(hv_WindowHandleImages);
        if (HDevWindowStack::IsOpen())
            ClearWindow(HDevWindowStack::GetActive());
        //Set default window extends
        if (HDevWindowStack::IsOpen())
            SetWindowExtents(HDevWindowStack::GetActive(),360, 0, 800, 400);
        SetPartStyle(hv_WindowHandleImages, 1);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    //Set the correct area (part) of the legend window.
    try
    {
        GetDictTuple(hv_ExampleInternals, "window_legend", &hv_WindowHandleLegend);
        HDevWindowStack::SetActive(hv_WindowHandleLegend);
        if (HDevWindowStack::IsOpen())
            ClearWindow(HDevWindowStack::GetActive());
        //Set default window extends
        if (HDevWindowStack::IsOpen())
            SetWindowExtents(HDevWindowStack::GetActive(),360, 800+5, 290, 500);
        if (HDevWindowStack::IsOpen())
            SetPart(HDevWindowStack::GetActive(),1, 1, -1, -1);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    if (HDevWindowStack::IsOpen())
        ClearWindow(HDevWindowStack::GetActive());
    return;
}

void HalxAI:: dev_display_screen_batch_size (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure explains the parameter 'batch_size'.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = "Model parameter: 'batch_size'";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The dataset is divided into smaller subsets of data";
    hv_Text[hv_Text.TupleLength()] = "which are called batches.";
    hv_Text[hv_Text.TupleLength()] = "The 'batch_size' determines the number of images taken";
    hv_Text[hv_Text.TupleLength()] = "into a batch and thus are processed simultaneously.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_device (HTuple hv_ExampleInternals, HTuple hv_DLDevice)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WindowHandleText, hv_DLDeviceType;
    HTuple  hv_DLDeviceName, hv_Text;

    //This procedure displays information about the used device.

    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);

    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);

    GetDlDeviceParam(hv_DLDevice, "type", &hv_DLDeviceType);
    GetDlDeviceParam(hv_DLDevice, "name", &hv_DLDeviceName);

    hv_Text = "This example can be run on a GPU or CPU.";
    hv_Text[hv_Text.TupleLength()] = "";
    if (0 != (int(hv_DLDeviceType!=HTuple("gpu"))))
    {
        hv_Text[hv_Text.TupleLength()] = "No GPU with necessary drivers and libraries has been found.";
        hv_Text[hv_Text.TupleLength()] = "";
    }
    hv_Text[hv_Text.TupleLength()] = "This example will run the deep learning operators";
    hv_Text[hv_Text.TupleLength()] = "on the following device:";
    hv_Text[hv_Text.TupleLength()] = "Device type: "+hv_DLDeviceType;
    hv_Text[hv_Text.TupleLength()] = "Device name: "+hv_DLDeviceName;

    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());

    return;
}

void HalxAI:: dev_display_screen_error (HTuple hv_ExampleInternals, HTuple *hv_Error)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_ExampleDataDir, hv_InitialModelFileName, hv_DataDirectory;
    HTuple  hv_DLDatasetFileName, hv_ModelExists, hv_DataExists;
    HTuple  hv_ErrorText;

    //This procedure checks whether all required files are present.
    //Display an error message if this is not the case.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display error text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    //Check if 'detect_pills_deep_learning_1_prepare.hdev' has been run
    //which means that both the initial model and preprocessed dataset are available.
    hv_ExampleDataDir = "detect_pills_data";
    hv_InitialModelFileName = hv_ExampleDataDir+"/pretrained_dl_model_detection.hdl";
    hv_DataDirectory = hv_ExampleDataDir+"/dldataset_pill_bag_512x320";
    hv_DLDatasetFileName = hv_DataDirectory+"/dl_dataset.hdict";
    //
    (*hv_Error) = 0;
    //
    FileExists(hv_InitialModelFileName, &hv_ModelExists);
    FileExists(hv_DLDatasetFileName, &hv_DataExists);
    //
    if (0 != (HTuple(hv_DataExists.TupleNot()).TupleOr(hv_ModelExists.TupleNot())))
    {
        (*hv_Error) = 1;
        hv_ErrorText = HTuple();
        //Part 1 should be run before continuing this example.
        hv_ErrorText[hv_ErrorText.TupleLength()] = "To run this example you need the output of:";
        hv_ErrorText[hv_ErrorText.TupleLength()] = " - 'detect_pills_deep_learning_1_prepare.hdev'";
        hv_ErrorText[hv_ErrorText.TupleLength()] = "Please run this example first.";
        set_display_font(hv_WindowHandleText, 20, "mono", "true", "false");
        if (HDevWindowStack::IsOpen())
            DispText(HDevWindowStack::GetActive(),hv_ErrorText, "window", "top", "left",
                     "red", "box", "true");
        set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
    }
    //
    return;
}

void HalxAI:: dev_display_screen_final (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure shows the final message of the example series.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    dev_open_example_text_window(hv_ExampleInternals);
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = HTuple("Now, the second part 'Training of the model' of the workflow");
    hv_Text[hv_Text.TupleLength()] = "for DL object detection is finished.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The trained model can now be evaluated and used for the inference";
    hv_Text[hv_Text.TupleLength()] = "of new images.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "For evaluation please open";
    hv_Text[hv_Text.TupleLength()] = "'detect_pills_deep_learning_3_evaluate.hdev'.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "For inference please open";
    hv_Text[hv_Text.TupleLength()] = "'detect_pills_deep_learning_4_infer.hdev'.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Please open the next example.", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_introduction_train (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure displays an overview on the different example parts.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the overview on the different example parts.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = HTuple("This example is part of a series of examples, which summarize ");
    hv_Text[hv_Text.TupleLength()] = "the workflow for DL object detection. It uses the MVTec pill bag dataset.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The four parts are: ";
    hv_Text[hv_Text.TupleLength()] = "1. Creation of the model and dataset preprocessing.";
    hv_Text[hv_Text.TupleLength()] = "2. Training of the model.";
    hv_Text[hv_Text.TupleLength()] = "3. Evaluation of the trained model.";
    hv_Text[hv_Text.TupleLength()] = "4. Inference on new images.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "This example covers part 2: 'Training of the model'.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_learning_rate (HTuple hv_ExampleInternals)
{

    // Local iconic variables
    HObject  ho_ImageLoss;

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text, hv_WindowHandleImages;

    //This procedure explains the learning rate.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = "Model parameter: 'learning_rate'";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The 'learning_rate' determines the size of the steps for optimizing";
    hv_Text[hv_Text.TupleLength()] = "the loss function:";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "     - A too high learning rate might result in divergence of";
    hv_Text[hv_Text.TupleLength()] = "       the optimization algorithm.";
    hv_Text[hv_Text.TupleLength()] = "     - A very low learning rate will take unnecessarily many steps.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The behavior of the loss curve for different learning rates is illustrated";
    hv_Text[hv_Text.TupleLength()] = "below.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    //Display learning rate curve.
    GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    ReadImage(&ho_ImageLoss, "dl_explanation/training_learning_rate_curves");
    if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageLoss, HDevWindowStack::GetActive());
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Loss", "image", 35, 110, "black", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Epochs", "image", 685, 1230, "black",
                 "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"good learning rate", "image", 670, 400,
                 "blue", "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"high learning rate", "image", 530, 500,
                 "cyan", "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"very high learning rate", "image", 220,
                 920, "red", "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"low learning rate", "image", 375, 800,
                 "orange", "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Loss curves for different learning rates",
                 "window", "top", "center", "black", "box", "true");
    //
    return;
}

void HalxAI:: dev_display_screen_num_epochs (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure explains the parameter 'num_epochs'.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = "Training parameter: 'num_epochs'";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "During an epoch the entire training data is used once.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The number of epochs depends on the individual problem.";
    hv_Text[hv_Text.TupleLength()] = HTuple("For datasets with a large number of classes, objects per image and");
    hv_Text[hv_Text.TupleLength()] = "variety of object sizes a larger number of epochs might be necessary.";
    hv_Text[hv_Text.TupleLength()] = "A good indicator is the rate by which the loss value decreases.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The number of epochs is set in the procedure ";
    hv_Text[hv_Text.TupleLength()] = "'create_dl_train_param'.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_other_params (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure explains further training parameters.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = HTuple("Additionally, there are more advanced parameters that can be specified");
    hv_Text[hv_Text.TupleLength()] = HTuple("to enhance the training process, for example parameters for:");
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = HTuple("   - Data augmentation (e.g., 'augmentation_percentage', 'rotation')");
    hv_Text[hv_Text.TupleLength()] = HTuple("   - Change strategy (e.g., to adapt the 'learning_rate' during training)");
    hv_Text[hv_Text.TupleLength()] = HTuple("   - Evaluation measure (e.g., 'mean_ap')");
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_parameters (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure explains model and training parameters in general.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = "There are multiple model and training parameters.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = HTuple("To set the model parameters 'set_dl_model_param' is used,");
    hv_Text[hv_Text.TupleLength()] = "while the training parameters are set in 'create_dl_train_param'.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "The parameters are employed to specify the training process.";
    hv_Text[hv_Text.TupleLength()] = "Some of them have a significant impact on the training result.";
    hv_Text[hv_Text.TupleLength()] = "The most prominent ones are explained in the following.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_training_goals_1 (HTuple hv_ExampleInternals)
{

    // Local iconic variables
    HObject  ho_ImageLoss;

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text, hv_WindowHandleImages;

    //This procedure explains the goals during the training of a model.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = "While training there are two main goals to be achieved:";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "--> 1.) The 'loss' is commonly used to optimize the model on the";
    hv_Text[hv_Text.TupleLength()] = HTuple("        training data. Hence, the objective is to minimize the loss");
    hv_Text[hv_Text.TupleLength()] = "        on the training data by updating the model parameters iteratively.";
    hv_Text[hv_Text.TupleLength()] = "    2.) For the evaluation measure on the validation data the 'mean_ap'";
    hv_Text[hv_Text.TupleLength()] = "        (mean average precision) is usually used for object detection.";
    hv_Text[hv_Text.TupleLength()] = "        This value should have an increasing trend during the training";
    hv_Text[hv_Text.TupleLength()] = "        process.";
    hv_Text[hv_Text.TupleLength()] = " ";
    hv_Text[hv_Text.TupleLength()] = "An example of the loss during a successful training is displayed below.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    //Display the training plot.
    GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    //
    ReadImage(&ho_ImageLoss, "dl_explanation/training_det_goals_loss");
    if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageLoss, HDevWindowStack::GetActive());
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Loss", "image", 15, 140, "black", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Epochs", "image", 470, 1220, "black",
                 "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"1.68", "image", 95, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"1.12", "image", 210, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"0.56", "image", 330, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"0.00", "image", 455, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"10", "image", 510, 460, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"20", "image", 510, 815, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"30", "image", 510, 1180, "gray", "box",
                 "false");
    //
    return;
}

void HalxAI:: dev_display_screen_training_goals_2 (HTuple hv_ExampleInternals)
{

    // Local iconic variables
    HObject  ho_ImageLoss;

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text, hv_WindowHandleImages;

    //This procedure explains the fundamental training goals.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 1);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = "While training there are two main goals to be achieved:";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "    1.) The 'loss' is commonly used to optimize the model on the";
    hv_Text[hv_Text.TupleLength()] = HTuple("        training data. Hence, the objective is to minimize the loss");
    hv_Text[hv_Text.TupleLength()] = "        on the training data by updating the model parameters iteratively.";
    hv_Text[hv_Text.TupleLength()] = "--> 2.) For the evaluation measure on the validation data the 'mean_ap'";
    hv_Text[hv_Text.TupleLength()] = "        (mean average precision) is usually used for object detection.";
    hv_Text[hv_Text.TupleLength()] = "        This value should have an increasing trend during the training";
    hv_Text[hv_Text.TupleLength()] = "        process.";
    hv_Text[hv_Text.TupleLength()] = " ";
    hv_Text[hv_Text.TupleLength()] = "An example of the 'mean_ap' during a successful training is displayed";
    hv_Text[hv_Text.TupleLength()] = "below.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    //Display the training plot.
    GetDictTuple(hv_ExampleInternals, "window_images", &hv_WindowHandleImages);
    HDevWindowStack::SetActive(hv_WindowHandleImages);
    //
    ReadImage(&ho_ImageLoss, "dl_explanation/training_det_goals_map");
    if (HDevWindowStack::IsOpen())
        DispObj(ho_ImageLoss, HDevWindowStack::GetActive());
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"mean_ap", "image", 15, 140, "black", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Epochs", "image", 470, 1220, "black",
                 "box", "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"1.00", "image", 25, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"0.80", "image", 145, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"0.60", "image", 265, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"0.40", "image", 385, 30, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"10", "image", 510, 415, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"20", "image", 510, 780, "gray", "box",
                 "false");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"30", "image", 510, 1140, "gray", "box",
                 "false");
    //
    return;
}

void HalxAI:: dev_display_screen_training_process (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_Text;

    //This procedure explains train_dl_model.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    hv_Text = HTuple("After the parameters are set, the model can be trained");
    hv_Text[hv_Text.TupleLength()] = "on the dataset with the procedure 'train_dl_model'.";
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "During the training the best training model is stored and";
    hv_Text[hv_Text.TupleLength()] = "written to the disk after the corresponding training step.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_display_screen_training_starts (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_ShowExampleScreens, hv_WindowHandleText;
    HTuple  hv_GPUAvailable, hv_Text;

    //This procedure gives a hint that the training starts.
    //
    GetDictTuple(hv_ExampleInternals, "show_example_screens", &hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    //Reset the open windows for a clean display.
    SetDictTuple(hv_ExampleInternals, "window_images_needed", 0);
    SetDictTuple(hv_ExampleInternals, "window_legend_needed", 0);
    dev_display_example_reset_windows(hv_ExampleInternals);
    //
    //Display the explanatory text or error message in case no GPU is available.
    GetDictTuple(hv_ExampleInternals, "window_text", &hv_WindowHandleText);
    HDevWindowStack::SetActive(hv_WindowHandleText);
    //
    GetDictTuple(hv_ExampleInternals, "gpu_available", &hv_GPUAvailable);
    //
    hv_Text = HTuple();
    hv_Text[hv_Text.TupleLength()] = HTuple("Now, the training of the model will start.");
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = HTuple("During training, the progress is indicated visually.");
    hv_Text[hv_Text.TupleLength()] = "";
    hv_Text[hv_Text.TupleLength()] = "Training can be performed on a GPU or CPU.";
    hv_Text[hv_Text.TupleLength()] = "See the respective system requirements in the Installation Guide.";
    hv_Text[hv_Text.TupleLength()] = " ";
    hv_Text[hv_Text.TupleLength()] = "The training will take a while and depends highly on";
    hv_Text[hv_Text.TupleLength()] = "the parameter settings and the specific device used.";
    hv_Text[hv_Text.TupleLength()] = " ";
    //
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),hv_Text, "window", "top", "left", "black",
                 "box", "true");
    if (HDevWindowStack::IsOpen())
        DispText(HDevWindowStack::GetActive(),"Press Run (F5) to continue", "window",
                 "bottom", "right", "black", HTuple(), HTuple());
    //
    return;
}

void HalxAI:: dev_example_init (HTuple hv_ShowExampleScreens, HTuple *hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WindowWidthText, hv_WindowHeightText;
    HTuple  hv_WindowBGColor, hv_WindowHandleText;

    //This procedure initializes the graphic windows that are used for explanations during the example.
    //
    //A dict that will be used/adapted by other example procedures.
    CreateDict(&(*hv_ExampleInternals));
    SetDictTuple((*hv_ExampleInternals), "show_example_screens", hv_ShowExampleScreens);
    if (0 != (hv_ShowExampleScreens.TupleNot()))
    {
        return;
    }
    //
    if (HDevWindowStack::IsOpen())
        CloseWindow(HDevWindowStack::Pop());
    hv_WindowWidthText = 800;
    hv_WindowHeightText = 300;
    hv_WindowBGColor = "gray";
    SetWindowAttr("background_color",hv_WindowBGColor);
    OpenWindow(0,0,hv_WindowWidthText,hv_WindowHeightText,0,"visible","",&hv_WindowHandleText);
    HDevWindowStack::Push(hv_WindowHandleText);
    set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
    SetDictTuple((*hv_ExampleInternals), "window_text", hv_WindowHandleText);
    SetDictTuple((*hv_ExampleInternals), "window_text_width", hv_WindowWidthText);
    SetDictTuple((*hv_ExampleInternals), "window_text_height", hv_WindowHeightText);
    //
    SetDictTuple((*hv_ExampleInternals), "window_images_needed", 0);
    SetDictTuple((*hv_ExampleInternals), "window_legend_needed", 0);
    //
    SetDictTuple((*hv_ExampleInternals), "gpu_available", 1);
    //
    return;
}

void HalxAI:: dev_open_example_image_window (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WindowHeightText, hv_WindowWidthImage;
    HTuple  hv_WindowHeightImages, hv_WindowBGColor, hv_WindowYImages;
    HTuple  hv_WindowXImages, hv_WindowHandleImages;

    //This procedure initializes the graphic windows that are used to display example images.
    //
    hv_WindowHeightText = 300;
    hv_WindowWidthImage = 800;
    hv_WindowHeightImages = 400;
    hv_WindowBGColor = "gray";
    //
    hv_WindowYImages = hv_WindowHeightText+60;
    hv_WindowXImages = 0;
    SetWindowAttr("background_color",hv_WindowBGColor);
    OpenWindow(hv_WindowYImages,hv_WindowXImages,hv_WindowWidthImage,hv_WindowHeightImages,0,"visible","",&hv_WindowHandleImages);
    HDevWindowStack::Push(hv_WindowHandleImages);
    set_display_font(hv_WindowHandleImages, 16, "mono", "true", "false");
    SetDictTuple(hv_ExampleInternals, "window_images", hv_WindowHandleImages);
    SetDictTuple(hv_ExampleInternals, "window_images_width", hv_WindowWidthImage);
    SetDictTuple(hv_ExampleInternals, "window_images_height", hv_WindowHeightImages);
    SetDictTuple(hv_ExampleInternals, "window_images_x", hv_WindowXImages);
    SetDictTuple(hv_ExampleInternals, "window_images_y", hv_WindowYImages);
    return;
}

void HalxAI:: dev_open_example_legend_window (HTuple hv_ExampleInternals, HTuple hv_WindowWidth)
{

    // Local control variables
    HTuple  hv_WindowImagesHeight, hv_WindowImagesWidth;
    HTuple  hv_WindowImagesX, hv_WindowImagesY, hv_WindowHandleLegend;

    //This procedure initializes the graphic windows that are used to display a legend.
    //
    GetDictTuple(hv_ExampleInternals, "window_images_height", &hv_WindowImagesHeight);
    GetDictTuple(hv_ExampleInternals, "window_images_width", &hv_WindowImagesWidth);
    GetDictTuple(hv_ExampleInternals, "window_images_x", &hv_WindowImagesX);
    GetDictTuple(hv_ExampleInternals, "window_images_y", &hv_WindowImagesY);
    SetWindowAttr("background_color","black");
    OpenWindow(hv_WindowImagesY,(hv_WindowImagesX+hv_WindowImagesWidth)+5,hv_WindowWidth,hv_WindowImagesHeight,0,"visible","",&hv_WindowHandleLegend);
    HDevWindowStack::Push(hv_WindowHandleLegend);
    set_display_font(hv_WindowHandleLegend, 14, "mono", "true", "false");
    SetDictTuple(hv_ExampleInternals, "window_legend", hv_WindowHandleLegend);
    return;
}

void HalxAI:: dev_open_example_text_window (HTuple hv_ExampleInternals)
{

    // Local iconic variables

    // Local control variables
    HTuple  hv_WindowWidthText, hv_WindowHeightText;
    HTuple  hv_WindowBGColor, hv_WindowHandleText;

    //This procedure initializes the graphic window which is used to display the text.
    //
    hv_WindowWidthText = 800;
    hv_WindowHeightText = 300;
    hv_WindowBGColor = "gray";
    SetWindowAttr("background_color",hv_WindowBGColor);
    OpenWindow(0,0,hv_WindowWidthText,hv_WindowHeightText,0,"visible","",&hv_WindowHandleText);
    HDevWindowStack::Push(hv_WindowHandleText);
    set_display_font(hv_WindowHandleText, 16, "mono", "true", "false");
    SetDictTuple(hv_ExampleInternals, "window_text", hv_WindowHandleText);
    SetDictTuple(hv_ExampleInternals, "window_text_width", hv_WindowWidthText);
    SetDictTuple(hv_ExampleInternals, "window_text_height", hv_WindowHeightText);
    return;
}

void HalxAI::YtCreateDLTrainParam(HTuple hv_DLModelHandle, HTuple hv_NumEpochs, HTuple hv_EvaluationIntervalEpochs, HTuple hv_EnableDisplay, HTuple hv_RandomSeed, HTuple hv_GenParamName, HTuple hv_GenParamValue, HTuple *hv_TrainParam)
{
    // Local control variables
    HTuple  hv_ModelType, hv_AvailableGenParam, hv_IndexGenParam;
    HTuple  hv_IndexFind, hv_IsString, hv_TrainParamAnomaly;
    HTuple  hv_DomainRatioKeyExists, hv_ErrorThresholdKeyExists;
    HTuple  hv_RegularizationNoiseKeyExists, hv_DisplayParam;
    HTuple  hv_EvaluateBeforeTrain, hv_EvaluationParam, hv_AugmentationParam;
    HTuple  hv_ClassIDsNoOrientation, hv_Exception, hv_ChangeStrategies;
    HTuple  hv_Indices, hv_SerializationStrategy, hv_SerializationStrategies;
    HTuple  hv_Seconds, hv_SetDisplayParam, hv_EvaluationComparisonKeys;
    HTuple  hv_ConvertToMean, hv_Index, hv_FoundIndices;

    //
    //This procedure creates a dictionary with all needed training parameters,
    //as required by train_dl_model as input.
    //
    //Check length of input GenParam tuple.
    if (0 != (int((hv_GenParamName.TupleLength())!=(hv_GenParamValue.TupleLength()))))
    {
        throw HException("GenParamName and GenParamValue have to have the same length.");
    }
    //
    //Some default parameters depend on model type.
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
    {
        throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
    }
    //
    //Check if the given GenParamName strings are available.
    if (0 != (int(hv_ModelType!=HTuple("anomaly_detection"))))
    {
        hv_AvailableGenParam.Clear();
        hv_AvailableGenParam[0] = "evaluate";
        hv_AvailableGenParam[1] = "augment";
        hv_AvailableGenParam[2] = "change";
        hv_AvailableGenParam[3] = "serialize";
        hv_AvailableGenParam[4] = "display";
        hv_AvailableGenParam[5] = "evaluate_before_train";
        if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            hv_AvailableGenParam.Clear();
            hv_AvailableGenParam[0] = "augment";
            hv_AvailableGenParam[1] = "change";
            hv_AvailableGenParam[2] = "serialize";
            hv_AvailableGenParam[3] = "display";
        }
    }
    else
    {
        hv_AvailableGenParam = "anomaly";
    }
    {
        HTuple end_val24 = (hv_GenParamName.TupleLength())-1;
        HTuple step_val24 = 1;
        for (hv_IndexGenParam=0; hv_IndexGenParam.Continue(end_val24, step_val24); hv_IndexGenParam += step_val24)
        {
            hv_IndexFind = hv_AvailableGenParam.TupleFind(HTuple(hv_GenParamName[hv_IndexGenParam]));
            if (0 != (int(hv_IndexFind==-1)))
            {
                throw HException(("The provided GenParamName "+HTuple(hv_GenParamName[hv_IndexGenParam]))+" is invalid.");
            }
        }
    }
    //
    //Check if display is enabled.
    TupleIsString(hv_EnableDisplay, &hv_IsString);
    if (0 != hv_IsString)
    {
        hv_EnableDisplay = int(hv_EnableDisplay==HTuple("true"));
    }
    else
    {
        hv_EnableDisplay = int(hv_EnableDisplay==1);
    }
    //
    //Initialize the dictionary holding the training parameters.
    CreateDict(&(*hv_TrainParam));
    //
    //** User supplied parameters: ***
    //
    //Set training parameters for anomaly detection models.
    if (0 != (int(hv_ModelType==HTuple("anomaly_detection"))))
    {
        get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "anomaly", &hv_TrainParamAnomaly);
        //Set default values in case no values are provided.
        if (0 != (int(hv_TrainParamAnomaly==HTuple())))
        {
            CreateDict(&hv_TrainParamAnomaly);
        }
        GetDictParam(hv_TrainParamAnomaly, "key_exists", "domain_ratio", &hv_DomainRatioKeyExists);
        if (0 != (hv_DomainRatioKeyExists.TupleNot()))
        {
            SetDictTuple(hv_TrainParamAnomaly, "domain_ratio", 0.1);
        }
        GetDictParam(hv_TrainParamAnomaly, "key_exists", "error_threshold", &hv_ErrorThresholdKeyExists);
        if (0 != (hv_ErrorThresholdKeyExists.TupleNot()))
        {
            SetDictTuple(hv_TrainParamAnomaly, "error_threshold", 0.001);
        }
        GetDictParam(hv_TrainParamAnomaly, "key_exists", "regularization_noise", &hv_RegularizationNoiseKeyExists);
        if (0 != (hv_RegularizationNoiseKeyExists.TupleNot()))
        {
            SetDictTuple(hv_TrainParamAnomaly, "regularization_noise", 0.0001);
        }
        //
        SetDictTuple(hv_TrainParamAnomaly, "max_num_epochs", hv_NumEpochs);
        SetDictTuple((*hv_TrainParam), "anomaly_param", hv_TrainParamAnomaly);
        CreateDict(&hv_DisplayParam);
        SetDictTuple(hv_DisplayParam, "enabled", hv_EnableDisplay);
        SetDictTuple((*hv_TrainParam), "display_param", hv_DisplayParam);
        return;
    }
    //
    //Set training parameters for all model types except 'anomaly_detection'.
    //
    //Number of epochs to train the model on the train split of the dataset.
    SetDictTuple((*hv_TrainParam), "num_epochs", hv_NumEpochs);
    //
    //Interval (in epochs) to evaluate the model on the validation split of the dataset.
    if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
    {
        //For models of type 'gc_anomaly_detection' no evaluation can be done.
        SetDictTuple((*hv_TrainParam), "evaluation_interval_epochs", 0);
    }
    else
    {
        SetDictTuple((*hv_TrainParam), "evaluation_interval_epochs", hv_EvaluationIntervalEpochs);
    }
    //
    //Transfer the parameter defining if an evaluation before training is to be done.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "evaluate_before_train",
                              &hv_EvaluateBeforeTrain);
    SetDictTuple((*hv_TrainParam), "evaluate_before_train", hv_EvaluateBeforeTrain);
    //
    //Transfer evaluation parameters used in further steps.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "evaluate", &hv_EvaluationParam);
    SetDictTuple((*hv_TrainParam), "evaluation_param", hv_EvaluationParam);
    //
    //Transfer augmentation parameters used in further steps.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "augment", &hv_AugmentationParam);
    if (0 != (int(hv_ModelType==HTuple("detection"))))
    {
        //In addition, add class IDs without orientation, since these classes require
        //special treatment during the augmentation.
        try
        {
            GetDlModelParam(hv_DLModelHandle, "class_ids_no_orientation", &hv_ClassIDsNoOrientation);
        }
        // catch (Exception)
        catch (HException &HDevExpDefaultException)
        {
            HDevExpDefaultException.ToHTuple(&hv_Exception);
            hv_ClassIDsNoOrientation = HTuple();
        }
        if (0 != (int((hv_ClassIDsNoOrientation.TupleLength())>0)))
        {
            if (0 != (int(hv_AugmentationParam==HTuple())))
            {
                CreateDict(&hv_AugmentationParam);
            }
            SetDictTuple(hv_AugmentationParam, "class_ids_no_orientation", hv_ClassIDsNoOrientation);
        }
    }
    SetDictTuple((*hv_TrainParam), "augmentation_param", hv_AugmentationParam);
    //
    //Change strategies for any parameters that need to be changed during training.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "change", &hv_ChangeStrategies);
    SetDictTuple((*hv_TrainParam), "change_strategies", hv_ChangeStrategies);
    //
    //Serialization strategies used during training.
    hv_Indices = hv_GenParamName.TupleFind("serialize");
    if (0 != (HTuple(int((hv_Indices.TupleLength())==0)).TupleOr(int(hv_Indices==-1))))
    {
        //Set a default in case no value is provided.
        CreateDict(&hv_SerializationStrategy);
        SetDictTuple(hv_SerializationStrategy, "type", "best");
        SetDictTuple(hv_SerializationStrategy, "basename", "model_best");
        hv_SerializationStrategies = hv_SerializationStrategy;
    }
    else
    {
        //Set user provided values.
        hv_SerializationStrategies = HTuple(hv_GenParamValue[hv_Indices]);
    }
    SetDictTuple((*hv_TrainParam), "serialization_strategies", hv_SerializationStrategies);
    //
    //Get random seed or set a useful default value.
    if (0 != (int((hv_RandomSeed.TupleLength())>0)))
    {
        SetDictTuple((*hv_TrainParam), "seed_rand", hv_RandomSeed);
    }
    else
    {
        //If no random seed is given we will use system time as a default.
        CountSeconds(&hv_Seconds);
        hv_RandomSeed = hv_Seconds.TupleInt();
        SetDictTuple((*hv_TrainParam), "seed_rand", hv_RandomSeed);
    }
    //
    //** Display parameters: ***
    //
    //Create display parameter dictionary.
    get_genparam_single_value(hv_GenParamName, hv_GenParamValue, "display", &hv_SetDisplayParam);
    if (0 != (int(hv_SetDisplayParam!=HTuple())))
    {
        hv_DisplayParam = hv_SetDisplayParam;
    }
    else
    {
        CreateDict(&hv_DisplayParam);
    }
    //
    SetDictTuple(hv_DisplayParam, "enabled", hv_EnableDisplay);
    SetDictTuple((*hv_TrainParam), "display_param", hv_DisplayParam);
    //
    //** Generic internal defaults: ***
    //
    //Default update interval (in seconds) of TrainInfo calculation and text/plot updates
    //in case display is enabled.
    SetDictTuple((*hv_TrainParam), "update_interval_seconds", 2);
    //
    //Evaluation comparison keys. Note, that internally only those keys apply which
    //are really available. No error is thrown as long as a valid key is given.
    //Hence, we use the major defaults here for classification ('top1_error'),
    //for detection ('mean_ap'), and for segmentation ('mean_iou') if no valid key
    //is given.
    hv_EvaluationComparisonKeys = HTuple();
    //
    try
    {
        GetDictTuple(hv_EvaluationParam, "measures", &hv_EvaluationComparisonKeys);
    }
    // catch (Exception)
    catch (HException &HDevExpDefaultException)
    {
        HDevExpDefaultException.ToHTuple(&hv_Exception);
    }
    //
    if (0 != (int(hv_EvaluationComparisonKeys==HTuple())))
    {
        if (0 != (int(hv_ModelType==HTuple("classification"))))
        {
            hv_EvaluationComparisonKeys = "top1_error";
        }
        else if (0 != (int(hv_ModelType==HTuple("detection"))))
        {
            hv_EvaluationComparisonKeys = "mean_ap";
        }
        else if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            hv_EvaluationComparisonKeys = "none";
        }
        else if (0 != (int(hv_ModelType==HTuple("ocr_detection"))))
        {
            hv_EvaluationComparisonKeys = "f_score";
        }
        else if (0 != (int(hv_ModelType==HTuple("ocr_recognition"))))
        {
            hv_EvaluationComparisonKeys = "accuracy";
        }
        else if (0 != (int(hv_ModelType==HTuple("segmentation"))))
        {
            hv_EvaluationComparisonKeys = "mean_iou";
        }
        else if (0 != (int(hv_ModelType==HTuple("3d_gripping_point_detection"))))
        {
            hv_EvaluationComparisonKeys = "mean_iou";
        }
    }

    if (0 != (int(hv_ModelType!=HTuple("ocr_detection"))))
    {
        //If the evaluation metric is 'precision', 'recall', 'f_score', or
        //'soap' we always take the mean value.
        hv_ConvertToMean.Clear();
        hv_ConvertToMean[0] = "precision";
        hv_ConvertToMean[1] = "recall";
        hv_ConvertToMean[2] = "f_score";
        hv_ConvertToMean[3] = "soap";
        {
            HTuple end_val193 = (hv_ConvertToMean.TupleLength())-1;
            HTuple step_val193 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val193, step_val193); hv_Index += step_val193)
            {
                hv_FoundIndices = (hv_EvaluationComparisonKeys.TupleEqualElem(HTuple(hv_ConvertToMean[hv_Index]))).TupleFind(1);
                if (0 != (int(hv_FoundIndices!=-1)))
                {
                    hv_EvaluationComparisonKeys[hv_FoundIndices] = "mean_"+HTuple(hv_EvaluationComparisonKeys[hv_FoundIndices]);
                    if (0 != (int(HTuple(hv_ConvertToMean[hv_Index])==HTuple("soap"))))
                    {
                        hv_EvaluationComparisonKeys[hv_FoundIndices] = HTuple(hv_EvaluationComparisonKeys[hv_FoundIndices])+"_tp";
                    }
                }
            }
        }
    }
    //
    SetDictTuple((*hv_TrainParam), "evaluation_comparison_keys", hv_EvaluationComparisonKeys);
    //
    //Number of samples used to average the loss during training. Note, this is used for display
    //and information calculation only and does not have an effect on training the model.
    SetDictTuple((*hv_TrainParam), "num_samples_mean_loss", 1000);
    //
    return;
}

void YTtrain_dl_model(HTuple hv_DLDataset, HTuple hv_DLModelHandle, HTuple hv_TrainParam, HTuple hv_StartEpoch, HTuple *hv_TrainResults, HTuple *hv_TrainInfos, HTuple *hv_EvaluationInfos)
{
    // Local control variables
    HTuple  hv_ModelType, hv_DLSamples, hv_TrainSampleIndices;
    HTuple  hv_NumTrainSamples, hv_EvaluationComparisonKeyExist;
    HTuple  hv_EvaluationComparisonKeys, hv_EvaluationOptimizationMethod;
    HTuple  hv_NumEpochs, hv_SeedRand, hv_SampleIndicesTrainRaw;
    HTuple  hv_Index, hv_Shuffled, hv_SampleSeedsTrainRaw, hv_BatchSize;
    HTuple  hv_EvaluateBeforeTraining, hv_ChangeStrategyData;
    HTuple  hv_SerializationData, hv_DisplayData, hv_DisplayEnabled;
    HTuple  hv_DisplayPreviewInitialized, hv_DisplayEvaluationEpochs;
    HTuple  hv_DisplayValidationEvaluationValues, hv_DisplayTrainEvaluationValues;
    HTuple  hv_DisplayLossEpochs, hv_DisplayLoss, hv_DisplayLearningRates;
    HTuple  hv_TrainResultsRestored, hv_StartTime, hv_ThresholdInformation;
    HTuple  hv_FirstIteration, hv_Epoch, hv_Iteration, hv_NumIterationsPerEpoch;
    HTuple  hv_BatchSizeDevice, hv_BatchSizeMultiplier, hv_BatchSizeModel;
    HTuple  hv_NumIterations, hv_SampleIndicesTrain, hv_IterationEvaluateOnly;
    HTuple  hv_BatchStart, hv_BatchEnd, hv_BatchIndices, hv_DLSampleBatch;
    HTuple  hv_AugmentationParam, hv_TrainResult, hv_EvaluationIntervalEpochs;
    HTuple  hv_EvaluationInterval, hv_ValidationEvaluationResult;
    HTuple  hv_TrainEvaluationResult, hv_DisplayParam, hv_SelectPercentageTrainSamples;
    HTuple  hv_EvaluationParam, hv__, hv_TrainEvaluationRatio;
    HTuple  hv_NumTrainEvaluationSampleIndices, hv_TrainEvaluationSampleIndices;
    HTuple  hv_Exception, hv_EvaluationInfo, hv_Valuevalidation;
    HTuple  hv_ValueTrain, hv_TrainInfoUpdateIntervalSeconds;
    HTuple  hv_LastUpdate, hv_Seconds, hv_NumSamplesMeanLoss;
    HTuple  hv_TrainInfo, hv_UpdateTime, hv_EpochsStatus, hv_MeanLoss;
    HTuple  hv_DisplayLearningRate, hv_NumImages, hv_UpdateImagesIntervalEpochs;
    HTuple  hv_UpdateImagesInterval, hv_WindowImages, hv_FirstCall;
    HTuple  hv_GenParamTiled, hv_TrainParamAnomaly, hv_WindowHandleInfo;
    HTuple  hv___Tmp_Ctrl_Dict_Init_0, hv___Tmp_Ctrl_0;

    //
    //This procedure contains all steps for training a model given through DLModelHandle
    //on a dataset DLDataset.
    //The required training parameters are provided through the dictionary TrainParam,
    //which can be created by create_dl_train_param.
    //The training is started at StartEpoch, which allows resuming the training of a model.
    //In case of models of type 'anomaly_detection', training cannot be resumed and hence,
    //StartEpoch is always 0.
    //
    //The procedure returns three dictionaries:
    //- TrainResults: Collected results returned by train_dl_model_batch of every iteration.
    //                For models of type 'anomaly_detection': The final error and the final epoch.
    //- TrainInfo: Collected information of the training progress. This dictionary is empty
    //             for models of type 'anomaly_detection'.
    //- EvaluationInfos: Evaluation results collected during training. This dictionary is empty
    //                   for models of type 'anomaly_detection'.
    //
    //Get the model type.
    GetDlModelParam(hv_DLModelHandle, "type", &hv_ModelType);
    if (0 != (HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(HTuple(int(hv_ModelType!=HTuple("anomaly_detection"))).TupleAnd(int(hv_ModelType!=HTuple("classification")))).TupleAnd(int(hv_ModelType!=HTuple("detection")))).TupleAnd(int(hv_ModelType!=HTuple("gc_anomaly_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_detection")))).TupleAnd(int(hv_ModelType!=HTuple("ocr_recognition")))).TupleAnd(int(hv_ModelType!=HTuple("segmentation")))).TupleAnd(int(hv_ModelType!=HTuple("3d_gripping_point_detection")))))
    {
        throw HException(("Current model type is not supported: \""+hv_ModelType)+"\"");
    }
    //
    //Get the samples for training.
    GetDictTuple(hv_DLDataset, "samples", &hv_DLSamples);
    find_dl_samples(hv_DLSamples, "split", "train", "match", &hv_TrainSampleIndices);
    hv_NumTrainSamples = hv_TrainSampleIndices.TupleLength();
    //
    //Check inconsistent training parameters.
    check_train_dl_model_params(hv_DLDataset, hv_DLModelHandle, hv_NumTrainSamples,
                                hv_StartEpoch, hv_TrainParam);
    //
    //Determine evaluation optimization method.
    GetDictParam(hv_TrainParam, "key_exists", "evaluation_comparison_keys", &hv_EvaluationComparisonKeyExist);
    if (0 != hv_EvaluationComparisonKeyExist)
    {
        GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
        get_dl_evaluation_optimization_method(hv_EvaluationComparisonKeys, &hv_EvaluationOptimizationMethod);
    }
    //
    if (0 != (int(hv_ModelType!=HTuple("anomaly_detection"))))
    {
        //
        //Check if training is required.
        GetDictTuple(hv_TrainParam, "num_epochs", &hv_NumEpochs);
        if (0 != (hv_StartEpoch.TupleIsNumber()))
        {
            if (0 != (int(hv_StartEpoch>=hv_NumEpochs)))
            {
                //Nothing to do.
                return;
            }
        }
        //
        //Set random seed according to parameter value.
        GetDictTuple(hv_TrainParam, "seed_rand", &hv_SeedRand);
        if (0 != (int((hv_SeedRand.TupleLength())>0)))
        {
            //Note, that setting this random seed will not enforce every training to
            //result in the exact same model because the cuDNN library uses approximate
            //algorithms on some architectures.
            //If you want to enforce bit-wise reproducibility, you should also set:
            //   'set_system('cudnn_deterministic', 'true')'
            //However, this can slow down computations on some architectures.
            SetSystem("seed_rand", hv_SeedRand);
        }
        //
        //Generate a random sample index for the whole training independent of batch size.
        hv_SampleIndicesTrainRaw = HTuple();
        {
            HTuple end_val63 = (hv_NumEpochs.TupleCeil())-1;
            HTuple step_val63 = 1;
            for (hv_Index=0; hv_Index.Continue(end_val63, step_val63); hv_Index += step_val63)
            {
                tuple_shuffle(hv_TrainSampleIndices, &hv_Shuffled);
                hv_SampleIndicesTrainRaw = hv_SampleIndicesTrainRaw.TupleConcat(hv_Shuffled);
            }
        }
        //
        //Generate a random seed pool for the whole training independent of batch size.
        hv_SampleSeedsTrainRaw = HTuple(((HTuple(2).TuplePow(31))-1)*HTuple::TupleRand(hv_SampleIndicesTrainRaw.TupleLength())).TupleInt();
        //
        //Initialize the variables for the training.
        //
        //Initialize the batch size with an invalid value so that
        //the while loop will initialize all values directly.
        hv_BatchSize = -1;
        //Initialize iteration overhead parameter to 0 or 1.
        //0: if no evaluation before training is performed
        //1: if evaluation before training is performed
        CreateDict(&hv___Tmp_Ctrl_Dict_Init_0);
        SetDictTuple(hv___Tmp_Ctrl_Dict_Init_0, "comp", "true");
        hv_EvaluateBeforeTraining = (hv_TrainParam.TupleConcat(hv___Tmp_Ctrl_Dict_Init_0)).TupleTestEqualDictItem("evaluate_before_train","comp");
        hv___Tmp_Ctrl_Dict_Init_0 = HTuple::TupleConstant("HNULL");
        //
        //Initialize change strategies.
        init_train_dl_model_change_strategies(hv_TrainParam, &hv_ChangeStrategyData);
        //
        //Initialize serialization strategies.
        init_train_dl_model_serialization_strategies(hv_TrainParam, &hv_SerializationData);
        //
        //Initialize visualizations if enabled.
        dev_display_init_train_dl_model(hv_DLModelHandle, hv_TrainParam, &hv_DisplayData);
        GetDictTuple(hv_DisplayData, "enabled", &hv_DisplayEnabled);
        hv_DisplayPreviewInitialized = 0;
        //
        //Initialize parameters to start new or resume previous training.
        restore_dl_train_info_for_resuming(hv_StartEpoch, hv_SerializationData, hv_TrainParam,
                                           hv_DisplayData, &(*hv_EvaluationInfos), &(*hv_TrainInfos), &hv_DisplayEvaluationEpochs,
                                           &hv_DisplayValidationEvaluationValues, &hv_DisplayTrainEvaluationValues,
                                           &hv_DisplayLossEpochs, &hv_DisplayLoss, &hv_DisplayLearningRates, &hv_TrainResultsRestored,
                                           &hv_StartEpoch);
        //
        //Start time for measurement of elapsed training time.
        CountSeconds(&hv_StartTime);
        //
        //In case of a 'gc_anomaly_detection' model it is necessary to normalize
        //the model outputs before training.
        if (0 != (int(hv_ModelType==HTuple("gc_anomaly_detection"))))
        {
            if (0 != hv_DisplayEnabled)
            {
                hv_ThresholdInformation.Clear();
                hv_ThresholdInformation[0] = "Preparing the model for training";
                hv_ThresholdInformation[1] = "by analyzing image statistics...";
                if (HDevWindowStack::IsOpen())
                    ClearWindow(HDevWindowStack::GetActive());
                if (HDevWindowStack::IsOpen())
                    DispText(HDevWindowStack::GetActive(),hv_ThresholdInformation, "window",
                             "top", "left", "black", "box", "false");
                CountSeconds(&hv___Tmp_Ctrl_0);
                SetDictTuple(hv_DisplayData, "last_update", hv___Tmp_Ctrl_0);
            }
            normalize_dl_gc_anomaly_features(hv_DLDataset, hv_DLModelHandle, HTuple());
        }
        //
        //The while loop needs to know if it is the very first iteration.
        hv_FirstIteration = 1;
        while (true)
        {
            //Do some initializations only for the very first iteration.
            if (0 != hv_FirstIteration)
            {
                //Jump to StartEpoch (Default: 0 but it could be used to resume training at given StartIteration).
                hv_Epoch = hv_StartEpoch;
            }
            else
            {
                hv_Epoch = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
            }
            //
            //Update any parameters based on strategies.
            update_train_dl_model_change_strategies(hv_DLModelHandle, hv_ChangeStrategyData,
                                                    hv_Epoch);
            //
            //Check if the current batch size and total model batch size differ.
            GetDlModelParam(hv_DLModelHandle, "batch_size", &hv_BatchSizeDevice);
            GetDlModelParam(hv_DLModelHandle, "batch_size_multiplier", &hv_BatchSizeMultiplier);
            hv_BatchSizeModel = hv_BatchSizeDevice*hv_BatchSizeMultiplier;
            //
            if (0 != (HTuple(int(hv_BatchSize!=hv_BatchSizeModel)).TupleOr(hv_FirstIteration)))
            {
                //Set the current value.
                hv_BatchSize = hv_BatchSizeModel;
                //Now, we compute all values which are related to the batch size of the model.
                //That way, the batch_size can be changed during the training without issues.
                //All inputs/outputs/visualizations are based on epochs.
                //
                //Calculate total number of iterations.
                hv_NumIterationsPerEpoch = ((hv_NumTrainSamples/(hv_BatchSize.TupleReal())).TupleFloor()).TupleInt();
                hv_NumIterations = (hv_NumIterationsPerEpoch*hv_NumEpochs).TupleInt();
                //Select those indices that fit into the batch size.
                hv_SampleIndicesTrain = hv_SampleIndicesTrainRaw.TupleSelectRange(0,(hv_NumIterations*hv_BatchSize)-1);
                //The TrainResults tuple will be updated every iteration.
                //Hence, we initialize it as a constant tuple for speedup.
                //It is based on the iterations and hence cannot be reused if the batch size changes.
                TupleGenConst(hv_NumIterations, -1, &(*hv_TrainResults));
                if (0 != (hv_FirstIteration.TupleNot()))
                {
                    hv_Iteration = (((hv_Epoch.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
                    hv_Epoch = (hv_Iteration+1)/(hv_NumIterationsPerEpoch.TupleReal());
                }
            }
            //
            //In the first iteration do some initializations.
            if (0 != hv_FirstIteration)
            {
                //Jump to StartEpoch (Default: 0 but it could be used to resume training at given StartIteration).
                hv_Iteration = (((hv_StartEpoch.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
                hv_FirstIteration = 0;
                if (0 != (int(((hv_Iteration*hv_BatchSize)+hv_BatchSize)>(hv_SampleIndicesTrain.TupleLength()))))
                {
                    hv_Iteration = hv_NumIterations-1;
                    break;
                }
                if (0 != (HTuple(int(hv_StartEpoch>0.0)).TupleAnd(int((hv_TrainResultsRestored.TupleLength())>0))))
                {
                    //Overwrite the first train results.
                    if (0 != (int((hv_TrainResultsRestored.TupleLength())>hv_Iteration)))
                    {
                        hv_TrainResultsRestored = hv_TrainResultsRestored.TupleSelectRange((hv_TrainResultsRestored.TupleLength())-hv_Iteration,(hv_TrainResultsRestored.TupleLength())-1);
                    }
                    (*hv_TrainResults)[HTuple::TupleGenSequence(hv_Iteration-(hv_TrainResultsRestored.TupleLength()),hv_Iteration-1,1)] = hv_TrainResultsRestored;
                }
                //
                //Add an iteration before starting the training for the evaluation if specified.
                hv_IterationEvaluateOnly = hv_Iteration-1;
                hv_Iteration = hv_Iteration-hv_EvaluateBeforeTraining;
            }
            if (0 != (int(hv_Iteration>hv_IterationEvaluateOnly)))
            {
                //
                //Generate the sample batch indices.
                hv_BatchStart = hv_Iteration*hv_BatchSize;
                hv_BatchEnd = (hv_BatchStart+hv_BatchSize)-1;
                hv_BatchIndices = hv_SampleIndicesTrain.TupleSelectRange(hv_BatchStart,hv_BatchEnd);
                //
                //Set a random seed for the sample batch.
                SetSystem("seed_rand", HTuple(hv_SampleSeedsTrainRaw[hv_BatchEnd]));
                //
                //Read preprocessed samples.
                read_dl_samples(hv_DLDataset, hv_BatchIndices, &hv_DLSampleBatch);
                //
                //Augment samples based on train parameter.
                GetDictTuple(hv_TrainParam, "augmentation_param", &hv_AugmentationParam);
                augment_dl_samples(hv_DLSampleBatch, hv_AugmentationParam);
                //
                //Train the model on current batch.
                TrainDlModelBatch(hv_DLModelHandle, hv_DLSampleBatch, &hv_TrainResult);
                //
                //We store each train result.
                (*hv_TrainResults)[hv_Iteration] = hv_TrainResult;
            }
            //
            //Evaluation handling.
            GetDictTuple(hv_TrainParam, "evaluation_interval_epochs", &hv_EvaluationIntervalEpochs);
            hv_EvaluationInterval = ((hv_EvaluationIntervalEpochs*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
            hv_ValidationEvaluationResult = HTuple();
            hv_TrainEvaluationResult = HTuple();
            GetDictTuple(hv_DisplayData, "display_param", &hv_DisplayParam);
            //Get percentage of evaluated training samples from display parameters.
            GetDictTuple(hv_DisplayParam, "selected_percentage_train_samples", &hv_SelectPercentageTrainSamples);
            //
            //Evaluate the current model.
            if (0 != (int(hv_EvaluationInterval>0)))
            {
                //Evaluate the model at given intervals.
                if (0 != (HTuple(HTuple(HTuple(int(hv_EvaluationInterval==1)).TupleOr(HTuple(int((hv_Iteration%hv_EvaluationInterval)==0)).TupleAnd(int(hv_Iteration!=0)))).TupleOr(int(hv_Iteration==(hv_NumIterations-1)))).TupleOr(int(hv_Iteration==hv_IterationEvaluateOnly))))
                {
                    GetDictTuple(hv_TrainParam, "evaluation_param", &hv_EvaluationParam);
                    //Evaluate on validation split.
                    evaluate_dl_model(hv_DLDataset, hv_DLModelHandle, "split", "validation",
                                      hv_EvaluationParam, &hv_ValidationEvaluationResult, &hv__);
                    //Evaluate a subset of the train split.
                    hv_TrainEvaluationRatio = hv_SelectPercentageTrainSamples/100.0;
                    hv_NumTrainEvaluationSampleIndices = (hv_TrainEvaluationRatio*(hv_TrainSampleIndices.TupleLength())).TupleInt();
                    if (0 != (int(hv_NumTrainEvaluationSampleIndices>0)))
                    {
                        tuple_shuffle(hv_TrainSampleIndices, &hv_TrainEvaluationSampleIndices);
                        //It might happen that the subset is too small for evaluation.
                        try
                        {
                            evaluate_dl_model(hv_DLDataset, hv_DLModelHandle, "sample_indices",
                                              hv_TrainEvaluationSampleIndices.TupleSelectRange(0,hv_NumTrainEvaluationSampleIndices-1),
                                              hv_EvaluationParam, &hv_TrainEvaluationResult, &hv__);
                        }
                        // catch (Exception)
                        catch (HException &HDevExpDefaultException)
                        {
                            HDevExpDefaultException.ToHTuple(&hv_Exception);
                        }
                    }
                    CreateDict(&hv_EvaluationInfo);
                    SetDictTuple(hv_EvaluationInfo, "epoch", hv_Epoch);
                    SetDictTuple(hv_EvaluationInfo, "iteration", hv_Iteration+hv_EvaluateBeforeTraining);
                    SetDictTuple(hv_EvaluationInfo, "result", hv_ValidationEvaluationResult);
                    SetDictTuple(hv_EvaluationInfo, "result_train", hv_TrainEvaluationResult);
                    (*hv_EvaluationInfos) = (*hv_EvaluationInfos).TupleConcat(hv_EvaluationInfo);
                    if (0 != hv_DisplayEnabled)
                    {
                        GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
                        reduce_dl_evaluation_result(hv_ValidationEvaluationResult, hv_EvaluationComparisonKeys,
                                                    &hv_Valuevalidation, &hv__);
                        reduce_dl_evaluation_result(hv_TrainEvaluationResult, hv_EvaluationComparisonKeys,
                                                    &hv_ValueTrain, &hv__);
                        hv_DisplayValidationEvaluationValues = hv_DisplayValidationEvaluationValues.TupleConcat(hv_Valuevalidation);
                        hv_DisplayTrainEvaluationValues = hv_DisplayTrainEvaluationValues.TupleConcat(hv_ValueTrain);
                        hv_DisplayEvaluationEpochs = hv_DisplayEvaluationEpochs.TupleConcat(hv_Epoch);
                    }
                }
            }
            if (0 != (int(hv_Iteration>hv_IterationEvaluateOnly)))
            {
                //
                //Check if an update is needed.
                GetDictTuple(hv_TrainParam, "update_interval_seconds", &hv_TrainInfoUpdateIntervalSeconds);
                GetDictTuple(hv_DisplayData, "last_update", &hv_LastUpdate);
                CountSeconds(&hv_Seconds);
                //Check for next update (enough time has elapsed or last iteration).
                if (0 != (HTuple(HTuple(int(((hv_LastUpdate-hv_Seconds).TupleAbs())>hv_TrainInfoUpdateIntervalSeconds)).TupleOr(int(hv_Iteration==(hv_NumIterations-1)))).TupleOr(int((hv_ValidationEvaluationResult.TupleLength())>0))))
                {
                    SetDictTuple(hv_DisplayData, "last_update", hv_Seconds);
                    GetDictTuple(hv_TrainParam, "evaluation_comparison_keys", &hv_EvaluationComparisonKeys);
                    GetDictTuple(hv_TrainParam, "num_samples_mean_loss", &hv_NumSamplesMeanLoss);
                    collect_train_dl_model_info(hv_DLModelHandle, (*hv_TrainResults), (*hv_EvaluationInfos),
                                                hv_EvaluationComparisonKeys, hv_EvaluationOptimizationMethod, hv_Iteration,
                                                hv_NumIterations, hv_NumIterationsPerEpoch, hv_NumSamplesMeanLoss,
                                                &hv_TrainInfo);

                    SetDictTuple(hv_TrainInfo, "start_epoch", hv_StartEpoch);
                    SetDictTuple(hv_TrainInfo, "start_time", hv_StartTime);
                    CountSeconds(&hv_UpdateTime);
                    SetDictTuple(hv_TrainInfo, "time_elapsed", hv_UpdateTime-hv_StartTime);
                    (*hv_TrainInfos) = (*hv_TrainInfos).TupleConcat(hv_TrainInfo);
                    //
                    //Display handling.
                    if (0 != hv_DisplayEnabled)
                    {
                        GetDictTuple(hv_TrainInfo, "epoch", &hv_EpochsStatus);
                        hv_DisplayLossEpochs = hv_DisplayLossEpochs.TupleConcat(hv_EpochsStatus);
                        GetDictTuple(hv_TrainInfo, "mean_loss", &hv_MeanLoss);
                        hv_DisplayLoss = hv_DisplayLoss.TupleConcat(hv_MeanLoss);
                        GetDlModelParam(hv_DLModelHandle, "learning_rate", &hv_DisplayLearningRate);
                        hv_DisplayLearningRates = hv_DisplayLearningRates.TupleConcat(hv_DisplayLearningRate);
                        dev_display_update_train_dl_model(hv_TrainParam, hv_DisplayData, hv_TrainInfo,
                                                          hv_DisplayLossEpochs, hv_DisplayLoss, hv_DisplayLearningRates, hv_DisplayEvaluationEpochs,
                                                          hv_DisplayValidationEvaluationValues, hv_DisplayTrainEvaluationValues);
                    }
                }
                //
                //Image result preview handling.
                if (0 != hv_DisplayEnabled)
                {
                    //Show interim results for test images.
                    //For models of type 'gc_anomaly_detection' this is not possible.
                    GetDictTuple(hv_DisplayParam, "num_images", &hv_NumImages);
                    if (0 != (int(hv_NumImages>0)))
                    {
                        //Check if the image preview has to be updated.
                        GetDictTuple(hv_DisplayParam, "update_images_interval_epochs", &hv_UpdateImagesIntervalEpochs);
                        hv_UpdateImagesInterval = (((hv_UpdateImagesIntervalEpochs.TupleReal())*hv_NumIterationsPerEpoch).TupleFloor()).TupleInt();
                        if (0 != (int(hv_UpdateImagesInterval==0)))
                        {
                            hv_UpdateImagesInterval = 1;
                        }
                        if (0 != (HTuple(int((hv_Iteration%hv_UpdateImagesInterval)==0)).TupleOr(hv_DisplayPreviewInitialized.TupleNot())))
                        {
                            GetDictTuple(hv_DisplayData, "window_images", &hv_WindowImages);
                            hv_FirstCall = int((hv_WindowImages.TupleLength())==0);
                            GetDictTuple(hv_DisplayParam, "tiled_param", &hv_GenParamTiled);
                            //
                            dev_display_dl_data_tiled(hv_DLDataset, hv_DLModelHandle, hv_NumImages,
                                                      "validation", hv_GenParamTiled, hv_WindowImages, &hv_WindowImages);
                            //
                            if (0 != hv_FirstCall)
                            {
                                SetDictTuple(hv_DisplayData, "window_images", hv_WindowImages);
                                set_display_font(hv_WindowImages, 12, "mono", "true", "false");
                            }
                            dev_display_tiled_legend(hv_WindowImages, hv_GenParamTiled);
                            hv_DisplayPreviewInitialized = 1;
                        }
                    }
                }
                //
                //Serialization handling.
                update_train_dl_model_serialization(hv_TrainParam, hv_SerializationData,
                                                    hv_Iteration, hv_NumIterations, hv_Epoch, hv_ValidationEvaluationResult,
                                                    hv_EvaluationOptimizationMethod, hv_DLModelHandle, (*hv_TrainInfos),
                                                    (*hv_EvaluationInfos));
            }
            //
            //Check for end of training.
            if (0 != (int(hv_Iteration>=(hv_NumIterations-1))))
            {
                break;
            }
            if (0 != (int(hv_Iteration==hv_IterationEvaluateOnly)))
            {
                hv_EvaluateBeforeTraining = 0;
            }
            //
            //Continue with next iteration.
            hv_Iteration += 1;
        }
        //
    }
    else
    {
        //Case for models of type 'anomaly_detection'.
        //
        //Read the training samples.
        read_dl_samples(hv_DLDataset, hv_TrainSampleIndices, &hv_DLSamples);
        //
        //Get training parameters for anomaly detection.
        GetDictTuple(hv_TrainParam, "anomaly_param", &hv_TrainParamAnomaly);
        //
        //Display information about training.
        GetDictTuple(hv_TrainParam, "display_param", &hv_DisplayParam);
        GetDictTuple(hv_DisplayParam, "enabled", &hv_DisplayEnabled);
        if (0 != hv_DisplayEnabled)
        {
            dev_display_train_info_anomaly_detection(hv_TrainParam, &hv_WindowHandleInfo);
        }
        //
        //Train the model.
        TrainDlModelAnomalyDataset(hv_DLModelHandle, hv_DLSamples, hv_TrainParamAnomaly,
                                   &(*hv_TrainResults));
        //
        //Initialize TrainInfos and EvaluationInfos
        (*hv_TrainInfos) = HTuple();
        (*hv_EvaluationInfos) = HTuple();
        //
        //Close window with information about the training.
        if (0 != hv_DisplayEnabled)
        {
            HDevWindowStack::SetActive(hv_WindowHandleInfo);
        }
    }
    //
    return;
}

void parse_filename(HTuple hv_FileName, HTuple *hv_BaseName, HTuple *hv_Extension, HTuple *hv_Directory)
{

  // Local control variables
  HTuple  hv_DirectoryTmp, hv_Substring;

  //This procedure gets a filename (with full path) as input
  //and returns the directory path, the base filename and the extension
  //in three different strings.
  //
  //In the output path the path separators will be replaced
  //by '/' in all cases.
  //
  //The procedure shows the possibilities of regular expressions in HALCON.
  //
  //Input parameters:
  //FileName: The input filename
  //
  //Output parameters:
  //BaseName: The filename without directory description and file extension
  //Extension: The file extension
  //Directory: The directory path
  //
  //Example:
  //basename('C:/images/part_01.png',...) returns
  //BaseName = 'part_01'
  //Extension = 'png'
  //Directory = 'C:\\images\\' (on Windows systems)
  //
  //Explanation of the regular expressions:
  //
  //'([^\\\\/]*?)(?:\\.[^.]*)?$':
  //To start at the end, the '$' matches the end of the string,
  //so it is best to read the expression from right to left.
  //The part in brackets (?:\\.[^.}*) denotes a non-capturing group.
  //That means, that this part is matched, but not captured
  //in contrast to the first bracketed group ([^\\\\/], see below.)
  //\\.[^.]* matches a dot '.' followed by as many non-dots as possible.
  //So (?:\\.[^.]*)? matches the file extension, if any.
  //The '?' at the end assures, that even if no extension exists,
  //a correct match is returned.
  //The first part in brackets ([^\\\\/]*?) is a capture group,
  //which means, that if a match is found, only the part in
  //brackets is returned as a result.
  //Because both HDevelop strings and regular expressions need a '\\'
  //to describe a backslash, inside regular expressions within HDevelop
  //a backslash has to be written as '\\\\'.
  //[^\\\\/] matches any character but a slash or backslash ('\\' in HDevelop)
  //[^\\\\/]*? matches a string od 0..n characters (except '/' or '\\')
  //where the '?' after the '*' switches the greediness off,
  //that means, that the shortest possible match is returned.
  //This option is necessary to cut off the extension
  //but only if (?:\\.[^.]*)? is able to match one.
  //To summarize, the regular expression matches that part of
  //the input string, that follows after the last '/' or '\\' and
  //cuts off the extension (if any) after the last '.'.
  //
  //'\\.([^.]*)$':
  //This matches everything after the last '.' of the input string.
  //Because ([^.]) is a capturing group,
  //only the part after the dot is returned.
  //
  //'.*[\\\\/]':
  //This matches the longest substring with a '/' or a '\\' at the end.
  //
  TupleRegexpMatch(hv_FileName, ".*[\\\\/]", &hv_DirectoryTmp);
  TupleSubstr(hv_FileName, hv_DirectoryTmp.TupleStrlen(), (hv_FileName.TupleStrlen())-1,
      &hv_Substring);
  TupleRegexpMatch(hv_Substring, "([^\\\\/]*?)(?:\\.[^.]*)?$", &(*hv_BaseName));
  TupleRegexpMatch(hv_Substring, "\\.([^.]*)$", &(*hv_Extension));
  //
  //
  //Finally all found backslashes ('\\') are converted
  //to a slash to get consistent paths
  TupleRegexpReplace(hv_DirectoryTmp, (HTuple("\\\\").Append("replace_all")), "/",
      &(*hv_Directory));
  return;
}

// Chapter: OCR / Deep OCR
// Short Description: Parse generic visualization parameters.
void parse_generic_visualization_parameters (HTuple hv_GenParamName, HTuple hv_GenParamValue,
    HTuple *hv_BoxColor, HTuple *hv_LineWidth, HTuple *hv_FontSize, HTuple *hv_ShowWords,
    HTuple *hv_ShowOrientation)
{

  // Local iconic variables

  // Local control variables
  HTuple  hv_ShowScoreMaps, hv_ParamIdx, hv_AllowedGenParams;
  HTuple  hv_CaseIdx, hv_BoolShowWords, hv_BoolShowArrow;

  //Set default values.
  (*hv_BoxColor) = "green";
  (*hv_LineWidth) = 3;
  (*hv_FontSize) = 12;
  hv_ShowScoreMaps = 1;
  (*hv_ShowWords) = 1;
  (*hv_ShowOrientation) = 1;

  //Parse the generic parameters.
  {
  HTuple end_val9 = (hv_GenParamName.TupleLength())-1;
  HTuple step_val9 = 1;
  for (hv_ParamIdx=0; hv_ParamIdx.Continue(end_val9, step_val9); hv_ParamIdx += step_val9)
  {
    hv_AllowedGenParams.Clear();
    hv_AllowedGenParams[0] = "box_color";
    hv_AllowedGenParams[1] = "line_width";
    hv_AllowedGenParams[2] = "font_size";
    hv_AllowedGenParams[3] = "show_words";
    hv_AllowedGenParams[4] = "show_orientation";
    TupleFind(hv_AllowedGenParams, HTuple(hv_GenParamName[hv_ParamIdx]), &hv_CaseIdx);
    switch (hv_CaseIdx.I())
    {
    case 0:
      //Get color.
      (*hv_BoxColor) = HTuple(hv_GenParamValue[hv_ParamIdx]);
      break;
    case 1:
      //Get line width.
      (*hv_LineWidth) = HTuple(hv_GenParamValue[hv_ParamIdx]);
      break;
    case 2:
      //Get font size.
      (*hv_FontSize) = HTuple(hv_GenParamValue[hv_ParamIdx]);
      break;
    case 3:
      //Check whether words shall be displayed.
      hv_BoolShowWords = HTuple(hv_GenParamValue[hv_ParamIdx]);
      if (0 != (int(hv_BoolShowWords==HTuple("true"))))
      {
        (*hv_ShowWords) = 1;
      }
      else
      {
        (*hv_ShowWords) = 0;
      }
      break;
    case 4:
      //Check whether arrow of the word box should be displayed.
      hv_BoolShowArrow = HTuple(hv_GenParamValue[hv_ParamIdx]);
      if (0 != (int(hv_BoolShowArrow==HTuple("true"))))
      {
        (*hv_ShowOrientation) = 1;
      }
      else
      {
        (*hv_ShowOrientation) = 0;
      }
      break;
    case -1:
      //General parameter not valid.
      throw HException(("The general parameter \""+HTuple(hv_GenParamName[hv_ParamIdx]))+"\" is not valid.");
    }
  }
  }
  return;
}
